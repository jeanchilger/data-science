patent_abstract,patent_title
""" This invention is a novel high-speed neural network based processor for solving the """"traveling salesman"""" and other global optimization problems. It comprises a novel hybrid architecture employing a binary synaptic array whose embodiment incorporates the fixed rules of the problem, such as the number of cities to be visited. The array is prompted by analog voltages representing variables such as distances. The processor incorporates two interconnected feedback networks, each of which solves part of the problem independently and simultaneously, yet which exchange information dynamically. ""","""Electronic neural network for solving """"traveling salesman"""" and similar global optimization problems"""
"Systems and methods are disclosed to recognize human action from one or more video frames by performing 3D convolutions to capture motion information encoded in multiple adjacent frames and extracting features from spatial and temporal dimensions therefrom; generating multiple channels of information from the video frames, combining information from all channels to obtain a feature representation for a 3D CNN model; and applying the 3D CNN model to recognize human actions.",3D convolutional neural networks for automatic human action recognition
A supervised procedure for obtaining weight values for back-propagation neural networks is described. The method according to the invention performs a sequence of partial optimizations in order to determine values for the network connection weights. The partial optimization depends on a constrained representation of hidden weights derived from a singular value decomposition of the input space as well as an Iterative Least Squares optimization solution for the output weights.,Accelerated training apparatus for back propagation networks
"A method of accelerating the training of an artificial neural network uses a computer configured as an artificial neural network with a network input and a network output, and having a plurality of interconnected units arranged in layers including an input layer and an output layer. Each unit has a multiplicity of unit inputs and a set of variables for operating upon the unit inputs to provide a unit output. A plurality of examples are serially provided to the network input and the network output is observed. The computer is programmed with a back propagation algorithm for adjusting each set of variables in response to feedback representing differences between the network output for each example and the desired output. The examples are iterated while those values which change are identified. The examples are reiterated and the algorithm is applied to only those values which changed in a previous iteration.",Accelerating learning in neural networks
"A system for bit-serial computation in a neural network is described. The system may be embodied on an integrated circuit and include one or more bit-serial tiles for performing bit-serial computations in which each bit-serial tile receives input neurons and synapses, and communicates output neurons. Also included is an activation memory for storing the neurons and a dispatcher and a reducer. The dispatcher reads neurons and synapses from memory and communicates either the neurons or the synapses bit-serially to the one or more bit-serial tiles. The other of the neurons or the synapses are communicated bit-parallelly to the one or more bit-serial tiles, or according to a further embodiment, may also be communicated bit-serially to the one or more bit-serial tiles. The reducer receives the output neurons from the one or more tiles, and communicates the output neurons to the activation memory.",Accelerator for deep neural networks
"An apparatus is described herein. The apparatus comprises an accumulator, a controller, and a convolutional neural network. The accumulator is to accumulate a plurality of values within a predetermined bit width. The controller is to determine a parameter quantization and a data quantization. The convolutional neural network is adapted to the data quantization, wherein a quantization point is selected based on the parameter quantization, data quantization, and accumulator bit width.",Accumulator constrained quantization of convolutional neural networks
"Approaches for accurate neural network training for library-based critical dimension (CD) metrology are described. Approaches for fast neural network training for library-based CD metrology are also described. In an example, a method includes optimizing a threshold for a principal component analysis (PCA) of a spectrum data set to provide a principal component (PC) value, estimating a training target for one or more neural networks, training the one or more neural networks based both on the training target and on the PC value provided from optimizing the threshold for the PCA, and providing a spectral library based on the one or more trained neural networks.",Accurate and fast neural network training for library-based critical dimension (CD) metrology
"Embodiments are generally directed to neural network training for library-based critical dimension metrology. An embodiment of a method includes optimizing a threshold for a principal component analysis of a spectrum data set to provide a principal component value, estimating a training target for one or more neural networks, training the one or more neural networks based both on the training target and on the principal component value provided from optimizing the threshold for the principal component analysis, and providing a spectral library based on the one or more trained neural networks.",Accurate and fast neural network training for library-based critical dimension (CD) metrology
"A method and system are provided for speech recognition. The speech recognition method includes the steps of preparing training data representing acoustic parameters of each of phonemes at each time frame; receiving an input signal representing a sound to be recognized and converting the input signal to input data; comparing the input data at each frame with the training data of each of the phonemes to derive a similarity measure of the input data with respect to each of the phonemes; and processing the similarity measures obtained in the comparing step using a neural net model governing development of activities of plural cells to conduct speech recognition of the input signal. In the processing step, each cell is associated with one respective phoneme and one frame, a development of the activity of each cell at each frame in the neural net model is suppressed by the activities of other cells on the same frame corresponding to different phonemes, and the development of the activity of each cell at each frame being enhanced by the activities of other cells corresponding to the same phoneme at different frames. In the process, the phoneme of a cell that has developed the highest activity is determined as a winner at the corresponding frame to produce a list of winners at respective frames. A phoneme is outputted as a recognition result for the input signal in accordance with the list of the winners at the respective frames that have been determined in the step of processing.",Acoustic speech recognition method and system using stereo vision neural networks with competition and cooperation
"An action recognition system and method are provided. The action recognition system includes an image capture device configured to capture an actual image depicting an object. The action recognition system includes a processor configured to render, based on a set of 3D CAD models, synthetic images with corresponding intermediate shape concept labels. The processor is configured to form a multi-layer CNN which jointly models multiple intermediate shape concepts, based on the rendered synthetic images. The processor is configured to perform an intra-class appearance variation-aware and occlusion-aware 3D object parsing on the actual image by applying the CNN thereto to generate an image pair including a 2D and 3D geometric structure of the object. The processor is configured to control a device to perform a response action in response to an identification of an action performed by the object, wherein the identification of the action is based on the image pair.",Action recognition system with landmark localization on objects in images using convolutional neural networks
"Tasks such as object classification from image data can take advantage of a deep learning process using convolutional neural networks. These networks can include a convolutional layer followed by an activation layer, or activation unit, among other potential layers. Improved accuracy can be obtained by using a generalized linear unit (GLU) as an activation unit in such a network, where a GLU is linear for both positive and negative inputs, and is defined by a positive slope, a negative slope, and a bias. These parameters can be learned for each channel or a block of channels, and stacking those types of activation units can further improve accuracy.",Activation layers for deep learning networks
"Tasks such as object classification from image data can take advantage of a deep learning process using convolutional neural networks. These networks can include a convolutional layer followed by an activation layer, or activation unit, among other potential layers. Improved accuracy can be obtained by using a generalized linear unit (GLU) as an activation unit in such a network, where a GLU is linear for both positive and negative inputs, and is defined by a positive slope, a negative slope, and a bias. These parameters can be learned for each channel or a block of channels, and stacking those types of activation units can further improve accuracy.",Activation layers for deep learning networks
"A method and a system for reducing the acoustic levels of internal and external sound fields generated by gas turbine engines has several actuators to generate sound, several sensors to measure the acoustic levels, and one or more controllers, The controllers are adaptive self-learning neural networks that control the actuators to generate sound in order to effect the reduction of the internal and external sound field as measured by the Sensors.",Active gas turbine (jet) engine noise suppression
"The present invention is predicated upon the fact that an emission trace from a plasma glow used in fabricating integrated circuits contains information about phenoma which cause variations in the fabrication process such as age of the plasma reactor, densities of the wafers exposed to the plasma, chemistry of the plasma, and concentration of the remaining material. In accordance with the present invention, a method for using neural networks to determine plasma etch end-point times in an integrated circuit fabrication process is disclosed. The end-point time is based on in-situ monitoring of the optical emission trace. The back-propagation method is used to train the network. More generally, a neural network can be used to regulate control variables and materials in a manufacturing process to yield an output product with desired quality attributes. An identified process signature which reflects the relation between the quality attribute and the process may be used to train the neural network.",Active neural network control of wafer attributes in a plasma etch process
"The present invention is predicated upon the fact that an emission trace from a plasma glow used in fabricating integrated circuits contains information about phenoma which cause variations in the fabrication process such as age of the plasma reactor, densities of the wafers exposed to the plasma, chemistry of the plasma, and concentration of the remaining material. In accordance with the present invention, a method for using neural networks to determine plasma etch end-point times in an integrated circuit fabrication process is disclosed. The end-point time is based on in-situ monitoring of the optical emission trace. The back-propagation method is used to train the network. More generally, a neural network can be used to regulate control variables and materials in a manufacturing process to yield an output product with desired quality attributes. An identified process signature which reflects the relation between the quality attribute and the process may be used to train the neural network.",Active neural network control of wafer attributes in a plasma etch process
"The present invention is predicated upon the fact that a process signature from a plasma process used in fabricating integrated circuits contains information about phenomena which cause variations in the fabrication process such as age of the plasma reactor, densities of the wafers exposed to the plasma, chemistry of the plasma, and concentration of the remaining material. In accordance with the present invention, a method for using neural networks to determine plasma etch end-point times in an integrated circuit fabrication process is disclosed. The end-point time is based on in-situ monitoring of at least two parameters during the plasma etch process. After the neural network is trained to associate a certain condition or set of conditions with the endpoint of the process, the neural network is used to control the process.",Active neural network determination of endpoint in a plasma etch process
"Systems and methods are provided for facilitating automated video scripting, Video frames may be analyzed to determine scores indicative of the association between a characteristic of the video frame and an attribute of a theme associated with a particular person. Then, video frames with particular scores can be added together to automatically create a video script. Neural networks can be used to determine the scores. The neural network may also be trained using training data, and updated based on the interaction of a person to a video script.",Adaptive and automatic video scripting
"An improved motor vehicle automatic climate control methodology individually develops climate control commands in response to ambient environmental conditions and a transient state estimator, and individually and adaptively adjusts the commands to improve driver comfort in response to driver override of respective automatic control settings. The adaptive adjustment of the climate control commands is carried by CMAC neural networks that take into account the environmental conditions and the dynamic state of the system when the respective overrides occur so as to minimize or eliminate the environmental state ambiguity and steady-state/transient coupling that occur in currently known control methodologies.",Adaptive automatic climate control method for a motor vehicle
"An adaptive control system (ACS) uses direct output feedback to control a plant. The ACS uses direct adaptive output feedback control developed for highly uncertain nonlinear systems, that does not rely on state estimation. The approach is also applicable to systems of unknown, but bounded dimension, whose output has known, but otherwise arbitrary relative degree. This includes systems with both parameter uncertainty and unmodeled dynamics. The result is achieved by extending the universal function approximation property of linearly parameterized neural networks to model unknown system dynamics from input/output data. The network weight adaptation rule is derived from Lyapunov stability analysis, and guarantees that the adapted weight errors and the tracking error are bounded.",Adaptive control system having direct output feedback and related apparatuses and methods
"An adaptive control system (ACS) uses direct output feedback to control a plant. The ACS uses direct adaptive output feedback control developed for highly uncertain nonlinear systems, that does not rely on state estimation. The approach is also applicable to systems of unknown, but bounded dimension, whose output has known, but otherwise arbitrary relative degree. This includes systems with both parameter uncertainty and unmodeled dynamics. The result is achieved by extending the universal function approximation property of linearly parameterized neural networks to model unknown system dynamics from input/output data. The network weight adaptation rule is derived from Lyapunov stability analysis, and guarantees that the adapted weight errors and the tracking error are bounded.",Adaptive control system having direct output feedback and related apparatuses and methods
"A job scheduler makes decisions concerning the order and frequency of access to a resource according to a substantially optimum delay cost function. The delay cost function is a single value function of one or more inputs, where at least one of the inputs is a delay time which increases as a job waits for service. The job scheduler is preferably used by a multi-user computer operating system to schedule jobs of different classes. The delay cost functions are preferably implemented by neural networks. The user specifies desired performance objectives for each job class. The computer system runs for a specified period of time, collecting data on system performance. The differences between the actual and desired performance objectives are computed, and used to adaptively train the neural network. The process repeats until the delay cost functions stabilize near optimum value. However, if the system configuration, workload, or desired performance objectives change, the neural network will again start to adapt.",Adaptive job scheduling using neural network priority functions
"A control system for controlling the output of at least one plant process output parameter is implemented by adaptive model predictive control using a neural network. An improved method and apparatus provides for sampling plant output and control input at a first sampling rate to provide control inputs at the fast rate. The MPC system is, however, provided with a network state vector that is constructed at a second, slower rate so that the input control values used by the MPC system are averaged over a gapped time period. Another improvement is a provision for on-line training that may include difference training, curvature training, and basis center adjustment to maintain the weights and basis centers of the neural in an updated state that can follow changes in the plant operation apart from initial off-line training data.",Adaptive model predictive process control using neural networks
"Neural networks may be used in certain automatic speech recognition systems. To improve performance of these neural networks, they may be updated/retrained during run time by training the neural network based on the output of a speech recognition system or based on the output of the neural networks themselves. The outputs may include weighted outputs, lattices, weighted N-best lists, or the like. The neural networks may be acoustic model neural networks or language model neural networks. The neural networks may be retrained after each pass through the network, after each utterance, or in varying time scales.",Adaptive neural network speech recognition models
"An adaptive plasma characterization system and method characterize a semiconductor plasma process using fuzzy logic and neural networks. The method includes the step of collecting input and output training data, where the input training data is based on variables associated with electrical power used to control a plasma chamber and results from execution of the plasma process. The method further includes the step of generating fuzzy logic-based input and output membership functions based on the training data. The membership functions enable estimation of an output parameter value of the plasma process, such that the membership functions characterize the plasma process with regard to the output parameter. Modifying the membership functions based on a neural network learning algorithm and output data provides ability to learn. Thus, etching process parameters such as etch rate, end point detection, and chamber maintenance can all be characterized in a manner that allows the system to operate autonomously.",Adaptive plasma characterization system
"An adaptive probabilistic computer-controlled method and system determines computer-controlled actions that are expected to reduce uncertainties that are embodied as probabilities and then updates the probabilities in accordance with the results of the computer-controlled actions. The updated probabilities inform the determination of subsequent computer-controlled actions. Expected values of information may also be applied in determining the subsequent computer-controlled actions. The computer-controlled actions may comprise analysis of content and generating recommendations that are delivered to users, and inferences from the analysis of content and usage behaviors may inform the updating of the probabilities. Statistical learning functions and/or neural networks may be applied in determining the computer-controlled actions.",Adaptive probabilistic computer-controlled method and system
"In a system comprising a plurality of resources for performing useful work, a resource allocation controller function, which is customized to the particular system's available resources and configuration, dynamically allocates resources and/or alters configuration to accommodate a changing workload. Preferably, the resource allocation controller is part of the computer's operating system which allocates resources of the computer system. The resource allocation controller uses a controller neural network for control, and a separate system model neural network for modelling the system and training the controller neural network. Performance data is collected by the system and used to train the system model neural network. A system administrator specifies computer system performance targets which indicate the desired performance of the system. Deviations in actual performance from desired performance are propagated back through the system model and ultimately to the controller neural network to create a closed loop system for resource allocation.",Adaptive resource allocation using neural networks
"In a system comprising a plurality of resources for performing useful work, a resource allocation controller function, which is customized to the particular system's available resources and configuration, dynamically allocates resources and/or alters configuration to accommodate a changing workload. Preferably, the resource allocation controller is part of the computer's operating system which allocates resources of the computer system. The resource allocation controller uses a controller neural network for control, and a separate system model neural network for modelling the system and training the controller neural network. Performance data is collected by the system and used to train the system model neural network. A system administrator specifies computer system performance targets which indicate the desired performance of the system. Deviations in actual performance from desired performance are propagated back through the system model and ultimately to the controller neural network to create a closed loop system for resource allocation.",Adaptive resource allocation using neural networks
""" A data string is a sequence of atomic units of data that represent information. In the context of computer data, examples of data strings include executable programs, data files, and boot records consisting of sequences of bytes, or text files consisting of sequences of bytes or characters. The invention solves the problem of automatically constructing a classifier of data strings, i.e., constructing a classifier which, given a string, determines which of two or more class labels should be assigned to it. From a set of (string, class-label) pairs, this invention provides an automated technique for extracting features of data strings that are relevant to the classification decision, and an automated technique for developing a classifier which uses those features to classify correctly the data strings in the original examples and, with high accuracy, classify correctly novel data strings not contained in the example set. The classifier is developed using """"adaptive"""" or """"learning"""" techniques from the domain of statistical regression and classification, such as, e.g., multi-layer neural networks. As an example, the technique can be applied to the task of distinguishing files or boot records that are infected by computer viruses from files or boot records that are not infected. ""","Adaptive statistical regression and classification of data strings, with application to the generic detection of computer viruses"
"An adaptive vector quantization process and quantizer (VQ) using a clustering technique known as AFLC (adaptive fuzzy leader clustering) is disclosed. The quantizer, AFLC-VQ, has been designed to vector quantize wavelet decomposed sub images with optimal bit allocation. The high-resolution sub images at each level have been statistically analyzed to conform to generalized Gaussian probability distributions by selecting the optimal number of filter taps. The adaptive characteristics of AFLC-VQ stem from using self-organizing neural networks with fuzzy membership values of the input samples for upgrading the cluster centroids based on well known optimization criteria. The centroid of each pattern group can represent all the other patterns in that cluster. The entire data set can be indexed into look up tables sent to the user for decoding and viewing the image. By generating look up tables or codebooks and entropy coding of the quantizer output, AFLC-VQ can compress images at 100:1 or greater for transmitting while reconstructing the images with high fidelity.",Adaptive vector quantization/quantizer
"A method includes determining, by a processor of a computing device, an expected performance or reliability of a first neural network of a first plurality of neural networks. The expected performance or reliability is determined based on a vector representing at least a portion of the first neural network, where the first neural network is generated based on an automated generative technique (e.g., a genetic algorithm) and where the first plurality of neural networks corresponds to a first epoch of the automated generative technique. The method also includes responsive to the expected performance or reliability of the first neural network failing to satisfy a threshold, adjusting a parameter of the automated generative technique. The method further includes, during a second epoch of the automated generative technique, generating a second plurality of neural networks based at least in part on the adjusted parameter.",Adjusting automated neural network generation based on evaluation of candidate neural networks
"A method of accelerating the training of an artificial neural network uses a computer configured as an artificial neural network with a network input and a network output, and having a plurality of interconnected units arranged in layers including an input layer and an output layer. Each unit has a multiplicity of unit inputs and a set of variables for operating upon a unit inputs to provide a unit output. The computer is programmed with a back propagation algorithm. A plurality of examples are serially provided to the network input and the network output is observed. The examples are iterated and proposed changes to each set of variables are calculated in response to feedback representing differences betwen the network output for each example and the desired output. The proposed changes are accumulated for a predetermined number of iterations, whereupon the accumulated proposed changes are added to the set of variables.",Adjusting neural networks
"A system and method are provided for driving assistance. The system includes an image capture device configured to capture an actual image relative to an outward view from a motor vehicle and depicting an object. The system further includes a processor configured to render, based on a set of 3D CAD models, synthetic images with corresponding intermediate shape concept labels. The processor is further configured to form a multi-layer CNN which jointly models multiple intermediate shape concepts, based on the rendered synthetic images. The processor is also configured to perform an intra-class appearance variation-aware and occlusion-aware 3D object parsing on the actual image by applying the CNN to the actual image to output an image pair including a 2D and 3D geometric structure of the object. The processor is additionally configured to perform an action to mitigate a likelihood of harm involving the motor vehicle, based on the image pair.",Advanced driver-assistance system with landmark localization on objects in images using convolutional neural networks
"A Hybrid Optoelectronic Neural Object Recognition System (HONORS), is disclosed, comprising two major building blocks: (1) an advanced grayscale optical correlator (OC) and (2) a massively parallel three-dimensional neural-processor. The optical correlator, with its inherent advantages in parallel processing and shift invariance, is used for target of interest (TOI) detection and segmentation. The three-dimensional neural-processor, with its robust neural learning capability, is used for target classification and identification. The hybrid optoelectronic neural object recognition system, with its powerful combination of optical processing and neural networks, enables real-time, large frame, automatic target recognition (ATR).",Advanced miniature processing handware for ATR applications
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for adversarial training of a neural network. One of the methods includes obtaining a plurality of training inputs; and training the neural network on each of the training inputs, comprising, for each of the training inputs: processing the training input using the neural network to determine a neural network output for the training input; applying a perturbation to the training input to generate an adversarial perturbation of the training input; processing the adversarial perturbation of the training input using the neural network to determine a neural network output for the adversarial perturbation; and adjusting the current values of the parameters of the neural network by performing an iteration of a neural network training procedure to optimize an adversarial objective function.",Adversarial training of neural networks
"In certain aspects, the disclosure provides soluble heteromeric polypeptide complexes comprising an extracellular domain of an ALK4 receptor and an extracellular domain of ActRIIB. In certain aspects, such soluble ALK4:ActRIIB complexes may be used to regulate (promote or inhibit) growth of tissues or cells including, for example, muscle, bone, cartilage, fat, neural tissue, tumors, and/or cancerous cells. In certain aspects, such ALK4:ActRIIB complexes are can be used to improve muscle formation, bone formation, metabolic parameters, and disorders associated with these tissues, cellular networks, kidney, and endocrine systems.",ALK4:ActRIIB heteromultimers and uses thereof
"A neuron circuit and a neural network including a four quadrant analog multiplier/summer circuit constructed in field effect transistors. The neuron circuit includes the analog multiplier/summer formed of an operational amplifier, plural sets of four field effect transistors, an RC circuit and a double inverter. The multiplier/summer circuit includes a set of four identical field effect transistors for each product implemented. This produces a four quadrant multiplication if the four field effect transistors operate in the triode mode. The output of the multiplier/summer is the sum of these products. The neural network includes a plurality of these neuron circuits. Each neuron circuit receives an input and a set of synaptic weight inputs. The output of each neuron circuit is supplied to the corresponding feedback input of each neuron circuit. The multiplier/summer of each neuron circuit produces the sum of the product of each neuron circuit output and its corresponding synaptic weight. The individual neuron circuits and the neural network can be constructed in MOS VLSI.",Analog continuous-time MOS vector multiplier circuit and a programmable MOS realization for feedback neural networks
"This is a fully parallel analog backpropagation learning processor which comprises a plurality of programmable resistive memory elements serving as synapse connections whose values can be weighted during learning with buffer amplifiers, summing circuits, and sample-and-hold circuits arranged in a plurality of neuron layers in accordance with delta-backpropagation algorithms modified so as to control weight changes due to circuit drift.",Analog hardware for delta-backpropagation neural networks
"This is a recurrent or feedforward analog neural network processor having a multi-level neuron array and a synaptic matrix for storing weighted analog values of synaptic connection strengths which is characterized by temporarily changing one connection strength at a time to determine its effect on system output relative to the desired target. That connection strength is then adjusted based on the effect, whereby the processor is taught the correct response to training examples connection by connection.",Analog hardware for learning neural networks
"An analog neural computing medium, neuron and neural networks are disclosed. The neural computing medium includes a phase change material that has the ability to cumulatively respond to multiple input signals. Input signals induce transformations among a plurality of accumulation states of the disclosed neural computing medium. The accumulation states are characterized by a high electrical resistance. Upon cumulative receipt of energy from one or more input signals that equals or exceeds a threshold value, the neural computing medium fires by transforming to a low resistance state. The disclosed neural computing medium may also be configured to perform a weighting function whereby it weights incoming signals. The disclosed neurons may also include activation units for further transforming signals transmitted by the accumulation units according to a mathematical operation. The artificial neurons, weighting units, accumulation units and activation units may be connected to form artificial neural networks.",Analog neurons and neurosynaptic networks
A system for converting an analog signal into a digital data stream includes a recurrent network with a plurality of converter circuits that individually receive the same analog signal as input. The circuits then generate a plurality of spike outputs that exhibit characteristics of the analog signal. Interconnecting feedback loops from each circuit output to the input of neighboring circuits queues the plurality of spike outputs to thereby self-organize the network. A digital clock is then used to establish predetermined time intervals for counting the spike outputs to create the digital data stream.,Analog to digital conversion using recurrent neural networks
"A four quadrant, analog multiplier circuit useful for MOS implementation of feedback/feedforward neural networks. The multiplier circuit uses only one op-amp and one pair of input MOS FETs. It becomes a multiplier/summer by the addition of only one additional pair of input FETs for each additional product to be summed and achieves the vector scalar product of 2 n-tuple vector inputs using only 2(n+1) MOS transistors.","Analog, continuous time vector scalar multiplier circuits and programmable feedback neural network using them"
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using recurrent neural networks to analyze health events. One of the methods includes: processing each of a plurality of initial temporal sequences of health events to generate, for each of the initial temporal sequences, a respective network internal state of a recurrent neural network for each time step in the initial temporal sequence; storing, for each of the initial temporal sequences, one or more of the network internal states for the time steps in the temporal sequence in a repository; obtaining a first temporal sequence; processing the first temporal sequence using the recurrent neural network to generate a sequence internal state for the first temporal sequence; and selecting one or more initial temporal sequences that are likely to include health events that are predictive of future health events in the first temporal sequence.",Analyzing health events using recurrent neural networks
"An articulated and animated toy capable of recognizing human users and selected inanimate objects and interacting therewith which includes a computer-based device having stored thereon encoded first human or human-like facial images, a video camera and video digitizer for acquiring data representative of a second human or human-like facial image, and software resident within said computer-based device for facial recognition, which includes Principal Component Analysis, Neural Networks, or another equivalent algorithm for comparing said first human or human-like facial images with said second human or human-like facial image and producing an output signal therefrom for use in identifying said human users. The apparatus can further include software for recognizing speech, generating speech and controlling animation of the articulated toy. In addition, said computer-based device is capable of learning and storing information pertaining to each of said human users such as name, age, sex, favorite color, etc., and to interact with each of said human users on an individual basis, providing entertainment tailored specifically to each of said human users.",Animated toy utilizing artificial intelligence and facial image recognition
"An articulated and animated toy capable of recognizing human users and interacting therewith which includes a computer-based device having stored thereon encoded first human fingerprint data, a fingerprint sensor for acquiring data representative of a second human fingerprint, and software resident within said computer-based device for fingerprint verification, which includes minutiae analysis, neural networks, or another equivalent algorithm for comparing said first human fingerprint data with said second human fingerprint data and producing an output signal therefrom for use in identifying said human users. The apparatus can further include software for recognizing speech, generating speech and controlling animation of the articulated toy. In addition, said computer-based device is capable of learning and storing information pertaining to each of said human users such as name, age, sex, favorite color, etc., and to interact with each of said human users on an individual basis, providing entertainment tailored specifically to each of said human users. In addition, the apparatus can control access to the Internet via integrated web browser software and thus provide protection, especially for young children, from inappropriate web site content.",Animated toy utilizing artificial intelligence and fingerprint verification
"Systems and methods for training a neural network to optimize network performance, including sampling an applied dropout rate for one or more nodes of the network to evaluate a current generalization performance of one or more training models. An optimized annealing schedule may be generated based on the sampling, wherein the optimized annealing schedule includes an altered dropout rate configured to improve a generalization performance of the network. A number of nodes of the network may be adjusted in accordance with a dropout rate specified in the optimized annealing schedule. The steps may then be iterated until the generalization performance of the network is maximized.",Annealed dropout training of neural networks
"Systems and methods for training a neural network to optimize network performance, including sampling an applied dropout rate for one or more nodes of the network to evaluate a current generalization performance of one or more training models. An optimized annealing schedule may be generated based on the sampling, wherein the optimized annealing schedule includes an altered dropout rate configured to improve a generalization performance of the network. A number of nodes of the network may be adjusted in accordance with a dropout rate specified in the optimized annealing schedule. The steps may then be iterated until the generalization performance of the network is maximized.",Annealed dropout training of neural networks
A method for annotation of skin images includes receiving a plurality of dermatoscopic images. Each of the dermatoscopic includes a region of lesion skin and a region of normal skin. A first convolutional neural network is trained according to an interior of the region of lesion skin using each of the plurality of dermatoscopic images. A second convolutional neural network is trained according to a boundary between the region of lesion skin and the region of normal skin. An additional dermatoscopic image is acquired. The first and second convolutional neural networks are used to identify a region of lesion skin within the acquired additional dermatoscopic image.,Annotation of skin image using learned feature representation
"Computer-implemented methods and apparatuses for anomaly detection in volumetric images are provided. A two-dimensional convolutional neural network (CNN) is used to encode slices within a volumetric image, such as a CT scan. The CNN may be trained using an output layer that is subsequently omitted during use of the CNN as an encoder. The CNN encoder output is applied to a recurrent neural network (RNN), such as a long short-term memory network. The RNN may output various indications of the presence, probability and/or location of anomalies within the volumetric image.",Anomaly detection in volumetric images using sequential convolutional and recurrent neural networks
"Computer-implemented methods and apparatuses for anomaly detection in volumetric images are provided. A two-dimensional convolutional neural network (CNN) is used to encode slices within a volumetric image, such as a CT scan. The CNN may be trained using an output layer that is subsequently omitted during use of the CNN as an encoder. The CNN encoder output is applied to a recurrent neural network (RNN), such as a long short-term memory network. The RNN may output various indications of the presence, probability and/or location of anomalies within the volumetric image.",Anomaly detection in volumetric medical images using sequential convolutional and recurrent neural networks
"An anomaly monitoring device includes two neural networks which are switchable between a training mode by using training samples and a checking mode for classifying, based on a training result, whether an amount of characteristics obtained by an operation of an apparatus indicates that the operation of an apparatus is normal and a mode switching unit controlling one of the neural networks to operate in training mode and the other neural network to operate in the checking mode. Further, the anomaly monitoring device includes a switching determining unit computing a judgment evaluation value serving to evaluate reliability of a judgment result of the other neural network operating in the checking mode, and for instructing the mode switching unit to have the one of the neural networks operate in the checking mode and the other neural network operate in training mode when the judgment evaluation value does not meet evaluation criteria.",Anomaly monitoring device using two competitive neural networks
"The present invention provides an apparatus and a method for classifying and recognizing image patterns using a second-order neural network, thereby achieving high-rate parallel processing while lowering the complexity. The second-order neural network, which is made of adders and multipliers, corrects positional translations generated in a complex-log mapping unit to output the same result for the same object irrespective of the scale and/or rotation of the object. The present invention enables high-rate image pattern classification and recognition based on parallel processing, which is the advantage obtained in neural network models, because consistent neural networks and consistent network structure computation models are applied to all steps from the image input step to the pattern classifying and recognizing step.",Apparatus and method for classifying and recognizing image patterns using neural network
"An automated computer-aided diagnosis (CAD) method and system using artificial neural networks (ANNs) for the quantitative analysis of image data. Three separate ANNs were applied for detection of interstitial disease on digitized two-dimensional chest images. The first ANN was trained with horizontal profiles in regions of interest (ROIs) selected from normal and abnormal chest radiographs. The second ANN was trained using vertical output patterns obtained from the 1.sup.st ANN for each ROI. The output value of the 2.sup.nd ANN was used to distinguish between normal and abnormal ROIS with interstitial infiltrates. If the ratio of the number of abnormal ROIs to the total number of all ROIs in a chest image was greater than a certain threshold level, the chest image was considered abnormal. In addition, the third ANN was applied to distinguish between normal and abnormal chest images where the chest image was not clearly normal or abnormal. The ANN trained with image data learns some statistical properties associated with interstitial infiltrates in chest radiographs. In addition, the same technique can be applied to higher-dimensional data (e.g., three-dimensional data and four-dimensional data including time-varying three-dimensional data).",Apparatus and method for computerized analysis of interstitial infiltrates in chest images using artificial neural networks
"A delay-line time-domain reflectometer includes a return detector configured to process a discharge pulse produced by discharge of a line capacitor, formed by the physical relationship of a pair of conductive wires forming a telephone line, from a predetermined DC voltage. The return detector includes a number of neural networks configured to process the discharge pulse under the control of a controller. The neural networks enable the controller to characterize the loop configuration of the telephone line, where the loop configuration includes the length of the telephone line, the position of any bridged tap connected to the telephone line and/or the length of any bridged tap connected to the telephone line.",Apparatus and method for detecting a bridged tap and/or an end-of-line of a conventional telephone line using delay-line time-domain reflectometry
"A learning system is provided, which includes network storage means for storing a network including a plurality of nodes, each of which holds a dynamics; and learning means for self-organizationally updating the dynamics of the network on the basis of measured time-series data.",Apparatus and method for embedding recurrent neural networks into the nodes of a self-organizing map
"The present invention is an apparatus and method for object recognition from at least an image stream from at least an image frame utilizing at least an artificial neural network. The present invention further comprises means for generating multiple components of an image pyramid simultaneously from a single image stream, means for providing the active pixel and interlayer neuron data to at least a subwindow processor, means for multiplying and accumulating the product of a pixel data or interlayer data and a synapse weight, and means for performing the activation of an accumulation. The present invention allows the artificial neural networks to be reconfigurable, thus embracing a broad range of object recognition applications in a flexible way. The subwindow processor in the present invention also further comprises means for performing neuron computations for at least a neuron. An exemplary embodiment of the present invention is used for object recognition, including face detection and gender recognition, in hardware. The apparatus comprises a digital circuitry system or IC that embodies the components of the present invention.",Apparatus and method for hardware implementation of object recognition from an image stream using artificial neural network
"The neural computing paradigm is characterized as a dynamic and highly computationally intensive system typically consisting of input weight multiplications, product summation, neural state calculations, and complete connectivity among the neurons. Herein is described neural network architecture for a Scalable Neural Array Process (SNAP) which uses a unique interconnection and communication scheme within an array structure that provides high performance for completely connected network models such as the Hopfield model. SNAP's packaging and expansion capabilities are addressed, demonstrating SNAP's scalability to larger networks. The array processor is made up of multiple sets of orthogonal interconnections and activity generators. Each activity generator is responsive to an output signal in order to generate a neuron value. The interconnection structure also uses special adder trees which respond in a first state to generate an output signal and in a second state to communicate a neuron value back to the input of the array processor.",Apparatus and method for neural processing
"Apparatus and methods for partial evaluation of synaptic updates in neural networks. In one embodiment, a pre-synaptic unit is connected to a several post synaptic units via communication channels. Information related to a plurality of post-synaptic pulses generated by the post-synaptic units is stored by the network in response to a system event. Synaptic channel updates are performed by the network using the time intervals between a pre-synaptic pulse, which is being generated prior to the system event, and at least a portion of the plurality of the post synaptic pulses. The system event enables removal of the information related to the portion of the post-synaptic pulses from the storage device. A shared memory block within the storage device is used to store data related to post-synaptic pulses generated by different post-synaptic nodes. This configuration enables memory use optimization of post-synaptic units with different firing rates.",Apparatus and method for partial evaluation of synaptic updates based on system events
"Apparatus and methods for partial evaluation of synaptic updates in neural networks. In one embodiment, a pre-synaptic unit is connected to a several post synaptic units via communication channels. Information related to a plurality of post-synaptic pulses generated by the post-synaptic units is stored by the network in response to a system event. Synaptic channel updates are performed by the network using the time intervals between a pre-synaptic pulse, which is being generated prior to the system event, and at least a portion of the plurality of the post synaptic pulses. The system event enables removal of the information related to the portion of the post-synaptic pulses from the storage device. A shared memory block within the storage device is used to store data related to post-synaptic pulses generated by different post-synaptic nodes. This configuration enables memory use optimization of post-synaptic units with different firing rates.",Apparatus and method for partial evaluation of synaptic updates based on system events
"Aspects for executing forward propagation of artificial neural network are described here. As an example, the aspects may include a plurality of computation modules connected via an interconnection unit; and a controller unit configured to decode an instruction into one or more groups of micro-instructions, wherein the plurality of computation modules are configured to perform respective groups of the micro-instructions.",Apparatus and method for performing a forward operation of artificil neural networks
A method and apparatus for testing automotive electronic control units and batteries and other equipment for identification and performance purposes utilizes neural networks to effect waveform analysis on a digitized signal. Identification of electronic control units is by means of correlation of resultant waveform data with corresponding data on known units. Battery testing is by waveform analysis of the battery current during transient connection of a load by a transistorized switching circuit. In both cases the method of testing includes a network learning stage and an ensuing recognition test routine for characteristic waveforms.,Apparatus and method for testing automotive electronic control units and batteries and related equipment
"Apparatus and methods for universal node design implementing a universal learning rule in a mixed signal spiking neural network. In one implementation, at one instance, the node apparatus, operable according to the parameterized universal learning model, receives a mixture of analog and spiking inputs, and generates a spiking output based on the model parameter for that node that is selected by the parameterized model for that specific mix of inputs. At another instance, the same node receives a different mix of inputs, that also may comprise only analog or only spiking inputs and generates an analog output based on a different value of the node parameter that is selected by the model for the second mix of inputs. In another implementation, the node apparatus may change its output from analog to spiking responsive to a training input for the same inputs.",Apparatus and methods for gating analog and spiking signals in artificial neural networks
"Provided herein are apparatus and methods relating to the development of instrumentation for high throughput network electrophysiology and cellular analysis. More specifically, provided herein are multiwell microelectrode arrays (MEAs) and methods for the development of such an apparatus in an inexpensive fashion with a flexible, ANSI/SBS-compliant (American National Standards Institute/Society for Biomolecular Screening) format. Microelectrode arrays are a grid of tightly spaced microelectrodes useful for stimulating and sensing electrically active cells, networks and tissue. The techniques described herein relate to the use of microfabrication in combination with certain large-area processes that have been employed to achieve multiwell MEAs in ANSI/SBS-compliant culture well formats, which are also transparent for inverted/backside microscopy compatibility. These multiwell MEAs can be used to investigate two and three-dimensional networks of electrically active cells and tissue such as cardiac, neural, and muscular in a high throughput fashion. Also being ANSI/SBS-compliant, they are compatible with machinery and robotics developed for the pharmaceutical industry for drug screening applications.",Apparatus and methods for high throughput network electrophysiology and cellular analysis
"Neural network apparatus and methods for implementing reinforcement learning. In one implementation, the neural network is a spiking neural network, and the apparatus and methods may be used for example to enable an adaptive signal processing system to effect focused exploration by associative adaptation, including providing a negative reward signal to the network, which may increase excitability of the neurons in combination with decrease in excitability of active neurons. In certain implementations, the increase is gradual and of smaller magnitude, compared to the excitability decrease. In some implementations, the increase/decrease of the neuron excitability is effectuated by increasing/decreasing an efficacy of the respective synaptic connections delivering presynaptic inputs into the neuron. The focused exploration may be achieved for instance by non-associative potentiation configured based at least on the input spike rate. The non-associative potentiation may further comprise depression of connections that provide input in excess of a desired limit.",Apparatus and methods for reinforcement learning in artificial neural networks
"An artificial network for encoding the binary on-state of one-out-of-N inputs, say j, when only one state is on at a time wherein the jth on-state is represented by a suitable output level of an N-input MP type neuron operating in the non-saturated region of the neuron output nonlinearity. A single line transmits the encoded amplitude level signal to a decoder having N single input neural networks. The N outputs of the decoder are in the off-state except for the output corresponding to the active input node of the encoder",Apparatus for a neural network one-out-of-N encoder/decoder
"Apparatus is provided for the readout, and in certain applications the display, of information stored within incoherent/coherent double angularly multiplexed volume holographic optical elements. Such multiplexed volume holographic optical elements are based on parallel incoherent/coherent double angularly multiplexed volume holographic recording and readout principles, and are designed to exhibit maximum optical throughput efficiency and minimum crosstalk. Applications for this novel holographic readout apparatus, when used in conjunction with the aforementioned incoherent/coherent double angularly multiplexed volume holographic optical elements, include photonic interconnections for neural networks, telecommunications switching, and digital computing; optical information processors and optical memories; and optical display systems. The holographic readout apparatus is based primarily on the use of a spatially distributed source array, which contains a plurality of optical sources that are at once both individually coherent and mutually incoherent. The incorporation of the incoherent/coherent source array enables embodiments of the apparatus that in turn allow for incoherent superposition of reconstructed images and simplified parallel readout of the multiplexed volume holographic optical elements. The additional provision of spatial light modulation means allows for independent selection of the subset of stored holographically-encoded information patterns to be simultaneously read out or displayed. The holographic readout apparatus is capable of reading out and displaying information stored in several variants of incoherent/coherent double angularly multiplexed volume holographic optical elements, including those that are either optically recorded or computer generated, and that are based on either continuous-volume (bulk) or stratified-volume holographic media.",Apparatus for incoherent/coherent readout and display of information stored in double angularly multiplexed volume holographic optical elements
"Apparatus for recognition of handwritten Chinese characters contains a bus, an input means connecting to the bus for receiving input imagery data created from a handwritten Chinese character, a Cellular Neural Networks or Cellular Nonlinear Networks (CNN) based integrated circuit operatively connecting to the bus for extracting features out of the input imagery data using pre-trained filter coefficients of a plurality of order convolutional layers stored therein, a memory connecting the bus, the memory being configured for storing weight coefficients of fully-connected (FC) layers, a processing unit connecting to the bus for performing computations of FC layers to classify the extracted features from the CNN based integrated circuit to a particular Chinese character in a predefined Chinese character set, and a display unit connecting to the bus for displaying the particular Chinese character. Greater than 95% recognition accuracy is achieved using multiple bi-valued 33 filter kernels as pre-trained filter coefficients.",Apparatus for recognition of handwritten Chinese characters
"An apparatus for recognizing driving environments of a vehicle including a plurality of sensors for detecting various parameters relating to driving conditions of the vehicle such as throttle valve open angle, vehicle running speed, brake pedal depression amount and gear shift range of an automatic transmission, first and second neuron interfaces for converting parameter values detected by the sensors into a plurality of input patterns having predetermined configuration, first and second neural networks having input layers to which corresponding input patterns are applied, hidden layers and output layers for producing recognition results, and a multiplexer for selecting one of the recognition results produced on the output layers of the first and second neural networks. The first neural network has a superior separating or recognizing and learning faculty, while the second neural network has a superior associating faculty. A accelerating pedal depression amount is detected by a sensor and a variation of the thus detected amount is compared with a reference value. When the variation is larger than the reference value, the recognition result produced by the first neural network is selected and when the variation is smaller than the reference value, the recognition result from the second neural network is selected.",Apparatus for recognizing driving environment of vehicle
"In a reproduced color correction system, a photometer measures external illuminant light and sends a measured result to a workstation. The workstation determines the type of an illuminant on the basis of the measured result and sends a selection signal and corresponding colorimetric value data to a neural network management unit. The neural network management unit is provided with a plurality of neural networks associated with types of illuminants. The neural network selected according to the selection signal converts the colorimetric value to a color separation value according to a post-learning transformation function. A color printing device outputs a color image on the basis of the generated color separation value. Thus, the neural network associated with the illuminant used for observation reference is selected, and appropriate color transformation is performed. Accordingly, even if the viewing condition is changed, color matching can be performed so that observed reproduced colors are unchanged.",Apparatus for reproducing color images
"Novel apparatus for simultaneous spatial modulation of a set of angularly multiplexed individually coherent but mutually incoherent optical beams is disclosed, comprising means for generating a set of two or more individually coherent beams that have at least one optical wavelength in common, pairwise, and are assured to be mutually incoherent, and means for directing the set of individually coherent but mutually incoherent beams to a spatial modulation means, such that a spatially overlapping group of individually coherent but mutually incoherent beams overlap spatially in at least one region of the spatial modulation means and are angularly multiplexed within the region. Such simultaneous spatial modulation is a key feature, for example, in highly multiplexed photonic interconnection, memory, and display systems with maximum optical throughput efficiency and minimum crosstalk, based on parallel incoherent/coherent double angularly multiplexed holographic recording and readout principles. Simultaneous spatial modulation is also of importance for the provision for arbitrarily weighted and independent interconnections in the development of densely interconnected photonic implementations of neural networks, photonic interconnection networks for telecommunications switching and digital computing applications, optical information processors, optical memories, and optical displays. Variants of the apparatus are provided that allow for the incorporation of optically isolated semiconductor laser diode arrays, vertical cavity surface emitting laser arrays that are partially mutually incoherent and partially wavelength division multiplexed, the combination of laser diode and phase modulator arrays to provide for controllable mutual incoherence, both pixelated and non-pixelated spatial light modulators, and both planar and volume holographic or diffractive optical elements employed as spatial light modulation means.",Apparatus for simultaneous spatial modulation of incoherent/coherent angulary multiplexed optical beams
"Apparatus for the operation of a plant for producing deinked pulp with state analysers constructed in the form of neural networks for the waste paper suspension. At least one measuring device (ME) records spectral and/or physical characteristic values (IMf, Mp) of a waste paper suspension (PS). Furthermore, there are closed-loop or open-loop control devices (RS1 . . . RS8) for operating means of a waste paper preparation (AAA) in the plant. According to the invention, there is at least one state analyser (ZA), configured in the form of a neural network (NNg) or a plurality of parallel neural networks (NN1 . . . NN4), for the waste paper suspension (PS). This analyser forms from the characteristic values (IMf, Mp) controlled variables (ST: AB, AZ, FL, AA, AS, AT) for process control of the closed-loop or open-loop control devices (RS1 . . . RS8) of operating means at least of the waste paper preparation (AAA). As controlled variables, the ratio of white to coloured papers (AB), the ratio of illustrated-magazine paper to newsprint paper (AZ), the average fibre length (FL), the ash content (AA), the content of dirt (AS) and/or the content of adhesive contaminants (AT) in the waste paper suspension (PS) are suitable with preference.",Apparatus for the operation of a plant for producing deinked pulp with state analysers constructed in the form of neural networks for the waste paper suspension
"An apparatus (100) is described which comprises at least one measuring unit (31-34) for recording test signals from neurons, a generator unit (10) for generating electrical stimulation signals in accordance with the test signals, and a plurality of stimulation units (11-14) that are connected to the generator unit (10). The stimulation units (11-14) stimulate a plurality of neural networks in a deferred manner by means of the stimulation signals and thus induce a deferred activity in the stimulated neural networks.",Apparatus for the stimulation of neural networks
"An apparatus for transforming a voice signal of a talker into a voice signal having characteristics of a different person provides apparatus for separating the talker's voice signal into a plurality of voice parameters including frequency components, a neural network for transforming at least some of the separated frequency components into those characteristic of the different person, and apparatus for combining the voice parameters for reconstituting the talker's voice signal having characteristics of the different person.",Apparatus for transforming voice using neural networks
"There is provided a customized personal terminal device capable of operating in response to input data peculiar to the operator, comprising a speech recognition unit for recognizing inputted speech, an image recognition unit for recognizing inputted image, and an instruction recognition unit for recognizing an inputted instruction. Neural networks respectively provided in at least two of the speech, image and instruction recognition units, a bus operatively connected to the respective recognition units, a processor operatively connected to the bus to perform processing upon the speech, and image and instruction recognized by the recognition units. Also, memory is operatively connected to the bus, and a control unit exercises control over information exchange between respective recognition units and the memory under the control of the processor.",Apparatus including a pair of neural networks having disparate functions cooperating to perform instruction recognition
"Methods and systems are disclosed herein in which a physical neural network can be configured utilizing nanotechnology. Such a physical neural network can comprise a plurality of molecular conductors (e.g., nanoconductors) which form neural connections between pre-synaptic and post-synaptic components of the physical neural network. Additionally, a learning mechanism can be applied for implementing Hebbian learning via the physical neural network. Such a learning mechanism can utilize a voltage gradient or voltage gradient dependencies to implement Hebbian and/or anti-Hebbian plasticity within the physical neural network. The learning mechanism can also utilize pre-synaptic and post-synaptic frequencies to provide Hebbian and/or anti-Hebbian learning within the physical neural network.",Application of hebbian and anti-hebbian learning to nanotechnology-based physical neural networks
"A method for computer-aided detection of anomalies in an image comprise the steps of: (1) dividing the image into a plurality of m.times.n regions; (2) subtracting the background from each of the regions; (3) for each of the regions, selecting a smaller p.times.q subregion; (4) normalizing the p.times.q subregion; (5) feeding the p.times.q subregions into a neural network system, the neural network system having plural member neural networks, each trained to recognize a particular preselected anomaly type; (6) comparing each output value of the plurality of member neural networks to a first threshold; (7) selecting a maximum value from the output values which are greater than the first threshold; (8) comparing the maximum value to a second threshold above which the presence of an anomaly is indicated, and storing the result; (9) clustering a plurality of the stored results to form clusters; and (10) marking the location of the clusters.",Application of neural networks as an aid in medical diagnosis and general anomaly detection
"An information processing system having neuron-like signal processors that are interconnected by synapse-like processing junctions that simulates and extends capabilities of biological neural networks. The information processing systems uses integrate-and-fire neurons and Temporally Asymmetric Hebbian learning (spike timing-dependent learning) to adapt the synaptic strengths. The synaptic strengths of each neuron are guaranteed to become optimal during the course of learning either for estimating the parameters of a dynamic system (system identification) or for computing the first principal component. This neural network is well-suited for hardware implementations, since the learning rule for the synaptic strengths only requires computing either spike-time differences or correlations. Such hardware implementation may be used for predicting and recognizing audiovisual information or for improving cortical processing by a prosthetic device.",Applications of an algorithm that mimics cortical processing
"Software for controlling processes in a heterogeneous semiconductor manufacturing environment may include a wafer-centric database, a real-time scheduler using a neural network, and a graphical user interface displaying simulated operation of the system. These features may be employed alone or in combination to offer improved usability and computational efficiency for real time control and monitoring of a semiconductor manufacturing process. More generally, these techniques may be usefully employed in a variety of real time control systems, particularly systems requiring complex scheduling decisions or heterogeneous systems constructed of hardware from numerous independent vendors.",Applications of neural networks
"Techniques are provided for approximating image processing functions using convolutional neural networks (CNNs). A methodology implementing the techniques according to an embodiment includes performing, by a CNN, a sequence of non-linear operations on an input image to generate an output image. The generated output image approximates the application of a targeted image processing operator to the input image. The CNN is trained on pairs of training input and output images, wherein the training output images are generated by application of the targeted image processing operator to the training input images. The CNN training process generates bias parameters and convolutional kernel parameters to be employed by the CNN for processing of intermediate image layers associated with processing stages between the input image and the output image, each of the processing stages associated with one of the sequence of non-linear operations. The parameters are associated with the targeted image processing operator.",Approximating image processing functions using convolutional neural networks
"Disclosed is an improved approach to implement artificial neural networks. According to some approaches, an advanced neural network is implemented using an internet-of-things methodology, in which a large number of ordinary items having RFID technology are utilized as the vast infrastructure of a neural network.",Architecture for implementing an improved neural network
"A one-diode circuit for negated implication (.about..fwdarw.) is derived from a 12-transistor Lukasiewicz implication circuit (.fwdarw.). The derivation also yields an adjustable three-transistor implication circuit with maximum error less than 1% of full scale. Two Lukasiewicz logic arrays (.English Pound.LAs) are proposed that use area-efficient implementations of the one-diode and three-transistor implication circuits. The very dense diode-tower .English Pound.LA contains 36,000 implications in an area that previously held 92 implications; the three-transistor .English Pound.LA contains 1,990 implications. Both .English Pound.LAs double the number of inputs per pin on the IC package. Very dense .English Pound.LAs make .English Pound.LA-based fuzzy controllers and neural networks practical. As an example, an .English Pound.LA retina that detects edges in 15 nanoseconds is described.",Area-efficient implication circuits for very dense lukasiewicz logic arrays
"A one-diode circuit for negated implication (.about..fwdarw.) is derived from a 12-transistor Lukasiewicz implication circuit (.fwdarw.). The derivation also yields an adjustable three-transistor implication circuit with maximum error less than 1% of full scale. Two Lukasiewicz logic arrays (.English Pound.LAs) are proposed that use area-efficient implementations of the one-diode and three-transistor implication circuits. The very dense diode-tower .English Pound.LA contains 36,000 implications in an area that previously held 92 implications; the three-transistor .English Pound.LA contains 1,990 implications. Both .English Pound.LAs double the number of inputs per pin on the IC package. Very dense .English Pound.LAs make .English Pound.LA-based fuzzy controllers and neural networks practical. As an example, an .English Pound.LA retina that detects edges in 15 nanoseconds is described.",Area-efficient implication circuits for very dense Lukasiewicz logic arrays
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for correcting a corrupted data sample using a trained deep neural network, the method including obtaining a feature representation of a corrupted data sample; and modifying the feature representation of the corrupted data sample to generate a feature representation of a corrected data sample by iteratively processing a current version of the feature representation of the corrupted data sample using the trained deep neural network to generate a current corruption score for the current version of the feature representation of the corrupted data sample and generating a less-corrupted version of the feature representation by performing an iteration of gradient descent against the current version of the feature representation of the corrupted data sample to reduce the current corruption score.",Artifact correction using neural networks
"An artificial intelligence inference computing device contains a printed circuit board (PCB) and a number of electronic components mounted thereon. Electronic components include a wireless communication module, a controller module, a memory module, a storage module and at least one cellular neural networks (CNN) based integrated circuit (IC) configured for performing convolutional operations in a deep learning model for extracting features out of input data. Each CNN based IC includes a number of CNN processing engines operatively coupled to at least one input/output data bus. CNN processing engines are connected in a loop with a clock-skew circuit. Wireless communication module is configured for transmitting pre-trained filter coefficients of the deep learning model, input data and classification results.",Artificial intelligence inference computing device
"At an artificial intelligence system, a neural network model is trained iteratively to generate similarity scores for image pairs. The model includes a first subnetwork with a first number of convolution layers, and a second subnetwork with a different number of convolution layers. A given training iteration includes determining, using a version of the model generated in an earlier iteration, similarity scores for a set of image pairs, and then selecting a subset of the pairs based on the similarity scores. The selected subset is used to train a subsequent version of the model. After the model is trained, it may be used to generate similarity scores for other image pairs, and responsive operations may be initiated if the scores meet a criterion.",Artificial intelligence system for image similarity analysis using optimized image pair selection and multi-scale convolutional neural networks
"A cyber security system that uses artificial intelligence, such neural networks, to monitor the security of a computer network and take automated remedial action based on the monitoring. The security system autonomically learns behavior profiles, attack profiles and circumvention techniques used to target the network. The remedial action taken by the system includes isolating any misuse that has been identified, surveilling the misuse in the isolated environment, analyzing its behavior profile and reconfiguring the network to enhance security.",Artificial intelligence with cyber security
"A technique improves training and speech quality of a text-to-speech (TTS) system having an artificial intelligence, such as a neural network. The TTS system is organized as a front-end subsystem and a back-end subsystem. The front-end subsystem is configured to provide analysis and conversion of text into input vectors, each having at least a base frequency, f0, a phenome duration, and a phoneme sequence that is processed by a signal generation unit of the back-end subsystem. The signal generation unit includes the neural network interacting with a pre-existing knowledgebase of phenomes to generate audible speech from the input vectors. The technique applies an error signal from the neural network to correct imperfections of the pre-existing knowledgebase of phenomes to generate audible speech signals. Speech signal specific modelling techniques in combination with applied psychoacoustic principles drive training efficiency of neural networks with positive impact on quality of generated speech signals.",Artificial intelligence-based text-to-speech system and method
This invention relates to a means for compensating for a whole or partial loss of speech. The means has a sensor unit in the form of a Logometrix pseudo palate and a palatometer which sense the position of a user's tongue while endeavouring to articulate words or sounds. The sensor unit is connected to a comparator which makes use of suitable artificial intelligence algorithms (such as Multi-Layer Perceptron Neural Networks and Hidden Markov Models) together with a library of stored words and sounds as well as tongue positions and signals related to jaw and lip movement as well as inhalation and exhalation to match words or sounds and transmit the matched words or sounds to a loudspeaker. Preferably the output of the loudspeaker will simulate the natural voice of the user.,Artificial larynx
"Power industry boiler tube failures are a major cause of utility forced outages in the United States, with approximately 41,000 tube failures occurring every year at a cost of $5 billion a year. Accordingly, early tube leak detection and isolation is highly desirable. Early detection allows scheduling of a repair rather than suffering a forced outage, and significantly increases the chance of preventing damage to adjacent tubes. The instant detection scheme starts with identification of boiler tube leak process variables which are divided into universal sensitive variables, local leak sensitive variables, group leak sensitive variables, and subgroup leak sensitive variables, and which may be automatically be obtained using a data driven approach and a leak sensitivity function. One embodiment uses artificial neural networks (ANN) to learn the map between appropriate leak sensitive variables and the leak behavior. The second design philosophy integrates ANNs with approximate reasoning using fuzzy logic and fuzzy sets. In the second design, ANNs are used for learning, while approximate reasoning and inference engines are used for decision making. Advantages include use of already monitored process variables, no additional hardware and/or maintenance requirements, systematic processing does not require an expert system and/or a skilled operator, and the systems are portable and can be easily tailored for use on a variety of different boilers.",Artificial neural network and fuzzy logic based boiler tube leak detection systems
"Power industry boiler tube failures are a major cause of utility forced outages in the United States, with approximately 41,000 tube failures occurring every year at a cost of $5 billion a year. Accordingly, early tube leak detection and isolation is highly desirable. Early detection allows scheduling of a repair rather than suffering a forced outage, and significantly increases the chance of preventing damage to adjacent tubes. The instant detection scheme starts with identification of boiler tube leak process variables which are divided into universal sensitive variables, local leak sensitive variables, group leak sensitive variables, and subgroup leak sensitive variables, and which may be automatically be obtained using a data driven approach and a leak sensitivity function. One embodiment uses artificial neural networks (ANN) to learn the map between appropriate leak sensitive variables and the leak behavior. The second design philosophy integrates ANNs with approximate reasoning using fuzzy logic and fuzzy sets. In the second design, ANNs are used for learning, while approximate reasoning and inference engines are used for decision making. Advantages include use of already monitored process variables, no additional hardware and/or maintenance requirements, systematic processing does not require an expert system and/or a skilled operator, and the systems are portable and can be easily tailored for use on a variety of different boilers.",Artificial neural network and fuzzy logic based boiler tube leak detection systems
"A method for predicting and optimizing magnetic core width of a write head using neural networks to analyze manufacturing parameters, and determining new manufacturing parameters that will provide more optimal magnetic core width results. The manufacturing parameters can include: write pole flare point; wrap around shield dimension; and side gap dimension.",Artificial neural network application for magnetic core width prediction and modeling for magnetic disk drive manufacture
"A neural network circuit is provided having a plurality of circuits capable of charge storage. Also provided is a plurality of circuits each coupled to at least one of the plurality of charge storage circuits and constructed to generate an output in accordance with a neuron transfer function. Each of a plurality of circuits is coupled to one of the plurality of neuron transfer function circuits and constructed to generate a derivative of the output. A weight update circuit updates the charge storage circuits based upon output from the plurality of transfer function circuits and output from the plurality of derivative circuits. In preferred embodiments, separate training and validation networks share the same set of charge storage circuits and may operate concurrently. The validation network has a separate transfer function circuits each being coupled to the charge storage circuits so as to replicate the training network's coupling of the plurality of charge storage to the plurality of transfer function circuits. The plurality of transfer function circuits may be constructed each having a transconductance amplifier providing differential currents combined to provide an output in accordance with a transfer function. The derivative circuits may have a circuit constructed to generate a biased differential currents combined so as to provide the derivative of the transfer function.",Artificial neural network with hardware training and hardware refresh
"A low-order model (LOM) of biological neural networks and its mathematical equivalents including the clusterer interpreter probabilistic associative memory (CIPAM) are disclosed. They are artificial neural networks (ANNs) organized as networks of processing units (PUs), Each PU comprising artificial neuronal encoders, synapses, spiking/nonspiking neurons, and a scheme for maximal generalization. If the weights in the artificial synapses in a PU have been learned (and then fixed) or can be adjusted by the unsupervised accumulation rule and the unsupervised covariance rule (or supervised covariance rule), the PU is called unsupervised (or supervised) PU. The disclosed ANNs, with these Hebbian-type learning rules, can learn large numbers of large input vectors with temporally/spatially hierarchical causes with ease and recognize such causes with maximal generalization despite corruption, distortion and occlusion. An ANN with a network of unsupervised PUs (called clusterer) and offshoot supervised PUs (called interpreter) is an architecture for many applications.",Artificial neural networks based on a low-order model of biological neural networks
"Artificial neural networks include a plurality of artificial neurons and a plurality of Boolean-complete compartments, a respective one of which couples a respective pair of artificial neurons. By providing Boolean-complete compartments, spurious complement memories can be avoided. A Boolean-complete compartment includes a collection of at least four Boolean functions that represent input vectors to the respective pair of artificial neurons. The collection of at least four Boolean functions are selected from sixteen possible Boolean functions that can represent input vectors to the respective pair of artificial neurons. A count for each of the at least four Boolean functions is also provided. The count represents a number of occurrences of each of the at least four Boolean functions in input vectors to the respective pair of artificial neurons. In order to read the artificial neural network, the network also includes a collection of transfer functions, a respective one of which is associated with a respective one the sixteen possible Boolean functions.",Artificial neural networks including Boolean-complete compartments
"A neuron element with electrically programmable synaptic weight for an artificial neural network features an excitatory-connection floating-gate transistor and an inhibitory-connection floating-gate transistor. The control gate electrodes of the two transistors are connected together, and the drain electrode of the inhibitory-connection transistor is connected to the source electrode of the excitatory-connection transistor. Both of the excitatory-connection and inhibitory-connection transistors have programming electrodes. The control gate electrodes and the programming electrodes can be utilized to program the threshold voltages of the transistors and thus the synaptic weight of the neuron element.",Artificial neuron element with electrically programmable synaptic weight for neural networks
"A pseudo-analog electronic or optoelectronic neuron stores synaptic weights as analog quantities, preferably as charges upon capacitors or upon the gates of floating gate transistors. Multiplication of a stored synaptic weight times a binary pulse-width-modulated synapse input signal periodically produces electrical charge of a first polarity on a first synapse capacitor. Meanwhile a fixed charge of opposite polarity is periodically produced at the same frequency upon another, second, synapse capacitor. The charges on both synapse capacitors at many synapses are periodically accumulated, and integrated, at a single neuron soma in the form of pulse-amplitude-modulated charge-encoded signals. This accumulation, and integration, transpires continuously progressively by a switched-capacitor technique, and during the entire duration of the input signal to each synapse. The net final result, expressed in signed electrical charge, is converted back to a PWM binary signal for transmission to further neurons. A fully capacitive synapse typically occupies a compact area of 45.lambda..times.42.lambda., consumes less than 2 .mu.W dynamic power (at 1 MHz) and offers more than 90% of the full voltage scale for linear weight adaptation. It is therefore well suited to large scale parallel implementations of adaptive neural networks.",Artificial neuron with switched-capacitor synapses using analog storage of synaptic weights
"The artificial olfactory system is an ultra-sensitive and selective odor sensing system for the detection of odorant molecules down to the part per trillion level. The system includes multiple ultra sensitive frequency sensors, such as sensors based on piezoelectric substrates or micro-machined resonators, capable of detecting frequency changes resulting from the interaction of odorant molecules with the sensor. A coating applied to the sensor greatly increases the surface of interaction between the odorant molecules or biological agents and the sensor. An array of these sensors, each responding to the interaction of an odorant molecule species but in a different manner, results in different frequency shifts. An ultra sensitive frequency measurement device measures as small as part per billion shift in frequency. An intelligent processor based on artificial neural networks and other intelligent signal processing system detects, recognizes, and generalizes the signature resulting from the collective response of all the sensors.",Artificial olfactory system
"Neuron component and method for use in artificial neural networks (ANNs) with input synapses (204, 204b . . . 204n), each synapse includes multiple weights called synapse weights (206-1, 206-2, 206-3). Each synapse further includes a facility to modulate, or gate, an input signal connected to the synapses, by each of the respective synapse weights within the synapse, supplying the result of each modulating operation. The neuron also sums the results of all modulating operations, and subjects the results to a transfer function. Each of the multiple weights associated with a given synapse, may be specified to have its own weight-adjustment facility (214, 214b, 214c), with its own error-values (216, 216b, 216c), and its own specified learning and aspect (1000) includes a separate sum (1018, 1018b) and transfer function (1020, 1020b) for each synapse weight.",Artificial synapse component using multiple distinct learning means with distinct predetermined learning acquisition times
"A system for allocating hall calls in a group of elevators includes a plurality of neural network modules to model, learn and predict passenger arrival rates and passenger destination probabilities. The models learn the traffic occurring in a building by inputting to the neural networks traffic data previously stored. The neural networks then adjust their internal structure to make historic predictions based on data of the previous day and real time predictions based on data of the last ten minutes. The predictions of arrival rates are combined to provide optimum predictions. From every set of historic car calls and the optimum arrival rates, a matrix is constructed which stores entries representing the number of passengers with the same intended destination for each hall call. The traffic predictions are used separately or in combination by a group control to improve operating cost computations and car allocation, thereby reducing the travelling and waiting times of current and future passengers.",Artificially intelligent traffic modeling and prediction system
Transponders capable of providing identification information and possibly additional information are detected from wireless access points of a computer network as a substitute for closed radio frequency identification (RFID) systems while providing numerous additional functionalities and applications. Total asset visibility or responses to more limited queries are provided by inclusion of a geographic information system software application. Location reporting of proximity of devices/transponders to access points can be enhanced to a fine-grained level by triangulation or other algorithms including neural networks.,Asset tracking using wireless LAN infrastructure
The assignment of phonemes to graphemes producing them in a lexicon having words (grapheme sequences) and their associated phonetic transcription (phoneme sequences) for the preparation of patterns for training neural networks for the purpose of grapheme-phoneme conversion is carried out with the aid of a variant of dynamic programming which is known as dynamic time warping (DTW).,Assignment of phonemes to the graphemes producing them
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for obtaining, by a first sequence-training speech model, a first batch of training frames that represent speech features of first training utterances; obtaining, by the first sequence-training speech model, one or more first neural network parameters; determining, by the first sequence-training speech model, one or more optimized first neural network parameters based on (i) the first batch of training frames and (ii) the one or more first neural network parameters; obtaining, by a second sequence-training speech model, a second batch of training frames that represent speech features of second training utterances; obtaining one or more second neural network parameters; and determining, by the second sequence-training speech model, one or more optimized second neural network parameters based on (i) the second batch of training frames and (ii) the one or more second neural network parameters.",Asynchronous optimization for sequence training of neural networks
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for obtaining, by a first sequence-training speech model, a first batch of training frames that represent speech features of first training utterances; obtaining, by the first sequence-training speech model, one or more first neural network parameters; determining, by the first sequence-training speech model, one or more optimized first neural network parameters based on (i) the first batch of training frames and (ii) the one or more first neural network parameters; obtaining, by a second sequence-training speech model, a second batch of training frames that represent speech features of second training utterances; obtaining one or more second neural network parameters; and determining, by the second sequence-training speech model, one or more optimized second neural network parameters based on (i) the second batch of training frames and (ii) the one or more second neural network parameters.",Asynchronous optimization for sequence training of neural networks
"An ATM traffic control apparatus and method for adaptively controlling ATM traffics. The ATM traffic control apparatus includes an output buffer for storing traffics generated by a plurality of traffic sources; traffic predictors of neural networks for generating predicted traffic values designating the number of cells which is expected to arrive during a future time slot, by adaptively learning the number of cells received during a setting time slot; a decision gate for deciding whether call congestion will happen by using predicted traffic values, an available buffer size of the output buffer and the number of cells to be transmitted during a setting time slot, and for generating the number of cells which can not be processed during a future time slot when it is decided that the congestion will happen; and a traffic controller of an expert system for calculating an optimal flow rate of each traffic source to control the congestion of the output buffer, by using service rates of the traffic sources, traffic types, peak bit rates, predicted traffic values, and the number of cells which can not be processed in the output buffer.",Asynchronous transfer mode (ATM) traffic control apparatus and control method for handling a wide variety of ATM services
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating an output sequence from an input sequence. In one aspect, one of the systems includes an encoder neural network configured to receive the input sequence and generate encoded representations of the network inputs, the encoder neural network comprising a sequence of one or more encoder subnetworks, each encoder subnetwork configured to receive a respective encoder subnetwork input for each of the input positions and to generate a respective subnetwork output for each of the input positions, and each encoder subnetwork comprising: an encoder self-attention sub-layer that is configured to receive the subnetwork input for each of the input positions and, for each particular input position in the input order: apply an attention mechanism over the encoder subnetwork inputs using one or more queries derived from the encoder subnetwork input at the particular input position.",Attention-based sequence transduction neural networks
An audio event detection system that subsamples input audio data using a series of recurrent neural networks to create data of a coarser time scale than the audio data. Data frames corresponding to the coarser time scale may then be upsampled to data frames that match the finer time scale of the original audio data frames. The resulting data frames are then scored with a classifier to determine a likelihood that the individual frames correspond to an audio event. Each frame is then weighted by its score and a composite weighted frame is created by summing the weighted frames and dividing by the cumulative score. The composite weighted frame is then scored by the classifier. The resulting score is taken as an overall score indicating a likelihood that the input audio data includes an audio event.,Audio event detection
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for augmenting neural networks with an external memory. One of the methods includes providing an output derived from the neural network output for the time step as a system output for the time step; maintaining a current state of the external memory; determining, from the neural network output for the time step, memory state parameters for the time step; updating the current state of the external memory using the memory state parameters for the time step; reading data from the external memory in accordance with the updated state of the external memory; and combining the data read from the external memory with a system input for the next time step to generate the neural network input for the next time step.",Augmented recurrent neural network with external memory
"By way of example, the technology disclosed by this document receives image data; extracts a depth image and a color image from the image data; creates a mask image by segmenting the depth image; determines a first likelihood score from the depth image and the mask image using a layered classifier; determines a second likelihood score from the color image and the mask image using a deep convolutional neural network; and determines a class of at least a portion of the image data based on the first likelihood score and the second likelihood score. Further, the technology can pre-filter the mask image using the layered classifier and then use the pre-filtered mask image and the color image to calculate a second likelihood score using the deep convolutional neural network to speed up processing.",Augmenting layer-based object detection with deep convolutional neural networks
"A system for obtaining optimum performance and optimum graceful degradation from Lie algebra descriptions of a spectrum of reconfigurable network architectures, including, neural nets and cellular automata comprised of interconnected nodes. The dynamic performance of the computational process is monitored by continued extraction of Liapounov exponent indicators, reconfiguring said reconfigurable network architecture when said indicators predict non-optimum performance. The reconfigurable networks are reconfigured and compensatory adjustments are made of signal sampling performance and operating system performance of said reconfigurable network architecture, and the operating system architecture is optimized to the computational task by reconfiguration of nodal capabilities and degree of interconnectedness between nodes to obtain any Lie algebra description architectural form between ideal neural net with maximum interconnectedness and ideal cellular automata with maximum nodal capability.",Automata networks and methods for obtaining optimized dynamically reconfigurable computational architectures and controls
"A system and method are described for automating the analysis of cephalometric x-rays. Included in the analysis is a method for automatic anatomical landmark localization based on convolutional neural networks. In an aspect, the system and method employ a deep database of images and/or prior image analysis results so as to improve the outcome from the present automated landmark detection scheme.",Automated cephalometric analysis using machine learning
"Embodiments of the present invention provide digital watermarking methods that embed a digital watermark in both the low and high frequencies of an image or other production, providing a digital watermark that is resistant to a variety of attacks. The digital watermarking methods of the present invention optimize the strength of the embedded digital watermark such that it is as powerful as possible without being perceptible to the human eye. The digital watermarking methods of the present invention do this relatively quickly, in real-time, and in an automated fashion using an intelligent system, such as a neural network. The digital watermarking methods of the present invention may also be used in a variety of new applications, such as the digital watermarking of sensitive aircraft parts and military equipment.",Automated digital watermarking methods using neural networks
"A computer system includes a memory storing a data structure representing a neural network. The data structure includes a plurality of fields including values representing topology of the neural network. The computer system also includes one or more processors configured to perform neural network classification by operations including generating a vector representing at least a portion of the neural network based on the data structure. The operations also include providing the vector as input to a trained classifier to generate a classification result associated with at least the portion of the neural network, where the classification result is indicative of expected performance or reliability of the neural network. The operations also include generating an output indicative of the classification result.",Automated evaluation of neural networks using trained classifier
"Disclosed are methods, apparatus and systems for gesture recognition based on neural network processing. One exemplary method for identifying a gesture communicated by a subject includes receiving a plurality of images associated with the gesture, providing the plurality of images to a first 3-dimensional convolutional neural network (3D CNN) and a second 3D CNN, where the first 3D CNN is operable to produce motion information, where the second 3D CNN is operable to produce pose and color information, and where the first 3D CNN is operable to implement an optical flow algorithm to detect the gesture, fusing the motion information and the pose and color information to produce an identification of the gesture, and determining whether the identification corresponds to a singular gesture across the plurality of images using a recurrent neural network that comprises one or more long short-term memory units.",Automated gesture identification using neural networks
"An automated method and system for digital imaging processing of radiologic images, wherein digital image data is acquired and subjected to multiple phases of digital imaging processing. During the Pre-Processing stage, simultaneous box-rim filtering and k-nearest neighbor processing and subsequent global thresholding are performed on the image data to enhance object-to-background contrast, merge subclusters and determine gray scale thresholds for further processing. Next, during the Preliminary Selection phase, body part segmentation, morphological erosion processing, connected component analysis and image block segmentation occurs to subtract unwanted image data preliminarily identify potentials areas including abnormalities. During the Pattern Classification phase, feature patterns are developed for each area of interest, a supervised, back propagation neural network is trained, a feed forward neural network is developed and employed to detect true and several false positive categories, and two types of pruned neural networks are utilized in connection with a heuristic decision tree to finally determine whether the regions of interest are abnormalities or false positives.",Automated method and system for digital image processing of radiologic images utilizing artificial neural networks
"Methods and apparatus for monitoring an arc welding process are disclosed. In a preferred embodiment, the present invention creates a digital representation of the arc created during welding and, using a neural network computer, determines if the arc is representative of normal or abnormal welding conditions. The neural network disclosed is trained to identify abnormal conditions and normal conditions and may be adaptively retrained to classify images that are not in the initial set of normal and abnormal images. In certain embodiments, other data, such as current, weld wire emission spectra, or shielding gas flow rate are also collected and the neural network is trained to monitor these data. Also, in certain embodiments, an audio signal is collected from the vicinity of the welding process and is used by the neural network computer to further classify the arc as normal or abnormal. The present invention is most preferably implemented in repetitive and continuous welding operations, such as those encountered in the manufacture and rebuilding of steam turbines.",Automated rotor welding processes using neural networks
An incident avoidance system includes a plurality of imaging sensors and a neural computing system. The neural network computing system is configured to receive an image feed from at least one of the plurality of imaging sensors and analyze the image feed to identify a pattern of behavior exhibited by subjects within the image feed. The neural computing system is further configured to determine whether the identified pattern of behavior matches a known type of behavior and send a command to one or more remote devices. One or both of a type of the command or the one or more remove devices are selected based on a result of the determination whether the identified pattern of behavior matches a known type of behavior.,Automated scenario recognition and reporting using neural networks
"Method for the automated, microscope-aided examination of tissue samples or samples of body fluids with the aid of neural networks. In a first method of examination the sample is firstly classified according to its type and subsequently a digitalized image is divided into connected segments which are examined by one or several neural networks. The sample is classified as pathological if cell types are present which do not belong to the type of sample or if structural cell or tissue changes are present. In a second method of examination the digitalized image is again segmented and the segments are examined for the presence of a cell object. This is followed by an examination whether the cell object is an individual cell or a cell complex. In a third step of the analysis it is determined whether the found cell object is located on one of the image borders. If this is the case then a further image is recorded in which the found cell objects are completely included. Finally the segments in which cell objects have been detected are analysed at a higher magnification.","Automated, microscope-assisted examination process of tissue or bodily fluid samples"
Design of a neural network for automatic detection of incidents on a freeway is described. A neural network is trained using a combination of both back-propagation and genetic algorithm-based methods for optimizing the design of the neural network. The back-propagation and genetic algorithm work together in a collaborative manner in the neural network design. The training starts with incremental learning based on the instantaneous error and the global total error is accumulated for batch updating at the end of the training data being presented to the neural network. The genetic algorithm directly evaluates the performance of multiple sets of neural networks in parallel and then use the analyzed results to breed new neural networks that tend to be better suited to the problems at hand.,Automatic freeway incident detection system and method using artificial neural network and genetic algorithms
"An automated sales promotion selection system uses neural networks to identify promising sales promotions based on recent customer purchases. The system includes a customer information device that receives customer data relating to customer purchases of items from an inventory of items, a central processing unit having a sales promotion neural network and a storage unit containing a plurality of item identifiers comprising potential customer purchases of additional items from the inventory, wherein the sales opportunity neural network responds to customer data received from the customer information device by determining if one or more of the item identifiers in the storage unit corresponds to an item likely to be purchased by one of the customers, and an output device that receives the item identifiers of the likely purchases determined by the sales promotion neural network and produces a sales promotion relating to at least one of the item identifiers.",Automatic sales promotion selection system and method
"An automated sales promotion selection system uses neural networks to identify promising sales promotions based on recent customer purchases. The system includes a customer information device that receives customer data relating to customer purchases of items from an inventory of items, a central processing unit having a sales promotion neural network and a storage unit containing a plurality of item identifiers comprising potential customer purchases of additional items from the inventory, wherein the sales opportunity neural network responds to customer data received from the customer information device by determining if one or more of the item identifiers in the storage unit corresponds to an item likely to be purchased by one of the customers, and an output device that receives the item identifiers of the likely purchases determined by the sales promotion neural network and produces a sales promotion relating to at least one of the item identifiers.",Automatic sales promotion selection system and method
"An automated sales promotion selection system uses neural networks to identify promising sales promotions based on recent customer purchases. The system includes a customer information device that receives customer data relating to customer purchases of items from an inventory of items, a central processing unit having a sales promotion neural network and a storage unit containing a plurality of item identifiers comprising potential customer purchases of additional items from the inventory, wherein the sales opportunity neural network responds to customer data received from the customer information device by determining if one or more of the item identifiers in the storage unit corresponds to an item likely to be purchased by one of the customers, and an output device that receives the item identifiers of the likely purchases determined by the sales promotion neural network and produces a sales promotion relating to at least one of the item identifiers.",Automatic sales promotion selection system and method
"Systems and methods are disclosed that optimize the combustion process in various reactors, furnaces, and internal combustion engines. Video cameras are used to evaluate the combustion flame grade. Depending on the desired form, standard or special video devices, or beam scanning devices, are used to image the combustion flame and by-products. The video device generates and outputs image signals during various phases of, and at various locations in, the combustion process. Other forms of sensors monitor and generate data signals defining selected parameters of the combustion process, such as air flow, fuel flow, turbulence, exhaust and inlet valve openings, etc. In a preferred form, a neural networks initially processes the image data and characterizes the combustion flame. A fuzzy logic controller and associated fuzzy logic rule base analyzes the image data from the neural network, along with other sensor information. The fuzzy logic controller determines and generates control signals defining adjustments necessary to optimize the combustion process.",Automatically optimized combustion control
"Systems and methods are disclosed that optimize the combustion process in various reactors, furnaces, and internal combustion engines. Video cameras are used to evaluate the combustion flame grade. Depending on the desired form, standard or special video devices, or beam scanning devices, are used to image the combustion flame and by-products. The video device generates and outputs image signals during various phases of, and at various locations in, the combustion process. Other forms of sensors monitor and generate data signals defining selected parameters of the combustion process, such as air flow, fuel flow, turbulence, exhaust and inlet valve openings, etc. In a preferred form, a neural networks initially processes the image data and characterizes the combustion flame. A fuzzy logic controller and associated fuzzy logic rule base analyzes the image data from the neural network, along with other sensor information. The fuzzy logic controller determines and generates control signals defining adjustments necessary to optimize the combustion process.",Automatically optimized combustion control
"Systems and methods are disclosed that optimize the combustion process in various reactors, furnaces, and internal combustion engines. Video cameras are used to evaluate the combustion flame grade. Depending on the desired form, standard or special video devices, or beam scanning devices, are used to image the combustion flame and by-products. The video device generates and outputs image signals during various phases of, and at various locations in, the combustion process. Other forms of sensors monitor and generate data signals defining selected parameters of the combustion process, such as air flow, fuel flow, turbulence, exhaust and inlet valve openings, etc. In a preferred form, a neural networks initially processes the image data and characterizes the combustion flame. A fuzzy logic controller and associated fuzzy logic rule base analyzes the image data from the neural network, along with other sensor information. The fuzzy logic controller determines and generates control signals defining adjustments necessary to optimize the combustion process.",Automatically optimized combustion control
"Systems and methods are disclosed that optimize the combustion process in various reactors, furnaces, and internal combustion engines. Video cameras are used to evaluate the combustion flame grade. Depending on the desired form, standard or special video devices, or beam scanning devices, are used to image the combustion flame and by-products. The video device generates and outputs image signals during various phases of, and at various locations in, the combustion process. Other forms of sensors monitor and generate data signals defining selected parameters of the combustion process, such as air flow, fuel flow, turbulence, exhaust and inlet valve openings, etc. In a preferred form, a neural networks initially processes the image data and characterizes the combustion flame. A fuzzy logic controller and associated fuzzy logic rule base analyzes the image data from the neural network, along with other sensor information. The fuzzy logic controller determines and generates control signals defining adjustments necessary to optimize the combustion process.",Automatically optimized combustion control
"In one aspect, the present disclosure relates to a method for automatically scaling a neural network including: receiving a neural network model; allocating a plurality of processing nodes for the neural network model, the number of allocated processing nodes determined based on an analysis of the neural network model; distributing training of the neural network model across the allocated processing nodes; receiving load information from the allocated processing nodes, the load information associated with the training of the neural network model; and adjusting the number of allocated processing nodes based on the load information.",Automatically scaling neural networks based on load
"The present disclosure is directed toward systems, methods, and non-transitory computer readable media that automatically select an image from a plurality of images based on the multi-context aware rating of the image. In particular, systems described herein can generate a plurality of probability context scores for an image. Moreover, the disclosed systems can generate a plurality of context-specific scores for an image. Utilizing each of the probability context scores and each of the corresponding context-specific scores for an image, the disclosed systems can generate a multi-context aware rating for the image. Thereafter, the disclosed systems can select an image from the plurality of images with the highest multi-context aware rating for delivery to the user. The disclosed system can utilize one or more neural networks to both generate the probability context scores for an image and to generate the context-specific scores for an image.",Automatically selecting images using multicontext aware ratings
"Petroleum oil is catalytically cracked by contacting oil with catalyst mixture consisting of a base cracking catalyst containing an stable Y-type zeolite and small amounts of rare-earth metal oxide, and an additive containing a shape-selective zeolite, in an FCC apparatus having a regeneration zone, a separation zone, and a stripping zone. Production of light-fraction olefins is maximized by applying appropriate process control, monitoring, and optimizing systems. Mathematical process models, including neural networks, statistical models and finite impulse models are used in conjunction with advanced controllers and optimizing routines to calculate optimal settings for various parameters. Process model and historical data to test a predictive system can provide early warning of potential performance degradation and equipment failure in the FCC unit, decreasing overall operating costs and increasing plant safety.",Automation and control of energy efficient fluid catalytic cracking processes for maximizing value added products
"An autonomous navigation system for a mobile vehicle arranged to move within an environment includes a plurality of sensors arranged on the vehicle and at least one neural network including an input layer coupled to the sensors, a hidden layer coupled to the input layer, and an output layer coupled to the hidden layer. The neural network produces output signals representing respective positions of the vehicle, such as the X coordinate, the Y coordinate, and the angular orientation of the vehicle. A plurality of patch locations within the environment are used to train the neural networks to produce the correct outputs in response to the distances sensed.",Autonomous navigation apparatus with neural network for a mobile vehicle
"Technical solutions are described for implementing a neural network. An example system includes a crosspoint array including a plurality of nodes, each node representing a weight assigned to a neuron of the neural network. The system also includes a capacitor associated with a set of nodes from the plurality of nodes, where the capacitor is configured to store a current value corresponding to a sum of outputs from each respective node from the set of nodes. The system also includes a clocking circuit that initiates a forward pass to propagate the current value stored in the capacitor to a subsequent layer of the neural network. The clocking circuit further initiates a backward pass to propagate the current value stored in the capacitor to a preceding layer of the neural network. The clocking circuit further initiates a weight-update pass to update the weights in the neural network.",Back propagation gates and storage capacitor for neural networks
"Methods and apparatuses for backlash compensation. A dynamics inversion compensation scheme is designed for control of nonlinear discrete-time systems with input backlash. The techniques of this disclosure extend the dynamic inversion technique to discrete-time systems by using a filtered prediction, and shows how to use a neural network (NN) for inverting the backlash nonlinearity in the feedforward path. The techniques provide a general procedure for using NN to determine the dynamics preinverse of an invertible discrete time dynamical system. A discrete-time tuning algorithm is given for the NN weights so that the backlash compensation scheme guarantees bounded tracking and backlash errors, and also bounded parameter estimates. A rigorous proof of stability and performance is given and a simulation example verifies performance. Unlike standard discrete-time adaptive control techniques, no certainty equivalence (CE) or linear-in-the-parameters (LIP) assumptions are needed.",Backlash compensation with filtered prediction in discrete time nonlinear systems by dynamic inversion using neural networks
A bandwidth compression and expansion system is provided in which analog data is processed in real time using a sub-sampling technique in which pixels or other data values within a sub-sampling region determine the value of a corresponding signal which also denotes trends or patterns in accordance with the other pixels or signal values within a sampling region encompassing the sub-sampling region. Neural networks are used to implement the sub-sampling process both during bandwidth compression and during bandwidth expansion in which interpolation and extrapolation are employed to reverse the sub-sampling process used during compression. The neural network forms part of an arrangement in which analog input signals are converted to digital signals that are then stored in a random access memory which operates in conjunction with an address generator for identifying a succession of sampling and sub-sampling regions within the memory. The output of the memory is converted to an analog signal before being held in a sample and hold memory for use in the neural network.,Bandwidth compression and expansion system
An optimization system is provided utilizing a Bayesian neural network calculation of a derivative wherein an output is optimized with respect to an input utilizing a stochastical method that averages over many regression models. This is done such that constraints from first principal models are incorporated in terms of prior art distributions.,Bayesian neural networks for optimization and control
"Example implementations include a system and method of recognizing behavior of a user. In example implementations, a first post and at least one subsequent post indicative of a product and associated with a first social media account is obtained. A relevance probability is calculated for each of the obtained first post and the at least one subsequent post. The obtained first post and the at least one subsequent post are sequentially analyzed by a second neural network to determine output values relevant to probability of purchasing the product. A probability of purchasing the product is calculated based on the determined output values associated with each post and the calculated relevance probabilities. Product-related information is transmitted to the user associated with the obtained first post based on the determined probability of purchasing the product.",Behavior prediction on social media using neural networks
"Described herein are techniques for operating a security server to determine behavioral profiles for entities in a network and to detect attacks or unauthorized traffic in a network based on those behavioral profiles. In one technique, a behavioral profile may be generated based on requests for security operations to be performed that are received at a security server from an entity in a network. The behavioral profile may be generated using learning techniques, including artificial intelligence techniques such as neural networks. When the security server receives from an entity one or more requests for security operations to be performed, the security server may compare properties of the requests to the behavioral profile for the entity and properties of requests commonly sent by the entity. The security server may determine a similarity score indicating how similar the request are to the behavioral profile and to requests commonly received from the entity.",Behavior-based security system
"Methods and apparatus are provided for implementing behavioral homeostasis in artificial neurons that use a dynamical spiking neuron model. The homeostatic mechanism may be driven by neuron state, rather than by neuron spiking rate, and this mechanism may drive changes to the neuron temporal dynamics, rather than to contributions of input or weights. As a result, certain aspects of the present disclosure are a more natural fit with spiking neural networks and have many functional and computational advantages. One example method for implementing homeostasis of an artificial nervous system generally includes determining one or more state variables of a neuron model used by an artificial neuron, based at least in part on dynamics of the neuron model; determining one or more conditions based at least in part on the state variables; and adjusting the dynamics based at least in part on the conditions.",Behavioral homeostasis in artificial nervous systems using dynamical spiking neuron models
"In an example, a circuit of a neural network implemented in an integrated circuit (IC) includes a layer of hardware neurons, the layer including a plurality of inputs, a plurality of outputs, a plurality of weights, and a plurality of threshold values, each of the hardware neurons including: a logic circuit having inputs that receive first logic signals from at least a portion of the plurality of inputs and outputs that supply second logic signals corresponding to an exclusive NOR (XNOR) of the first logic signals and at least a portion of the plurality of weights; a counter circuit having inputs that receive the second logic signals and an output that supplies a count signal indicative of the number of the second logic signals having a predefined logic state; and a compare circuit having an input that receives the count signal and an output that supplies a logic signal having a logic state indicative of a comparison between the count signal and a threshold value of the plurality of threshold values; wherein the logic signal output by the compare circuit of each of the hardware neurons is provided as a respective one of the plurality of outputs.",Binary neural networks on progammable integrated circuits
Methods and apparatuses for providing biometric authentication of a test user using a registration process where a reference data sample representative of one or more biometric attributes of a reference user is used to train a plurality of neural networks to achieve a target output. The weights that achieve this in the plurality of neural networks may be stored on a user device as a first data set. A second data set representative of one or more biometric attributes may be obtained from the test user using the authentication device or received from the user device. The first data set may be received by the authentication device and used as weights in an artificial neural network and the second data set may be used as inputs. The output of the neural network may determine a degree of correlation between the reference user and the test user to be authenticated.,Biometric identity verification
"A method for selecting bit widths for a fixed point machine learning model includes evaluating a sensitivity of model accuracy to bit widths at each computational stage of the model. The method also includes selecting a bit width for parameters, and/or intermediate calculations in the computational stages of the mode. The bit width for the parameters and the bit width for the intermediate calculations may be different. The selected bit width may be determined based on the sensitivity evaluation.",Bit width selection for fixed point neural networks
"Briefly, embodiments of methods and/or systems of training multiclass convolutional neural networks (CNNs) are disclosed. For one embodiment, as an example, an auxiliary CNN may be utilized to form an ensemble with the collection as a linear combination. The linear combination may be based, at least in part, on boost prediction error encountered during the training process.",Boosted deep convolutional neural networks (CNNs)
"A brain condition can be tracked based on identification of co-activation of two antagonistic networks of a patient's brain. Various embodiments concerns methods and devices for sensing one or more signals indicative of brain activity, detecting one or more episodes of default mode network activation based on the one or more signals, detecting one or more episodes of salience network activation based on the one or more signals, and identifying one or more episodes of temporal co-activation of the default mode network and the salience network based on the detected one or more episodes of default mode network activation and the one or more episodes of salience network activation. The brain condition can be tracked and treated based on the identification of the one or more episodes of co-activation.",Brain condition monitoring based on co-activation of neural networks
A suite of predictions is defined to model the financial data commonly used to calculate technical indicators one or more periods in the future. Neural networks are trained to make these predictions. The predictions are then integrated with the standard technical indicator calculations to produce predictive technical indicators which are superior because they lead more and lag less.,Calculating predictive technical indicators
"Systems and methods are disclosed for routing callers to agents in a contact center, along with an intelligent routing system. An exemplary method includes combining multiple output variables of a pattern matching algorithm (for matching callers and agents) into a single metric for use in the routing system. The pattern matching algorithm may include a neural network architecture, where the exemplary method combines output variables from multiple neural networks. The method may include determining a Z-score of the variable outputs and determining a linear combination of the determined Z-scores for a desired output. Callers may be routed to agents via the pattern matching algorithm to maximize the output value or score of the linear combination. The output variables may include revenue generation, cost, customer satisfaction performance, first call resolution, cancellation, or other variable outputs from the pattern matching algorithm of the system.",Call routing methods and systems based on multiple variable standardized scoring
"The present disclosure relates to a response analysis system that employs a small-data training dataset to train a neural network that accurately performs domain-agnostic opinion mining. For example, in one or more embodiments, the response analysis system trains a response classification neural network using part of speech information (e.g., syntactic information) to learn and apply response classification labels for opinion text responses. In particular, the response analysis system employs part of speech information patterns without regard to word patterns to determine whether words in a text response correspond to an opinion, the target of the opinion, or neither. In addition, the trained response classification neural network has a significantly reduced learned parameter space, which decreases processing, memory requirements, and overall complexity.",Capturing rich response relationships with small-data neural networks
"Physical neural networks based nanotechnology include dendrite circuits that comprise non-volatile nanotube switches. A first terminal of the non-volatile nanotube switches is able to receive an electrical signal and a second terminal of the non-volatile nanotube switches is coupled to a common node that sums any electrical signals at the first terminals of the nanotube switches. The neural networks further includes transfer circuits to propagate the electrical signal, synapse circuits, and axon circuits.",Carbon nanotube-based neural networks and methods of making and using same
"A process and apparatus for monitoring catalyst conversion activity includes a predictor of feedgas emissions and a predictor of tailpipe emissions, each predictor providing an output for generating a ratio of conversion activity. Each predictor comprises a trained neural network receiving at least one of, and preferably a plurality of, the engine operating condition signals available from an electronic engine control. Preferably, each neural network is trained by inputting accumulated data acquired from performance evaluation of a plurality of vehicles having consistent powertrains but with different degrees of deterioration.",Catalyst monitor with direct prediction of hydrocarbon conversion efficiency by dynamic neural networks
"A novel class of information-processing systems called a cellular neural network is discussed. Like a neural network, it is a large-scale nonlinear analog circuit which processes signals in real time. Like cellular automata, it is made of a massive aggregate of regularly spaced circuit clones, called cells, which communicate with each other directly only through its nearest neighbors. Each cell is made of a linear capacitor, a nonlinear voltage-controlled current source, and a few resistive linear circuit elements. Cellular neural networks share the best features of both worlds; its continuous time feature allows real-time signal processing found within the digital domain and its local interconnection feature makes it tailor made for VLSI implementation. Cellular neural networks are uniquely suited for high-speed parallel signal processing.",Cellular neural network
"Deep Neural Networks (DNN) are time shifted relative to one another and trained. The time-shifted networks may then be combined to improve recognition accuracy. The approach is based on an automatic speech recognition (ASR) system using DNN and using time shifted features. Initially, a regular ASR model is trained to produce a first trained DNN. Then a top layer (e.g., SoftMax layer) and the last hidden layer (e.g., Sigmoid) are fine-tuned with same data set but with a feature window left- and right-shifted to create respective second and third left-shifted and right-shifted DNNs. From these three DNN networks, four combination networks may be generated: left- and right-shifted, left-shifted and centered, centered and right-shifted, and left-shifted, centered, and right-shifted. The centered networks are used to perform the initial (first-pass) ASR. Then the other six networks are used to perform rescoring. The resulting are combined using ROVER (recognizer output voting error reduction) or another technique to improve recognition performance as compared to the centered DNN by itself.","Centered, left- and right-shifted deep neural networks and their combinations"
""" A chaotic recurrent neural network includes N chaotic neural networks for receiving an external input and the outputs of N-1 chaotic neural networks among said N chaotic neural networks and performing an operation according to the following dynamic equation ##EQU1## wherein W.sub.ij is a synapse connection coefficient of the feedback input from the """"j""""th neuron to the """"i""""th neuron, X.sub.i (t) is the output of the """"i""""th neuron at time t, and .gamma..sub.i, .alpha. and and k are a time-delaying constant, a non-negative parameter and a refractory time attenuation constant, respectively, and wherein Z.sub.i (t) represents X.sub.i (t) when i belongs to the neuron group I and represents a.sub.i (t) when i belongs to the external input group E. Also, a learning algorithm for the chaotic recurrent neural network increases its learning efficiency. """,Chaotic recurrent neural network and learning method therefor
"For digital pathology imaging, intelligent processing, such as automatic recognition or content-based retrieval, is one significant benefit that drives the wide application of this technology. Before any intelligent processing on pathology images, every image is converted into a feature vector which quantitatively capture its visual characteristics. An algorithm characterizing pathology images with statistical analysis of local responses of neural networks is described herein. The algorithm framework enables extracting sophisticated textural features that are well adapted to the image data of interest.",Characterizing pathology images with statistical analysis of local neural network responses
A charge domain bit serial vector matrix multiplier for real time signal processing of mixed digital/analog signals for implementing opto-electronic neural networks and other signal processing functions. A combination of CCD and DCSD arrays permits vector/matrix multiplication with better than 10.sup.11 multiply accumulates per second on a one square centimeter chip. The CCD array portion of the invention is used to load and move charge packets into the DCSD array for processing therein. The CCD array is also used to empty the matrix of unwanted charge. The DCSD array is designed to store a plurality of charge packets representing the respective matrix values such as the synaptic interaction matrix of a neural network. The vector multiplicand may be applied in bit serial format. The row or sensor lines of the DCSD array are used to accumulate the results of the multiply operation. Each such row output line is provided with a divide-by-two/accumulate CCD circuit which automatically compensates for the increasing value of the input vector element's bits from least significant bit to most significant bit. In a similar fashion each row output line can be provided with a multiply-by-two/accumulate CCD circuit which automatically accounts for the decreasing value of the input vector element's bits from most significant bit to least significant bit. The accumulated charge packet output of the array may be preferably converted to a digital signal compatible with the input vector configuration by utilizing a plurality of analog-to-digital converters.,Charge domain bit serial vector-matrix multiplier and method thereof
"A semiconductor charge transfer synapse cell has a capacitor coupled between an input line and an intermediate node. A voltage pulse applied to the input line causes charge transfer from one summing line to another through a pair of series connected field-effect devices. Each of the devices has an associated gate potential which controls its resistance. In response to the low-to-high voltage transition of the input pulse current flows through the devices from the intermediate node to the summing lines. A high-to-low transition causes current to flow in the opposite direction. Because the relative conductances of the devices are different depending on the direction of current flow, a net charge is transferred from one summing line to the other. The amount of charge transferred is a function of the amplitude of the pulsed input, the gate potentials, and the capacitance value.",Charge domain differential conductance synapse cell for neural networks
"Circuit arrangement for calculating matrix operations, such as those which recur frequently in signal processing, specifically in conjunction with neural networks, having a systolic array of multipliers and adders, downstream from which a recursive accumulator is connected. In addition to products, sums and differences of matrices, this circuit arrangement also allows squares, absolute magnitudes of sums and differences and squares of sums and differences of two matrices to be calculated very efficiently. Furthermore, with the aid of the recursive accumulator, it is possible to transpose matrices, to calculate row sums and column sums, and to search for minimum or maximum matrix elements.",Circuit arrangement for calculating matrix operations in signal processing
"In a neural network of N neuron circuits, having an engaged neuron's calculated p bit wide distance between an input vector and a prototype vector and stored in the weight memory thereof, an aggregate search/sort circuit (517) of N engaged neurons' search/sort circuits. The aggregate search/sort circuit determines the minimum distance among the calculated distances. Each search/sort circuit (502-1) has p elementary search/sort units connected in series to form a column, such that the aggregate circuit is a matrix of elementary search/sort units. The distance bit signals of the same bit rank are applied to search/sort units in each row. A feedback signal is generated by ORing in an OR gate (12.1) all local search/sort output signals from the elementary search/sort units of the same row. The search process is based on identifying zeroes in the distance bit signals, from the MSB's to the LSB's. As a zero is found in a row, all the columns with a one in that row are excluded from the subsequent row search. The search process continues until only one distance, the minimum distance, remains and is available at the output of the OR circuit. The above described search/sort circuit may further include a latch allowing the aggregate circuit to sort remaining distances in increasing order.",Circuit for searching/sorting data in neural networks
"The improved neural network of the present invention results from the combination of a dedicated logic block with a conventional neural network based upon a mapping of the input space usually employed to classify an input data by computing the distance between said input data and prototypes memorized therein. The improved neural network is able to classify an input data, for instance, represented by a vector A even when some of its components are noisy or unknown during either the learning or the recognition phase. To that end, influence fields of various and different shapes are created for each neuron of the conventional neural network. The logic block transforms at least some of the n components (A1, . . . , An) of the input vector A into the m components (V1, . . . , Vm) of a network input vector V according to a linear or non-linear transform function F. In turn, vector V is applied as the input data to said conventional neural network. The transform function F is such that certain components of vector V are not modified, e.g. Vk=Aj, while other components are transformed as mentioned above, e.g. Vi=Fi(A1, . . . , An). In addition, one (or more) component of vector V can be used to compensate an offset that is present in the distance evaluation of vector V. Because, the logic block is placed in front of the said conventional neural network any modification thereof is avoided.",Circuits and method for shaping the influence field of neurons and neural networks resulting therefrom
"A boosting and pruning system and method for utilizing a plurality of neural networks, preferably those based on adaptive resonance theory (ART), in order to increase pattern classification accuracy is presented. The method utilizes a plurality of N randomly ordered copies of the input data, which is passed to a plurality of sets of booster networks. Each of the plurality of N randomly ordered copies of the input data is divided into a plurality of portions, preferably with an equal allocation of the data corresponding to each class for which recognition is desired. The plurality of portions is used to train the set of booster networks. The rules generated by the set of booster networks are then pruned in an intra-booster pruning step, which uses a pair-wise Fuzzy AND operation to determine rule overlap and to eliminate rules which are sufficiently similar. This process results in a set of intra-booster pruned booster networks. A similar pruning process is applied in an inter-booster pruning process, which eliminates rules from the intra-booster pruned networks with sufficient overlap. The final, derivative booster network captures the essence of the plurality of sets of booster networks and provides for higher classification accuracy than available using a single network.",Classification method and apparatus based on boosting and pruning of multiple classifiers
A method of classifying substrates with a metrology tool is herein disclosed. The method begins by training a deep learning framework using convolutional neural networks with a training dataset for classifying image dataset. Obtaining a new image from the meteorology tool. Running the new image through the deep learning framework to classify the new image.,"Classification, search and retrieval of semiconductor processing metrology images using deep learning/convolutional neural networks"
A method of classifying substrates with a metrology tool is herein disclosed. The method begins by training a deep learning framework using convolutional neural networks with a training dataset for classifying image dataset. Obtaining a new image from the meteorology tool. Running the new image through the deep learning framework to classify the new image.,"Classification, search and retrieval of semiconductor processing metrology images using deep learning/convolutional neural networks"
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for classifying videos using neural networks. One of the methods includes obtaining a temporal sequence of video frames, wherein the temporal sequence comprises a respective video frame from a particular video at each of a plurality time steps; for each time step of the plurality of time steps: processing the video frame at the time step using a convolutional neural network to generate features of the video frame; and processing the features of the video frame using an LSTM neural network to generate a set of label scores for the time step and classifying the video as relating to one or more of the topics represented by labels in the set of labels from the label scores for each of the plurality of time steps.",Classifying videos using neural networks
"Characteristics of the plasma in a plasma-based manufacturing process step are monitored directly and in real time by observing the spectrum which it produces. An artificial neural network analyzes the plasma spectrum and generates control signals to control one or more of the process input parameters in response to any deviation of the spectrum beyond a narrow range. In an embodiment, a plasma reaction chamber forms a plasma in response to input parameters such as gas flow, pressure and power. The chamber includes a window through which the electromagnetic spectrum produced by a plasma in the chamber, just above the subject surface, may be viewed. The spectrum is conducted to an optical spectrometer which measures the intensity of the incoming optical spectrum at different wavelengths. The output of optical spectrometer is provided to an analyzer which produces a plurality of error signals, each indicating whether a respective one of the input parameters to the chamber is to be increased or decreased. The microcontroller provides signals to control respective controls, but these lines are intercepted and first added to the error signals, before being provided to the controls for the chamber. The analyzer can include a neural network and an optional spectrum preprocessor to reduce background noise, as well as a comparator which compares the parameter values predicted by the neural network with a set of desired values provided by the microcontroller.",Closed loop adaptive control of spectrum-producing step using neural networks
"Preferred embodiments include encoders and encoding methods for encoding integers as sparse binary vectors as used in neural networks. The encoding is by position of nonzero components; such as for N component vectors, the integer n is represented by a sequence of n components equal to zero followed by a sequence of log.sub.2 N components equal to one and then a sequence of N-n-log.sub.2 N components equal to zero. Other preferred embodiments include permutations of vector components while retaining the same number of nonzero components and also with partitioning into more and less significant subvectors.",Closeness code and method
""" A plurality of neural networks are coupled to an output neural network, or judge network, to form a clustered neural network. Each of the plurality of clustered networks comprises a supervised learning rule back-propagated neural network. Each of the clustered neural networks are trained to perform substantially the same mapping function before they are clustered. Following training, the clustered neural network computes its output by taking an """"average"""" of the outputs of the individual neural networks that make up the cluster. The judge network combines the outputs of the plurality of individual neural networks to provide the output from the entire clustered network. In addition, the output of the judge network may be fed back to each of the individual neural networks and used as a training input thereto, in order to provide for continuous training. The use of the clustered network increases the speed of learning and results in better generalization. In addition, clustering multiple back-propagation networks provides for increased performance and fault tolerance when compared to a single unclustered network having substantially the same computational complexity. The present invention may be used in applications that are amenable to neural network solutions, including control and image processing applications. Clustering of the networks also permits the use of smaller networks and provides for improved performance. The clustering of multiple back-propagation networks provides for synergy that improves the properties of the clustered network over a comparably complex non-clustered network. """,Clustered neural networks
"A current-mode four-quadrant analog multiplier is provided, which is constructed based on CMOS (complementary metal-oxide semiconductor) technology, capable of generating an output current signal which is proportional in magnitude to the product of two input current signals. This current-mode analog multiplier is designed based on the translinear circuit principle. The current-mode analog multiplier has high precision, wide current dynamic range, and is insensitive to temperature and process, suitable for use in VLSI implementation of many analog circuits and systems, such as fuzzy logic controllers and analog neural networks.",CMOS current-mode four-quadrant analog multiplier
"Methods and systems for license plate recognition utilizing a trained neural network. In an example embodiment, a neural network can be subject to operations involving iteratively training and adapting the neural network for a particular task such as, for example, text recognition in the context of a license plate recognition application. The neural network can be trained to perform generic text recognition utilizing a plurality of training samples. The neural network can be applied to a cropped image of a license plate in order to recognize text and produce a license plate transcription with respect to the license plate. An example of such a neural network is a CNN (Convolutional Neural. Network).",Coarse-to-fine cascade adaptations for license plate recognition with convolutional neural networks
"The invention integrates emerging applications, tools and techniques for machine learning in medicine with videoconference networking technology in novel business methods that support rapid adaptive learning for medical minds and machines. These methods can leverage domain knowledge and clinical expertise with cognitive collaboration, augmented medical intelligence and cybernetic workflow streams for learning health care systems. The invention enables multimodal cognitive communications, collaboration, consultation and instruction between and among cognitive collaborants, including heterogeneous networked teams of persons, machines, devices, neural networks, robots and algorithms. It provides for both synchronous and asynchronous cognitive collaboration with multichannel, multiplexed imagery data streams during various stages of medical disease and injury managementdetection, diagnosis, prognosis, treatment, measurement and monitoring, as well as resource utilization and outcomes reporting. The invention acquires both live stream and archived medical imagery data from network-connected medical devices, cameras, signals, sensors and imagery data repositories, as well as multiomic data sets from structured reports and clinical documents. It enables cognitive curation, annotation and tagging, as well as encapsulation, saving and sharing of collaborated imagery data streams as packetized medical intelligence. The invention augments packetized medical intelligence through recursive cognitive enrichment, including multimodal annotation and [semantic] metadata tagging with resources consumed and outcomes delivered. Augmented medical intelligence can be saved and stored in multiple formats, as well as retrieved from standards-based repositories. The invention provides neurosynaptic network connectivity for medical images and video with multi-channel, multiplexed gateway streamer servers that can be configured to support workflow orchestration across the enterpriseon platform, federated or cloud data architectures, including ecosystem partners. It also supports novel methods for managing augmented medical intelligence with networked metadata repositories [inclduing imagery data streams annotated with semantic metadata]. The invention helps prepare streaming imagery data for cognitive enterprise imaging. It can be incorporate and combine various machine learning techniques [e.g., deep, reinforcement and transfer learning, convolutional neural networks and NLP] to assist in curating, annotating and tagging diagnostic, procedural and evidentiary medical imaging. It also supports real-time, intraoperative imaging analytics for robotic-assisted surgery, as well as other imagery guided interventions. The invention facilitates collaborative precision medicine, and other clinical initiatives designed to reduce the cost of care, with precision diagnosis [e.g., integrated in vivo, in vitro, in silico] and precision targeted treatment [e.g., precision dosing, theranostics, computer-assited surgery]. Cybernetic workflow streamscognitive communications, collaboration, consultation and instruction with augmented medical intelligenceenable care delivery teams of medical minds and machines to deliver the right care, for the right patient, at the right time, in the right place - and deliver that care faster, smarter, safer, more precisely, cheaper and better.","Cognitive collaboration with neurosynaptic imaging networks, augmented medical intelligence and cybernetic workflow streams"
"Designs for cognitive memory systems storing input data, images, or patterns, and retrieving it without knowledge of where stored when cognitive memory is prompted by query pattern that is related to sought stored pattern. Retrieval system of cognitive memory uses autoassociative neural networks and techniques for pre-processing query pattern to establish relationship between query pattern and sought stored pattern, to locate sought pattern, and to retrieve it and ancillary data. Cognitive memory, when connected to computer or information appliance introduces computational architecture that applies to systems and methods for navigation, location and recognition of objects in images, character recognition, facial recognition, medical analysis and diagnosis, video image analysis, and to photographic search engines that when prompted with a query photograph containing faces and objects will retrieve related photographs stored in computer or other information appliance, and will identify URL's of related photographs and documents stored on the World Wide Web.",Cognitive memory and auto-associative neural network based search engine for computer and network located images and photographs
"Designs for cognitive memory systems storing input data, images, or patterns, and retrieving it without knowledge of where stored when cognitive memory is prompted by query pattern that is related to sought stored pattern. Retrieval system of cognitive memory uses autoassociative neural networks and techniques for pre-processing query pattern to establish relationship between query pattern and sought stored pattern, to locate sought pattern, and to retrieve it and ancillary data. Cognitive memory, when connected to computer or information appliance introduces computational architecture that applies to systems and methods for navigation, location and recognition of objects in images, character recognition, facial recognition, medical analysis and diagnosis, video image analysis, and to photographic search engines that when prompted with a query photograph containing faces and objects will retrieve related photographs stored in computer or other information appliance, and will identify URL's of related photographs and documents stored on the World Wide Web.",Cognitive memory and auto-associative neural network based search engine for computer and network located images and photographs
"A collision-avoidance system for use with an autonomous-capable vehicle can continuously receive image frames captured of the roadway to determine drivable space in a forward direction of the vehicle. The system can determine, for each image frame, whether individual regions of the image frame depict drivable space. The system can do so using machine-learned image recognition algorithms such as convolutional neural networks generated using extensive training data. Using such techniques, the system can label regions of the image frames as corresponding to drivable space or non-drivable space. By analyzing the labeled image frames, the system can determine whether the vehicle is likely to impact a region of non-drivable space. And, in response to such a determination, the system can generate control signals that override other control systems or human operator input to control the brakes, the steering, or other sub-systems of the vehicle to avoid the collision.",Collision-avoidance system for autonomous-capable vehicle
"A data compression and recovery apparatus compresses picture element data of a color image by expressing two primary color values of each picture element as a set of parameter values of a neural network in conjunction with reference color data values of a corresponding block of picture elements. Date recovery is achieved by inputting each block of reference color values to a neural network while establishing the corresponding set of parameter values in the network, to thereby obtain the original pair of encoded primary color values for each of successive picture elements. The third primary color can be used as the reference color.",Color image data compression and recovery apparatus based on neural networks
"When a required color image is to be output from a color image output device using an image input device for outputting color separation value signals corresponding to a read color image, if a change in image reproduction environment is detected by each of sensors provided to these devices, learning processing is properly executed. Using neural networks of a color conversion section and a color correction section which are optimized by the learning processing, a signal output from the image input device is color-converted and color-corrected. The color-corrected image signal (color separation value signals) is supplied to the color image output device to reproduce a color image. Since the learning processing is properly executed in correspondence with detection of an environmental variation by the sensors, the color image output device can stably keep reproducing the same color in consideration of the device characteristics including a physical change in temperature or humidity, and characteristics which change upon a change in color material such as inks, ribbons, or the like.",Color image reproducing system with image signal correction function
"A color management method/apparatus generates image color matching and International Color Consortium (ICC) color printer profiles using a reduced number of color patch measurements. Color printer characterization, and the generation of ICC profiles usually require a large number of measured data points or color patches and complex interpolation techniques. This invention provides an optimization method/apparatus for performing LAB to CMYK color space conversion, gamut mapping, and gray component replacement. A gamut trained network architecture performs LAB to CMYK color space conversion to generate a color profile lookup table for a color printer, or alternatively, to directly control the color printer in accordance with the a plurality of color patches that accurately. represent the gamut of the color printer. More specifically, a feed forward neural network is trained using an ANSI/IT-8 basic data set consisting of 182 data points or color patches, or using a lesser number of data points such as 150 or 101 data points when redundant data points within linear regions of the 182 data point set are removed. A 5-to-7 neuron neural network architecture is preferred to perform the LAB to CMYK color space conversion as the profile lookup table is built, or as the printer is directly controlled. For each CMYK signal, an ink optimization criteria is applied, to thereby control ink parameters such as the total quantity of ink in each CMYK ink printed pixel, and/or to control the total quantity of black ink in each CMYK ink printed pixel.",Color printer characterization using optimization theory and neural networks
"A color-recognition camera comprises a red-green-blue CCD-imaging device that provides an analog RGB-video signal. A set of three analog-to-digital converters convert the analog RGB-video signal into a digital RGB-video signal. A digital comparator tests the digital RGB-video signal pixel-by-pixel for a match against a color setpoint. If a match occurs, a pixel with a particular color represented by the color setpoint has been recognized and a &#8220;hit&#8221; is output. A pixel address counter provides a pixel address output each time a &#8220;hit&#8221; is registered. The number of hits per video frame are accumulated, and a color-match area magnitude value is output for each frame. Alternatively, neural networks are used to indicate hits when a pixel in the video image comes close enough to the color setpoint value. Just how close can be &#8220;learned&#8221; by the neural network.",Color recognition camera
"A two-level hierarchical approach for process fault diagnosis is an operating system employs a function-oriented approach at a first level and a component characteristic-oriented approach at a second level, where the decision-making procedure is structured in order of decreasing intelligence with increasing precision. At the first level, the diagnostic method is general and has knowledge of the overall process including a wide variety of plant transients and the functional behavior of the process components. An expert system classifies malfunctions by function to narrow the diagnostic focus to a particular set of possible faulty components that could be responsible for the detected functional misbehavior of the operating system. At the second level, the diagnostic method limits its scope to component malfunctions, using more detailed knowledge of component characteristics. Trained artificial neural networks are used to further narrow the diagnosis and to uniquely identify the faulty component by classifying the abnormal condition data as a failure of one of the hypothesized components through component characteristics. Once an anomaly is detected, the hierarchical structure is used to successively narrow the diagnostic focus from a function misbehavior, i.e., a function oriented approach, until the fault can be determined, i.e., a component characteristic-oriented approach.",Combined expert system/neural networks method for process fault diagnosis
"The neural computing paradigm is characterized as a dynamic and highly computationally intensive system typically consisting of input weight multiplications, product summation, neural state calculations, and complete connectivity among the neurons. Herein is described neural network architecture for a Scalable Neural Array Process (SNAP) which uses a unique intercommunication scheme within an array structure that provides high performance for completely connected network models such as the Hopfield model. SNAP's packaging and expansion capabilities are addressed, demonstrating SNAP's scalability to larger networks. The array processor uses a special type of adder tree which computes in a first direction and communicates in a second direction. The adder tree is thus responsive to a compute state and a communication state. The adder tree has the ability to provide a first driver responsive to a compute state for communicating an adder output to a data path and a second driver responsive to the communication state for connecting the data path to the neuron inputs.",Communicating adder tree system for neural array processor
"Disclosed herein are methods of expressing a heterologous nucleic acid sequence, such as a sequence encoding a detectable protein, in a primary neuron (or plurality of primary neurons) and other neurons that are monosynaptically connected to the primary neuron (or plurality of primary neurons). Such methods involve viruses (such as, rabies viruses) defective for transsynaptic transport (TST-defective virus) and in situ complementation of the defect in a manner that permits only monosynaptic transport of the TST-defective virus. The TST-defective virus and, therefore, any heterologous nucleic acid sequence it carries in its genome, are not transmitted to neurons that are not monosynaptically connected to the primary neuron (or plurality of primary neurons). Also disclosed are methods of targeting a TST-defective virus to a genetically defined primary neuron (or plurality of primary neurons). The disclosed technology enables far more specific labelling and/or manipulation of neural networks than has previously been possible.",Compositions and methods for monosynaptic transport
"Disclosed herein are methods of expressing a heterologous nucleic acid sequence, such as a sequence encoding a detectable protein, in a primary neuron (or plurality of primary neurons) and other neurons that are monosynaptically connected to the primary neuron (or plurality of primary neurons). Such methods involve viruses (such as, rabies viruses) defective for transsynaptic transport (TST-defective virus) and in situ complementation of the defect in a manner that permits only monosynaptic transport of the TST-defective virus. The TST-defective virus and, therefore, any heterologous nucleic acid sequence it carries in its genome, are not transmitted to neurons that are not monosynaptically connected to the primary neuron (or plurality of primary neurons). Also disclosed are methods of targeting a TST-defective virus to a genetically defined primary neuron (or plurality of primary neurons). The disclosed technology enables far more specific labelling and/or manipulation of neural networks than has previously been possible.",Compositions and methods for monosynaptic transport
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for compressing images using neural networks. One of the methods includes receiving an image; processing the image using an encoder neural network, wherein the encoder neural network is configured to receive the image and to process the image to generate an output defining values of a first number of latent variables that each represent a feature of the image; generating a compressed representation of the image using the output defining the values of the first number of latent variables; and providing the compressed representation of the image for use in generating a reconstruction of the image.",Compressing images using neural networks
"Embodiments of the present invention are employ dynamical, nanoscale devices, including memristive connections between nanowires, for constructing parallel, distributed, dynamical computational networks and systems, including perceptron networks and neural networks. In many embodiments of the present invention, neuron-like computational devices are constructed from silicon-based microscale and/or submicroscale components, and interconnected with one another by dynamical interconnections comprising nanowires and memristive connections between nanowires. In many massively parallel, distributed, dynamical computing systems, including the human brain, there may be a far greater number of interconnections than neuron-like computational nodes. Use of dynamical nanoscale devices for these connections results in enormous design, space, energy, and computational efficiencies.",Computational nodes and computational-node networks that include dynamical-nanodevice connections
"An apparatus to facilitate compute optimization is disclosed. The apparatus includes a plurality of processing units each comprising a plurality of execution units (EUs), wherein the plurality of EUs comprise a first EU type and a second EU type.",Compute optimization mechanism for deep neural networks
"An apparatus to facilitate compute optimization is disclosed. The apparatus includes a memory device including a first integrated circuit (IC) including a plurality of memory channels and a second IC including a plurality of processing units, each coupled to a memory channel in the plurality of memory channels.",Compute optimization mechanism for deep neural networks
"One embodiment provides for a compute apparatus to perform machine learning operations, the apparatus comprising a decode unit to decode a single instruction into a decoded instruction that specifies multiple operands including an input value and a quantized weight value associated with a neural network and an arithmetic logic unit including a barrel shifter, an adder, and an accumulator register, wherein to execute the decoded instruction, the barrel shifter is to shift the input value by the quantized weight value to generate a shifted input value and the adder is to add the shifted input value to a value stored in the accumulator register and update the value stored in the accumulator register.",Compute optimizations for neural networks
"Computer aided diagnosis techniques in medical imaging are developed for the automated differentiation between benign and malignant lesions and go beyond computer aided detection by providing cancer likelihood for a detected lesion given image and/or patient characteristics. A computer aided detection and diagnosis algorithm for mammographic calcification clusters is developed and evaluated. The emphasis is on the diagnostic component although the algorithm includes automated detection, segmentation, and classification steps based on wavelet filters and artificial neural networks. Classification features are selected primarily from descriptors of the morphology of the individual calcifications and the distribution of the cluster as well as patient's demographics as input to the network. Te selected features are robust morphological and distributional descriptors, relatively insensitive to segmentation and detection errors such as false positive signals and variations among imaging sources or imaging equipment.",Computer aided diagnosis of mammographic microcalcification clusters
"A computer system splits a data space to partition data between processors or processes. The data space may be split into sub-regions which need not be orthogonal to the axes defined by the data space's parameters, using a decision tree. The decision tree can have neural networks in each of its non-terminal nodes that are trained on, and are used to partition, training data. Each terminal, or leaf, node can have a hidden layer neural network trained on the training data that reaches the terminal node. The training of the non-terminal nodes' neural networks can be performed on one processor and the training of the leaf nodes' neural networks can be run on separate processors. Different target values can be used for the training of the networks of different non-terminal nodes. The non-terminal node networks may be hidden layer neural networks. Each non-terminal node automatically may send a desired ratio of the training records it receives to each of its child nodes, so the leaf node networks each receives approximately the same number of training records. The system may automatically configures the tree to have a number of leaf nodes equal to the number of separate processors available to train leaf node networks. After the non-terminal and leaf node networks have been trained, the records of a large data base can be passed through the tree for classification or for estimation of certain parameter values.",Computer system and computerized method for partitioning data for parallel processing
"A computer system splits a data space to partition data between processors or processes. The data space may be split into sub-regions which need not be orthogonal to the axes defined the data space's parameters, using a decision tree. The decision tree can have neural networks in each of its non-terminal nodes that are trained on, and are used to partition, training data. Each terminal, or leaf, node can have a hidden layer neural network trained on the training data that reaches the terminal node. The training of the non-terminal nodes' neural networks can be performed on one processor and the training of the leaf nodes' neural networks can be run on separate processors. Different target values can be used for the training of the networks of different non-terminal nodes. The non-terminal node networks may be hidden layer neural networks. Each non-terminal node automatically may send a desired ratio of the training records it receives to each of its child nodes, so the leaf node networks each receives approximately the same number of training records. The system may automatically configures the tree to have a number of leaf nodes equal to the number of separate processors available to train leaf node networks. After the non-terminal and leaf node networks have been trained, the records of a large data base can be passed through the tree for classification or for estimation of certain parameter values.",Computer system and computerized method for partitioning data for parallel processing
"A database often contains sparse, i.e., under-represented, conditions which might be not represented in a training data set for training an analytical model if the training data set is created by stratified sampling. Sparse conditions may be represented in a training set by using a data set which includes essentially all of the data in a database, without stratified sampling. A series of samples, or &#8220;windows,&#8221; are used to select portions of the large data set for phases of training. In general, the first window of data should be a reasonably broad sample of the data. After the model is initially trained using a first window of data, subsequent windows are used to retrain the model. For some model types, the model is modified in order to provide it with some retention of training obtained using previous windows of data. Neural networks and Kohonen networks may be used without modification. Models such as probabilistic neural networks, generalized regression neural networks, Gaussian radial basis functions, decision trees, including K-D trees and neural trees, are modified to provide them with properties of memory to retain the effects of training with previous training data sets. Such a modification may be provided using clustering. is Parallel training models which partition the training data set into disjoint subsets are modified so that the partitioner is trained only on the first window of data, whereas subsequent windows are used to train the models to which the partitioner applies the data in parallel.",Computer system and process for training of analytical models using large data sets
"A computer system comprises at least one genetic optimization agent holding a pool of genotypes, representing possible solutions to a problem. The genetic optimization agent generates new genotypes from the pool, evaluates the new genotypes according to predetermined fitness criteria, and selects the fittest of the genotypes to form a new generation of genotypes in the pool. The system also includes a number of further agents, for generating further solutions to the problem, using different techniques, such as simulated annealing, constraint logic, and neural networks. These further solutions are also represented by genotypes. The genetic optimization agent imports genotypes from the further agents and adds them to its pool of genotypes for breeding and selection. The genetic optimization agent thus provides a way of integrating a number of different problem-solving agents, in such a way as to achieve synergy between them.",Computer system using genetic optimization techniques
"Described are systems, media, and methods for applying deep convolutional neural networks to medical images to generate a real-time or near real-time diagnosis.",Computer-aided diagnosis system for medical images using deep convolutional neural networks
"A method and an apparatus for generating a g2p model based on AI are provided. The method includes: during performing a grapheme-to-phoneme conversion training by a neural network on each word in training data, screening nodes in a hidden layer of the neural network randomly according to a preset node ratio so as to obtain retaining nodes for training each word; training each word with a sub-neural network corresponding to the retaining nodes and updating a weight of each retaining node of the sub-neural network; and performing a mean processing on the weights of the retaining nodes of respective sub-neural networks, so as to generate the grapheme-to-phoneme model.",Computer-implemented method and apparatus for generating grapheme-to-phoneme model
"A method and apparatus for color matching are provided, in which paint recipe neural networks are utilized. The color of a standard is expressed as color values. The neural network includes an input layer having nodes for receiving input data related to paint bases. Weighted connections connect to the nodes of the input layer and have coefficients for weighting the input data. An output layer having nodes are either directly or indirectly connected to the weighted connections and generates output data related to color values. The data to the input layer and the data from the output layer are interrelated through the neural network's nonlinear relationship. The paint color matching neural network can be used for, but not limited to, color formula correction, matching from scratch, effect pigment identification, selection of targets for color tools, searching existing formulas for the closest match, identification of formula mistakes, development of color tolerances and enhancing conversion routines.",Computer-implemented neural network color matching formulation applications
"A method and apparatus for color matching are provided, in which paint recipe neural networks are utilized. The color of a standard is expressed as color values. The neural network includes an input layer having nodes for receiving input data related to paint bases. Weighted connections connect to the nodes of the input layer and have coefficients for weighting the input data. An output layer having nodes are either directly or indirectly connected to the weighted connections and generates output data related to color values. The data to the input layer and the data from the output layer are interrelated through the neural network's nonlinear relationship. The paint color matching neural network can be used for, but not limited to, color formula correction, matching from scratch, effect pigment identification, selection of targets for color tools, searching existing formulas for the closest match, identification of formula mistakes, development of color tolerances and enhancing conversion routines.",Computer-implemented neural network color matching formulation system
"A method, system and computer readable medium configured for computerized detection of lung abnormalities, including obtaining a standard digital chest image and a soft-tissue digital chest image; generating a first difference image from the standard digital chest image and a second difference image from the soft-tissue digital chest image; identifying candidate abnormalities in the first and second difference images; extracting from the standard digital chest image and the first difference image predetermined first features of each of the candidate abnormalities identified in the first difference image; extracting from the soft-tissue digital chest image and the second difference images predetermined second features of each of the candidate abnormalities identified in the second difference image; analyzing the extracted first features and the extracted second features to identify and eliminate false positive candidate abnormalities respectively corresponding thereto; applying extracted features from remaining candidate abnormalities derived respectively from the first and second difference images and remaining after the elimination of the false positive candidate abnormalities to respective artificial neural networks to eliminate further false positive candidate abnormalities; performing a logical OR operation of the candidate abnormalities derived respectively from the first and second difference images and remaining after the elimination of the false positive candidate abnormalities; and outputting a signal indicative of a result of performing the logical OR operation. The logical OR combination, of locations of the candidate abnormalities detected in the first difference image and the second difference image, yields an improved detection sensitivity (over 90%) and only slightly increased false positives rate (3.2 false positives per chest image).",Computerized detection of lung nodules using energy-subtracted soft-tissue and standard chest images
"Systems and methods are provided for calculating authenticity of a human user. One method comprises receiving, via a network, an electronic request from a user device, instantiating a video connection with the user device; generating, using a database of questions, a first question; providing, via the network, the generated question to the user device; analyzing video and audio data received via the connection to extract facial expressions, calculating, using convolutional neural networks, first data and second data corresponding predetermined emotions based on facial expressions and audio data; generating candidate emotion data using the first and second data; determining whether the candidate emotion data predicts a predetermined emotion, and generating a second question to collect additional data for aggregating with the first and second data or determining the authenticity of the user and using the determined authenticity to decide on the user request.",Computerized systems and methods for determining authenticity using micro expressions
"A computing element for use in an array in a neural network. Each computing element has K (K>1) input signal terminals, K input backpropagated signal terminals, K output backpropagated signal terminals and at least one output terminal. The input terminals of the computing element located in row i, column j of the array of computing elements receive a sequence of concurrent input signals on K parallel input lines representing a parallel input signal S.sub.ij having vector elements (s.sub.ij1, s.sub.ij2, s.sub.ij3, . . . , s.sub.ijk).sup.T. The K input backpropagated signal terminals are coupled to receive an m-dimensional (m<K) backpropagated signal vector characterized to provide a measure of the performance error of the computing element. The computing element comprises a weighting function means responsive to the concurrent input signal S.sub.ij for computing a K-dimensional weighting coefficient and a scalar activation signal u.sub.ij by computing a K-dimensional weighting-coefficient vector, W.sub.ij =(w.sub.ij1, w.sub.ij2, . . . , w.sub.ijk).sup.T, and by forming the vector inner product of the input signal S.sub.ij vector elements and the weighting-coefficient vector, W.sub.ij. Feedback signals x.sub.ijk =w.sub.ijk *p.sub.ij are provided from the output backpropagated signal terminals where p.sub.ij provides a performance error of all columns of computing elements subsequent to this computing element weighted by the gain of the computing element. A nonlinear processor maps successive values of u.sub.ij through a nonlinear mapping function, M.sub.ij to provide a single-valued output signal y.sub.ij. The nonlinear processor responds to an m-dimensional backpropagated signal vector, X.sub.ij+1 =(x.sub.1,j+1,p ; x.sub.2,j+1,p ; x.sub.3,j+1,p ; . . . x.sub.m,j+1,p).sup.T characterized to provide a measure of the performance error of all computing elements subsequent to the computing element. Vector X.sub.i,j+1 comprises the pth member of all backpropagated error vectors from the computing elements of column j+1.",Computing element for neural networks
"The present disclosure is directed to parallelization of artificial neural network processing by conditionally synchronizing, among multiple computer processors, either the input or output of individual operations, and by conditionally using either rows or columns of certain matrices used in the operations. The conditional processing may depend upon the relative sizes of the input and output of the specific operations to be performed. For example, if a current layer matrix of values is larger than a next layer matrix of values to be computed, then rows of a weight matrix may be used by the computer processors to compute the next layer matrix. If the current layer matrix is smaller than the next layer matrix, then columns of the weight matrix may be used by the computer processors to compute the next layer matrix.",Conditional parallel processing in fully-connected neural networks
"For use in recognizing an input pattern consisting off feature vectors positioned at a first, . . . , an i-th, . . . , and an I-th pattern time instant along a pattern time axis, a connected word recognition system comprises first through N-th neural networks B(1) to B(N) which are assigned to reference words identified by a first, . . . , an n-th, . . . , and an N-th word identifier and are arranged along a signal time axis divisible into a first . . . , a j-th, . . . , and a J-th signal time instant. The n-th word identifier n corresponds to consecutive ones of the pattern time instants by a first function n(i). The time axes are related to each other by a second function j(i). Among various loci (n(i), j(i)) in a space defined by the word identifiers and the time axes, an optimum locus (n(i), j(i)) is determined to maximize a summation of output signals of the respective neural networks when the consecutive pattern time instants are varied between the first and the I-th pattern time instants for each word identifier. The input pattern is recognized as a concatenation of word identifiers used as optimum first functions n(i) in the optimum locus. Preferably, the optimum locus is determined by a dynamic programming algorithm. If possible, use of a finite-state automaton is more preferred.",Connected word recognition system including neural networks arranged along a signal time axis
"A system, method, and computer program product are provided for efficient allocation of attributes corresponding to neurons or connections of multiple types using a common data structure. A map file is generated by a pre-processor in order to map an attribute of a neuron or connection to a particular location within the common data structure based on a type associated with the neuron or connection, while allowing a neuron or connection of a different type to map its own attribute to that same particular location. Additionally, kernel code can be written to reference attribute names made available by the map file in order to provide reusability of code.",Context aware device execution for simulating neural networks in compute unified device architecture
"Context-based priors are utilized in machine learning networks (e.g., neural networks) for detecting objects in images. The likely locations of objects are estimated based on context labels. A machine learning network identifies a context label of an entire image. Based on the context label, the network selects a set of likely regions for detecting objects of interest in the image.",Context-based priors for object detection in images
"A system, method and computer program product for visualization of context-based search results, including a plurality of neurons, the neurons being associated with words and documents; a plurality of connections between the neurons; a map that displays at least some of the neurons to a user, wherein the display of the neurons on the map corresponds to their relevance to a search query; a display of the links to the relevant documents; and means for changing positions of the neurons relative to each other based on input from the user. Changing a position of one neuron relative to other neurons also changes positions of other contextually relevant neurons, and displays different relevant documents. The map displays the neurons with their relevance identified by any of font type, color, transparency and font size. The map includes icons in proximity to the displayed word neurons for identifying those neurons as irrelevant. Links to the documents are obtained from a search engine having an input query. The map displays annotations and/or keywords to the documents next to the displayed documents.",Context-based search query visualization and search query context management using neural networks
"A system, method and computer program product for visualization of context-based search results, including a plurality of neurons, the neurons being associated with words and documents; a plurality of connections between the neurons; a map that displays at least some of the neurons to a user, wherein the display of the neurons on the map corresponds to their relevance to a search query; a display of the links to the relevant documents; and means for changing positions of the neurons relative to each other based on input from the user. Changing a position of one neuron relative to other neurons also changes positions of other contextually relevant neurons, and displays different relevant documents. The map displays the neurons with their relevance identified by any of font type, color, transparency and font size. The map includes icons in proximity to the displayed word neurons for identifying those neurons as irrelevant. Links to the documents are obtained from a search engine having an input query. The map displays annotations and/or keywords to the documents next to the displayed documents.",Context-based search visualization and context management using neural networks
"Certain aspects of the present disclosure provide methods and apparatus for a continuous-time neural network event-based simulation that includes a multi-dimensional multi-schedule architecture with ordered and unordered schedules and accelerators to provide for faster event sorting; and a formulation of modeling event operations as anticipating (the future) and advancing (update/jump ahead/catch up) rules or methods to provide a continuous-time neural network model. In this manner, the advantages include faster simulation of spiking neural networks (order(s) of magnitude); and a method for describing and modeling continuous time neurons, synapses, and general neural network behaviors.",Continuous time spiking neural network event-based simulation that schedules co-pending events using an indexable list of nodes
A computer-based multi-layer artificial network named Continuous-weight neural network (CWNN) configured to receive an input feature set wherein the input feature set comprises a variable number of features is disclosed. A method for classifying input sets based on a trained CWNN is also disclosed. Various implementation examples are also provided.,Continuous-weight neural networks
Test molding and mass-production molding are performed by an injection molding machine that includes a control apparatus in which neural networks are used. A quality prediction function determined based on the test molding is revised as necessary during mass-production molding.,Control apparatus for injection molding machine
"A control method of controlling a controlled system according to the invention comprises the first step of inputting a current and future target controlled variable to a first neural network model which performs learning using a past target controlled variable for the controlled system as an input signal and a past manipulated variable as a teacher signal, thereby obtaining a current virtual manipulated variable, the second step of causing a second neural network model, which have learnt to predict a behavior of the controlled system, to receive the virtual manipulated variable obtained in the first step and a controlled variable obtained from the controlled system at a current time, thereby obtaining a predicted controlled variable, the third step of obtaining an error of the predicted controlled variable obtained in the second step with respect to the target controlled variable, the fourth step of obtaining a correction amount for the virtual manipulated variable in accordance with a back propagation calculation of the second neural network model, using the error obtained in the third step, thereby correcting the virtual manipulated variable with the correction amount, and the fifth step of outputting the virtual manipulated variable corrected in the fourth step to the controlled system.",Control method and apparatus using two neural networks
"A neural network apparatus and method for use in applications such as in a voltage/reactive-power controller in which a neuro control-object simulator and a neuro controller pre-learn so as to make input-output relations of the controller match the input-output relations of a control unit and so as to make input-output relations of the simulator match input-output relations of a control object. The controller re-learns so as to make the output of the simulator match an input corresponding to a desired output of the control object. After re-learning, the controller controls the control-object.",Control method using neural networks and a voltage/reactive-power controller for a power system using the control method
"A system for tuning a process control loop includes a tuner module for receiving an error signal representative of the difference between a set point and a process variable, the module generating a first process control signal for controlling the process. The system further includes a controller module for receiving the error signal and a parameter signal from a nonlinear module to generate a second process control signal for controlling the process, wherein the nonlinear module applies a nonlinear procedure to generate the parameter signal. The system further includes a switching means coupled to the tuner module and the controller module to select the appropriate process control signal for controlling the process. The system provided uses nonlinear techniques in the nonlinear module to approximate the desired controller tuning parameters. The nonlinear techniques include neural network tuning, fuzzy logic tuning and nonlinear functions, including sigmoid tuning. A system also provides that the nonlinear module use nonlinear techniques to approximate the desired process model parameters. According to an embodiment of the present invention, the nonlinear module includes a process model identification module and a controller tuning module that provides controller parameters and model identification parameters using neural networks, fuzzy logic and nonlinear functions, including sigmoid tuning.",Control-loop auto-tuner with nonlinear tuning rules estimators
"Systems and methods for automatically self-correcting or correcting in real-time one or more neural networks after detecting a triggering event, or breaching boundary conditions are provided. Such a triggering event may indicate incorrect output signal or data being generated by the one or more neural networks. In particular, machine controllers of the invention limit the operations of neural networks to be within boundary conditions. Autonomous machines of the invention can be self-corrected after a breach of a boundary condition is detected. Autonomous land vehicles of the invention are capable of determining the timing of automatic transition to the manual control from automated driving mode. The controller of the invention filters and saves input-output data sets that fall within boundary conditions for later training of neural networks. The controllers of the invention include security architectures to prevent damages from virus attacks or system malfunctions.",Controller systems and methods of limiting the operation of neural networks to be within one or more conditions
"Systems and methods for automatically self-correcting or correcting in real-time one or more neural networks after detecting a triggering event, or breaching boundary conditions are provided. Such a triggering event may indicate incorrect output signal or data being generated by the one or more neural networks. In particular, machine controllers of the invention limit the operations of neural networks to be within boundary conditions. Autonomous machines of the invention can be self-corrected after a breach of a boundary condition is detected. Autonomous land vehicles of the invention are capable of determining the timing of automatic transition to the manual control from automated driving mode. The controller of the invention filters and saves input-output data sets that fall within boundary conditions for later training of neural networks. The controllers of the invention include security architectures to prevent damages from virus attacks or system malfunctions.",Controller systems and methods of limiting the operation of neural networks to be within one or more conditions
"A system and method is disclosed for converting an existing circuit description from a lower level description, such as RTL, to a higher-level description, such as TLM, while raising the abstraction level. By changing the abstraction level, the conversion is not simply a code conversion from one language to another, but a process of learning the circuit using neural networks and representing the circuit using a system of equations that approximate the circuit behavior, particularly with respect to timing aspects. A higher level of abstraction eliminates much of the particular implementation details, and allows easier and faster design exploration, analysis, and test, before implementation. In one aspect, a model description of the circuit, protocol information relating to the circuit, and simulation data associated with the lower level description of the circuit are used to generate an abstract model of the circuit that approximates the circuit behavior.",Conversion of circuit description to an abstract model of the circuit
"A system and method is disclosed for converting an existing circuit description from a lower level description, such as RTL, to a higher-level description, such as TLM, while raising the abstraction level. By changing the abstraction level, the conversion is not simply a code conversion from one language to another, but a process of learning the circuit using neural networks and representing the circuit using a system of equations that approximate the circuit behavior, particularly with respect to timing aspects. A higher level of abstraction eliminates much of the particular implementation details, and allows easier and faster design exploration, analysis, and test, before implementation. In one aspect, a model description of the circuit, protocol information relating to the circuit, and simulation data associated with the lower level description of the circuit are used to generate an abstract model of the circuit that approximates the circuit behavior.",Conversion of circuit description to an abstract model of the circuit
"A system and method is disclosed for converting an existing circuit description from a lower level description, such as RTL, to a higher-level description, such as TLM, while raising the abstraction level. By changing the abstraction level, the conversion is not simply a code conversion from one language to another, but a process of learning the circuit using neural networks and representing the circuit using a system of equations that approximate the circuit behavior, particularly with respect to timing aspects. A higher level of abstraction eliminates much of the particular implementation details, and allows easier and faster design exploration, analysis, and test, before implementation. In one aspect, a model description of the circuit, protocol information relating to the circuit, and simulation data associated with the lower level description of the circuit are used to generate an abstract model of the circuit that approximates the circuit behavior.",Conversion of circuit description to an abstract model of the circuit
"A method of training neural systems and estimating regression coefficients of regression models with respect to an error criterion is disclosed. If the error criterion is a risk-averting error criterion, the invented method performs the training/estimation by starting with a small value of the risk-sensitivity index of the risk-averting error criterion and gradually increasing it to ensure numerical feasibility. If the error criterion is a risk-neutral error criterion such as a standard sum-of-squares error criterion, the invented method performs the training/estimation first with respect to a risk-averting error criterion associated with the risk-neutral error criterion. If the result is not satisfactory for the risk-neutral error criterion, further training/estimation is performed either by continuing risk-averting training/estimation with decreasing values of the associated risk-averting error criterion or by training/estimation with respect to the given risk-neutral error criterion or by both.",Convexification method of training neural networks and estimating regression models
Systems and methods for classifying defects using hot scans and convolutional neural networks (CNNs) are disclosed. Primary scanning modes are identified by a processor and a hot scan of a wafer is performed. Defects of interest and nuisance data are selected and images of those areas are captured usa7ing one or more secondary scanning modes. Image sets are collected and divided into subsets. CNNs are trained using the image subsets. An ideal secondary scanning mode is determined and a final hot scan is performed. Defects are filtered and classified according to the final hot scan and the ideal secondary scanning mode. Disclosed systems for classifying defects utilize image data acquisition subsystems such as a scanning electron microscope as well as processors and electronic databases.,Convolutional neural network-based mode selection and defect classification for image fusion
The present disclosure provides devices and systems for diagnosing and characterizing cancer in a subject. Devices include microfilters and microfiltration systems useful for the isolation and characterization of cells from a subject.,Convolutional neural networks for cancer diagnosis
"Technical solutions are described for implementing a convolutional neural network (CNN) using resistive processing unit (RPU) array. An example method includes configuring an RPU array corresponding to a convolution layer in the CNN based on convolution kernels of the layer. The method further includes performing forward pass computations via the RPU array by transmitting voltage pulses corresponding to input data to the RPU array, and storing values corresponding to output currents from the RPU arrays as output maps. The method further includes performing backward pass computations via the RPU array by transmitting voltage pulses corresponding to error of the output maps, and storing the output currents from the RPU arrays as backward error maps. The method further includes performing update pass computations via the RPU array by transmitting voltage pulses corresponding to the input data of the convolution layer and the error of the output maps to the RPU array.",Convolutional neural networks using resistive processing unit array
"A cortronic neural network defines connections between neurons in a number of regions using target lists, which identify the output connections of each neuron and the connection strength. Neurons are preferably sparsely interconnected between regions. Training of connection weights employs a three stage process, which involves computation of the contribution to the input intensity of each neuron by every currently active neuron, a competition process that determines the next set of active neurons based on their current input intensity, and a weight adjustment process that updates and normalizes the connection weights based on which neurons won the competition process, and their connectivity with other winning neurons.",Cortronic neural networks with distributed processing
"Systems and methods create high quality audio-centric, image-centric, and integrated audio-visual summaries by seamlessly integrating image, audio, and text features extracted from input video. Integrated summarization may be employed when strict synchronization of audio and image content is not required. Video programming which requires synchronization of the audio content and the image content may be summarized using either an audio-centric or an image-centric approach. Both a machine learning-based approach and an alternative, heuristics-based approach are disclosed. Numerous probabilistic methods may be employed with the machine learning-based learning approach, such as nave Bayes, decision tree, neural networks, and maximum entropy. To create an integrated audio-visual summary using the alternative, heuristics-based approach, a maximum-bipartite-matching approach is disclosed by way of example.","Creating audio-centric, image-centric, and integrated audio-visual summaries"
"Estimation sections which have beforehand learned a relationship between known connection data pertaining to connection design and unknown connection data pertaining to connection design for the known connection data estimate the unknown connection data for the known connection data in accordance wit an input of the known connection data, on the basis of the result of learning. The respective estimation sections are formed from a multilayer feedforward neural network in which layers constituted of a plurality of neurons are coupled together in a direction in which the layer runs from an input layer to an output layer by way of an intermediate layer.",Crimping connection design system using multilayer feedforward neural networks
"Embodiments of a computer-implemented method for training a convolutional neural network (CNN) that is pre-trained using a set of color images are disclosed. The method comprises receiving a training dataset including multiple multidimensional images, each multidimensional image including a color image and a depth image; performing a fine-tuning of the pre-trained CNN using the depth image for each of the plurality of multidimensional images; obtaining a depth CNN based on the pre-trained CNN, wherein the depth CNN is associated with a first set of parameters; replicating the depth CNN to obtain a duplicate depth CNN being initialized with the first set of parameters; and obtaining a depth-enhanced color CNN based on the duplicate depth CNN being fine-tuned using the color image for each of the plurality of multidimensional images, wherein the depth-enhanced color CNN is associated with a second set of parameters.",Cross-trained convolutional neural networks using multimodal images
"A method and apparatus of correcting for saturation in a current transformer, which outputs a current measurement, is provided. A switching algorithm receives a value of the current measurement from the current transformer and determines within which of three ranges the value falls. If the value falls in a first range, the current measurement is provided to a protective device such as a relay. If the value falls in a second range, the current measurement is provided to an artificial neural network that produces an output that accounts for saturation of the current transformer. If the value falls in a third range, the current measurement is provided to another artificial neural network that produces an output that accounts for saturation of the current transformer.",Current transformer saturation correction using artificial neural networks
"A system and method for customer-side market segmentation and categorization. This segmentation is done without disclosing sensitive private customer information to the business. A customer downloads a categorization module to a portable device (PDA, wireless cellular phone, etc.) or personal computer. A business defines a decision procedure corresponding to a set of defined customer categories. The business sends their rule set to the customer's device, which uses the rules and a set of stored customer-specific historical and demographic information to determine into which of the business-specific customer categories the customer falls. The categorization module may use any of a variety of methods, such as decision trees, neural networks, Bayesian belief networks, k-nearest neighbor, genetic algorithms, or rule sets. The customer category is sent to the business without other personal data for the business to prepare appropriate promotional material or initiate specific actions.",Customer-side market segmentation
"There is provided a customized personal terminal device capable of operating in response to input data peculiar to the operator, comprising a speech recognition unit for recognizing inputted speech, an image recognition unit for recognizing inputted image, and an instruction recognition unit for recognizing an inputted instruction. Neural networks are provided in at least two of the speech, image and instruction recognition units, a bus operatively connected to the respective recognition units, a processor operatively connected to the bus to perform processing upon the speech, and image and instruction recognized by the recognition units. Also, memory is operatively connected to the bus, and a control unit exercises control over information exchange between respective recognition units and the memory under the control of the processor.",Customized personal terminal device
A system is provided for unsupervised cross-domain image generation relative to a first and second image domain that each include real images. A first generator generates synthetic images similar to real images in the second domain while including a semantic content of real images in the first domain. A second generator generates synthetic images similar to real images in the first domain while including a semantic content of real images in the second domain. A first discriminator discriminates real images in the first domain against synthetic images generated by the second generator. A second discriminator discriminates real images in the second domain against synthetic images generated by the first generator. The discriminators and generators are deep neural networks and respectively form a generative network and a discriminative network in a cyclic GAN framework configured to increase an error rate of the discriminative network to improve synthetic image quality.,Cyclic generative adversarial network for unsupervised cross-domain image generation
"Surveillance platforms in airborne craft (8,10), land based vehicles (12), vessels at sea or fixed structures (14) detect dangers using conventional scanners and transmit information signals describing the dangers to a control center (2) which analyzes the data and determines the degree of danger and its geographic extent. The center generates a danger warning and emergency response including a danger index. The warning/response message identifies the degree of danger (danger index 144) and the GPS coordinates (142) of the impacted geographic area for a wide region or regions of the earth (FIGS. 2-6). A vulnerability index (FIG. 16) determined using neural networks (FIGS. 13-14) and fuzzy logic (FIGS. 15-20) enables a prioritized warning/response. The center broadcasts (18) the danger warning and emergency response (FIG. 9) to a large population of remotely located warning devices (11), such as a network of pagers each of which has a GPS receiver (6,28). The pagers compare the received danger coordinates with their own GPS coordinates and each pager determines the extent to which it is in danger. The warning device automatically issues a warning signal or signals, which may be audible, visual or vibratory, appropriate to the degree of danger. Emergency manned vehicles may also directly receive the broadcast warning/response and be immediately alerted to act appropriately relative to the degree of danger. One embodiment broadcasts (16) directly to home T.V.'s and radios (17) which have internal GPS receivers and which display/annunciate an emergency message customized to that receiver resulting from the internal comparison of the danger coordinates versus the local receiver coordinates.",Danger warning and emergency response system and method
"Surveillance platforms detect dangers and transmit information signals describing the dangers to a control center, which determines the degree of danger and its geographic extent. The center generates a message that identifies the degree of danger and GPS coordinates of the impacted geographic area for a region. A vulnerability index determined using neural networks and fuzzy logic enables a prioritized message. The center broadcasts the message to remotely located warning devices, which compare the received danger coordinates with their own GPS coordinates and determine the extent to which they are in danger. Warning signals can issue automatically, appropriate to the degree of danger. Emergency manned vehicles may also directly receive the broadcast message and act appropriately relative to the degree of danger.",Danger warning and emergency response system and method
"The present invention relates to the analysis of data to identify relationships between the input data and one or more conditions. One method of analyzing such data is by the use of neural networks which are non-linear statistical data modelling tools, the structure of which may be changed based on information that is passed through the network during a training phase. A known problem that affects neural networks is the issue of overtraining which arises in overcomplex or overspecified systems when the capacity of the network significantly exceeds the needed parameters. The present invention provides a method of analyzing data using a neural network with a constrained architecture that mitigates the problems associated with the prior art.",Data analysis method and system
"A data communication apparatus comprises: means for dividing data to be transmitted into a plurality of blocks and extracting the data from each block; a first multi-layered neural network of three or more layers which has weighting coefficients to output the same data as the input data for the data extracted from each block and which can output data from an intermediate layer; the transmission data extracted from each block being inputted to the first neural network and outputted from the intermediate layer; means for encoding the transmission data which is outputted from the intermediate layer of the first neural network and, thereafter, transmitting; means for receiving and decoding the transmitted data; a second multi-layered neural network of three or more layers which has the same weight coefficients as those of the first neural network and can input data from an intermediate layer; the decoded data of each block being inputted to the second neural network and outputted from an output layer; and means for restoring the data on the basis of the output data from the output layer of the second neural network.",Data communication method and apparatus using neural-networks
"A method, computer program product, and system for sparse convolutional neural networks that improves efficiency is described. Multi-bit data for input to a processing element is received at a compaction engine. The multi-bit data is determined to equal zero and a single bit signal is transmitted from the memory interface to the processing element in lieu of the multi-bit data, where the single bit signal indicates that the multi-bit data equals zero. A compacted data sequence for input to a processing element is received by a memory interface. The compacted data sequence is transmitted from the memory interface to an expansion engine. Non-zero values are extracted from the compacted data sequence and zeros are inserted between the non-zero values by the expansion engine to generate an expanded data sequence that is output to the processing element.",Data compaction and memory bandwidth reduction for sparse neural networks
"This application discloses a neural network that also functions as a packet data network using an MPLS-type label switching technology. The neural network uses its intelligence to build and manage label switched paths (LSPs) to transport user packets and solve complex mathematical problems. This architecture is well suited to interconnect large numbers of processors or computers into a neural network exhibiting advanced intelligence which can be used for complex activities such as managing the power grid. However, the methods taught here can be applied to other data networks including ad-hoc, mobile, Information Centric, Content Centric, Sensor, and traditional IP packet networks, cell or frame-switched networks, time-slot networks and the like.",Data neural network system and method
"In a neural network which includes one input layer, one or more intermediate layers and one output layer, neural elements in the input layer and neural elements in the intermediate layer are divided into groups. Arithmetic operations representing the coupling between the neural elements of the input layer and the neural elements of the intermediate layer are put into table form.",Data processing using neural networks having conversion tables in an intermediate layer
"In a neural network which includes one input layer, one or more intermediate layers and one output layer, neural elements in the input layer and neural elements in the intermediate layer are divided into groups. Arithmetic operations representing the coupling between the neural elements of the input layer and the neural elements of the intermediate layer are put into table form.",Data processing using neural networks having conversion tables in an intermediate layer
"A system and method of computer data analysis using neural networks. In one embodiment of the invention, the system and method includes generating a data representation using a data set, the data set including a plurality of attributes, wherein generating the data representation includes: modifying the data set using a training algorithm, wherein the training algorithm includes growing the data set; and performing convergence testing, wherein convergence testing checks for convergence of the training algorithm, and wherein the modifying of the data set is repeated until convergence of the training algorithm occurs; and displaying one or more subsets of the data set using the data representation. In one embodiment, the data representation is a knowledge filter that includes a representation of an input data set. The representation may be constructed during a training process. In one exemplary embodiment, the training process uses unsupervised neural networks to create the data representation. In general terms, the data representation may include a number of coupled, or connected, hexagons called nodes. Considering relevant attributes, two nodes that are closer together may be more similar than two nodes that are further apart.",Data set modification using training algorithm that grows the data set
The present subject matter relates to methodologies for providing error correction compensation to measurement systems. Data-dependant jitter may be compensated by examining both short-term and long-term bit histories after applying a predetermined synthesized calibration pattern having selected characteristics to the measurement system. Neural networks may be provided to produce error correction signals that may be applied to measured data on a bit-by-bit basis to correct jitter. The synthesized calibration sequence may correspond to a base pattern having two segments; a first segment may correspond to a copy of the base pattern while the second segment may be a copy of the base pattern with some sections inverted.,Data-dependent jitter (DDJ) calibration methodology
"A method of operating a neural network includes determining a complexity, such as a number) of separable filters approximating a filter. The method further includes selectively applying a decomposed convolution to the filter based on the determined number of separable filters.",Decomposing convolution operation in neural networks
A method of training a neural network includes encouraging one or more filters in the neural network to have a low rank.,Decomposing convolution operation in neural networks
"Systems and methods are provided for automatically scoring a constructed response. The constructed response is processed to generate a plurality of numerical vectors that is representative of the constructed response. A model is applied to the plurality of numerical vectors. The model includes an input layer configured to receive the plurality of numerical vectors, the input layer being connected to a following layer of the model via a first plurality of connections. Each of the connections has a first weight. An intermediate layer of nodes is configured to receive inputs from an immediately-preceding layer of the model via a second plurality of connections, each of the connections having a second weight. An output layer is connected to the intermediate layer via a third plurality of connections, each of the connections having a third weight. The output layer is configured to generate a score for the constructed response.",Deep convolutional neural networks for automated scoring of constructed responses
"In some embodiments, techniques for synthesizing an image style based on a plurality of neural networks are described. A computer system selects a style image based on user input that identifies the style image. The computer system generates an image based on a generator neural network and a loss neural network. The generator neural network outputs the synthesized image based on a noise vector and the style image and is trained based on style features generated from the loss neural network. The loss neural network outputs the style features based on a training image. The training image and the style image have a same resolution. The style features are generated at different resolutions of the training image. The computer system provides the synthesized image to a user device in response to the user input.",Deep high-resolution style synthesis
"A local processing device contains a bus, an input interface and at least one cellular neural networks (CNN) based integrated circuit (IC). The input interface is receiving a 2-D symbol representing a Chinese poetry or verse. The 2-D symbol is a matrix of NN pixels of K-bit data that contains a super-character. The matrix is divided into MM sub-matrices each containing (N/M)(N/M) pixels. Each of the sub-matrices represents an ideogram. K, N and M are positive integers, and N is a multiple of M. CNN based IC is configured for understanding semantic meaning of the Chinese poetry or verse within the super-character contained in the 2-D symbol. The ideogram is created by embedded fonts of all of the characters contained in a corresponding phrase of the Chinese poetry or verse or is a pictogram representing artistic conception of each sentence of the Chinese poetry or verse.",Deep learning device for local processing classical chinese poetry and verse
"There is disclosed a system and method for training a set of expression and neutral convolutional neural networks using a single performance mapped to a set of known phonemes and visemes in the form predetermined sentences and facial expressions. Then, subsequent training of the convolutional neural networks can occur using temporal data derived from audio data within the original performance mapped to a set of professionally-created three dimensional animations. Thereafter, with sufficient training, the expression and neutral convolutional neural networks can generate facial animations from facial image data in real-time without individual specific training.",Deep learning-based facial animation for head-mounted display
"The technology disclosed relates to constructing a convolutional neural network-based classifier for variant classification. In particular, it relates to training a convolutional neural network-based classifier on training data using a backpropagation-based gradient update technique that progressively match outputs of the convolutional network network-based classifier with corresponding ground truth labels. The convolutional neural network-based classifier comprises groups of residual blocks, each group of residual blocks is parameterized by a number of convolution filters in the residual blocks, a convolution window size of the residual blocks, and an atrous convolution rate of the residual blocks, the size of convolution window varies between groups of residual blocks, the atrous convolution rate varies between groups of residual blocks. The training data includes benign training examples and pathogenic training examples of translated sequence pairs generated from benign variants and pathogenic variants.",Deep learning-based techniques for training deep convolutional neural networks
"Disclosed is a feature extraction and classification methodology wherein audio data is gathered in a target environment under varying conditions. From this collected data, corresponding features are extracted, labeled with appropriate filters (e.g., audio event descriptions), and used for training deep neural networks (DNNs) to extract underlying target audio events from unlabeled training data. Once trained, these DNNs are used to predict underlying events in noisy audio to extract therefrom features that enable the separation of the underlying audio events from the noisy components thereof.",Deep neural net based filter prediction for audio event classification and extraction
"A method and system for labeling a selected word of a sentence using a deep neural network includes, in one exemplary embodiment, determining an index term corresponding to each feature of the word, transforming the index term or terms of the word into a vector, and predicting a label for the word using the vector. The method and system, in another exemplary embodiment, includes determining, for each word in the sentence, an index term corresponding to each feature of the word, transforming the index term or terms of each word in the sentence into a vector, applying a convolution operation to the vector of the selected word and at least one of the vectors of the other words in the sentence, to transform the vectors into a matrix of vectors, each of the vectors in the matrix including a plurality of row values, constructing a single vector from the vectors in the matrix, and predicting a label for the selected word using the single vector.",Deep neural networks and methods for using same
"The use of a pipelined algorithm that performs parallelized computations to train deep neural networks (DNNs) for performing data analysis may reduce training time. The DNNs may be one of context-independent DNNs or context-dependent DNNs. The training may include partitioning training data into sample batches of a specific batch size. The partitioning may be performed based on rates of data transfers between processors that execute the pipelined algorithm, considerations of accuracy and convergence, and the execution speed of each processor. Other techniques for training may include grouping layers of the DNNs for processing on a single processor, distributing a layer of the DNNs to multiple processors for processing, or modifying an execution order of steps in the pipelined algorithm.",Deep neural networks training for speech and pattern recognition
"Systems, methods, and non-transitory computer-readable media are disclosed for segmenting objects in digital visual media utilizing one or more salient content neural networks. In particular, in one or more embodiments, the disclosed systems and methods train one or more salient content neural networks to efficiently identify foreground pixels in digital visual media. Moreover, in one or more embodiments, the disclosed systems and methods provide a trained salient content neural network to a mobile device, allowing the mobile device to directly select salient objects in digital visual media utilizing a trained neural network. Furthermore, in one or more embodiments, the disclosed systems and methods train and provide multiple salient content neural networks, such that mobile devices can identify objects in real-time digital visual media feeds (utilizing a first salient content neural network) and identify objects in static digital images (utilizing a second salient content neural network).",Deep salient content neural networks for efficient digital object segmentation
"A Convolutional Neural Network (CNN) includes an initial set of convolutional layers and max pooling units, in which any input is convoluted with the learned image filters and the output is a stack of the different filter responses. Max pooling produces a scaled version of the output. The process can be repeated several times, resulting in a stack of space invariant-scaled images. Since the operation is space invariant, the computations of these layers not need to be recomputed if interested just in certain regions of the image. A Region Of Interest (ROI) Pooling layer is used to select regions to be processed by the set of fully connected layers, which uses the response of the multiple convolutional layers of the network to determine the regions where the objects (of different scales) could be located. This object proposal method is implemented as a Region Of Interest (ROI) Selector.",Deeply learned convolutional neural networks (CNNS) for object localization and classification
"A defect inspection apparatus for inspecting an object to be inspected for a defect by processing an image taken from the object, includes: neural networks provided respectively for individual defect types to be classified; a learning unit which makes the neural networks learn based on the corresponding defect types to be classified; and a defect detection unit which classifies and detects defect types using the neural networks that have learned.",Defect inspection apparatus
"Embodiments of end-to-end deep learning systems and methods are disclosed to recognize speech of vastly different languages, such as English or Mandarin Chinese. In embodiments, the entire pipelines of hand-engineered components are replaced with neural networks, and the end-to-end learning allows handling a diverse variety of speech including noisy environments, accents, and different languages. Using a trained embodiment and an embodiment of a batch dispatch technique with GPUs in a data center, an end-to-end deep learning system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",Deployed end-to-end speech recognition
"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. While operating in either mode, an array of sensors can be used to pilot the vehicle including stereo cameras and 3D sensors. Stereo camera and 3D sensors can also be employed to assist occupants while piloting vehicles. Deep convolutional neural networks can be employed to determine estimated depth maps from stereo images of scenes in real time for vehicles in autonomous and occupant piloted modes.",Depth map estimation with stereo images
"The present invention extends to methods, systems, and computer program products for detecting available parking spaces in a parking environment. Radar systems are utilized to gather data about a parking lot environment. The radar data is provided to a neural network model as an input. Algorithms employing neural networks can be trained to recognize parked vehicles and conflicting data regarding debris, shopping carts, street lamps, traffic signs, pedestrians, etc. The neural network model processes the radar data to estimate parking space boundaries and to approximate the parking space boundaries as splines. The neural network model outputs spline estimations to a vehicle computer system. The vehicle computer system utilizes the spline estimates to detect available parking spaces. The spline estimates are updated as the vehicle navigates the parking environment.",Detecting available parking spaces
"A method includes generating an index representation of characters of code of a given file and mapping the index representation to a vector space providing contextual representation of the characters utilizing an embedding layer of a recurrent neural network (RNN). The method also includes identifying one or more code features in the mapped index representation utilizing at least one hidden layer of the RNN, detecting sequences of the identified code features in the mapped index representation utilizing a plurality of memory units of a recurrent layer of the RNN, and generating a classification result for the given file based on the detected sequences of code features utilizing one or more classification layers of the RNN. The method further comprises utilizing the classification result to determine if the given file contains code of a designated code type, and modifying access by a given client device to the given file responsive to the determination.",Detecting code obfuscation using recurrent neural networks
"The present invention extends to methods, systems, and computer program products for detecting, classifying, and tracking abnormal data in a data stream. Embodiments include an integrated set of algorithms that enable an analyst to detect, characterize, and track abnormalities in real-time data streams based upon historical data labeled as predominantly normal or abnormal. Embodiments of the invention can detect, identify relevant historical contextual similarity, and fuse unexpected and unknown abnormal signatures with other possibly related sensor and source information. The number, size, and connections of the neural networks all automatically adapted to the data. Further, adaption appropriately and automatically integrates unknown and known abnormal signature training within one neural network architecture solution automatically. Algorithms and neural networks architecture are data driven, resulting more affordable processing. Expert knowledge can be incorporated to enhance the process, but sufficient performance is achievable without any system domain or neural networks expertise.","Detecting, classifying, and tracking abnormal data in a data stream"
"A transformed image is received. The transformed image includes an other-than-visible light image that has been captured using a transformation device. A region of the transformed image is isolated, the region being less than an entirety of the transformed image. By applying to the region a convolutional Neural Network (CNN) which executes using a processor and a memory, and by processing only the region of the transformed image, an object of interest is detected in the region. Upon detecting, an indication is produced to indicate the presence of the object of interest in the region.",Detection of objects in images using region-based convolutional neural networks
"The overall invention categorizes patients with suspected acute myocardial infarction (AMI) with regard to a) AMI/non-AMI; b) infarct size (e.g. Major/Minor); c) time since onset of infarction; and d) non-AMI with/without minor myocardial damage (MMD). Generally, the above categorization is based on frequent timed blood sampling and measurement of selected biochemical markers of AMI with different rates of appearance in circulating blood. The computations are performed by using specially designed artificial neural networks. According to a first main aspect of the invention, early, i.e. generally within 3 hours from admission of the patient, detection/exclusion of acute myocardial infarction is provided. Furthermore, early prediction of the infarct size and early estimation of the time from onset are also provided.",Detection/exclusion of acute myocardial infarction using neural network analysis of measurements of biochemical markers
"In one embodiment, a method includes receiving an image on a computing device. The computing device may further execute a weakly-supervised classification algorithm to determine whether a target feature is present in the received image. As an example, the weakly-supervised classification algorithm may determine whether a building is depicted in the received image. In response to determining that a target feature is present, the method further includes using a weakly-supervised segmentation algorithm of the convoluted neural network to segment the received image for the target feature. Based on a determined footprint size of the target feature, a distribution of statistical information over the target feature in the image can be calculated.",Determination of population density using convoluted neural networks
"Methods, apparatus, and systems are provided for measuring the supply of a consumable product/energy source, such as electrical power, to a facility over time and analyzing the measurements to determine the consumption or supply of the product by one or more loads and/or sources in the facility, and to determine induced and residual heat flow through the facility's envelope. Various aspects compare the measured supply of the consumable product to a database of consumption signatures, which characterize access to the consumable product by particular users. In doing so, costs for the product may be more accurately divided between different tenants of the facility without having to install individual services or measurement equipment for each individual tenant. Operating conditions and facility characteristics, such as temperatures, load factors, insulation factors, etc., may be further considered in determining a particular user's access of the consumable product. To aid in the controlling of energy use, thermal resistance factors of the building are determined, which are based on the induced and residual heat flow through the facility. Various algorithms are used including smart agents (e.g. neural networks) to determine the consumption of the consumable product by a particular user, to create the database of consumption signatures, and to determine the thermal resistance factors.",Determining energy consumption in a structure
"Systems and methods can include training a deep convolutional neural network model to provide a beam model for a radiation machine, such as to deliver a radiation treatment dose to a subject. A method can include determining a range of parameter values for at least one parameter of a beam model corresponding to the radiation machine, generating a plurality of sets of beam model parameter values, wherein one or more individual sets of beam model parameter values can include a parameter value selected from the determined range of parameter values, providing a plurality of corresponding dose profiles respectively corresponding to respective individual sets beam model parameter values in the plurality of sets of beam model parameter values, and training the neural network model using the plurality of beam models and the corresponding dose profiles.",Determining parameters for a beam model of a radiation machine using deep convolutional neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for disambiguating word sense. One of the methods includes maintaining a respective word sense numeric representation of each of a plurality of word senses of a particular word; receiving a request to determine the word sense of the particular word when included in a particular text sequence, the particular text sequence comprising one or more context words and the particular word; determining a context numeric representation of the context words in the particular text sequence; and selecting a word sense of the plurality of word senses having a word sense numeric representation that is closest to the context numeric representation as the word sense of the particular word when included in the particular text sequence.",Determining word senses using neural networks
"Based on the encoding of deterministic finite-state automata (DFA) in discrete-time, second-order recurrent neural networks, an algorithm constructs an augmented recurrent neural network that encodes a FFA and recognizes a given fuzzy regular language with arbitrary accuracy.",Deterministic encoding of fuzzy finite state automata in continuous recurrent neural networks
"Neural networks are used to classify objects automatically by means of Doppler-broadened radar echo signals. The classification device KK contains a neural network (NET, NET2) which has an input layer (IL) of input nodes (IN1, . . . , IN57) for features (M) of the Doppler-broadened radar echo signals, and an output layer (OL) of output nodes (ON1, ON2, ON3) for predetermined classes to which the objects can be allocated. The neural network (NET, NET2) is adapted to the external conditions prevailing at the time of the classification operation. The adaptation takes place either via accessible input nodes (ZN1, ZN2) into which control information (SI) can be entered, and which cause the neural network (NET) to adapt to one or to several external influence factors, or via a selection device (SEL) which, from the parameters (P1, . . . , P4) of several neural networks stored in a memory (MEM), which are trained with training data under respectively different conditions of external influence factors, selects the one most similar to the prevailing conditions.",Device and method for classifying objects in an environmentally adaptive manner
"A device for distributing resources of a given physical network among logical links by subdividing physical link capacities into logical links using an algorithm. The device comprises a first neural network, in which one part of the algorithm is implemented, and a second neural network, in which a second part of the algorithm is implemented, said two neural networks interworking to compute logical link capacities. Furthermore, a method for distributing resources of a given physical network among logical links by subdividing physical link capacities into said logical links is provided. More specifically, the method involves the use of a first neural network, in which one part of an algorithm is implemented, and a second neural network, in which a second part of an algorithm is implemented, said two neural networks interworking to compute logical link capacities so that the operation of the physical network, given an objective function, is generally optimized, according to the objective function.",Device and method for determining a distribution of resources of a physical network
"An anomalous effect detector responsive to an influence of mind comprises a source of non-deterministic random numbers, SNDRN, a phase-sensitive filter and a results interface. In some embodiments, the phase-sensitive filter comprises a complex filter. An artificial sensory neuron comprises a SNDRN. Preferably, several artificial sensory neurons are grouped in a small volume. An analog artificial sensory detector comprises a plurality of analog artificial sensory neurons, an abstracting processor and a control or feedback unit. Some embodiments include an artificial neural network. An artificial consciousness network contains a plurality of artificial neural networks. One of the artificial neural networks comprises an activation pattern meta-analyzer. An artificial consciousness device comprises a cluster of artificial consciousness networks, a sensory input device to provide sensory input signals to the input of one or more ANNs in ACD, and an output device.",Device and method responsive to influences of mind
"The invention relates to a device for designing a neural network, in which to determine the number of neurons (21 . . . 24) in the intermediate layer, the domain of the input signal (X1, X2) in question is subdivided into a predefinable number of subdomains, and in the case of a multiplicity n of input signals (X1, X2), the n-dimensional value space of the n input signals is subdivided in conformance with the subdomains in question into n-dimensional partial spaces, and the supporting values (xi, yi) of the training data are assigned to the subdomains or partial spaces, and the subdomains or partial spaces having the most supporting values are selected, and in which case, for each selected subdomain or partial space, provision is made for a neuron in the intermediate layer preceding the output layer. The device according to the invention can be advantageously used for designing neural networks where the training data are unevenly distributed. The invention is generally suited for applications in neural networks.",Device for designing a neural network and neural network
"The present disclosure relates to a processor for implementing artificial neural networks, for example, convolutional neural networks. The processor includes a memory controller group, an on-chip bus and a processor core, wherein the processor core further includes a register map, a first instruction unit, a second instruction unit, an instruction distributing unit, a data transferring controller, a buffer module and a computation module. The processor of the present disclosure may be used for implementing various neural networks with increased computation efficiency.",Device for implementing artificial neural network with multiple instruction units
"A discovery system employing a neural network, training within this system, that is stimulated to generate novel output patterns through various forms of perturbation applied to it, a critic neural network likewise capable of training in situ within this system, that learns to associate such novel patterns with their utility or value while triggering reinforcement learning of the more useful or valuable of these patterns within the former net. The device is capable of bootstrapping itself to progressively higher levels of adaptive or creative competence, starting from no learning whatsoever, through cumulative cycles of experimentation and learning. Optional feedback mechanisms between the latter and former self-learning artificial neural networks are used to accelerate the convergence of this system toward useful concepts or plans of action.",Device for the autonomous bootstrapping of useful information
"A venue system of a client device can submit a location request to a server, which returns multiple venues that are near the client device. The client device can use one or more machine learning schemes (e.g., convolutional neural networks) to determine that the client device is located in one of specific venues of the possible venues. The venue system can further select imagery for presentation based on the venue selection. The presentation may be published as ephemeral message on a network platform.",Device location based on machine learning classifications
"A venue system of a client device can submit a location request to a server, which returns multiple venues that are near the client device. The client device can use one or more machine learning schemes (e.g., convolutional neural networks) to determine that the client device is located in one of specific venues of the possible venues. The venue system can further select imagery for presentation based on the venue selection. The presentation may be published as ephemeral message on a network platform.",Device location based on machine learning classifications
Aspects of data compression/decompression for neural networks are described herein. The aspects may include a model data converter configured to convert neural network content values into pseudo video data. The neural network content values may refer to weight values and bias values of the neural network. The pseudo video data may include one or more pseudo frames. The aspects may further include a compression module configured to encode the pseudo video data into one or more neural network data packages.,"Devices for compression/decompression, system, chip, and electronic device"
"Devices and methods for transmitting neural signals from a proximal stump of a transected nerve to a prosthetic apparatus are disclosed employing microelectrodes, preferably conductive fiber networks, capable of sensing electrical signals from a nerve and transmitting such signals to a prosthetic apparatus; and a semipermeable guidance channel disposed about the microelectrodes. The channels include an opening adapted to receive the proximal stump of a transected nerve, such that the channel promotes the growth of the stump and the formation of an electrical connection between the transected nerve and the microelectrode.",Devices for neural signal transmission
"A defined zero point voltage (V.sub.0), dependent on a settable zero point voltage target value (V.sub.0,soll), is enabled in amplifier stages (1 . . . k) with neuron MOS transistors (T10,1 . . . T10,k). This is generally required because, for example, due to a process-caused charging of the floating gates of the neuron MOS transistors, and due to a capacitively coupled-in voltage from the channel region, an undefined zero point displacement of the transmission characteristic curve results. The devices can be used together with the amplifier stages, e.g. in video and audio technology, in sensor technology, in analog computers, in fuzzy circuits and in neural networks.",Devices for the self-adjusting setting of the operating point in amplifier circuits with neuron MOS transistors
"A user identification system includes an image recognition network to analyze image data and generate shape data based on the image data. The system also includes a generalist network to analyze the shape data and generate general category data based on the shape data. The system further includes a specialist network to compare the general category data with a characteristic to generate narrow category data. Moreover, the system includes a classifier layer including a plurality of nodes to represent a classification decision based on the narrow category data.","Devices, methods and systems for biometric user recognition utilizing neural networks"
"Control of a process in accordance with both optimal process values (t.sub.d), which may be fixed or slowly varying, and actual process output values (t.sub.r-1) generated during a previous interval (r-1) is accomplished by a differential process controller (10). The controller (10) employs two artificial neural networks (36 and 38), each generating a separate intermediate control vector for controlling the process in accordance with a separate one of the vectors t.sub.d and t.sub.r-1. A first summing amplifier (42) computes the difference between the intermediate control vectors and generates a differential control vector which varies accordingly. A second summing amplifier (44) sums the differential control vector, together with the output signal of the summing amplifier generated during the immediately previous interval (r-1), to generate a control signal c.sub.r for controlling the process.",Differential process controller using artificial neural networks
"A maximum-likelihood sequence estimator receiver includes a matched filter connected to a digital transmission channel and a sampler for providing sampled signals output by the matched filter. The sampled signals are input to an analog neural network to provide high-speed outputs representative of the transmission channel signals. The neural network outputs are also provided as inputs to a coefficient estimator which produces coefficients for feedback to the matched filter. For time-varying transmission channel characteristics, the coefficient estimator provides a second coefficient output which is utilized for changing the interconnection strengths of the neural network connection matrix to offset the varying transmission channel characteristics.",Digital adaptive receiver employing maximum-likelihood sequence estimation with neural networks
"Plural-bit digital input signals to be subjected to weighted summation are bit-sliced; and a number N of respective first through N.sup.th weighted summations of the bits of the digital input signals in each bit slice are performed, resulting in a respective set of first through N.sup.th partial weighted summation results. Each weighted summation of a bit slice of the digital input signals is performed using a capacitive network that generates partial weighted summation results in the analog regime; and analog-to-digital conversion circuitry digitizes the partial weighted summation results. Weighted summations of the digitized partial weighted summation results of similar ordinal number are then performed to generate first through N.sup.th final weighted summation results in digital form, which results are respective correlations of the pattern of the digital input signals with the patterns of weights established by the capacitive networks. A neural net layer can be formed by combining such weighted summation circuitry with digital circuits processing each final weighted summation result non-linearly, with a system function that is sigmoidal.",Digital correlators incorporating analog neural network structures operated on a bit-sliced basis
"According to an example, a digital image may be processed by an ensemble of convolutional neural networks (CNNs) to classify objects in the digital image. For each CNN, a candidate architecture and candidate parameters may be selected to build a plurality of CNNs. Once it is determined that a predetermined number of CNNs, each having different values for the selected candidate parameters, meet a validation threshold, an ensemble of CNNs may be generated from the predetermined number of CNNs. The predictions from the ensemble of CNNs may then be aggregated to accurately classify the objects in the digital image.",Digital image processing using convolutional neural networks
"Digital integrated circuit (IC) for extracting features out of input image is disclosed. The IC contains one or more identical cellular neural networks (CNN) processing engines operatively coupled to at least one I/O data bus. Each CNN processing engine includes a CNN processing block, a first set of memory buffers for storing imagery data and a second set of memory buffers for storing filter coefficients. CNN processing block is configured to simultaneously perform 33 convolutions at MM pixel locations using received imagery data and corresponding filter coefficients. Imagery data represents a (M+2)-pixel by (M+2)-pixel region of the input image. CNN processing block further performs rectification and/or 22 pooling operations as directed. When two or more CNN processing engines are configured on the IC, CNN processing engines are connected to one another as a loop via a clock-skew circuit for cyclic data access. M is a positive integer.",Digital integrated circuit for extracting features out of an input image based on cellular neural networks
"Direct-bonded native interconnects and active base dies are provided. In a microelectronic architecture, active dies or chiplets connect to an active base die via their core-level conductors. These native interconnects provide short data paths, which forgo the overhead of standard interfaces. The system saves redistribution routing as the native interconnects couple in place. The base die may contain custom logic, allowing the attached dies to provide stock functions. The architecture can connect diverse interconnect types and chiplets from various process nodes, operating at different voltages. The base die may have state elements for drive. Functional blocks aboard the base die receive native signals from diverse chiplets, and communicate with all attached chiplets. The chiplets may share processing and memory resources of the base die. Routing blockages are minimal, improving signal quality and timing. The system can operate at dual or quad data rates. The architecture facilitates ASIC, ASSP, and FPGA ICs and neural networks, reducing footprint and power requirements.",Direct-bonded native interconnects and active base die
"A discriminant neural network and a method of training the network are disclosed. The network includes a set of hidden nodes having associated weights, and the number of hidden nodes is minimized by the training method of the invention. The training method includes the steps of 1) loading a training data set and assigning it to a residual data set, 2) computing a vector associated with a first hidden node using the residual data set, 3) projecting training data onto a hyperplane associated with said first hidden node, 4) determining the number and locations of hard-limiter thresholds associated with the first node, and 5) repeating the above for successive hidden nodes after removing satisfied subsets from the training data until all partitioned regions of the input data space are satisfied.",Discriminant neural networks
"Discriminative pretraining technique embodiments are presented that pretrain the hidden layers of a Deep Neural Network (DNN). In general, a one-hidden-layer neural network is trained first using labels discriminatively with error back-propagation (BP). Then, after discarding an output layer in the previous one-hidden-layer neural network, another randomly initialized hidden layer is added on top of the previously trained hidden layer along with a new output layer that represents the targets for classification or recognition. The resulting multiple-hidden-layer DNN is then discriminatively trained using the same strategy, and so on until the desired number of hidden layers is reached. This produces a pretrained DNN. The discriminative pretraining technique embodiments have the advantage of bringing the DNN layer weights close to a good local optimum, while still leaving them in a range with a high gradient so that they can be fine-tuned effectively.",Discriminative pretraining of deep neural networks
"Discriminative pretraining technique embodiments are presented that pretrain the hidden layers of a Deep Neural Network (DNN). In general, a one-hidden-layer neural network is trained first using labels discriminatively with error back-propagation (BP). Then, after discarding an output layer in the previous one-hidden-layer neural network, another randomly initialized hidden layer is added on top of the previously trained hidden layer along with a new output layer that represents the targets for classification or recognition. The resulting multiple-hidden-layer DNN is then discriminatively trained using the same strategy, and so on until the desired number of hidden layers is reached. This produces a pretrained DNN. The discriminative pretraining technique embodiments have the advantage of bringing the DNN layer weights close to a good local optimum, while still leaving them in a range with a high gradient so that they can be fine-tuned effectively.",Discriminative pretraining of deep neural networks
"One embodiment of a speech recognition system is organized with speech input signal preprocessing and feature extraction followed by a fuzzy matrix quantizer (FMQ). Frames of the speech input signal are represented by a vector .function. of line spectral pair frequencies and are fuzzy matrix quantized to respective a vector .function. entries in a codebook of the FMQ. A distance measure between .function. and .function., d(.function.,.function.), is defined as ##EQU1## where the constants .alpha..sub.1, a.sub.2, .beta..sub.1 and .beta..sub.2 are set to substantially minimize quantization error, and e.sub.i is the error power spectrum of the speech input signal and a predicted speech input signal at the ith line spectral pair frequency of the speech input signal. The speech recognition system may also include hidden Markov models and neural networks, such as a multilevel perceptron neural network, speech classifiers.",Distance measure in a speech recognition system for speech recognition using frequency shifting factors to compensate for input signal frequency shifts
"In one embodiment, a matrix operation associated with a plurality of input matrices may be performed. The plurality of input matrices may be partitioned into a plurality of input partitions, wherein the plurality of input matrices is partitioned based on a number of available processing elements. The plurality of input partitions may be distributed among a plurality of processing elements, wherein each input partition is distributed to a particular processing element of the plurality of processing elements. A plurality of partial matrix operations may be performed using the plurality of processing elements, and partial matrix data may be transmitted between the plurality of processing elements while performing the plurality of partial matrix operations. A result of the matrix operation may be determined based on the plurality of partial matrix operations.",Distributed matrix multiplication for neural networks
"A distributed stress wave analysis system is disclosed for detecting structure borne sounds cause by friction. The detected information is processed using feature extraction and neural network artificial intelligence software. The system consists of stress wave sensors, interconnect cables, and preferably three modules: (1) distributed processing units, (2) maintenance advisory panel, and (3) laptop computer. A derived stress wave pulse train which is independent of background levels of vibration and audible noise is used to extract signature features, which when processed by neural networks of polynomial equations, characterize the mechanical health of the monitored components. The system includes an adjustable data fusion architecture to optimize indication thresholds, maximize fault detection probability, and minimize false alarms.",Distributed stress wave analysis system
"A divide-and-conquer (DAC) method and system improve the detection of abnormalities, like lung nodules, in radiological images via the use of zone-based digital image processing and artificial neural networks. The DAC method and system divide the lung zone into different zones in order to enhance the efficiency in detection. Different image enhancement techniques are used for each different zone to enhance nodule images, as are different zone-specific techniques for selecting suspected abnormalities, extracting image features corresponding to selected abnormalities, and classifying the abnormalities as either true or false abnormalities.",Divide-and-conquer method and system for the detection of lung nodule in radiological images
"This invention is an oligomer-based analog neural network (ANN) comprising weight and saturation oligomers, the concentrations of which are selected such that activation of the ANN by a set of input oligomers generates a set of output oligomers, the sequences and relative concentrations of which are dependent on the sequences and relative concentrations of the input oligomers. The invention further includes methods for using such an ANN for solving any problems amenable to solution by a trained neural network. A preferred embodiment of the claimed invention is a DNA-based ANN that accepts cDNA molecules as inputs and analyzes the gene expression profile of the cells from which the cDNA is derived. The DNA-based ANN is typically trained with a computer to identify the weights giving accurate mapping of the inputs to the outputs; and the concentrations of weight oligomers of the DNA-based ANN are then selected accordingly.",DNA-based analog neural networks
"A docking station for use with an environmental monitoring instrument to provide predictive diagnostic information. The docking station is connected, typically via the Internet, to a remote service center, and exposure data, calibration data and diagnostic data are communicated from the instrument to the docking station and from the docking station to the service center. Mathematical analysis of the collected data from all available sources is performed at the service center and predictive warnings are generated to alert the users of potential instrument faults, thus allowing preemptive maintenance. The analysis methods include principle component analysis and other statistical methods, fuzzy logic and neural networks. This docking station can be used with monitoring instruments for water quality, pollution control, indoor air quality and breathing air quality.",Docking station for environmental monitoring instruments
"Methods are provided for downhole sensing and flow control utilizing neural networks. In a described embodiment, a temporary sensor is positioned downhole with a permanent sensor. Outputs of the temporary and permanent sensors are recorded as training data sets. A neural network is trained using the training data sets. When the temporary sensor is no longer present or no longer operational in the well, the neural network is capable of determining the temporary sensor's output in response to the input to the neural network of the permanent sensor's output.",Downhole sensing and flow control utilizing neural networks
"A parallel architecture matrix algebraic processing system exhibits patterns of arrayed (i) light transmitters and (ii) light receivers that are identical, but at differing scales. Planar arrays of one or more optoelectronic processors--principally semiconductor chips or chip arrays--having both computational and light input/output capabilities optically communicate from one plane to the next through free-space space-invariant optical data distributions--principally lenses and computer-generated holograms--having both replication and distribution capabilities. Each optoelectronic processor, or OP, consists of a number of arrayed optoelectronic processing elements, or OPEs. The OPEs, in turn, typically consist of a number of optoelectronic sub-processing units are preferably electrically interconnected in a tree-based structure, preferably an H-tree. Leaf units include typically one light detector plus local memory, logic circuitry, and electrical input/output. Fanning units typically include local memory, logic circuitry, and electrical input/output. A root unit typically includes electrically-connected local memory, logic circuitry, electrical input/output, and a light transmitter. Vector results of algebraic computations and combinations are flexibly performable in the units of each OPE, and variously optically distributable to other OPEs in successive OPs. The versatile algebraic vector manipulations and vector distributions support primitive functions such as intrinsic and extrinsic vector outer products; operations such as vector-matrix multiplication; and complex systems such as neural networks, fuzzy logic and relational databases. A system of .gtoreq.10.sup.3 fully optically communicating OPEs achieves capacities of 10.sup.6 -10.sup.8 interconnects, and processing speeds of 10.sup.12 interconnects/second.",Dual-scale topology optoelectronic matrix algebraic processing system
"Systems, methods, and apparatus, including computer programs encoded on a computer storage medium, for selecting an actions from a set of actions to be performed by an agent interacting with an environment. In one aspect, the system includes a dueling deep neural network. The dueling deep neural network includes a value subnetwork, an advantage subnetwork, and a combining layer. The value subnetwork processes a representation of an observation to generate a value estimate. The advantage subnetwork processes the representation of the observation to generate an advantage estimate for each action in the set of actions. The combining layer combines the value estimate and the respective advantage estimate for each action to generate a respective Q value for the action. The system selects an action to be performed by the agent in response to the observation using the respective Q values for the actions in the set of actions.",Dueling deep neural networks
""" The present invention provides an apparatus for decoding and classifying a digital audio input signal and for reconstructing the digital audio input signal, so that when the reconstructed signal is converted to an analog signal by a digital to analog converter (""""DAC""""), the analog signal can drive a preamplifier, power amplifier or speakers directly. In particular, the present invention proposes a digital filter than can be adapted to have appropriate filtering characteristics based on the signal being filtered. The invention uses a neural network to adjust coefficients of a digital filter, depending on whether the digital audio input signal is more periodic or more aperiodic. If the digital audio input signal is more periodic, the coefficients will configure the digital filter so that the filter has the characteristics of an analog brickwall filter. Whereas if the digital audio input signal is more aperiodic, the coefficients produced by the neural network will configure the digital filter to have more characteristics of an interpolation filter. The neural network is trained to recognize certain periodic and aperiodic signals and to produce digital filter parameters, preferably polynomial coefficients, correspondingly. The coefficients are selected to respond to the pure or blended periodic and aperiodic features of certain archetypal input signals. """,Dynamic digital filter using neural networks
"Dynamically filtering and classifying messages, as good messages, bulk periodicals, or spam. A regular expression recognizer, and pre-trained neural networks. The neural networks distinguish likely good from likely spam, and also operate at a more discriminating level to distinguish among the three categories above. A dynamic whitelist and blacklist; sending addresses are collected when the number of their messages indicates the sender is good or a spammer. A dynamically selected set of regular expressions input to the neural networks.",Dynamic message filtering
"Dynamically filtering and classifying messages, as good messages, bulk periodicals, or spam. A regular expression recognizer, and pre-trained neural networks. The neural networks distinguish likely good from likely spam, and also operate at a more discriminating level to distinguish among the three categories above. A dynamic whitelist and blacklist; sending addresses are collected when the number of their messages indicates the sender is good or a spammer. A dynamically selected set of regular expressions input to the neural networks.",Dynamic message filtering
"An adaptative source rate control method and apparatus utilizing a neural network are presented for controlling a data transmission of a media object over a communication network. A back propagation method transmitting control parameters related to the operation of a communications network is used for to dynamically adjust the performance of the network, in view of network parameters being sourced to a point of transmission. The bit rate and quantization level of the data stream are dynamically adjusted and shaped by the neural network in response to control parameters.",Dynamic rate adaptation using neural networks for transmitting video data
An information processing system having signal processors that are interconnected by processing junctions that simulate and extend biological neural networks. Each processing junction receives signals from one signal processor and generates a new signal to another signal processor. The response of each processing junction is determined by internal junction processes and is continuously changed with temporal variation in the received signal. Different processing junctions connected to receive a common signal from a signal processor respond differently to produce different signals to downstream signal processors. This transforms a temporal pattern of a signal train of spikes into a spatio-temporal pattern of junction events and provides an exponential computational power to signal processors. Each signal processing junction can receive a feedback signal from a downstream signal processor so that an internal junction process can be adjusted to learn certain characteristics embedded in received signals.,Dynamic synapse for signal processing in neural networks
An information processing system having signal processors that are interconnected by processing junctions that simulate and extend biological neural networks. Each processing junction receives signals from one signal processor and generates a new signal to another signal processor. The response of each processing junction is determined by internal junction processes and is continuously changed with temporal variation in the received signal. Different processing junctions connected to receive a common signal from a signal processor respond differently to produce different signals to downstream signal processors. This transforms a temporal pattern of a signal train of spikes into a spatio-temporal pattern of junction events and provides an exponential computational power to signal processors. Each signal processing junction can receive a feedback signal from a downstream signal processor so that an internal junction process can be adjusted to learn certain characteristics embedded in received signals.,Dynamic synapse for signal processing in neural networks
"A technique of scoring a query against a document using sequence to sequence neural networks. The technique comprises: receiving a query comprising a plurality of words from a user; performing a search for a document comprising words based on the query; feeding the words of the document as the input of an encoder of a multilayer sequence to sequence converter; generating a plurality of vectors at a decoder of the multilayer sequence to sequence converter, each vector comprising a probability associated with a respective word in the query; looking up in the respective vector each word's probability of being associated with the document; multiplying every word's probability together to determine an overall probability of the query being associated with the document; and returning the document to the user if the overall probability of the query being associated with the document is greater than a threshold value.",Dynamic tensor attention for information retrieval scoring
A coprocessor and method for processing convolutional neural networks includes a configurable input switch coupled to an input. A plurality of convolver elements are enabled in accordance with the input switch. An output switch is configured to receive outputs from the set of convolver elements to provide data to output branches. A controller is configured to provide control signals to the input switch and the output switch such that the set of convolver elements are rendered active and a number of output branches are selected for a given cycle in accordance with the control signals.,"Dynamically configurable, multi-ported co-processor for convolutional neural networks"
"Dynamically updating neural network systems may be implemented to generate, train, evaluate and update artificial neural network data structures used by content distribution networks. Such systems and methods described herein may include generating and training neural networks, using neural networks to perform predictive analysis and other decision-making processes within content distribution networks, evaluating the performance of neural networks, and generating and training pluralities of replacement candidate neural networks within cloud computing architectures and/or other computing environments.",Dynamically updated neural network structures for content distribution networks
"Systems and methods achieving scalable and efficient connectivity in neural algorithms by re-calculating network connectivity in an event-driven way are disclosed. The disclosed solution eliminates the storing of a massive amount of data relating to connectivity used in traditional methods. In one embodiment, a deterministic LFSR is used to quickly, efficiently, and cheaply re-calculate these connections on the fly. An alternative embodiment caches some or all of the LFSR seed values in memory to avoid sequencing the LFSR through all states needed to compute targets for a particular active neuron. Additionally, connections may be calculated in a way that generates neural networks with connections that are uniformly or normally (Gaussian) distributed.",Efficient and scalable systems for calculating neural network connectivity in an event-driven way
"Systems and methods for efficient implementation of a convolutional layer of a convolutional neural network are disclosed. In one aspect, weight values of kernels in a kernel stack of a convolutional layer can be reordered into a tile layout with tiles of runnels. Pixel values of input activation maps of the convolutional layer can be reordered into an interleaved layout comprising a plurality of clusters of input activation map pixels. The output activation maps can be determined using the clusters of the input activation map pixels and kernels tile by tile.",Efficient data layouts for convolutional neural networks
"The present invention provides a circuit arrangement to convert fixed, or grounded resistors, to floating resistors. In particular, the circuit arrangement provides for the coupling of active electrical resistance devices to provide a relatively high value electrical resistance between two non-grounded nodes of the circuit arrangement in the order of Giga-ohms. The invention further provides for the magnitude of the floating electrical resistance to be determined by the magnitude of electrical current supply thus providing a means to select the magnitude of the floating electrical resistance by selecting by selecting the magnitude of electrical current supply. The circuit arrangement requires relatively few active devices and consumes a relatively small amount of electrical power in operation. The floating resistor of the present invention may be used in applications where a relatively high value resistor consuming a relatively small area of silicon, exhibiting relatively good linearity and wide dynamic range are required. Applications for such a device include neural networks, image processing and vision systems.",Electrically controlled very high value floating CMOS resistor
An electrochemical synapse adapted for use in a neural network which includes an input terminal and an output terminal located at a distance of less than 100 microns from the input terminal. A permanent interconnect having controllable conductivity is located between the two inputs. The conductivity of the permanent interconnect is controlled by either growing or eliminating metallic whiskers between the inputs. The growth and elimination of whiskers provides a rapid and controllable electrochemical synapse. Partial neural network systems are disclosed utilizing the electrochemical synapse.,Electrochemical synapses for artificial neural networks
"Systems and methods for altering neurite growth are generally described. In some embodiments, a system may include a neuron comprising a neurite and electrodes able to generate a physical guidance cue. The physical guidance cue may be used to alter the growth of the neurite and may be temporally and spatially dynamic, such that neurite growth may be altered in a spatial and/or temporal manner. Dynamic control of neurite growth may be used to form directional neural connections, intersections, and/or overlaps.",Electrokinetic confinement of neurite growth for dynamically configurable neural networks
"Systems and methods for altering neurite growth are generally described. In some embodiments, a system may include a neuron comprising a neurite and electrodes able to generate a physical guidance cue. The physical guidance cue may be used to alter the growth of the neurite and may be temporally and spatially dynamic, such that neurite growth may be altered in a spatial and/or temporal manner. Dynamic control of neurite growth may be used to form directional neural connections, intersections, and/or overlaps.",Electrokinetic confinement of neurite growth for dynamically configurable neural networks
"Neuromorphic circuits are multi-cell networks configured to imitate the behavior of biological neural networks. A neuromorphic circuit is provided which comprises a network of neurons each identified by a neuron address in the network, each neuron being able to receive and process at least one input signal and then later emit on an output of the neuron a signal representing an event which occurs inside the neuron, and a programmable memory composed of elementary memories each associated with a respective neuron. The elementary memory, which is a memory of post-synaptic addresses and weights, comprises an activation input linked by a conductor to the output of the associated neuron to directly receive an event signal emitted by this neuron without passing through an address encoder or decoder. The post-synaptic addresses extracted from an elementary memory activated by a neuron are applied, with associated synaptic weights, as inputs to the neural network.",Electronic circuit with neuromorphic architecture
"Electronic circuitry in the form of input and output circuits simulate the functions of neurons of most conceivable types. The input circuit has a signal regulating circuit which automatically reduces or increases its output amplitude, based on prior experience, simulating reverberation and memory neurons, respectively. An output stage has an integrator and a threshold circuit with a possible plurality of different types of inputs applied thereto for generating an output which simulates the responsiveness of a neuron. Different combinations of input and output circuits are used to simulate different types of neurons which can then be assembled into neural networks.",Electronic neuron simulation with more accurate functions
"An electronically controllable resistor (ECR) which functions as a fixed or variable resistor over a wide range of operating conditions. The value of the resistance may be altered in a highly linear fashion by altering a digital input thereto. The ECR utilizes an array of transmission gates, preferably having a uniform inherent resistance and preferably fabricated using CMOS technology which are grouped in commonly controlled groups. Each group preferably contains a number of transmission gates which relates to the numbers of transmission gates in other groups in a binary fashion. The source of digital control signals is preferably provided by a digital memory device which can be integrated with the transmission gate array. An operational amplifier can also be provided on the chip to form a complete neural processing element for inclusion in large neural networks.",Electronically controllable resistor
"A simple format is disclosed and referred to as Elementary Network Description (END). The format can fully describe a large-scale neuronal model and embodiments of software or hardware engines to simulate such a model efficiently. The architecture of such neuromorphic engines is optimal for high-performance parallel processing of spiking networks with spike-timing dependent plasticity. The format is specifically tuned for neural systems and specialized neuromorphic hardware, thereby serving as a bridge between developers of brain models and neuromorphic hardware manufactures.",Elementary network description for efficient link between neuronal models and neuromorphic systems
"The present invention relates to a method of embedding a neural network into an application program such as a spreadsheet program. The method comprises providing an application program in which information is stored in rows and columns or a database containing fields and records and embedding a neural network in the application program or database using the stored information. The embedding step includes allocating unused memory in the application program and creating both a neural network engine and an application interface structure from the unused memory. Once the neural network engine and an application interface structure have been created, the neural network may be trained using variable numerical and symbolic data stored within the application program. Once training is completed, the neural network is ready for use, merely by using a recall function built into the applications program.",Embedding neural networks into spreadsheet applications
"A plurality of neural networks or other models can be used in employee selection technologies. A hiring recommendation can be based at least on processing performed by a plurality of neural networks. For example, parallel or series processing by neural networks can be performed. A neural network can be coupled to one or more other neural networks. A binary or other n-ary output can be generated by one or more of the neural networks. In a series arrangement, candidates can be processed sequentially in multiple stages, and those surviving the stages are recommended for hire.",Employee selection via multiple neural networks
"Techniques for reconstructing a signal encoded with a time encoding machine (TEM) using a recurrent neural network including receiving a TEM-encoded signal, processing the TEM-encoded signal, and reconstructing the TEM-encoded signal with a recurrent neural network.",Encoding and decoding machine with recurrent neural networks
"The present invention is directed to a deep neural network (DNN) having a triplet network architecture, which is suitable to perform speaker recognition. In particular, the DNN includes three feed-forward neural networks, which are trained according to a batch process utilizing a cohort set of negative training samples. After each batch of training samples is processed, the DNN may be trained according to a loss function, e.g., utilizing a cosine measure of similarity between respective samples, along with positive and negative margins, to provide a robust representation of voiceprints.",End-to-end speaker recognition using deep neural network
"The present invention is directed to a deep neural network (DNN) having a triplet network architecture, which is suitable to perform speaker recognition. In particular, the DNN includes three feed-forward neural networks, which are trained according to a batch process utilizing a cohort set of negative training samples. After each batch of training samples is processed, the DNN may be trained according to a loss function, e.g., utilizing a cosine measure of similarity between respective samples, along with positive and negative margins, to provide a robust representation of voiceprints.",End-to-end speaker recognition using deep neural network
"Embodiments of end-to-end deep learning systems and methods are disclosed to recognize speech of vastly different languages, such as English or Mandarin Chinese. In embodiments, the entire pipelines of hand-engineered components are replaced with neural networks, and the end-to-end learning allows handling a diverse variety of speech including noisy environments, accents, and different languages. Using a trained embodiment and an embodiment of a batch dispatch technique with GPUs in a data center, an end-to-end deep learning system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",End-to-end speech recognition
"A method, system and machine-readable storage medium for monitoring an engine using a cascaded neural network that includes a plurality of neural networks is disclosed. In operation, the method, system and machine-readable storage medium store data corresponding to the cascaded neural network. Signals generated by a plurality of engine sensors are then inputted into the cascaded neural network. Next, a second neural network is updated at a first rate, with an output of a first neural network, wherein the output is based on the inputted signals. In response, the second neural network outputs at a second rate, at least one engine control signal, wherein the second rate is faster than the first rate.",Engine control system using a cascaded neural network
"A method, system and machine-readable storage medium for monitoring an engine using a cascaded neural network that includes a plurality of neural networks is disclosed. In operation, the method, system and machine-readable storage medium store data corresponding to the cascaded neural network. Signals generated by a plurality of engine sensors are then inputted into the cascaded neural network. Next, a second neural network is updated at a first rate, with an output of a first neural network, wherein the output is based on the inputted signals. In response, the second neural network outputs at a second rate, at least one engine control signal, wherein the second rate is faster than the first rate.",Engine control system using a cascaded neural network
"The present disclosure provides systems and methods that leverage machine-learned models (e.g., neural networks) to provide enhanced communication assistance. In particular, the systems and methods of the present disclosure can include or otherwise leverage a machine-learned communication assistance model to detect problematic statements included in a communication and/or provide suggested replacement statements to respectively replace the problematic statements. In one particular example, the communication assistance model can include a long short-term memory recurrent neural network that detects an inappropriate tone or unintended meaning within a user-composed communication and provides one or more suggested replacement statements to replace the problematic statements.",Enhanced communication assistance with deep learning
"This disclosure relates to digital image segmentation and region of interest identification. A computer implemented image segmentation method and system are particularly disclosed, including a predictive model trained based on a deep fully convolutional neural network. The model is trained using a loss function in at least one intermediate layer in addition to a loss function at the final stage of the full convolutional neural network. The predictive segmentation model trained in such a manner requires less training parameters and facilitates quicker and more accurate identification of relevant local and global features in the input image. In one implementation, the fully convolutional neural network is further supplemented with a conditional adversarial neural networks iteratively trained with the fully convolutional neural network as a discriminator measuring the quality of the predictive model generated by the fully convolutional neural network.",Enhanced convolutional neural network for image segmentation
"The invention discloses several computation and control techniques which use historic information as well as other cues in order to enhance the accuracy of a radio position fix. These computational techniques include neural networks, mapped grid coefficients as input to a set of simultaneous or differential equations, and table lookup of correction coefficients for known low accuracy positions. The invention further discloses techniques for receiver array synchronization so that all system elements in a particular coverage area obtain a time reference appropriate for time of flight radio location measurements. The invention further teaches techniques to enhance the accuracy of a position fix by use of both fixed references, which are located in a coverage area, as well as a mobile reference carried by a search team. The invention also discloses techniques to provide information appropriate to guide a search team to an unknown positioned transmitter that is located within a building or structure. The invention discloses techniques to train a central computing unit, by using actuarial data, so that multi-path errors resulting from fixed or mobile obstacles may be reduced.",Enhanced position calculation
"The invention discloses several computation and control techniques which use historic information as well as other cues in order to enhance the accuracy of a radio position fix. These computational techniques include neural networks, mapped grid coefficients as input to a set of simultaneous or differential equations,and table lookup of correction coefficients for known low accuracy positions. The invention further discloses techniques for receiver array synchronization so that all system elements in a particular coverage area obtain a time reference appropriate for time of flight radio location measurements. The invention further teaches techniques to enhance the accuracy of a position fix by use of both fixed references, which are located in a coverage area, as well as a mobile reference carried by a search team. The invention also discloses techniques to provide information appropriate to guide a search team to an unknown positioned transmitter that is located within a building or structure. The invention discloses techniques to train a central computing unit, by using actuarial data, so that multi-path errors resulting from fixed or mobile obstacles may be reduced.",Enhanced position calculation
"The invention discloses several computation and control techniques which use historic information as well as other cues in order to enhance the accuracy of a radio position fix. These computational techniques include neural networks, mapped grid coefficients as input to a set of simultaneous or differential equations,and table lookup of correction coefficients for known low accuracy positions. The invention further discloses techniques for receiver array synchronization so that all system elements in a particular coverage area obtain a time reference appropriate for time of flight radio location measurements. The invention further teaches techniques to enhance the accuracy of a position fix by use of both fixed references, which are located in a coverage area, as well as a mobile reference carried by a search team. The invention also discloses techniques to provide information appropriate to guide a search team to an unknown positioned transmitter that is located within a building or structure. The invention discloses techniques to train a central computing unit, by using actuarial data, so that multi-path errors resulting from fixed or mobile obstacles may be reduced.",Enhanced position calculation
"Systems and methods for enhancing reverberated audio signals are disclosed. In one embodiment, a method is disclosed comprising receiving an audio signal; partitioning a frequency domain representation of the audio signal into a plurality of sub-band vectors; inputting each sub-band vector into a corresponding deep neural network; calculating, using the corresponding deep neural networks, a plurality of output vectors for each sub-band; concatenating the plurality of output vectors to generate a clean audio feature matrix; and converting the clean audio feature matrix into a time-domain audio signal.",Enhancing audio signals using sub-band deep neural networks
"Systems and methods for enhancing reverberated audio signals are disclosed. In one embodiment, a method is disclosed comprising receiving an audio signal; partitioning a frequency domain representation of the audio signal into a plurality of sub-band vectors; inputting each sub-band vector into a corresponding deep neural network; calculating, using the corresponding deep neural networks, a plurality of output vectors for each sub-band; concatenating the plurality of output vectors to generate a clean audio feature matrix; and converting the clean audio feature matrix into a time-domain audio signal.",Enhancing audio signals using sub-band deep neural networks
An ensemble learning based image classification system contains multiple cellular neural networks (CNN) based integrated circuits (ICs) operatively coupling together as a set of base learners of an ensemble for an image classification task. Each CNN based IC is configured with at least one distinct deep learning model in form of filter coefficients. The ensemble learning based image classification system further contains a controller configured as a meta learner of the ensemble and a memory based data buffer for holding various data used in the ensemble by the controller and the CNN based ICs. Various data may include input imagery data to be classified. Various data may also include extracted feature vectors or image classification outputs out of the set of base learners. The extracted feature vectors or image classification outputs are then used by the meta learner to further perform the image classification task.,Ensemble learning based image classification systems
An ensemble learning based image classification system contains multiple cellular neural networks (CNN) based integrated circuits (ICs) operatively coupling together as a set of base learners of an ensemble for an image classification task. Each CNN based IC is configured with at least one distinct deep learning model in form of filter coefficients. The ensemble learning based image classification system further contains a controller configured as a meta learner of the ensemble and a memory based data buffer for holding various data used in the ensemble by the controller and the CNN based ICs. Various data may include input imagery data to be classified. Various data may also include extracted feature vectors or image classification outputs out of the set of base learners. The extracted feature vectors or image classification outputs are then used by the meta learner to further perform the image classification task.,Ensemble learning based image classification systems
"Methods of creating and using robust neural network ensembles are disclosed. Some embodiments take the form of computer-based methods that comprise receiving a set of available inputs; receiving training data; training at least one neural network for each of at least two different subsets of the set of available inputs; and providing at least two trained neural networks having different subsets of the available inputs as components of a neural network ensemble configured to transform the available inputs into at least one output. The neural network ensemble may be applied as a log synthesis method that comprises: receiving a set of downhole logs; applying a first subset of downhole logs to a first neural network to obtain an estimated log; applying a second, different subset of the downhole logs to a second neural network to obtain an estimated log; and combining the estimated logs to obtain a synthetic log.",Ensembles of neural networks with different input sets
A generative adversarial network (GAN) system includes a generator sub-network configured to examine one or more images of actual damage to equipment. The generator sub-network also is configured to create one or more images of potential damage based on the one or more images of actual damage that were examined. The GAN system also includes a discriminator sub-network configured to examine the one or more images of potential damage to determine whether the one or more images of potential damage represent progression of the actual damage to the equipment.,Equipment damage prediction system using neural networks
"Code word generation by recursive reverse flows in a neural network, and transmission systems encoding using such code words. The neural network (30) may be an array of operational amplifiers (34) as neurons with inverted amplifier output feedback through resistors (32) as the interconnection strengths to the amplifier inputs. The inversion of the amplifier output implies the dynamical flow of the neuron states is away from stored vectors; this contrasts with Hopfield networks which have a dynamical flow to stored states and thus an associative memory function. The method of generating code words recursively uses this reverse dynamical flow with previously generated code words as the stored vectors. That is, the already generated code words define the stored vectors in a neural network, then the reverse dynamical flow finds a new vector away from the stored vectors, and lastly this new vector defines the next code word and the cycle repeats with the augmented set of stored vectors.",Error control system and method
"Apparatus for measuring neural network activity with a textured semiconductor substrate. Sensor elements have a respective detection electrode on the substrate surface for detecting neural network signals, and the detected neural signals are a basis for outputting electrical sensor output signals via respective sensor element outputs. Each amplifier element has an input and an output. Each of the sensor elements has associated therewith one of the amplifier elements whose input is connected to the sensor output of the respective sensor element. The amplified sensor output signal is output the amplifier output as an amplifier output signal. An activity evaluator has an input, which is connected to at least one of the amplifier outputs, and an output. The activity evaluation device produces an activity signal, which is a measure of activity of the neural network, based on the amplifier output signal, and outputs the amplifier output signal via the evaluation output.",Event detectionapparatus and method for measuring the activity of neural networks
Apparatus and methods for event based communication in a spiking neuron network. The network may comprise units communicating by spikes via synapses. The spikes may communicate a payload data. The data may comprise one or more bits. The payload may be stored in a buffer of a pre-synaptic unit and be configured to accessed by the post-synaptic unit. Spikes of different payload may cause different actions by the recipient unit. Sensory input spikes may cause postsynaptic response and trigger connection efficacy update. Teaching input spikes trigger the efficacy update without causing the post-synaptic response.,Event-based communication in spiking neuron networks communicating a neural activity payload with an efficacy update
""" The present invention relates to the interrelationships between nature (as mediated by evolution and genetic algorithms) and nurture (as mediated by gradient-descent supervised learning) in a population of neural networks for pattern recognition. The Baldwin effect is demonstrated that learning can change the rate of evolution of the population's genome - a """"pseudo-Lamarkian"""" process, in which information learned is ultimately encoded in the genome by a purely Darwinian process. Selectivity is shown for this effect: too much learning or too little learning in each generation leads to slow evolution of the genome, whereas an intermediate amount leads to most rapid evolution. For a given number of learning trials throughout a population, the most rapid evolution occurs if different individuals each receive a different number of learning trials, rather than the same number. Because all biological networks possess structure due to evolution, it is important that such interactions between learning and evolution be understood. Hybrid systems can take advantage both of gradient descents (learning) and large jumps (genetic algorithms) in very complicated energy landscapes and hence may play an increasingly important role in the design of artificial neural systems. """,Evolution and learning in neural networks: the number and distribution of learning trials affect the rate of evolution
"A method of estimating soot loading in a diesel particulate filter (DPF) in a vehicle exhaust system includes estimating an engine-out soot rate using a first neural network that has a first set of vehicle operating conditions as inputs. The method further includes estimating DPF soot loading using a second neural network that has the estimated engine-out soot rate from the first neural network and a second set of vehicle operating conditions as inputs. Estimating the engine-out soot rate and estimating the DPF soot loading are performed by an electronic controller that executes the first and the second neural networks. The method also provides for training the first and second neural networks both offline (for initial settings of the neural networks in the vehicle), and online (when the vehicle is being used by a vehicle operator). An exhaust system has a controller that implements the method.",Exhaust system and method of estimating diesel particulate filter soot loading for same using two-tier neural network
"Deep Neural Network (DNN) training technique embodiments are presented that train a DNN while exploiting the sparseness of non-zero hidden layer interconnection weight values. Generally, a fully connected DNN is initially trained by sweeping through a full training set a number of times. Then, for the most part, only the interconnections whose weight magnitudes exceed a minimum weight threshold are considered in further training. This minimum weight threshold can be established as a value that results in only a prescribed maximum number of interconnections being considered when setting interconnection weight values via an error back-propagation procedure during the training. It is noted that the continued DNN training tends to converge much faster than the initial training.",Exploiting sparseness in training deep neural networks
"An approach to extending the recognizable labels of a label recognizer makes use of an encoding of linguistic inputs and label attributes into comparable vectors. The encodings may be determined with artificial neural networks (ANNs) that are jointly trained, and a comparison between the encoding of a sentence input and the encoding of an intent attribute vector may use a fixed function, which does not have to be trained. The encoding of label attributes can generalize permitting adding of a new label via corresponding attributes, thereby avoiding the need to immediately retrain a label recognizer with example inputs.",Extendable label recognition of linguistic input
"A method for extracting a representation from an image includes inputting an image to a pre-trained neural network. The gradient of a loss function is computed with respect to parameters of the neural network, for the image. A gradient representation is extracted for the image based on the computed gradients, which can be used, for example, for classification or retrieval.",Extracting gradient features from neural networks
"The present disclosure provides novel techniques for defining empirical models having control, prediction, and optimization modalities. The empirical models may include neural networks and support vector machines. The empirical models may include asymptotic analysis as part of the model definition as allow the models to achieve enhanced results, including enhanced high-order behaviors. The high-order behaviors may exhibit gains that are non-zero trending, which may be useful for controller modalities.","Extrapolating empirical models for control, prediction, and optimization applications"
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for gaze position prediction using neural networks. One of the systems includes a neural network comprising one or more neural network layers, wherein the neural network is configured to obtain a collection of input facial images of a user, wherein the collection of input facial images of the user comprises (i) a query image of the user, (ii) one or more calibration images of the user, and (iii) a respective calibration label that labels a known gaze position of the user for each of the one or more calibration images of the user; and process the received collection of input facial images of the user using the one or more neural network layers to generate a neural network output that characterizes a gaze position of the user in the query image.",Eye gaze tracking using neural networks
"Face hallucination using a bi-channel deep convolutional neural network (BCNN), which can adaptively fuse two channels of information. In one example, the BCNN is implemented to extract high level features from an input image. The extracted high level features are combined with low level details in the input image to produce the higher resolution image. Preferably, a proper coefficient is obtained to adaptively combine the high level features and the low level details.",Face hallucination using convolutional neural networks
"A face recognition method using artificial neural network and an apparatus thereof are provided. The apparatus comprises an eigenpaxel selection unit which generates eigenpaxels indicating characteristic patterns of a face and selects a predetermined number of eigenpaxels among the generated eigenpaxels; an eigenfiltering unit which filters an input image with the selected eigenpaxels; a predetermined number of neural networks, each of which corresponds to one of the selected eigenpaxels, receives an image signal which is filtered by the corresponding eigenpaxel, and output a face recognition result; and a determination unit which receives the recognition result from each of the neural networks and outputs a final face recognition result of the input image.",Face recognition method using artificial neural network and apparatus thereof
"A biometric facial image verification system capable of recognizing human users which includes a smart-card having stored thereon encoded first human facial images, a video camera and video digitizer embedded within said smart-card for acquiring data representative of a second human facial image. A computer-based device with a docking station capable of receiving said smart-card and software resident within said computer-based device for facial recognition, which includes Principal Component Analysis, Neural Networks, or another equivalent algorithm for comparing said first human facial images with said second human facial image and producing an output signal therefrom for use in verifying the identity of said human users. The apparatus can further include software for fingerprint and speech recognition. In addition, said smart-card is capable of acquiring and storing information pertaining to each of said human users such as would be required for use in a high-security environment or preventing fraud in point of sale and Internet-based financial transactions.",Facial image verification utilizing smart-card with integrated video camera
"The present invention overcomes the limitations of the prior art by performing facial landmark localization in a coarse-to-fine manner with a cascade of neural network levels, and enforcing geometric constraints for each of the neural network levels. In one approach, the neural network levels may be implemented with deep convolutional neural network. One aspect concerns a system for localizing landmarks on face images. The system includes an input for receiving a face image, and an output for presenting landmarks identified by the system. Neural network levels are coupled in a cascade from the input to the output for the system. Each neural network level produces an estimate of landmarks. The estimate of landmarks is more refined than an estimate of landmark of a previous neural network level.",Facial landmark localization using coarse-to-fine cascaded neural networks
"The innovation describes and discloses systems and methods related to deep neural networks employing machine learning to detect item 2D landmark points from a single image, such as those of an image of a face, and to estimate their 3D coordinates and shape rapidly and accurately. The system also provides for mapping by a feed-forward neural network that defines two criteria, one to learn to detect important shape landmark points on the image and another to recover their depth information. An aspect of the innovation may utilize camera models in a data augmentation approach that aids machine learning of a complex, non-linear mapping function. Other augmentation approaches are also considered.",Fast and precise object alignment and 3D shape reconstruction from a single 2D image
"Deep Neural Networks (DNNs) with many hidden layers and many units per layer are very flexible models with a very large number of parameters. As such, DNNs are challenging to optimize. To achieve real-time computation, embodiments disclosed herein enable fast DNN feature transformation via optimized memory bandwidth utilization. To optimize memory bandwidth utilization, a rate of accessing memory may be reduced based on a batch setting. A memory, corresponding to a selected given output neuron of a current layer of the DNN, may be updated with an incremental output value computed for the selected given output neuron as a function of input values of a selected few non-zero input neurons of a previous layer of the DNN in combination with weights between the selected few non-zero input neurons and the selected given output neuron, wherein a number of the selected few corresponds to the batch setting.",Fast deep neural network feature transformation via optimized memory bandwidth utilization
"A phase diversity wavefront correction system for use in a multiple aperture optical imaging system forms an in-focus image as a composite, focused image from the multiple apertures of the system and also forms an additional image which is deliberately made out of focus to a known extent. Taken together, the two images are processed to create one or more metrics, such as the power metric and sharpness metric. Neural networks are provided, each having an output corresponding to a parameter of an aperture of the imaging system, such as a piston position (axial displacement) or tip/tilt (angular displacement) of one telescope with respect to the others in the system. The neural networks each correspond to one parameter of a telescope or a combinations of parameters and are trained to identify a subset of elements within the metrics that, when input into the network, produce the best estimate of the piston or tip/tilt position relative to a reference telescope or an estimate of a combination of parameters, such as the average of a subset of telescopes. During active use of the system, metrics generated from the in-focus and out-of-focus images of the object scene and the trained neural networks are used to provide estimates of piston and/or tip/tilt positions which are in turn used to drive the pistons and/or tip/tilt controllers to correct for aberrant movement and keep the telescopes phased.",Fast phase diversity wavefront correction using a neural network
A fatigue monitoring system and method is disclosed in which a stream of data relating to the stresses experienced at a plurality of locations over the structure during operation is applied to a neural network trained to remove data stream values deemed to be in error. The data from the neural network is then processed to determine the fatigue life.,Fatigue monitoring systems and methods incorporating neural networks
""" Any deterministic finite-state automata (DFA) can be implemented in a sparse recurrent neural network (RNN) with second-order weights and sigmoidal discriminant functions. Construction algorithms can be extended to fault-tolerant DFA implementations such that faults in an analog implementation of neurons or weights do not affect the desired network performance. The weights are replicated k times for k-1 fault tolerance. Alternatively, the independent network is replicated 2k+1 times and the majority of the outputs is used for a k fault tolerance. In a further alternative solution, a single network with k.eta. neurons uses a """"n choose k""""encoding algorithm for k fault tolerance. """,Fault-tolerant implementation of finite-state automata in recurrent neural networks
"A system is described herein which uses a neural network having an input layer that accepts an input vector and a feature vector. The input vector represents at least part of input information, such as, but not limited to, a word or phrase in a sequence of input words. The feature vector provides supplemental information pertaining to the input information. The neural network produces an output vector based on the input vector and the feature vector. In one implementation, the neural network is a recurrent neural network. Also described herein are various applications of the system, including a machine translation application.",Feature-augmented neural networks and applications of same
""" A Forward Feed Neural Network is disclosed using data flow techniques on a data flow microprocessor. As a result of this invention, a neural network is provided that has the capacity of """"learning"""" to distinguish among patterns of data which may differ recognizably from idealized cases, and is able to perform pattern recognition faster while utilizing less memory and fewer clock cycles than neural networks implemented on sequential processors. This implementation is simpler and faster because of an inherent similarity between the flow of information in the brain and in data flow architecture. """,Feed-forward neural network
"A method and apparatus for detecting a singing frequency in a signal processing system using two neural-networks is disclosed. The first one (a hit neural network) monitors the maximum spectral peak FFT bin as it changes with time. The second one (change neural network) monitors the monotonic increasing behavior. The inputs to the neural-networks are the maximum spectral magnitude bin and its rate of change in time. The output is an indication whether howling is likely to occur and the corresponding singing frequency. Once the singing frequency is identified, it can be suppressed using any one of many available techniques such as notch filters. Several improvements of the base method or apparatus are also disclosed, where additional neural networks are used to detect more than one singing frequency.",Feedback elimination method and apparatus
"In an artificial neural network a method and neuron device that produce weight-adjustment factors, also called error values (116), for pre-synaptic neurons (302a . . . 302c) that are used to adjust the values of connection weights (106 . . . 106n) in neurons (100) used in artificial neural networks (ANNs). The amount of influence a pre-synaptic neuron has had over a post-synaptic neuron is calculated during signal propagation in the post-synaptic neuron (422a . . . 422n) and accumulated for the pre-synaptic neuron (426) for each post-synaptic neuron to which the pre-synaptic neuron's output is connected (428). Influence values calculated for use by pre-synaptic neurons may further be modified by the post-synaptic neuron's output value (102) (option 424), and its error value (116) (option 1110).",Feedback-tolerant method and device producing weight-adjustment factors for pre-synaptic neurons in artificial neural networks
"A method of optimizing performance of a well system utilizes a neural network. In a described embodiment, the method includes the step of accumulating data indicative of the performance of the well system in response to variable influencing parameters. The data is used to train a neural network to model an output of the well system in response to the influencing parameters. An output of the neural network may then be input to a valuing model, e.g., to permit optimization of a value of the well system. The optimization process yields a set of prospective influencing parameters which may be incorporated into the well system to maximize its value.",Field/reservoir optimization utilizing neural networks
A method of training a neural network model includes determining a specificity of multiple filters after a predetermined number of training iterations. The method also includes determining whether to continue training each filter of the multiple filters based at least in part on the specificity. The method further includes classifying an input based on features obtained by convolving the input with the trained filters.,Filter specificity as training criterion for neural networks
"A technique for fingerprint classification and/or identification, in which a fingerprint is defined by areas containing patterns of ridges and valleys. At least one local pattern is determined using locations and characterizations of the fingerprint, which are indicated by a rapid change in direction of the ridges and valleys. The fingerprint is classified into types based upon the relative locations and characterizations of said local pattern(s). The fingerprint identification process can utilize minutiae location and angles as well as local pattern characterizations. Neural networks are utilized in determining the local patterns. The amount of data required to store data defining the fingerprints using the local pattern and/or minutiae techniques is significantly reduced.",Fingerprint classification system
"In an image classification method, a feature vector representing an input image is generated by unsupervised operations including extracting local descriptors from patches distributed over the input image, and a classification value for the input image is generated by applying a neural network (NN) to the feature vector. Extracting the feature vector may include encoding the local descriptors extracted from each patch using a generative model, such as Fisher vector encoding, aggregating the encoded local descriptors to form a vector, projecting the vector into a space of lower dimensionality, for example using Principal Component Analysis (PCA), and normalizing the feature vector of lower dimensionality to produce the feature vector representing the input image. A set of mid-level features representing the input image may be generated as the output of an intermediate layer of the NN.",Fisher vectors meet neural networks: a hybrid visual classification architecture
"A neural network including a set of input nodes may consume a respective stream of time-series data recorded during a flight of a flying aircraft, each stream of time-series data representing measurements of a respective flight parameter captured by a sensor at various time-steps of the flight. A training circuit set may train the neural network to predict a future measurement of the flight parameter. Training the neural network may include comparing a predictive value from the neural network to a measured value of a flight parameter and modifying structural components of the neural network to bring the predictive value closer to the measured value. A parameter acquisition circuit set may acquire time-series data of a flight parameter. A prediction circuit set may apply the time-series data to the trained neural network to predict the next measurement for the flight parameter in the time-series data.",Flight parameter prediction using neural networks
"A weighted sum is a key computation for many neural networks and other machine learning algorithms. Integrated circuit designs that perform a weighted sum are presented. Weights are stored as threshold voltages in an array of flash transistors. By putting the circuits into a well-defined voltage state, the transistors that hold one set of weights will pass current equal to the desired sum. The current flowing through a given transistor is unaffected by operation of remaining transistors in the circuit.",Floating-gate transistor array for performing weighted sum computation
"The present disclosure relates to a font recognition system that employs a multi-task learning framework and training to improve font classification and remove negative side effects caused by intra-class variances of glyph content. For example, in one or more embodiments, the font recognition system trains a hybrid font recognition neural network that includes two or more font recognition neural networks and a weight prediction neural network. The hybrid font recognition neural network determines and generates classification weights based on which font recognition neural network within the hybrid font recognition neural network is best suited to classify the font in an input text image. By employing a hybrid trained font classification neural network, the font recognition system can improve overall font recognition as well as remove the negative side effects from diverse glyph content.",Font recognition by dynamically weighting multiple deep learning neural networks
A method and system for detecting and extracting accurate and precise structure in documents. A high-resolution image of documents is segmented into a set of tiles. Each tile is processed by a convolutional network and subsequently by a set of recurrent networks for each row and column. A global-lookup process is disclosed that allows future information required for accurate assessment by the recurrent neural networks to be considered. Utilization of high-resolution image allows for precise and accurate feature extraction while segmentation into tiles facilitates the tractable processing of the high-resolution image within reasonable computational resource bounds.,Form structure extraction network
"A four quadrant multiplier using multiple input floating-gate MOS transistors is provided. It is based on the square law characteristics of the MOS transistor and can be realised with only four floating gate MOS transistors, two resistors and a current source. The four floating gate transistors are configured with their sources connected in common and biased by a single current source. Output is taken between two common drain connections. Each transistor has three control gates with two being provided for selected ones of the two input signals and one for a biasing signal (optional). Input signals can be connected to the control gates in either a differential or single ended configuration. In one application, a programmable synaptic cell for neural networks employs the multi-input floating-gate MOS four-quadrant analog multiplier. Varying of the neural weight connection strength of each synaptic cell is achieved by two possible methods. One method involves programming charges into or out of the primary floating-gate of the MFMOS devices associated with the multiplier. The other method is to configure the third input gate of each MFMOS device of the multiplier as another (secondary) floating-gate structure whereby charge can be programmed into or out of this secondary floating-gate structure and its coupling area to the primary floating-gate would determine the neural weight. The differential output current is proportional to the product of the input signal and the programmed charge difference. In a natural extension an array of individually programmable synaptic cells form a neural network.",Four quadrant square law analog multiplier using floating gate MOS transitions
Techniques related to implementing neural networks for speech recognition systems are discussed. Such techniques may include implementing frame skipping with approximated skip frames and/or distances on demand such that only those outputs needed by a speech decoder are provided via the neural network or approximation techniques.,Frame skipping with extrapolation and outputs on demand neural network for automatic speech recognition
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for frequency based audio analysis using neural networks. One of the methods includes training a neural network that includes a plurality of neural network layers on training data, wherein the neural network is configured to receive frequency domain features of an audio sample and to process the frequency domain features to generate a neural network output for the audio sample, wherein the neural network comprises (i) a convolutional layer that is configured to map frequency domain features to logarithmic scaled frequency domain features, wherein the convolutional layer comprises one or more convolutional layer filters, and (ii) one or more other neural network layers having respective layer parameters that are configured to process the logarithmic scaled frequency domain features to generate the neural network output.",Frequency based audio analysis using neural networks
"A method, computer readable medium, and system are disclosed for classifying video image data. The method includes the steps of processing training video image data by at least a first layer of a convolutional neural network (CNN) to extract a first set of feature maps and generate classification output data for the training video image data. Spatial classification accuracy data is computed based on the classification output data and target classification output data and spatial discrimination factors for the first layer are computed based on the spatial classification accuracies and the first set of feature maps.",Fusing multilayer and multimodal deep neural networks for video classification
"An method and apparatus for extracting an interpretable, meaningful, and concise rule set from neural networks is presented. The method involves adjustment of gain parameter, &lgr; and the threshold, Tj for the sigmoid activation function of the interactive-or operator used in the extraction/development of a rule set from an artificial neural network. A multi-stage procedure involving coarse and fine adjustment is used in order to constrain the range of the antecedents of the extracted rules to the range of values of the inputs to the artificial neural network. Furthermore, the consequents of the extracted rules are provided based on degree of membership such that they are easily understandable by human beings. The method disclosed may be applied to any pattern recognition task, and is particularly useful in applications such as vehicle occupant sensing and recognition, object recognition, gesture recognition, and facial pattern recognition, among others.",Fuzzy expert system for interpretable rule extraction from neural networks
""" In the present invention, prior art techniques are extended to allow application of the backpropagation learning technique to artificial neural networks derived from fuzzy expert system rule-bases. A method in accordance with the invention, referred to herein as a Fuzzy Expert Network (FEN), is implemented in a programmed machine such as a computer to provide automated learning of both """"fine"""" and """"coarse"""" knowledge in a network of artificial neural objects (ANOs) implementing fuzzy modeling rules. Through application of the FEN method, an event-driven fuzzy expert network comprising acyclically connected ANOs derived from fuzzy modelling rules may be implemented. Neural objects implement one or more fuzzy combining and defuzzification rules and use backpropagation of error techniques to implement learning. As in prior art, the FEN allows each ANO to adjust its input weight parameters--""""fine"""" knowledge learning. Unlike prior art, the FEN allows each ANO to modify its internal parameters--""""coarse"""" knowledge learning. This latter action means that individual ANOs have the capability to modify the parameters of the fuzzy rule's membership function upon which they are based. In this way the FEN is able to change the structure of its encoded knowledge over time, making it a more adaptable architecture for autonomous and/or adaptable control systems. Simulation results showing the FEN's learning and adaptability behavior are given. """,Fuzzy expert system learning network
"There is disclosed a pattern identifying neural network comprising at least an input and an output layer, the output layer having a plurality of principal nodes, each principal node trained to recognize a different class of patterns, and at least one fuzzy node trained to recognize all classes of patterns recognized by the principal nodes but with outputs set out at levels lower than the corresponding outputs of the principal nodes.",Fuzzy neural networks
"The present disclosure relates to a gait recognition method based on deep learning, which comprises recognizing an identity of a person in a video according to the gait thereof through dual-channel convolutional neural networks sharing weights by means of the strong learning capability of the deep learning convolutional neural network. Said method is quite robust to gait changes across a large view, which can effectively solve the problem of low precision in cross-view gait recognition existing with the prior art gait recognition technology. Said method can be widely used in scenarios having video monitors, such as security monitoring in airports and supermarkets, person recognition, criminal detection, etc.",Gait recognition method based on deep learning
"Reformulated gasoline (RFG) testing recently required by EPA involves measuring sulfur, olefin, aromatic contents, Reid Vapor Pressure (RVP), and benzene, distillation properties, plus total air pollutants (TAPs), volatile organic carbon (VOC), and nitrogen oxides (NOx). Measuring driveability, although not required, is desirable. All of these tests can be conducted by spectrometer, preferably in the IR range, more preferably in the NIR range, and most preferably by a single instrument operating at high-correlation wavelengths. Importantly, VOC, TAP, NOx, and RVP may be correlated to IR absorbance at certain bands. Statistical methods including PLS, MLR, PCR, and neural networks can be used and derivatives of first, particularly second, or other orders can be used. Results can be displayed on a single screen.",Gasoline RFG analysis by a spectrometer
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating a final classification output for an image of eye tissue. The image is provided as input to each of one or more segmentation neural networks to obtain one or more segmentation maps of the eye tissue in the image. A respective classification input is generated from each of the segmentation maps. For each of the segmentation maps, the classification input for the segmentation map is provided as input to each of one or more classification neural networks to obtain, for each segmentation map, a respective classification output from each classification neural network. A final classification output for the image is generated from the respective classification outputs for each of the segmentation maps.",Generalizable medical image analysis using segmentation and classification neural networks
"A computer system computes a score for a received data exchange and, in accordance with a neural network and input variables determined by received current exchange and history data, the computed score indicates a condition suitable for a denial. A set of attribution scores are computed using an Alternating Decision Tree model in response to a computed score that is greater than a predetermined score threshold value for the denial. The computed score is provided to an assessment unit and, if the computed score indicates a condition suitable for the denial and if attribution scores are computed, then a predetermined number of input variable categories from a rank-ordered list of input variable categories is also provided to the assessment unit of the computer system.",Generating accurate reason codes with complex non-linear modeling and neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating an output sequence of audio data that comprises a respective audio sample at each of a plurality of time steps. One of the methods includes, for each of the time steps: providing a current sequence of audio data as input to a convolutional subnetwork, wherein the current sequence comprises the respective audio sample at each time step that precedes the time step in the output sequence, and wherein the convolutional subnetwork is configured to process the current sequence of audio data to generate an alternative representation for the time step; and providing the alternative representation for the time step as input to an output layer, wherein the output layer is configured to: process the alternative representation to generate an output that defines a score distribution over a plurality of possible audio samples for the time step.",Generating audio using neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for augmenting neural networks with an external memory. One of the methods includes receiving a plurality of high-dimensional data items; generating a circulant embedding matrix for the high-dimensional data items, wherein the circulant embedding matrix is a matrix that is fully specified by a single vector; for each high-dimensional data item, generating a compact representation of the high-dimensional data item, comprising computing a product of the circulant embedding matrix and the high dimensional data item by performing a circular convolution of the single vector that fully specifies the circulant embedding matrix and the high dimensional data item using a Fast Fourier Transform (FFT); and generating a compact representation of the high dimensional data item by computing a binary map of the computed product.",Generating compact representations of high-dimensional data
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating images using neural networks. One of the methods includes generating the output image pixel by pixel from a sequence of pixels taken from the output image, comprising, for each pixel in the output image, generating a respective score distribution over a discrete set of possible color values for each of the plurality of color channels.",Generating images using neural networks
"The present disclosure provides systems and methods that include or otherwise leverage a machine-learned neural synthesizer model. Unlike a traditional synthesizer which generates audio from hand-designed components like oscillators and wavetables, the neural synthesizer model can use deep neural networks to generate sounds at the level of individual samples. Learning directly from data, the neural synthesizer model can provide intuitive control over timbre and dynamics and enable exploration of new sounds that would be difficult or impossible to produce with a hand-tuned synthesizer. As one example, the neural synthesizer model can be a neural synthesis autoencoder that includes an encoder model that learns embeddings descriptive of musical characteristics and an autoregressive decoder model that is conditioned on the embedding to autoregressively generate musical waveforms that have the musical characteristics one audio sample at a time.",Generating music with deep neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating output sequences from input sequences. One of the methods includes obtaining an input sequence having a first number of inputs arranged according to an input order; processing each input in the input sequence using an encoder recurrent neural network to generate a respective encoder hidden state for each input in the input sequence; and generating an output sequence having a second number of outputs arranged according to an output order, each output in the output sequence being selected from the inputs in the input sequence, comprising, for each position in the output order: generating a softmax output for the position using the encoder hidden states that is a pointer into the input sequence; and selecting an input from the input sequence as the output at the position using the softmax output.",Generating output sequences from input sequences using neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating parse trees for input text segments. One of the methods includes obtaining an input text segment comprising a plurality of inputs arranged according to an input order; processing the inputs in the input text segment using an encoder long short term memory (LSTM) neural network to generate a respective encoder hidden state for each input in the input text segment; and processing the respective encoder hidden states for the inputs in the input text segment using an attention-based decoder LSTM neural network to generate a linearized representation of a parse tree for the input text segment.",Generating parse trees of text segments using neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating parse trees for input text segments. One of the methods includes obtaining an input text segment, processing the input text segment using a first long short term memory (LSTM) neural network to convert the input text segment into an alternative representation for the input text segment, and processing the alternative representation for the input text segment using a second LSTM neural network to generate a linearized representation of a parse tree for the input text segment.",Generating parse trees of text segments using neural networks
"Methods of directly analyzing wireline well logging data to derive pore types, pore volumes and capillary pressure curves from the wireline logs are disclosed. A trained and validated neural network is applied to wireline log data on porosity, bulk density and shallow, medium and deep conductivity to derive synthetic pore type proportions as a function of depth. These synthetic data are then applied through a derived and validated capillary pressure curve data model to derive pore volume and pressure data as a function of borehole depth.",Generating pore types and synthetic capillary pressure curves from wireline logs using neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating representations of input sequences. One of the methods includes obtaining an input sequence, the input sequence comprising a plurality of inputs arranged according to an input order; processing the input sequence using a first long short term memory (LSTM) neural network to convert the input sequence into an alternative representation for the input sequence; and processing the alternative representation for the input sequence using a second LSTM neural network to generate a target sequence for the input sequence, the target sequence comprising a plurality of outputs arranged according to an output order.",Generating representations of input sequences using neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating representations of input sequences. One of the methods includes receiving a grapheme sequence, the grapheme sequence comprising a plurality of graphemes arranged according to an input order; processing the sequence of graphemes using a long short-term memory (LSTM) neural network to generate an initial phoneme sequence from the grapheme sequence, the initial phoneme sequence comprising a plurality of phonemes arranged according to an output order; and generating a phoneme representation of the grapheme sequence from the initial phoneme sequence generated by the LSTM neural network, wherein generating the phoneme representation comprises removing, from the initial phoneme sequence, phonemes in one or more positions in the output order.",Generating representations of input sequences using neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network. One of the methods includes accessing a first neural network that was trained to recognize a given keyword or keyphrase using a set of hotword training data, wherein the hotword training data includes positive hotword training data that correspond to utterances of the keyword or keyphrase, and negative hotword training data that corresponds to utterances of words or phrases that are other than the keyword or keyphrase, selecting a seed hotsound, mapping, to a feature space, (i) the positive hotword training data, (ii) the negative hotword training data, and (iii) the seed hotsound, performing an optimization of a position of the seed hotsound within the feature space to generate a modified seed hotsound, generating a set of hotsound training data using the modified seed hotsound, training a second neural network to recognize the modified seed hotsound using the generated set of hotsound training data, and using the trained second neural network to recognize the modified hotsound.",Generating sounds for detectability by neural networks
"Various implementations disclosed herein include an expert-assisted phoneme recognition neural network system configured to recognize phonemes within continuous large vocabulary speech sequences without using language specific models (left-context), look-ahead (right-context) information, or multi-pass sequence processing, and while operating within the resource constraints of low-power and real-time devices. To these ends, in various implementations, an expert-assisted phoneme recognition neural network system as described herein utilizes a-priori phonetic knowledge. Phonetics is concerned with the configuration of the human vocal tract while speaking and acoustic consequences on vocalizations. While similar sounding phonemes are difficult to detect and are frequently misidentified by previously known neural networks, phonetic knowledge gives insight into what aspects of sound acoustics contain the strongest contrast between similar sounding phonemes. Utilizing features that emphasize the respective second formants allows for more robust sound discrimination between these problematic phonemes.",Generation of phoneme-experts for speech recognition
"Features are disclosed for using an artificial neural network to generate customized speech recognition models during the speech recognition process. By dynamically generating the speech recognition models during the speech recognition process, the models can be customized based on the specific context of individual frames within the audio data currently being processed. In this way, dependencies between frames in the current sequence can form the basis of the models used to score individual frames of the current sequence. Thus, each frame of the current sequence (or some subset thereof) may be scored using one or more models customized for the particular frame in context.",Generative modeling of speech using neural networks
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for a neural network system. In one aspect, a neural network system includes a recurrent neural network that is configured to, for each time step of a predetermined number of time steps, receive a set of latent variables for the time step and process the latent variables to update a hidden state of the recurrent neural network; and a generative subsystem that is configured to, for each time step, generate the set of latent variables for the time step and provide the set of latent variables as input to the recurrent neural network; update a hidden canvas using the updated hidden state of the recurrent neural network; and, for a last time step, generate an output image using the updated hidden canvas for the last time step.",Generative neural networks
"Neural networks for object detection in images are used with a spatial pyramid pooling (SPP) layer. Using the SPP network structure, a fixed-length representation is generated regardless of image size and scale. The feature maps are computed from the entire image once, and the features are pooled in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. Thus, repeated computation of the convolutional features is avoided while accuracy is enhanced.",Generic object detection in images
"A system and method for generating a neural network ensemble. Conventional algorithms are used to train a number of neural networks having error diversity, for example by having a different number of hidden nodes in each network. A genetic algorithm having a multi-objective fitness function is used to select one or more ensembles. The fitness function includes a negative error correlation objective to insure diversity among the ensemble members. A genetic algorithm may be used to select weighting factors for the multi-objective function. In one application, a trained model may be used to produce synthetic open hole logs in response to inputs of cased hole log data.",Genetic algorithm based selection of neural network ensemble for processing well logging data
The disclosure relates to the use of genetic learning techniques to evolve neural network architectures for specific applications in which a general representation of neural network architecture is linked with a genetic learning strategy to create a very flexible environment for the construction of custom neural networks.,Genetic algorithm synthesis of neural networks
"A generic algorithm search is applied to determine an optimum set of values (e.g., interconnection weights in a neural network), each value being associated with a pair of elements drawn from a universe of N elements, N an integer greater than zero, where the utility of any possible set of said values may be measured. An initial possible set of values is assembled, the values being organized in a matrix whose rows and columns correspond to the elements. A genetic algorithm operator is applied to generate successor matrices from said matrix. Matrix computations are performed on the successor matrices to generate measures of the relative utilities of the successor matrices. A surviving matrix is selected from the successor matrices on the basis of the metrics. The steps are repeated until the metric of the surviving matrix is satisfactory.",Genetic algorithm technique for designing neural networks
"Genetically adaptive neural network systems and methods provide environmentally adaptable classification algorithms for use, among other things, in multi-static active sonar classification. Classification training occurs in-situ with data acquired at the onset of data collection to improve the classification of sonar energy detections in difficult littoral environments. Accordingly, in-situ training sets are developed while the training process is supervised and refined. Candidate weights vectors evolve through genetic-based search procedures, and the fitness of candidate weight vectors is evaluated. Feature vectors of interest may be classified using multiple neural networks and statistical averaging techniques to provide accurate and reliable signal classification.",Genetically adaptive neural network classification systems and methods
"An apparatus, method, and a computer program is provided for gesture recognition using neural networks. An initial point is recorded when a user presses a finger on a screen. Subsequent points are recorded and an angle is calculated from point to point as the user periodically moves the finger. A set of the calculated angles are compared with an ideal angle in order to recognize the gesture.",Gesture recognition using neural networks
"A global predictive monitoring system for a manufacturing facility. The system may be employed in an integrated circuit (IC) device fabrication facility to monitor processing of semiconductor wafers. The system may include deployment of a swarm of individually separate agents running in computers in the facility. Each agent may comprise a genetic algorithm and use several neural networks for computation. Each agent may be configured to receive a limited set of inputs, such as defectivity data and WIP information, and calculate a risk from the inputs. A risk may be a value indicative of a production yield. Each agent may also generate a quality value indicative of a reliability of the risk value. New agents may be generated from the initial population of agents. Outputs from the agents may be collected and used to calculate projections indicative of a trend of the production yield.",Global predictive monitoring system for a manufacturing facility
A GPS receiver includes a satellite receiver/processor having an input that receives input signals from at least one GPS satellite. The output of the receiver/processor provides satellite-related navigation information. A neural network receives the satellite-related information to obtain an output signal representative of receiver-related navigation information. The neural network includes a first node layer connected to a second node layer through a first connection layer and a third node layer connected to the second node layer through a second connection layer. Each of the node layers comprises a plurality of neurons.,GPS navigation system using neural networks
A GPS receiver includes a satellite receiver/processor having an input that receives input signals from at least one GPS satellite. The output of the receiver/processor provides satellite-related navigation information. A neural network receives the satellite-related information to obtain an output signal representative of receiver-related navigation information. The neural network includes a first node layer connected to a second node layer through a first connection layer and a third node layer connected to the second node layer through a second connection layer. Each of the node layers comprises a plurality of neurons.,GPS navigation system using neural networks
"GPS satellite (4) ranging signals (6) received (32) on comm1, and DGPS auxiliary range correction signals and pseudolite carrier phase ambiguity resolution signals (8) from a fixed known earth base station (10) received (34) on comm2, at one of a plurality of vehicles/aircraft/automobiles (2) are computer processed (36) to continuously determine the one's kinematic tracking position on a pathway (14) with centimeter accuracy. That GPS-based position is communicated with selected other status information to each other one of the plurality of vehicles (2), to the one station (10), and/or to one of a plurality of control centers (16), and the one vehicle receives therefrom each of the others' status information and kinematic tracking position. Objects (22) are detected from all directions (300) by multiple supplemental mechanisms, e.g., video (54), radar/lidar (56), laser and optical scanners. Data and information are computer processed and analyzed (50,52,200,452) in neural networks (132, FIGS. 6-8) in the one vehicle to identify, rank, and evaluate collision hazards/objects, an expert operating response to which is determined in a fuzzy logic associative memory (484) which generates control signals which actuate a plurality of control systems of the one vehicle in a coordinated manner to maneuver it laterally and longitudinally to avoid each collision hazard, or, for motor vehicles, when a collision is unavoidable, to minimize injury or damage therefrom. The operator is warned by a heads up display and other modes and may override. An automotive auto-pilot mode is provided.",GPS vehicle collision avoidance warning and control system and method
"GPS satellite (4) ranging signals (6) received (32) on comm1, and DGPS auxiliary range correction signals and pseudolite carrier phase ambiguity resolution signals (8) from a fixed known earth base station (10) received (34) on comm2, at one of a plurality of vehicles/aircraft/automobiles (2) are computer processed (36) to continuously determine the one's kinematic tracking position on a pathway (14) with centimeter accuracy. That GPS-based position is communicated with selected other status information to each other one of the plurality of vehicles (2), to the one station (10), and/or to one of a plurality of control centers (16), and the one vehicle receives therefrom each of the others' status information and kinematic tracking position. Objects (22) are detected from all directions (300) by multiple supplemental mechanisms, e.g., video (54), radar/lidar (56), laser and optical scanners. Data and information are computer processed and analyzed (50,52,200,452) in neural networks (132, FIGS. 6-8) in the one vehicle to identify, rank, and evaluate collision hazards/objects, an expert operating response to which is determined in a fuzzy logic associative memory (484) which generates control signals which actuate a plurality of control systems of the one vehicle in a coordinated manner to maneuver it laterally and longitudinally to avoid each collision hazard, or, for motor vehicles, when a collision is unavoidable, to minimize injury or damage therefrom. The operator is warned by a heads up display and other modes and may override. An automotive auto-pilot mode is provided.",GPS vehicle collision avoidance warning and control system and method
"GPS satellite (4) ranging signals (6) received (32) on comm1, and DGPS auxiliary range correction signals and pseudolite carrier phase ambiguity resolution signals (8) from a fixed known earth base station (10) received (34) on comm2, at one of a plurality of vehicles/aircraft/automobiles (2) are computer processed (36) to continuously determine the one's kinematic tracking position on a pathway (14) with centimeter accuracy. That GPS-based position is communicated with selected other status information to each other one of the plurality of vehicles (2), to the one station (10), and/or to one of a plurality of control centers (16), and the one vehicle receives therefrom each of the others' status information and kinematic tracking position. Objects (22) are detected from all directions (300) by multiple supplemental mechanisms, e.g., video (54), radar/lidar (56), laser and optical scanners. Data and information are computer processed and analyzed (50,52,200,452) in neural networks (132, FIGS. 6-8) in the one vehicle to identify, rank, and evaluate collision hazards/objects, an expert operating response to which is determined in a fuzzy logic associative memory (484) which generates control signals which actuate a plurality of control systems of the one vehicle in a coordinated manner to maneuver it laterally and longitudinally to avoid each collision hazard, or, for motor vehicles, when a collision is unavoidable, to minimize injury or damage therefrom. The operator is warned by a heads up display and other modes and may override. An automotive auto-pilot mode is provided.",GPS vehicle collision avoidance warning and control system and method
"A method for producing a graph representation of an input image, the method including the procedures of applying convolutional layers of a trained convolutional neural network on the input image, defining a receptive field of a last convolutional layer of the trained convolutional neural network as a vertex of the graph representation, defining a vector of a three dimensional output matrix of the last convolutional layer that is mapped to the receptive field as a descriptor for the vertex and determining an edge between a pair of vertices of the graph representation by applying an operator on a pair of descriptors respective of the pair of vertices.",Graph image representation from convolutional neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for implementing grid Long Short-Term Memory (LSTM) neural networks that includes a plurality of N-LSTM blocks arranged in an N-dimensional grid. Each N-LSTM block is configured to: receive N input hidden vectors, the N input hidden vectors each corresponding to a respective one of the N dimensions; receive N input memory vectors, the N input memory vectors each corresponding to a respective one of the N dimensions; and, for each of the dimensions, apply a respective transform for the dimension to the memory hidden vector corresponding to the dimension and the input hidden vector corresponding to the dimension to generate a new hidden vector corresponding to the dimension and a new memory vector corresponding to the dimension.",Grid long short-term memory neural networks
"Light weight personal handheld home monitoring and managing device, which includes a Sound Sensor network/array of Sound Sensor networks combined with an Artificial Neural Network (ANN) and a build in system and methods, making this device an intelligent and portable apparatus to address specific health issues. The combined apparatus is used for managing and/or guidance and/or diagnosing and/or controlling and managing purposes. This present version of the apparatus will address pulmonary disorders and diseases or similar ailments.",Handheld home monitoring sensors network device
"New neural networks for handwriting recognition may be build from existing neural networks. An existing neural network pre-trained for a starting language is chosen based on a desired target language. The neural network is modified so that it may be used to recognize characters of the target language, and the modified neural network is used in a handwriting recognizer for the target language. Modification includes copying one or more of the primary outputs of the existing neural network. An appropriate starting language may be chosen based on the desired target language. In addition, a super network may be provided that is a relatively large neural network configured to recognize characters from a number of different languages. One may customize a handwriting recognizer using such a super network by programming a mask to block outputs from the super network that are not necessary for the language desired to be recognized.",Handwriting recognition using neural networks
"A method and apparatus for calculating an expected access time associated with one of a plurality of disk drive commands employs one or more neural networks. A plurality of disk drive commands received from an external source are stored in a memory, typically in a queue. Using a neural network, an expected access time associated with each of the queued commands is determined. Determining the expected access time associated with each of the queued commands involves determining a time for performing a seek and settle operation for each of the queued commands and a latency time associated with each of the queued commands. The command indicated by the neural network as having a minimum expected access time relative to access times associated with other ones of the queued commands is identified for execution. A first neural network may be used to determine an expected access time associated with each read command stored in a read command queue and a second neural network may be used to determine an expected access time associated with each write command stored in a write command queue. A pair of read and write neural networks may be associated with each of a number of read/write transducers employed in a disk drive system. The neural network may be trained at the time of manufacture and on a periodic basis during the service life of the disk drive.",Hard disk drive employing neural network for performing expected access time calculations
"Examples herein relate to hardware accelerators for calculating node values of neural networks. An example hardware accelerator may include a crossbar array programmed to calculate node values of a neural network and a current comparator to compare an output current from the crossbar array to a threshold current according to an update rule to generate new node values. The crossbar array has a plurality of row lines, a plurality of column lines, and a memory cell coupled between each unique combination of one row line and one column line, where the memory cells are programmed according to a weight matrix. The plurality of row lines are to receive an input vector of node values, and the plurality of column lines are to deliver an output current to be compared with the threshold current.",Hardware accelerators for calculating node values of neural networks
"An analog-digital crosspoint-network includes a plurality of rows and columns, a plurality of synaptic nodes, each synaptic node of the plurality of synaptic nodes disposed at an intersection of a row and column of the plurality of rows and columns, wherein each synaptic node of the plurality of synaptic nodes includes a weight associated therewith, a column controller associated with each column of the plurality of columns, wherein each column controller is disposed to enable a weight change at a synaptic node in communication with said column controller, and a row controller associated with each row of the plurality of rows, wherein each row controller is disposed to control a weight change at a synaptic node in communication with said row controller.",Hardware analog-digital neural networks
"This application discloses hardware suitable for use in a neural network system. It makes use of Z-technology modules, each containing densely packaged electronic circuitry. The modules provide access planes which are electrically connected to circuitry located on planar surfaces interfacing with such access planes. One such planar surface comprises a resistive feedback network. By combining two Z-technology modules, whose stacked chips are in planes perpendicular to one another, and using switching networks between the two modules, the system provides bidirectional accessibility of each individual electronic element in the neural network to most or all of the other individual electronic elements in the system.",Hardware for electronic neural network
"Systems, methods, and computer media for implementing convolutional neural networks efficiently in hardware are disclosed herein. A memory is configured to store a sparse, frequency domain representation of a convolutional weighting kernel. A time-domain-to-frequency-domain converter is configured to generate a frequency domain representation of an input image. A feature extractor is configured to access the memory and, by a processor, extract features based on the sparse, frequency domain representation of the convolutional weighting kernel and the frequency domain representation of the input image. The feature extractor includes convolutional layers and fully connected layers. A classifier is configured to determine, based on extracted features, whether the input image contains an object of interest. Various types of memory can be used to store different information, allowing information-dense data to be stored in faster (e.g., faster access time) memory and sparse data to be stored in slower memory.",Hardware-efficient deep convolutional neural networks
"This invention relates to sensor arrangements and signal processing architectures for touch-based user interfaces comprising multiple sensor types and other arrangements so as to create user interface output signals responsive to the touch of at least one human finger. Sensor types and other arrangements can include capacitive tactile sensor arrays, optical tactile sensor arrays, proximity sensor arrays, pressure sensor arrays, and video cameras. At least one software algorithm comprises at least one of a functional partition (wherein some user interface output signals are derived only from a pre-specified sensor), decision-based selection (wherein some user interface output signals are selectively derived from a selected sensor), or sensor-fusing (wherein user interface output signals are obtained from threshold testing, conditional testing, vector quantization, algorithms employing parameterized calculations, algorithms employing compensation calculations and operations, artificial neural networks, etc.)",Heterogeneous tactile sensing via multiple sensor types
"This invention relates to sensor arrangements and signal processing architectures for touch-based user interfaces comprising multiple sensor types and other arrangements so as to create user interface output signals responsive to the touch of at least one human finger. Sensor types and other arrangements can include capacitive tactile sensor arrays, optical tactile sensor arrays, proximity sensor arrays, pressure sensor arrays, and video cameras. At least one software algorithm comprises at least one of a functional partition (wherein some user interface output signals are derived only from a pre-specified sensor), decision-based selection (wherein some user interface output signals are selectively derived from a selected sensor), or spatial information processing (wherein user interface output signals are obtained from threshold testing, conditional testing, vector quantization, algorithms employing parameterized calculations, algorithms employing compensation calculations and operations, artificial neural networks, etc.).",Heterogeneous tactile sensing via multiple sensor types using spatial information processing
"Sensor arrangements and signal processing for touch-based user interfaces comprising multiple sensor types and other arrangements so as to create user interface output signals responsive to touch. Various types of sensors and other measurement arrangements can include capacitive tactile sensor arrays, optical tactile sensor arrays, proximity sensor arrays, pressure sensor arrays, and video cameras. In one approach, spatial information processing acts on initial image processing data acting separately on the data or measurements provided by each sensor. At least one software algorithm comprises at least one of a functional partition (wherein some user interface output signals are derived only from a pre-specified sensor), decision-based selection (wherein some user interface output signals are selectively derived from a selected sensor), or spatial information processing (wherein user interface output signals are obtained from threshold testing, conditional testing, vector quantization, algorithms employing parameterized calculations, algorithms employing compensation calculations and operations, artificial neural networks, etc.).",Heterogeneous tactile sensing via multiple sensor types using spatial information processing acting on initial image processed data from each sensor
"The present invention defines a method for emulating an iterated process represented by a series of related tasks and a control mechanism that monitors and enables the iterative execution of those tasks until data associated with the process converges to predetermined goals or objectives. The invention defines a method in which fuzzy neural networks and discreet algorithms are applied to perform the process tasks and in which configurable, reloadable finite state machines are applied to control the execution of those tasks. In particular, the present invention provides a method for emulating the process of designing integrated circuit (IC) applications and printed circuit board (PCB) applications for the purpose of simulating, emulating, analyzing, optimizing and predicting the behavioral and physical characteristics of the application at the earliest possible stage of the process. The invention applies fuzzy neural networks and configurable, reloadable finite state machines to emulate the IC or PCB design process, enabling the invention to emulate the the computer aided design (CAD) tools used to perform the design process tasks as well as the individuals using those tools. By emulating the combination of man and machine performances, the invention can more accurately predict the results of a given task than tools that consider only the machine element. The invention also provides a means to adapt the performance and behavior of any element of the invention using historical data compiled from previous design or manufacturing experiences, allowing the invention to incorporate the knowledge gained from previous designs into current designs.",Hierarchical adaptive state machine for emulating and augmenting software
"Hierarchical branching deep convolutional neural networks (HD-CNNs) improve existing convolutional neural network (CNN) technology. In a HD-CNN, classes that can be easily distinguished are classified in a higher layer coarse category CNN, while the most difficult classifications are done on lower layer fine category CNNs. Multinomial logistic loss and a novel temporal sparsity penalty may be used in HD-CNN training. The use of multinomial logistic loss and a temporal sparsity penalty causes each branching component to deal with distinct subsets of categories.",Hierarchical deep convolutional neural network for image classification
"Hierarchical routing for two-way information flow and structural plasticity in a neural network is provided. In one embodiment the network includes multiple core modules, wherein each core module has a plurality of incoming connections with predetermined addresses. Each core module also has a plurality of outgoing connections such that each outgoing connection targets an incoming connection in a core module among the multiple core modules. The network also has a routing system that selectively routes signals among the core modules based on a reconfigurable hierarchical organization of the core modules. The network approximates a fully connected network such that each outgoing connection on any core module can target and reach any incoming connection on any core module without requiring a fully connected network. The routing system provides two-way information flow between neurons utilizing hierarchical routing.",Hierarchical routing for two-way information flow and structural plasticity in neural networks
"Pattern recognition, for instance optical character recognition, is achieved by training a neural network, scanning an image, segmenting the image to detect a pattern, preprocessing the detected pattern, and applying the preprocessed detected pattern to the trained neural network. The preprocessing includes determining a centroid of the pattern and centrally positioning the centroid in a frame containing the pattern. The training of the neural network includes randomly displacing template patterns within frames before applying the template patterns to the neural network.",High accuracy optical character recognition using neural networks with centroid dithering
"Nodal outputs are discretized to values of S2.sup.n where n is an integer and S is equal to +1 or -1. During forward propagation, this offers the advantage of forming a product of a nodal output and a weight using a simple shift operation rather than a multiply operation. Replacing multiply operations with shift operations through out a neural network improves response times and permits building larger networks that have broader applicability. Training is also improved by increasing the efficiency of backward propagation. The multiplications involved in backward propagation are reduced To shift operations by discretizing the errors associated with each node so that they are represented as 2.sup.n where n is an integer and S is equal to +1 or -1.",High efficiency learning network
"An apparatus includes a first memory interface circuit, a second memory interface circuit, and a compression circuit coupled between the first memory interface circuit and the second memory interface circuit. The compression circuit may be configured to receive a coding block of data via the first memory interface circuit, generate a reduced size representation of the coding block, and write the reduced size representation of the coding block to an external memory using the second memory interface circuit. The reduced size representation of said coding block generally comprises a first bit map, a second bit map, and zero or more non-zero values.",High throughput hardware unit providing efficient lossless data compression in convolution neural networks
"High-gain MOCVD-grown (metal-organic chemical vapor deposition) AlGaAs/GaAs/AlGaAs n-p-n double heterojunction bipolar transistors (DHBTs) (14) and Darlington phototransistor pairs (14, 16) are provided for use in optical neural networks and other optoelectronic integrated circuit applications. The reduced base (22) doping level used herein results in effective blockage of Zn out-diffusion, enabling a current gain of 500, higher than most previously reported values for Zn-diffused-base DHBTs. Darlington phototransistor pairs of this material can achieve a current gain of over 6,000, which satisfies the gain requirement for optical neural network designs, which advantageously may employ novel neurons (10) comprising the Darlington phototransistor pair in series with a light source (12).",High-gain AlGaAs/GaAs double heterojunction Darlington phototransistors for optical neural networks
"The present invention relates to a method and system for classifying high-resolution melt (HRM) curves, and, more specifically, to a method and system for classifying HRM curves by genotype where the curves are represented by a mathematical function with varying coefficient values.",High-resolution melt curve classification using neural networks
"A method for magnetic resonance imaging (MRI) scans a field of view and acquires sub-sampled multi-channel k-space data U. An imaging model A is estimated. Sub-sampled multi-channel k-space data U is divided into sub-sampled k-space patches, each of which is processed using a deep convolutional neural network (ConvNet) to produce corresponding fully-sampled k-space patches, which are assembled to form fully-sampled k-space data V, which is transformed to image space using the imaging model adjoint Aadj to produce an image domain MRI image. The processing of each k-space patch ui preferably includes applying the k-space patch ui as input to the ConvNet to infer an image space bandpass-filtered image yi, where the ConvNet comprises repeated de-noising blocks and data-consistency blocks; and estimating the fully-sampled k-space patch vi from the image space bandpass-filtered image yi using the imaging model A and a mask matrix.",Highly-scalable image reconstruction using deep convolutional neural networks with bandpass filtering
"An on-line training neural network for process control system and method trains by retrieving training sets from the stream of process data. The neural network detects the availability of new training data, and constructs a training set by retrieving the corresponding input data. The neural network is trained using the training set. Over time, many training sets are presented to the neural network. When multiple presentations are needed to effectively train, a buffer of training sets is filled and updated as new training data becomes available. The size of the buffer is selected in accordance with the training needs of the neural network. Once the buffer is full, a new training set bumps the oldest training set off the top of the buffer stack. The training sets in the buffer stack can be presented one or more times each time a new training set is constructed. An historical database of timestamped data can be used to construct training sets when training input data has a time delay from sample time to availability for the neural network. The timestamps of the training input data are used to select the appropriate timestamp at which input data is retrieved for use in the training set. Using the historical database, the neural network can be trained retrospectively by searching the historical database and constructing training sets based on past data.",Historical database training method for neural networks
"An on-line training neural network for controlling a process for producing a product having at least one product property that trains by retrieving training sets from a stream of process data. The neural network detects the availability of new training data, and constructs a training set by retrieving the corresponding input data. The neural network is trained using the training set. Over time, many training sets are presented to the neural network. When multiple presentations are needed to effectively train, a buffer of training sets is filled and updated as new training data becomes available. The size of the buffer is selected in accordance with the training needs of the neural network. Once the buffer is full, a new training set bumps the oldest training set off the top of the buffer stack. The training sets in the buffer stack can be presented one or more times each time a new training set is constructed. An historical database of timestamped data can be used to construct training sets when training input data has a time delay from sample time to availability for the neural network. The timestamps of the training input data are used to select input data for use in the training set. Using the historical database, the neural network can be trained retrospectively by searching the historical database and constructing training sets based on past data.",Historical database training method for neural networks
"An on-line training neural network for process control system and method trains by retrieving training sets from the stream of process data. The neural network detects the availability of new training data, and constructs a training set by retrieving the corresponding input data. The neural network is trained using the training set. Over time, many training sets are presented to the neural network. When multiple presentations are needed to effectively train, a buffer of training sets is filled-and updated as new training data becomes available. The size of the buffer is selected in accordance with the training needs of the neural network. Once the buffer is full, a new training set bumps the oldest training set off the top of the buffer stack. The training sets in the buffer stack can be presented one or more times each time a new training set is constructed. An historical database of timestamped data can be used to construct training sets when training input data has a time delay from sample time to availability for the neural network. The timestamps of the training input data are used to select the appropriate timestamp at which input data is retrieved for use in the training set. Using the historical database, the neural network can be trained retrospectively by searching the historical database and constructing training sets based on past data.",Historical database training method for neural networks
""" An interceptor's point of impact on a targeted missile is quickly revealed in the milliseconds preceeding and following the impact by illuminating the target with radar signals at a high pulse repetition rate and observing the reflected radar echoes on an A-scope display. The position within the returned radar echo of a double echo and related changing phenomenon indicates the point of impact. Failing intercept, the miss distance is computed from the relative slant ranges to the targeted missile, the interceptor, and the double echo. The type warhead killed is revealed by a spectrograph slaved to the radar's antenna. Various techniques assist with the interpretation of the displayed patterns, including subtraction of previously stored patterns and display of the difference, display of characteristic patterns of various known missiles and interceptors stored in """"look up"""" tables, and neural networks. """,Hit verification technique
"Systems and methods for determining the position and classification of an object and which may provide signals that control deployment of an active restraint device, for example. Using a pulsed laser light beam from a laser source that is spread and preferably diffused to avoid ocular damage, an interference pattern is returned to a sensing module through a spectral filter. There it is optionally combined with a reference beam from the laser source, modified to emulate coherence length effects, and incident upon a phase transmission holographic template that may be segmented into regions for example. Each region of the holographic template contains Fourier transform images of occupant types. Behind the holographic template is a detector array that is sensitive to the laser light. An interference pattern derived from the object is convoluted or cross-correlated with the template. When an match occurs, a bright spot appears on the detector array. The location of this spot within the region contains position information. The relative brightness and location of spots within each region provide information relative to their classification. Using fuzzy logic, neural networks, or an algebraic algorithm, this information is decoded, and a decision made as to the type and location of the object. With this information, a deployment algorithm for the active restraint device, in conjunction with other information, can make the appropriate choice on whether or not to deploy the device.",Holographic object position and type sensing system and method
"A method of determining properties relating to the manufacture of an injection-molded article is described. The method makes use of a hybrid model which includes at least one neural network and at least one rigorous model. In order to forecast (or predict) properties relating to the manufacture of a plastic molded part, a hybrid model is used which includes: one or more neural networks NN1, NN2, NN3, NN4, . . . , NNk; and one or more rigorous models R1, R2, R3, R4, . . . , which are connected to one another. The rigorous models are used to map model elements which can be described in mathematical formulae. The neural model elements are used to map processes whose relationship is present only in the form of data, as it is typically impossible to model such processes rigorously. As a result, a forecast (or prediction) relating to properties including, for example, the mechanical, thermal and rheological processing properties and relating to the cycle time of a plastic molded part can be made.",Hybrid model and method for determining manufacturing properties of an injection-molded part
"A method of predicting the properties (e.g., mechanical and/or processing properties) of an injection-molded article is disclosed. The method makes use of a hybrid model which includes at least one neural network. In order to forecast (or predict) properties with respect to the manufacture of a plastic molded article, a hybrid model is used in the present invention, which includes: one or more neural networks NN1, NN2, NN3, NN4, . . . , NNk; and optionally one or more rigorous models R1, R2, R3, R4, . . . , which are connected to one another. The rigorous models are used to map model elements which can be described in mathematical formulae. The neural networks are used to map processes whose relationship is present only in the form of data, as it is in effect impossible to model such processes rigorously. As a result, a forecast relating to properties including the mechanical, thermal and rheological processing properties and relating to the process time of a plastic molded article is obtained.",Hybrid model and method for determining mechanical properties and processing properties of an injection-molded part
"The hybrid artificial immune system consists of three main layers, including a solution application layer that interacts with the environment, a solution generation layer that solves combinatorial optimization problems and a modeling layer that analyzes problems and presents solution scenarios. The system solves evolutionary multi-objective optimization problems in network computing, robotics, artificial neural networks, protein network modeling, evolutionary systems and evolutionary hardware.",Hybrid multi-layer artificial immune system
"A hybrid network 100 which combines a neural network of the self-organized type 110 with a plurality of neural networks of the supervised learning type 150,160,170 to successfully retrieve building address information from a database using imperfect textual retrieval keys. Generally, the self-organized type is a Kohonen Feature Map network, whereas each supervised learning type is a Back Propagation network. A user query 105 produces an activation response 111,112,113 from the self-organized network 110 and this response, along with a new query 151,161,171 derived from the original query 105, activates a selected one of the learning networks R.sub.1,R.sub.2,R.sub.M to retrieve the requested information.",Hybrid multi-layer neural networks
"A system and a method for recognizing patterns comprises a first stage for xtracting features from inputted patterns and for providing topological representations of the characteristics of the inputted patterns and a second stage for classifying and recognizing the inputted patterns. The first stage comprises two one-layer neural networks and the second stage comprises a feedforward two-layer neural network. Supplying signals representative of a set of inputted patterns to the input layers of the first and second neural networks, training the first and second neural networks using a competitive learning algorithm, and generating topological representations of the input patterns using the first and second neural networks The method further comprises providing a third neural network for classifying and recognizing the inputted patterns and training the third neural network with a back-propagation algorithm so that the third neural network recognizes at least one interested pattern.",Hybrid neural network for pattern recognition
"A method uses a hybrid neural network including a self organizing mapping neural network (SOM NN) and a, back-propagation neural network (BP NN) for color identification. In the method the red, green and blue (RGB) of color samples are input as features of training samples and are automatically classified by way of SOM NN. Afterwards, the outcomes of SOM NN are respectively delivered to various BP NN for further learning; and the map relationship of the input and the output defines the X,Y, Z corresponding the x, y and z values of a coordinate system of the standard color samples of RGB and IT8. By way of the above learning structure, a non-linear model of color identification can be set up. After color samples are self organized and classified by SOM NN network, data can be categorized in clusters as a result of characteristic difference thereof. Then the data are respectively sent to BP NN for learning whereby-the learning system not only can be quickly converged but also lower error discrepancy in operation effectively.",Hybrid neural networks for color identification
"A hybrid frame, phone, diphone, morpheme, and word-level Deep Neural Networks (DNN) in model training and applications-is based on training a regular ASR system, which can be based on Gaussian Mixture Models (GMM) or DNN. All the training data (in the format of features) are aligned with the transcripts in terms of phonemes and words with the timing information and new features are formed in terms of phonemes, diphones, morphemes, and up to words. Regular ASR produces a result lattice with timing information for each word. A feature is then extracted and sent to the word-level DNN for scoring Phoneme features are sent to corresponding DNNs for training. Scores are combined to form the word level scores, a rescored lattice and a new recognition result.","Hybrid phoneme, diphone, morpheme, and word-level deep neural networks"
"The technology relates to converting text to speech utilizing recurrent neural networks (RNNs). The recurrent neural networks may be implemented as multiple modules for determining properties of the text. In embodiments, a part-of-speech RNN module, letter-to-sound RNN module, a linguistic prosody tagger RNN module, and a context awareness and semantic mining RNN module may all be utilized. The properties from the RNN modules are processed by a hyper-structure RNN module that determine the phonetic properties of the input text based on the outputs of the other RNN modules. The hyper-structure RNN module may generate a generation sequence that is capable of being converting to audible speech by a speech synthesizer. The generation sequence may also be optimized by a global optimization module prior to being synthesized into audible speech.",Hyper-structure recurrent neural networks for text-to-speech
"A system that identifies attributes of an item depicted in an image using artificial intelligence is provided. For example, the system may use one or more deep belief networks (DBNs) or convolution neural networks (CNNs) trained to analyze images and identify attributes in items depicted in the images. A first artificial intelligence module may analyze an image to determine a type of item depicted in the image. The system may then select a second artificial intelligence module that is associated with the type of item and use the second artificial intelligence module to identify attributes in the item depicted in the image. Identified attributes, if associated with a confidence level over a threshold value, may be provided to a user. The user may provide feedback on the accuracy of the identified attributes, which can be used to further train the first and/or second artificial intelligence modules.",Identification of item attributes using artificial intelligence
"A system that identifies attributes of an item depicted in an image using artificial intelligence is provided. For example, the system may use one or more deep belief networks (DBNs) or convolution neural networks (CNNs) trained to analyze images and identify attributes in items depicted in the images. A first artificial intelligence module may analyze an image to determine a type of item depicted in the image. The system may then select a second artificial intelligence module that is associated with the type of item and use the second artificial intelligence module to identify attributes in the item depicted in the image. Identified attributes, if associated with a confidence level over a threshold value, may be provided to a user. The user may provide feedback on the accuracy of the identified attributes, which can be used to further train the first and/or second artificial intelligence modules.",Identification of item attributes using artificial intelligence
"A method for identifying an object within a video sequence, wherein the video sequence comprises a sequence of images, wherein the method comprises, for each of one or more images of the sequence of images: using a first neural network to determine whether or not an object of a predetermined type is depicted within the image; and in response to the first neural network determining that an object of the predetermined type is depicted within the image, using an ensemble of second neural networks to identify the object determined as being depicted within the image.",Identifying an object within content
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using recurrent neural networks to analyze health events. One of the methods includes: processing each of a plurality of initial temporal sequences of health events to generate, for each of the initial temporal sequences, a respective network internal state of a recurrent neural network for each time step in the initial temporal sequence; storing, for each of the initial temporal sequences, one or more of the network internal states for the time steps in the temporal sequence in a repository; obtaining a first temporal sequence; processing the first temporal sequence using the recurrent neural network to generate a sequence internal state for the first temporal sequence; and selecting one or more initial temporal sequences that are likely to include health events that are predictive of future health events in the first temporal sequence.",Identifying predictive health events in temporal sequences using recurrent neural network
"Embodiments are directed to identifying allocation discrepancies. Data models and Benchmark models may be provided to an analysis engine. Discrepancy models may be provided to the analysis engine, such that each discrepancy model may be arranged to include one or more rules. The analysis engine may be employed to search for discrepancies in the data models based on the discrepancy models and the benchmark models. If discrepancies may be identified by the analysis engine, one or more notifications may be provided to one or more users. Also, the discrepancy models may be modified based on subsequent feedback provided by the one or more users. Correlations in the resource allocation values may be identified based on machine learning that includes one or more of linear regression, deep learning neural networks, or the like. And, additional discrepancy models may be provided based on the identified correlations.",Identifying resource allocation discrepancies
"Deep convolutional neural networks receive local and global representations of images as inputs and learn the best representation for a particular feature through multiple convolutional and fully connected layers. A double-column neural network structure receives each of the local and global representations as two heterogeneous parallel inputs to the two columns. After some layers of transformations, the two columns are merged to form the final classifier. Additionally, features may be learned in one of the fully connected layers. The features of the images may be leveraged to boost classification accuracy of other features by learning a regularized double-column neural network.",Image assessment using deep convolutional neural networks
"A neural network system that includes: multiple subnetworks that includes: a first subnetwork including multiple first modules, each first module including: a pass-through convolutional layer configured to process the subnetwork input for the first subnetwork to generate a pass-through output; an average pooling stack of neural network layers that collectively processes the subnetwork input for the first subnetwork to generate an average pooling output; a first stack of convolutional neural network layers configured to collectively process the subnetwork input for the first subnetwork to generate a first stack output; a second stack of convolutional neural network layers that are configured to collectively process the subnetwork input for the first subnetwork to generate a second stack output; and a concatenation layer configured to concatenate the pass-through output, the average pooling output, the first stack output, and the second stack output to generate a first module output for the first module.",Image classification neural networks
"Methods, and systems, including computer programs encoded on computer storage media for compressing data items with variable compression rate. A system includes an encoder sub-network configured to receive a system input image and to generate an encoded representation of the system input image, the encoder sub-network including a first stack of neural network layers including one or more LSTM neural network layers and one or more non-LSTM neural network layers, the first stack configured to, at each of a plurality of time steps, receive an input image for the time step that is derived from the system input image and generate a corresponding first stack output, and a binarizing neural network layer configured to receive a first stack output as input and generate a corresponding binarized output.",Image compression with recurrent neural networks
"Techniques are provided for image segmentation based on image differencing, using recursive neural networks. A methodology implementing the techniques according to an embodiment includes quantizing pixels of a first image frame, performing a rigid translation of the quantized first image frame to generate a second image frame, and performing a differencing operation between the quantized first image frame and the second image frame to generate a sparse image frame. A neural network can then be applied to the sparse image frame to generate a segmented image. In still another embodiment, the methodology is applied to a sequence or set of image frames, for example from a video or still camera, and pixels from a first and second image frame of the sequence/set are quantized. The sparse image frame is generated from a difference between quantized image frames. The method further includes training the neural network on sparse training image frames.",Image difference based segmentation using recursive neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for image generation using neural networks. In one of the methods, an initial image is received. Data defining an objective function is received, and the objective function is dependent on processing of a neural network trained to identify features of an image. The initial image is modified to generate a modified image by iteratively performing the following: a current version of the initial image is processed using the neural network to generate a current objective score for the current version of the initial image using the objective function; and the current version of the initial image is modified to increase the current objective score by enhancing a feature detected by the processing.",Image generation using neural networks
"Image hole filling that account for global structure and local texture. One exemplary technique involves using both a content neural network and a texture neural network. The content neural network is trained to encode image features based on non-hole image portions and decode the image features to fill holes. The texture neural network is trained to extract image patch features that represent texture. The exemplary technique receives an input image that has a hole and uses the two neural networks to fill the hole and provide a result image. This is accomplished by selecting pixel values for the hole based on a content constraint that uses the content neural network to account for global structure and a texture constraint that uses the texture neural network to account for local texture. For example, the pixel values can be selected by optimizing a loss function that implements the constraints.",Image hole filling that accounts for global structure and local texture
"A method, system, and computer program product for modifying an appearance of an anatomical structure in a medical image, e.g., rib suppression in a chest radiograph. The method includes: acquiring, using a first imaging modality, a first medical image that includes the anatomical structure; applying the first medical image to a trained image processing device to obtain a second medical image, corresponding to the first medical image, in which the appearance of the anatomical structure is modified; and outputting the second medical image. Further, the image processing device is trained using plural teacher images obtained from a second imaging modality that is different from the first imaging modality. In one embodiment, the method also includes processing the first medical image to obtain plural processed images, wherein each of the plural processed images has a corresponding image resolution; applying the plural processed images to respective multi-training artificial neural networks (MTANNs) to obtain plural output images, wherein each MTANN is trained to detect the anatomical structure at one of the corresponding image resolutions; and combining the plural output images to obtain a second medical image in which the appearance of the anatomical structure is enhanced.",Image modification and detection using massive training artificial neural networks (MTANN)
"A neurography system (10) is disclosed for generating diagnostically useful images of neural tissue (i.e., neurograms) employing a modified magnetic resonance imaging system (14). In one embodiment, the neurography system selectively images neural tissue by employing one or more gradients to discriminate diffusion anisotropy in the tissue and further enhances the image by suppressing the contribution of fat to the image. The neurography system is part of a broader medical system (12), which may include an auxiliary data collection system (22), diagnostic system (24), therapeutic system (26), surgical system (28), and training system (30). These various systems are all constructed to take advantage of the information provided by the neurography system regarding neural networks, which information was heretofore unavailable.",Image neurography and diffusion anisotropy imaging
"A system and method of image processing using neural networks to control image processing elements. Neural network parameters are defined by genotypes consisting of network vectors. Genotypes may be selectively mutated and cross-bred to provide a mechanism for modifying the behavior of the neural networks, or phenotypes. Genetic modeling processes are used to perform such mutation and cross-over. User feedback concerning output images, is used to select particular genotypes for further mutation and exploration. Preconditioning is employed to extract structural information from source images prior to network processing. Genetic morphing and subnet fusion are also available, to provide additional variations on image processing operations.",Image processing using genetic mutation of neural network parameters
"This disclosure relates to digital image segmentation, region of interest identification, and object recognition. This disclosure describes a method, a system, for image segmentation based on fully convolutional neural network including an expansion neural network and contraction neural network. The various convolutional and deconvolution layers of the neural networks are architected to include a coarse-to-fine residual learning module and learning paths, as well as a dense convolution module to extract auto context features and to facilitate fast, efficient, and accurate training of the neural networks capable of producing prediction masks of regions of interest. While the disclosed method and system are applicable for general image segmentation and object detection/identification, they are particularly suitable for organ, tissue, and lesion segmentation and detection in medical images.",Image segmentation and object detection using fully convolutional neural network
Neural-network-based image segmentation techniques are provided herein. An input image that includes a plurality of characters can be received. Boundaries between the characters can be identified using a trained neural network. The input image can be segmented along the boundaries identified between the characters. The neural network can be trained using a training image and a training target vector. The training target vector can indicate one or more boundaries between characters in the training image. Neural-network-based segmentation can be used alone or in conjunction with other segmentation techniques to improve overall segmentation accuracy.,Image segmentation in optical character recognition using neural networks
Neural-network-based image segmentation techniques are provided herein. An input image that includes a plurality of characters can be received. Boundaries between the characters can be identified using a trained neural network. The input image can be segmented along the boundaries identified between the characters. The neural network can be trained using a training image and a training target vector. The training target vector can indicate one or more boundaries between characters in the training image. Neural-network-based segmentation can be used alone or in conjunction with other segmentation techniques to improve overall segmentation accuracy.,Image segmentation in optical character recognition using neural networks
"Example aspects of the present disclosure are directed to systems and methods that perform image style transfer for three-dimensional models. In some implementations, the systems and methods can use machine-learned models such as, for example, convolutional neural networks to generate image style and content information used to perform style transfer. The systems and methods of the present disclosure can operate in a rendered image space. In particular, a computing system can iteratively modify an attribute rendering map (e.g., texture map, bump map, etc.) based on information collected from a different rendering of the model at each of a plurality of iterations, with the end result being that the attribute rendering map mimics the style of one or more reference images in content-preserving way. In some implementations, a computation of style loss at each iteration can be performed using multi-viewpoint averaged scene statistics, instead of treating each viewpoint independently.",Image style transfer for three-dimensional models
"A method and system for analyzing text in an image. Classification and localization information is identified for the image at a word and character level. A detailed profile is generated that includes attributes of the words and characters identified in the image. One or more objects representing a predicted source of the text are identified in the image. In one embodiment, neural networks are employed to determine localization information and classification information associated with the identified object of interest (e.g., a text string, a character, or a text source).",Image text recognition
"This invention concerns an immunoassay for quantitative determination of the amount of the complex (PSA-A2M) between prostate specific antigen (PSA) and &agr;2-macroglobulin (A2M) in a sample. The assay comprises the steps of removing immunoreactive PSA from the sample, treating the PSA-A2M complex in the remaining supernatant so as to make the PSA thereof immunoreactive, determining the immunoreactive PSA derived from the PSA-A2M complex by exposing it to an antibody which binds immunoreactive PSA, and detecting the PSA. The invention also concerns a method for differentiating patients with cancer of the prostate (PCa) from patients with benign prostatic hyperplasia (BPH) or healthy male subjects without PCa, wherein the individual's body fluid concentration of PSA has been determined as free PSA and as total PSA. The method is characterized in that PSA complexed with A2M (PSA-A2M) in the individual's serum sample has been determined, and that the ration between PSA-A2M and other forms of PSA is calculated, or that the diagnostic value is calculated by logistic regression, neural networks, fussy logic or similar mathematical and statistical methods using PSA-A2M and other forms of PSA, such as total PSA, free PSA and PSA-ACT as input variables.",Immunoassay for quantitative determination of the complex between prostate specific antigen (PSA) and &agr;2-macroglobulin (A2M) in a sample
"A neural prosthesis includes a centralized device that can provide power, data, and clock signals to one or more individual neural prosthesis subsystems. Each subsystem may include a number of individually addressable, programmable modules that can be dynamically allocated or shared among neural prosthetic networks to achieve complex, coordinated functions or to operate in autonomous groups.",Implantable networked neural system
"This invention is in the field of machine learning and neural associative memory. In particular the invention discloses a neural associative memory structure for storing and maintaining associations between memory address patterns and memory content patterns using a neural network, as well as methods for retrieving such associations. A method for a non-linear synaptic learning of discrete synapses is disclosed, and its application on neural networks is laid out.",Implementing a neural associative memory based on non-linear learning of discrete synapses
"A method of achieving automatic learning of an input vector presented to an artificial neural network (ANN) formed by a plurality of neurons, using the K nearest neighbor (KNN) mode. Upon providing an input vector to be learned to the ANN, a Write component operation is performed to store the input vector components in the first available free neuron of the ANN. Then, a Write category operation is performed by assigning a category defined by the user to the input vector. Next, a test is performed to determine whether this category matches the categories of the nearest prototypes, i.e. which are located at the minimum distance. If it matches, this first free neuron is not engaged. Otherwise, it is engaged by assigning the matching category to it. As a result, the input vector becomes the new prototype with the matching category associated thereto. Further described is a circuit which automatically retains the first free neuron of the ANN for learning.",Implementing automatic learning according to the K nearest neighbor mode in artificial neural networks
"Methods, systems, and computer storage media for implementing neural networks in fixed point arithmetic computing systems. In one aspect, a method includes the actions of receiving a request to process a neural network using a processing system that performs neural network computations using fixed point arithmetic; for each node of each layer of the neural network, determining a respective scaling value for the node from the respective set of floating point weight values for the node; and converting each floating point weight value of the node into a corresponding fixed point weight value using the respective scaling value for the node to generate a set of fixed point weight values for the node; and providing the sets of fixed point floating point weight values for the nodes to the processing system for use in processing inputs using the neural network.",Implementing neural networks in fixed point arithmetic computing systems
"A hybrid protein (GFP-TTC) comprising the non-toxic proteolytic C fragment of tetanus toxin fused to green fluorescent protein was used to analyze the functional synaptic organization of neural networks. When injected intramuscularly in vivo, the GFP-TTC hybrid protein binds to tetanus neurotoxin receptors and clusters very rapidly to the active neuromuscular junction. Membrane traffic by GFP-TTC at the pre-synaptic level of the neuromuscular junction is strongly and rapidly influenced by exogenously co-injecting neurotrophic factors, such as BDNF, NT-4, and GDNF, but not by NGF, NT-3, and CNTF. The membrane traffic, directly detected using GFP-TTC in vivo, permits methods of analyzing synaptic functioning as well as methods of modulating neuronal transport using neurotrophic factors and agonists or antagonists thereof.",In vivo modulation of neuronal transport
"Novel multiplexed volume holographic optical elements for the development of highly multiplexed photonic interconnection and holographic memory systems with maximum optical throughput efficiency and minimum crosstalk, based on parallel incoherent/coherent double angularly multiplexed volume holographic recording and readout principles, are disclosed. These principles further provide for arbitrarily weighted and independent interconnections, which are of potential importance in the development of densely interconnected photonic implementations of neural networks, photonic interconnection networks for telecommunications switching and digital computing applications, optical information processors, and optical memories. Utilization of the principles that are key features of this holographic element allows for the single step transfer of all or part of the information stored in a three-dimensional holographic storage device to a second such device in a single exposure step. Variants of the multiplexed volume holographic optical element include bulk holographic recording media as well as stratified volume holographic optical elements, comprising in either case both holographic (optical) modulation patterns and computer-generated holograms. Further variants of the multiplexed volume holographic optical element incorporate a subhologram structure within the volume holographic optical element that allows for high efficiency recording in certain real time photorefractive media.",Incoherent/coherent double angularly multiplexed volume holographic optical elements
"Novel apparatuses for readout of multiplexed volume holographic optical elements, based on parallel incoherent/coherent double angularly multiplexed holographic recording and readout principles, provide for hologram readout with high optical throughput efficiency and minimal crosstalk. Such holographic element readout apparatuses have applications in photonic interconnections for neural networks, telecommunications switching and digital computing; optical information processors and optical memories; and optical display systems. Embodiments are included that allow incoherent superposition of reconstructed images and simplified parallel readout of the volume holographic optical elements. The apparatuses can read out holographic elements that are either optically or computer generated and that are based on continuous-volume or stratified-volume holographic media.",Incoherent/coherent readout of double angularly multiplexed volume holographic optical elements
"A method of biasing a deep neural network includes determining whether an element has an increased probability of being present in an input to the network. The method also includes adjusting a bias of activation functions of neurons in the network to increase sensitivity to the element. In one configuration, the bias is adjusted without adjusting weights of the network. The method further includes adjusting an output of the network based on the biasing.",Incorporating top-down information in deep neural networks via the bias term
"An information processing apparatus, includes a lower time series data generation unit having a plurality of recurrent neural networks which learn predetermined time series data, and generating prediction time series data. An upper time series data generation unit has recurrent neural networks which learn error time series data that is time series data of errors raised at the time of the learning by the respective plural recurrent neural networks of the lower time series data generation unit. Generation of prediction error time series data that is time series data of prediction errors; and a conversion unit that performs nonlinear conversion for the prediction errors generated by the upper time series data generation unit. The lower time series data generation unit outputs the prediction time series data according to the prediction errors.","Information processing apparatus, method, and program using recurrent neural networks"
"A data processing technique uses an Artificial Neural Network (ANN) with Rectifier Linear Units (ReLU) to yield improve accuracy in a runtime task, for example, in processing audio-based data acquired by a speech-enabled device. The technique includes a first aspect that relates to initialization of the ANN weights to initially yield a high fraction of positive outputs from the ReLU. These weights are then modified using an iterative procedure in which the weights are incrementally updated. A second aspect relates to controlling the size of the incremental updates (a learning rate) during the iterations of training according to a variance of the weights at each layer.",Initializing and learning rate adjustment for rectifier linear unit based artificial neural networks
"Disclosed is an integrated imaging sensor/neural network controller for combustion control systems. The controller uses electronic imaging sensing of chemiluminescence from a combustion system, combined with neural network image processing, to sensitively identify and control a complex combustion system. The imaging system used is not adversely affected by the normal emissions variations caused by changes in burner load and flame position. By incorporating neural networks to learn emission patterns associated with combustor performance, control using image technology is fast enough to be used in a real time, closed loop control system. This advance in sensing and control strategy allows use of the spatial distribution of important parameters in the combustion system in identifying the overall operation condition of a given combustor and in formulating a control response accorded to a pre-determined control model.",Integrated imaging sensor/neural network controller for combustion systems
"An apparatus and method for recognizing written items including characters and symbols is disclosed. A scanner is utilized for scanning the characters and symbols. A recognition module is used to confidently identify the scanned characters and symbols. The recognition module includes a mechanism for recognizing characters. This mechanism includes a character recognition rule base which yields identified characters and unidentified characters. The unidentified characters are conveyed to neural networks for recognition. The recognition module also includes a mechanism for recognizing symbols. This mechanism includes a symbol recognition rule base which yields identified symbols and unidentified symbols. The unidentified symbols are conveyed to neural networks for recognition. The recognition module also includes a mechanism for context processing of the characters and symbols. The context processor utilizes a multilevel blackboard with a number of ascending levels. The blackboard combines characters and symbols into logical units. The blackboard also serves to verify the identity of the characters and symbols. The resultant data from the recognition module is placed in a metafile which is conveyed to a modification module. The modification module includes graphics editing software to edit the scanned characters and symbols. After editing, a translator is used to convert the scanned characters and symbols to a format suitable for a CAD system or data base.",Integrated method and apparatus for character and symbol recognition
"The present invention relates to an intelligent adaptive system and method for monitoring leakage of oil pipeline networks based on big data. The present invention effectively analyzes a large amount of data collected on site within a reasonable time period and obtains a state of a pipeline network by an intelligent adaptive method, thereby obtaining a topological structure of a pipeline network. The present invention specifically adopts a flow balance method in combination with information conformance theory to analyze whether the pipeline network has leakage; small amount of leakage and slow leakage can be perfectly and accurately alarmed upon detection; as a generalized regression neural network is adopted to locate a leakage of the pipeline network, an accuracy of a result is increased. Therefore, the present invention adopts a policy and intelligent adaptive method based on big data to solve problems of detecting and locating leakage of the pipeline network.",Intelligent adaptive system and method for monitoring leakage of oil pipeline networks based on big data
"An intelligent control system based on an explicit model of cognitive development (Table 1) performs high-level functions. It comprises up to O hierarchically stacked neural networks, Nm, . . . , Nm+(O1), where m denotes the stage/order tasks performed in the first neural network, Nm, and O denotes the highest stage/order tasks performed in the highest-level neural network. The type of processing actions performed in a network, Nm, corresponds to the complexity for stage/order m. Thus N1 performs tasks at the level corresponding to stage/order 1. N5 processes information at the level corresponding to stage/order 5. Stacked neural networks begin and end at any stage/order, but information must be processed by each stage in ascending order sequence. Stages/orders cannot be skipped. Each neural network in a stack may use different architectures, interconnections, algorithms, and training methods, depending on the stage/order of the neural network and the type of intelligent control system implemented.",Intelligent control with hierarchal stacked neural networks
"An intelligent control system based on an explicit model of cognitive development (Table 1) performs high-level functions. It comprises up to O hierarchically stacked neural networks, Nm, . . . , Nm+(O1), where m denotes the stage/order tasks performed in the first neural network, Nm, and O denotes the highest stage/order tasks performed in the highest-level neural network. The type of processing actions performed in a network, Nm, corresponds to the complexity for stage/order m. Thus N1 performs tasks at the level corresponding to stage/order 1. N5 processes information at the level corresponding to stage/order 5. Stacked neural networks begin and end at any stage/order, but information must be processed by each stage in ascending order sequence. Stages/orders cannot be skipped. Each neural network in a stack may use different architectures, interconnections, algorithms, and training methods, depending on the stage/order of the neural network and the type of intelligent control system implemented.",Intelligent control with hierarchical stacked neural networks
"A system and method of detecting an aberrant message is provided. An ordered set of words within the message is detected. The set of words found within the message is linked to a corresponding set of expected words, the set of expected words having semantic attributes. A set of grammatical structures represented in the message is detected, based on the ordered set of words and the semantic attributes of the corresponding set of expected words. A cognitive noise vector comprising a quantitative measure of a deviation between grammatical structures represented in the message and an expected measure of grammatical structures for a message of the type is then determined. The cognitive noise vector may be processed by higher levels of the neural network and/or an external processor.",Intelligent control with hierarchical stacked neural networks
"An intelligent control system based on an explicit model of cognitive development (Table 1) performs high-level functions. It comprises up to O hierarchically stacked neural networks, Nm, . . . , Nm+(O1), where m denotes the stage/order tasks performed in the first neural network, Nm, and O denotes the highest stage/order tasks performed in the highest-level neural network. The type of processing actions performed in a network, Nm, corresponds to the complexity for stage/order m. Thus N1 performs tasks at the level corresponding to stage/order 1. N5 processes information at the level corresponding to stage/order 5. Stacked neural networks begin and end at any stage/order, but information must be processed by each stage in ascending order sequence. Stages/orders cannot be skipped. Each neural network in a stack may use different architectures, interconnections, algorithms, and training methods, depending on the stage/order of the neural network and the type of intelligent control system implemented.",Intelligent control with hierarchical stacked neural networks
"A system and method of detecting an aberrant message is provided. An ordered set of words within the message is detected. The set of words found within the message is linked to a corresponding set of expected words, the set of expected words having semantic attributes. A set of grammatical structures represented in the message is detected, based on the ordered set of words and the semantic attributes of the corresponding set of expected words. A cognitive noise vector comprising a quantitative measure of a deviation between grammatical structures represented in the message and an expected measure of grammatical structures for a message of the type is then determined. The cognitive noise vector may be processed by higher levels of the neural network and/or an external processor.",Intelligent control with hierarchical stacked neural networks
"An intelligent control system based on an explicit model of cognitive development (Table 1) performs high-level functions. It comprises up to O hierarchically stacked neural networks, Nm, . . . , Nm+(O1), where m denotes the stage/order tasks performed in the first neural network, Nm, and O denotes the highest stage/order tasks performed in the highest-level neural network. The type of processing actions performed in a network, Nm, corresponds to the complexity for stage/order m. Thus N1 performs tasks at the level corresponding to stage/order 1. N5 processes information at the level corresponding to stage/order 5. Stacked neural networks begin and end at any stage/order, but information must be processed by each stage in ascending order sequence. Stages/orders cannot be skipped. Each neural network in a stack may use different architectures, interconnections, algorithms, and training methods, depending on the stage/order of the neural network and the type of intelligent control system implemented.",Intelligent control with hierarchical stacked neural networks
"A method of processing information is provided. The method involves receiving a message; processing the message with a trained artificial neural network based processor, having at least one set of outputs which represent information in a non-arbitrary organization of actions based on an architecture of the artificial neural network based processor and the training; representing as a noise vector at least one data pattern in the message which is incompletely represented in the non-arbitrary organization of actions; analyzing the noise vector distinctly from the trained artificial neural network; searching at least one database; and generating an output in dependence on said analyzing and said searching.",Intelligent control with hierarchical stacked neural networks
"A system and method of detecting an aberrant message is provided. An ordered set of words within the message is detected. The set of words found within the message is linked to a corresponding set of expected words, the set of expected words having semantic attributes. A set of grammatical structures represented in the message is detected, based on the ordered set of words and the semantic attributes of the corresponding set of expected words. A cognitive noise vector comprising a quantitative measure of a deviation between grammatical structures represented in the message and an expected measure of grammatical structures for a message of the type is then determined. The cognitive noise vector may be processed by higher levels of the neural network and/or an external processor.",Intelligent control with hierarchical stacked neural networks
"An intelligent control system based on an explicit model of cognitive development (Table 1) performs high-level functions. It comprises up to O hierarchically stacked neural networks, Nm, . . . , Nm+(O1), where m denotes the stage/order tasks performed in the first neural network, Nm, and O denotes the highest stage/order tasks performed in the highest-level neural network. The type of processing actions performed in a network, Nm, corresponds to the complexity for stage/order m. Thus N1 performs tasks at the level corresponding to stage/order 1. N5 processes information at the level corresponding to stage/order 5. Stacked neural networks begin and end at any stage/order, but information must be processed by each stage in ascending order sequence. Stages/orders cannot be skipped. Each neural network in a stack may use different architectures, interconnections, algorithms, and training methods, depending on the stage/order of the neural network and the type of intelligent control system implemented.",Intelligent control with hierarchical stacked neural networks
"An intelligent control system based on an explicit model of cognitive development (Table 1) performs high-level functions. It comprises up to O hierarchically stacked neural networks, Nm, . . . , Nm+(O1), where m denotes the stage/order tasks performed in the first neural network, Nm, and O denotes the highest stage/order tasks performed in the highest-level neural network. The type of processing actions performed in a network, Nm, corresponds to the complexity for stage/order m. Thus N1 performs tasks at the level corresponding to stage/order 1. N5 processes information at the level corresponding to stage/order 5. Stacked neural networks begin and end at any stage/order, but information must be processed by each stage in ascending order sequence. Stages/orders cannot be skipped. Each neural network in a stack may use different architectures, interconnections, algorithms, and training methods, depending on the stage/order of the neural network and the type of intelligent control system implemented.",Intelligent control with hierarchical stacked neural networks
"A method of processing information is provided. The method involves receiving a message; processing the message with a trained artificial neural network based processor, having at least one set of outputs which represent information in a non-arbitrary organization of actions based on an architecture of the artificial neural network based processor and the training; representing as a noise vector at least one data pattern in the message which is incompletely represented in the non-arbitrary organization of actions; analyzing the noise vector distinctly from the trained artificial neural network; searching at least one database; and generating an output in dependence on said analyzing and said searching.",Intelligent control with hierarchical stacked neural networks
"A plant controller using reinforcement learning for controlling a plant includes action and critic networks with enhanced learning for generating a plant control signal. Learning is enhanced within the action network by using a neural network configured to operate according to unsupervised learning techniques based upon a Kohonen Feature Map. Learning is enhanced within the critic network by using a distance parameter which represents the difference between the actual and desired states of the quantitative performance, or output, of the plant when generating the reinforcement signal for the action network.",Intelligent controller with neural network and reinforcement learning
"The control of emissions from fossil-fired boilers wherein an injection of substances above the primary combustion zone employs multi-layer feedforward artificial neural networks for modeling static nonlinear relationships between the distribution of injected substances into the upper region of the furnace and the emissions exiting the furnace. Multivariable nonlinear constrained optimization algorithms use the mathematical expressions from the artificial neural networks to provide the optimal substance distribution that minimizes emission levels for a given total substance injection rate. Based upon the optimal operating conditions from the optimization algorithms, the incremental substance cost per unit of emissions reduction, and the open-market price per unit of emissions reduction, the intelligent emissions controller allows for the determination of whether it is more cost-effective to achieve additional increments in emission reduction through the injection of additional substance or through the purchase of emission credits on the open market. This is of particular interest to fossil-fired electrical power plant operators. The intelligent emission controller is particularly adapted for determining the economical control of such pollutants as oxides of nitrogen (NOx) and carbon monoxide (CO) emitted by fossil-fired boilers by the selective introduction of multiple inputs of substances (such as natural gas, ammonia, oil, water-oil emulsion, coal-water slurry and/or urea, and combinations of these substances) above the primary combustion zone of fossil-fired boilers.",Intelligent emissions controller for substance injection in the post-primary combustion zone of fossil-fired boilers
"Presented herein are embodiments of a multimodal Recurrent Neural Network (m-RNN) model for generating novel image captions. In embodiments, it directly models the probability distribution of generating a word given a previous word or words and an image, and image captions are generated according to this distribution. In embodiments, the model comprises two sub-networks: a deep recurrent neural network for sentences and a deep convolutional network for images. In embodiments, these two sub-networks interact with each other in a multimodal layer to form the whole m-RNN model. The effectiveness of an embodiment of model was validated on four benchmark datasets, and it outperformed the state-of-the-art methods. In embodiments, the m-RNN model may also be applied to retrieval tasks for retrieving images or captions.",Intelligent image captioning
"A process for intelligent importation of information from a foreign application user interface includes extraction of raster data from a pre-designated region of a screen displayed in the foreign application, segmentation of the raster data into prospective sets of character raster data; application of the character raster data and a feature data set and a vector data set derived from the character raster data as inputs to respective raster, feature, and vector artificial neural networks to generate candidate characters; using a voting process to identify a character represented by the character raster data from the candidate characters; assembly of the remaining characters as recognized by the neural networks into a key; and association of the key with an external data file which may be stored and thereafter retrieved in association with the screen displayed in the foreign application.",Intelligent importation of information from foreign applications user interface
"A neural control logic scheme based on prediction and pattern recognition techniques is used to control electrochemical processes such as aluminum electrolytic cells. The predictive capacity of feedforward neural networks is used to predict the future values of decision variables to be used by the cell's control logic, enabling the control logic to apply anticipated actions to cells in different conditions, thus avoiding anode effects and improving cell stability. The pattern-recognition capacity of LVQ-type neural networks is used to provide a closed-loop control structure to the feeding of the cell as a function of cell resistance, alumina concentration and cell condition. The closed-loop control structure enables the cell to operate at a near-optimal regime regardless of the condition of the cell.",Intelligent process control using predictive and pattern recognition techniques
"Recurrent neural networks (RNNs) can be visualized. For example, a processor can receive vectors indicating values of nodes in a gate of a RNN. The values can result from processing data at the gate during a sequence of time steps. The processor can group the nodes into clusters by applying a clustering method to the values of the nodes. The processor can generate a first graphical element visually indicating how the respective values of the nodes in a cluster changed during the sequence of time steps. The processor can also determine a reference value based on multiple values for multiple nodes in the cluster, and generate a second graphical element visually representing how the respective values of the nodes in the cluster each relate to the reference value. The processor can cause a display to output a graphical user interface having the first graphical element and the second graphical element.",Interactive visualizations for a recurrent neural network
A method of internal connection for neural network linking successive neuron layers and useful in image analysis and image and signal processing is provided. The neuron output states of a new neuron layer are represented by functions obtained by the method. A weighted summation of functions which represent the output state of a neuron from a preceding layer is carried out. A saturation function is applied to the result of the weighted summation. A function is outputted which is representative of the output state of the neuron layer.,Internal connection method for neural networks
"An artificial intelligence system is used with a conglomeration of fluorescence data to provide a method of improving recognition of an unknown from its spectral pattern. Customized neural network systems allow the ultimate organization and resourceful use of assumption-free variables already existing in a total scanning fluorescence database for a much more comprehensive, discrete and accurate differentiation and matching of spectra than is possible with human memory. The invention provides increased speed of fingerprinting analysis, accuracy and reliability together with a decreased learning curve and heightened objectivity for the analysis.",Interpretation of fluorescence fingerprints of crude oils and other hydrocarbon mixtures using neural networks
"A speech signal isolation system configured to isolate and reconstruct a speech signal transmitted in an environment in which frequency components of the speech signal are masked by background noise. The speech signal isolation system obtains a noisy speech signal from an audio source. The noisy speech signal may then be fed through a neural network that has been trained to isolate and reconstruct a clean speech signal from against background noise. Once the noisy speech signal has been fed through the neural network, the speech signal isolation system generates an estimated speech signal with substantially reduced noise.",Isolating speech signals utilizing neural networks
"An approach to joint acoustic and visual processing associates images with corresponding audio signals, for example, for the retrievals of images according to voice queries. A set of paired images and audio signals are processed without requiring transcription, segmentation, or annotation of either the images or the audio. This processing of the paired images and audio is used to determine parameters of an image processor and an audio processor, with the outputs of these processors being comparable to determine a similarity across acoustic and visual modalities. In some implementations, the image processor and the audio processor make use of deep neural networks. Further embodiments associate parts of images with corresponding parts of audio signals.",Joint acoustic and visual processing
"A technical solution is described for implementing a computer-executed system of association memory matrices to replace the proximal layers of a convolutional neural network (CNN). An example method includes configuring one Associative Memory Matrix (AMM) for each configured layer in the CNN. This one-to-one conversion method motivates the name to the product: the Joint Proximity Association Template (JPAT) for Neural Networks. The invention is a numerically stable soft-ware based implementation that (1) reduces the long training times, (2) reduces the execution time, and (3) produces bidirectional intra-layer connections and potentially, inter-layer connections as well. The method further includes, potentially, forming a single AMM, from the multiple AMMs corresponding to the multiple and proximal layers of the CNN, in anticipation of the well-known Universal Approximation Theorem.",Joint proximity association template for neural networks
"Video description generation using neural network training based on relevance and coherence is described. In some examples, long short-term memory with visual-semantic embedding (LSTM-E) can maximize the probability of generating the next word given previous words and visual content and can create a visual-semantic embedding space for enforcing the relationship between the semantics of an entire sentence and visual content. LSTM-E can include a 2-D and/or 3-D deep convolutional neural networks for learning powerful video representation, a deep recurrent neural network for generating sentences, and a joint embedding model for exploring the relationships between visual content and sentence semantics.",Jointly modeling embedding and translation to bridge video and language
"Supervised machine learning using convolutional neural network (CNN) is applied to denoising images rendered by MC path tracing. The input image data may include pixel color and its variance, as well as a set of auxiliary buffers that encode scene information (e.g., surface normal, albedo, depth, and their corresponding variances). In some embodiments, a CNN directly predicts the final denoised pixel value as a highly non-linear combination of the input features. In some other embodiments, a kernel-prediction neural network uses a CNN to estimate the local weighting kernels, which are used to compute each denoised pixel from its neighbors. In some embodiments, the input image can be decomposed into diffuse and specular components. The diffuse and specular components are then independently preprocessed, filtered, and postprocessed, before recombining them to obtain a final denoised image.",Kernel-predicting convolutional neural networks for denoising
"Joint provisioning of cell sector capacity (CSC) and a defined customer service level (CSL) is provided utilizing a knowledge discovery and data mining-assisted multi-radio access technology controller. For example, Strategic Performance Indexes, CSC and CSL, are identified. The relationships between CSC, CSL, ergodic channel capacity (ECC) and an interface load (IL) for a radio network (RN) (or cell sector of an RN) are determined. Extensive information associated with the RN is collected and neural networks analysis is employed to reduce the information to a manageable set including the specific information associated with ECC and IL. The reduced set of information is mapped to ECC and IL using eigenvalue analysis, and the relationships between the ECC, IL, CSC and CSL are employed to determine the CSC and CSL for the RN (or cell sector of the RN). Network assignments and/or parameters can be updated based on the results.",Knowledge discovery and data mining-assisted multi-radio access technology control
"Systems and methods for determining knowledge-guided information for a recurrent neural networks (RNN) to guide the RNN in semantic tagging of an input phrase are presented. A knowledge encoding module of a Knowledge-Guided Structural Attention Process (K-SAP) receives an input phrase and, in conjunction with additional sub-components or cooperative components generates a knowledge-guided vector that is provided with the input phrase to the RNN for linguistic semantic tagging. Generating the knowledge-guided vector comprises at least parsing the input phrase and generating a corresponding hierarchical linguistic structure comprising one or more discrete sub-structures. The sub-structures may be encoded into vectors along with attention weighting identifying those sub-structures that have greater importance in determining the semantic meaning of the input phrase.",Knowledge-guided structural attention processing
"A system and method are provided. The system includes an image capture device configured to capture an actual image depicting an object. The system also includes a processor. The processor is configured to render, based on a set of 3D Computer Aided Design (CAD) models, a set of synthetic images with corresponding intermediate shape concept labels. The processor is also configured to form a multi-layer Convolutional Neural Network (CNN) which jointly models multiple intermediate shape concepts, based on the rendered synthetic images. The processor is further configured to perform an intra-class appearance variation-aware and occlusion-aware 3D object parsing on the actual image by applying the CNN to the actual image to output an image pair including a 2D geometric structure and a 3D geometric structure of the object depicted in the actual image.",Landmark localization on objects in images using convolutional neural networks
"Systems and processes for language identification using recurrent neural networks are provided. An example method includes, at an electronic device, receiving a first typed character of a character sequence and determining a character context of the first typed character based on the first typed character and a second typed character of the character sequence. The method further includes determining a confidence level that the character sequence is associated with a language of a plurality of languages based on the character context of the first typed character, and determining whether the confidence level exceeds a threshold, in accordance with a determination that the confidence level exceeds the threshold, providing the language as a candidate language, and in accordance with a determination that the confidence level does not exceed the threshold, forgoing providing the language as a candidate language.",Language identification using recurrent neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for classification using a neural network. One of the methods for processing an input through each of multiple layers of a neural network to generate an output, wherein each of the multiple layers of the neural network includes a respective multiple nodes includes for a particular layer of the multiple layers: receiving, by a classification system, an activation vector as input for the particular layer, selecting one or more nodes in the particular layer using the activation vector and a hash table that maps numeric values to nodes in the particular layer, and processing the activation vector using the selected nodes to generate an output for the particular layer.",Large-scale classification in neural networks using hashing
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for classification using a neural network. One of the methods for processing an input through each of multiple layers of a neural network to generate an output, wherein each of the multiple layers of the neural network includes a respective multiple nodes includes for a particular layer of the multiple layers: receiving, by a classification system, an activation vector as input for the particular layer, selecting one or more nodes in the particular layer using the activation vector and a hash table that maps numeric values to nodes in the particular layer, and processing the activation vector using the selected nodes to generate an output for the particular layer.",Large-scale classification in neural networks using hashing
"Customizable neural network in which one or more resistors form each synapse. All the resistors in the synaptic array are identical, thus simplifying the processing issues. Highly doped, amorphous silicon is used as the resistor material, to create extremely high resistances occupying very small spaces. Connected in series with each resistor in the array is at least one severable conductor whose uppermost layer has a lower reflectivity of laser energy than typical metal conductors at a desired laser wavelength.",Laser programmable integrated curcuit for forming synapses in neural networks
"Neural networks may be used in certain automatic speech recognition systems. To improve performance at these neural networks, the present system converts the lattice into a matrix form, thus maintaining certain information included in the lattice that might otherwise be lost while also placing the lattice in a form that may be manipulated by other components to perform operations such as checking ASR results. The matrix representation of the lattice may be transformed into a vector representation by calculations performed at a recurrent neural network (RNN). By representing the lattice as a vector representation the system may perform additional operations, such as ASR results confirmation.",Lattice decoding and result confirmation using recurrent neural networks
"An automatic speech recognition (ASR) system may convert an ASR output lattice into a matrix form, thus maintaining certain information included in the lattice that might otherwise be lost in an N-best list output. The matrix representation of the lattice may be encoded using a recurrent neural network (RNN) to create a vector representation of the lattice. The vector representation may then be used by the system to perform additional operations, such as ASR results confirmation.",Lattice encoding using recurrent neural networks
"Convolution neural networks are able to be trained using a GPU and a CPU. To efficiently utilize a device's resources, the HetNet and HybNet approaches have been developed. The HetNet approach separates batches into partitions such that the GPU and CPU process separate batches. The HybNet approach separates the layers of a convolution neural network for the GPU and CPU.",Learning convolution neural networks on heterogeneous CPU-GPU platform
"A first set of attributes (e.g., style) is generated through pre-trained single column neural networks and leveraged to regularize the training process of a regularized double-column convolutional neural network (RDCNN). Parameters of the first column (e.g., style) of the RDCNN are fixed during RDCNN training. Parameters of the second column (e.g., aesthetics) are fine-tuned while training the RDCNN and the learning process is supervised by the label identified by the second column (e.g., aesthetics). Thus, features of the images may be leveraged to boost classification accuracy of other features by learning a RDCNN.",Learning image categorization using related attributes
"A neural network (100) has an input layer, a hidden layer, and an output layer. The neural network stores weight values which operate on data input at the input layer to generate output data at the output layer. An error computing unit (87) receives the output data and compares it with desired output data from a learning data storage unit (105) to calculate error values representing the difference. An error gradient computing unit (81) calculates an error gradient, i.e. rate and direction of error change. A ratio computing unit (82) computes a ratio or percentage of a prior conjugate vector and combines the ratio with the error gradient. A conjugate vector computing unit (83) generates a present line search conjugate vector from the error gradient value and a previously calculated line search gradient vector. A line search computing unit (95) includes a weight computing unit (88) which calculates a weight correction value. The weight correction value is compared (18) with a preselected maximum or upper limit correction value (.kappa.). The line search computing unit (95) limits adjustment of the weight values stored in the neural network in accordance with the maximum weight correction value.",Learning method and apparatus for neural networks and simulator with neural network
"A learning method for extracting features from an input image by hardware optimization using n blocks in a convolutional neural network (CNN) is provided. The method includes steps of: a learning device instructing a first convolutional layer of a k-th block to elementwise add a (1_1)-st to a (k_1)-st feature maps or their processed feature maps, and instructing a second convolutional layer of the k-th block to generate a (k_2)-nd feature map; and feeding a pooled feature map, generated by pooling an ROI area on an (n_2)-nd feature map or its processed feature map, into a feature classifier; and instructing a loss layer to calculate losses by referring to outputs of the feature classifier and their corresponding GT. By optimizing hardware, CNN throughput can be improved, and the method becomes more appropriate for compact networks, mobile devices, and the like. Further, the method allows key performance index to be satisfied.","Learning method and learning device for extracting feature from input image by using convolutional layers in multiple blocks in CNN, resulting in hardware optimization which allows key performance index to be satisfied, and testing method and testing device using the same"
"A method for detecting jittering in videos generated by a shaken camera to remove the jittering on the videos using neural networks is provided for fault tolerance and fluctuation robustness in extreme situations. The method includes steps of: a computing device, generating each of t-th masks corresponding to each of objects in a t-th image; generating each of t-th object motion vectors of each of object pixels, included in the t-th image by applying at least one 2-nd neural network operation to each of the t-th masks, each of t-th cropped images, each of (t1)-th masks, and each of (t1)-th cropped images; and generating each of t-th jittering vectors corresponding to each of reference pixels among pixels in the t-th image by referring to each of the t-th object motion vectors. Thus, the method is used for video stabilization, object tracking with high precision, behavior estimation, motion decomposition, etc.","Learning method and learning device for removing jittering on video acquired through shaking camera by using a plurality of neural networks for fault tolerance and fluctuation robustness in extreme situations, and testing method and testing device using the same"
"In a learning method for training a recurrent neural network having a number of inputs and a number of outputs with at least one output being connected via a return line to an input, the return line is separated during training of the neural network, thereby freeing the input connected to the return line for use as an additional input during training, together with the other inputs. The additional input values, which must be estimated or predicted for supply to the thus-produced additional training inputs, are generated by treating each additional input value to be generated as a missing value in the time series of input quantities. Error distribution densities for the additional input values are calculated on the basis of the known values from the time series and their known or predetermined error distribution density, and samples are taken from this error distribution density according to the Monte Carlo method. These each lead to an estimated or predicted value whose average is introduced for the additional input value to be predicted. The method can be employed for the operation as well as for the training of the neural network, and is suitable for use in all known fields of utilization of neural networks.",Learning method for a neural network
"The invention relates to a learning process generating neural networks designed to sort data into two classes separated by a non-linear surface and built up as the needs of the task to be carried out are defined. This surface is either quadratic, or partly linear and partly quadratic. Applications include shape recognition and sorting of objects or data.",Learning method generating small size neurons for data classification
"Learning processes for a single hidden layer neural network, including linear input units, nonlinear hidden units, and linear output units, calculate the lower-layer network parameter gradients by taking into consideration a solution for the upper-layer network parameters. The upper-layer network parameters are calculated by a closed form formula given the lower-layer network parameters. An accelerated gradient algorithm can be used to update the lower-layer network parameters. A weighted gradient also can be used. With the combination of these techniques, accelerated training with faster convergence, to a point with a lower error rate, can be obtained.",Learning processes for single hidden layer neural networks with linear output units
A method tests a subscriber line. The method includes determining values of electrical line features from electrical measurements on the subscriber line and processing a portion of the values of the electrical features with a neural network. The neural network predicts whether the line qualifies to support one or more preselected data services from the portion of the values.,Line qualification with neural networks
A method and system is provided for predicting loads within a power system through the training of on-line and an off-line neural networks. Load data and load increments are used with an on-line load prediction scheme to generate predicted load values to optimize power generation and minimize costs. This objective is achieved by employing a method and system which predicts short term load trends through the use of historical load data and short term load forecast data.,Load prediction based on-line and off-line training of neural networks
"Accurately detection of logos in media content on media presentation devices is addressed. Logos and products are detected in media content produced in retail deployments using a camera. Logo recognition uses saliency analysis, segmentation techniques, and stroke analysis to segment likely logo regions. Logo recognition may suitably employ feature extraction, signature representation, and logo matching. These three approaches make use of neural network based classification and optical character recognition (OCR). One method for OCR recognizes individual characters then performs string matching. Another OCR method uses segment level character recognition with N-gram matching. Synthetic image generation for training of a neural net classifier and utilizing transfer learning features of neural networks are employed to support fast addition of new logos for recognition.",Logo recognition in images and videos
"A method for creating on chip analog mathematical engines is provided utilizing a neural network with a switched capacitor structure to implement coefficients for weighted connections and error functions for the neural network. The neural networks are capable of any transfer function, learning, doing pattern recognition, clustering, control or many other functions. The switched capacitor charge controls allow for nodal control of charge transfer based switched capacitor circuits. The method reduces reliance on passive component programmable arrays to produce programmable switched capacitor circuit coefficients. The switched capacitor circuits are dynamically scaled without having to rely on switched in unit passives, such as unit capacitors, and the complexities of switching these capacitors into and out of circuit. The current, and thus the charge transferred is controlled at a nodal level, and the current rather than the capacitors are scaled providing a more accurate result in addition to saving silicon area.",Low power integrated analog mathematical engine
"A neural network includes an electronic synapse array of multiple digital synapses interconnecting a plurality of digital electronic neurons. Each synapse interconnects an axon of a pre-synaptic neuron with a dendrite of a post-synaptic neuron. Each neuron integrates input spikes and generates a spike event in response to the integrated input spikes exceeding a threshold. A decoder receives spike events sequentially and transmits the spike events to selected axons in the synapse array. An encoder transmits spike events corresponding to spiking neurons. A controller coordinates events from the synapse array to the neurons, and signals when neurons may compute their spike events within each time step, ensuring one-to-one correspondence with an equivalent software model. The synapse array includes an interconnecting crossbar that sequentially receives spike events from axons, wherein one axon at a time drives the crossbar, and the crossbar transmits synaptic events in parallel to multiple neurons.",Low-power event-driven neural computing architecture in neural networks
"Determining semantically equivalent text or questions using hybrid representations based on neural network learning. Weighted bag-of-words and convolutional neural networks (CNN) based distributed vector representations of questions or text may be generated to compute the semantic similarity between questions or text. Weighted bag-of-words and CNN based distributed vector representations may be jointly used to compute the semantic similarity. A pair-wise ranking loss function trains neural network. In one embodiment, the parameters of the system are trained by minimizing a pair-wise ranking loss function over a training set using stochastic gradient descent (SGD).",Machine learning and training a computer-implemented neural network to retrieve semantically equivalent questions using hybrid in-memory representations
"A company may desire to maintain a quality level for messages sent by customer service representatives to customers. The company may receive a message input by a customer service representative, modify the message with one or more neural networks, and transmit the modified message to a customer. To modify a message, an input vector may be created for each word of the message where the input vector is created using a word embedding of the word and a feature vector that represents the characters of the word. The input vectors for the words of the message may be sequentially processed with an encoding neural network to compute a message encoding vector that represents the message. The message encoding vector may then be processed by a decoding neural network to sequentially generate the words of a modified message. The modified message may then be transmitted to the customer.",Maintaining quality of customer support messages
"In the control of a power station installation having a number of power station blocks, in which each power station block is controlled by using at least one reference variable, it is intended to permit reliable determination of especially favorable reference variables while also taking the current installation condition into account. To this end, a management system for the power station installation includes a computer unit which determines reference variables for the power station block or for each of the power station blocks through the use of a genetic algorithm, and an optimization module which is connected to the computer unit. The optimization module is connected to a number of neural networks and one neural network is assigned to each power station block.",Management system for a power station installation
"Systems and methods are disclosed for using machine learning (e.g., neural networks and/or combinatorial learning) to solve the non-linear problem of predicting the provisioning of a server farm (e.g., cloud resources). The machine learning may be performed using commercially available products, such as the SNNS product from The University of Stuttgard of Germany. The system, which includes a neural network for machine learning, is provided with an identification of inputs and outputs to track, and the system provides correlations between those. Rather than static rules, the machine learning provides dynamic provisioning recommendations with corresponding confidence scores. Based on the data collected/measured by the neural network, the provisioning recommendations will change as well as the confidence scores.",Managing computer server capacity
"The use of neural networks has been employed to adjust processing during the fabrication of articles. For example, in the production of photolithographic masks by electron beam irradiation of a mask blank in a desired pattern, electrons scattered from the mask substrate cause distortion of the pattern. Adjustment for such scattering is possible during the manufacturing process by employing an adjustment function determined by a neural network whose parameters are established relative to a prototypical mask pattern.",Manufacturing adjustment during article fabrication
"Features are disclosed for using a neural network to tag sequential input without using an internal representation of the neural network generated when scoring previous positions in the sequence. A predicted or determined label (e.g., the highest scoring or otherwise most probable label) for input at a given position in the sequence can be used when scoring input corresponding to the next position the sequence. Additional features are disclosed for training a neural network for use in tagging sequential input without using an internal representation of the neural network generated when scoring previous positions the sequence.",Markov-based sequence tagging using neural networks
"A mask neutral network for processing that allows an external source of control to continuously direct state transition of the neural network toward selected states and away from other states. The network, through externally controlled masking, can focus attention on selected attributes of observed data, solutions or results. The masking is appliciable across three major categories of networks in that it facilitates augmented recall, directed learning and constrained optimization.",Mask controled neural networks
"A method of processing x-ray images comprises training an artificial neural network to process multi-spectral x-ray projections to determine composition information about an object in terms of equivalent thickness of at least one basis material. The method further comprises providing a multi-spectral x-ray projection of an object, wherein the multi-spectral x-ray projection of the object contains energy content information describing the energy content of the multi-spectral x-ray projection, The multi-spectral x-ray projection is then processed with the artificial neural network to determine composition information about the object, and then the composition information about the object is provided",Material decomposition of multi-spectral X-ray projections using neural networks
"A method of processing x-ray images comprises training an artificial neural network to process multi-spectral x-ray projections to determine composition information about an object in terms of equivalent thickness of at least one basis material. The method further comprises providing a multi-spectral x-ray projection of an object, wherein the multi-spectral x-ray projection of the object contains energy content information describing the energy content of the multi-spectral x-ray projection. The multi-spectral x-ray projection is then processed with the artificial neural network to determine composition information about the object, and then the composition information about the object is provided.",Material decomposition of multi-spectral x-ray projections using neural networks
"Systems and methods for processing electronic imaging data obtained from medical imaging procedures are disclosed herein. Some embodiments relate to data processing mechanisms for medical imaging and diagnostic workflows involving the use of machine learning techniques such as deep learning, artificial neural networks, and related algorithms that perform machine recognition of specific features and conditions in imaging data. In an example, a deep learning model is selected for automated image recognition of a particular medical condition on image data, and applied to the image data to recognize characteristics of the particular medical condition. Based on the characteristics recognized by the automated image recognition on the image data, an electronic workflow for performing a diagnostic evaluation of the medical imaging study may be modified, updated, or prioritized.",Medical evaluation machine learning workflows and processes
"Systems and methods for processing electronic imaging data obtained from medical imaging procedures are disclosed herein. Some embodiments relate to data processing mechanisms for medical imaging and diagnostic workflows involving the use of machine learning techniques such as deep learning, artificial neural networks, and related algorithms that perform machine recognition of specific features and conditions in imaging data. In an example, a deep learning model is selected for automated image recognition of a particular medical condition on image data, and applied to the image data to recognize characteristics of the particular medical condition. Based on the characteristics recognized by the automated image recognition on the image data, an electronic workflow for performing a diagnostic evaluation of the medical imaging study may be modified, updated, or prioritized.",Medical evaluation machine learning workflows and processes
Hopfield and BAM neural network training or learning rules allowing memorization of a greater number of patterns. Successive over-relaxation is used in the learning rules based on the training patterns and the output vectors. Neural networks trained in this manner can better serve as the neural networks in a variety of pattern recognition and element correlation systems.,Memory capacity neural network
"Aspects of the present disclosure are directed to techniques that improve performance of CNN systems through the effect of improved memory efficiencies for CNNs operating on GPUs. Aspects of the disclosure demonstrate that off-chip memory in such CNN systems is underutilized due to at least three characteristics namely, data layout, data locality and inter-kernel redundancy. Aspects of the disclosure examine the performance impact of different data layouts and then describe a method to produce data layout selection for various layers of the CNN including a fast transformation implementation. Disclosed are improvements to data locality from working set expansion, elimination of inter-kernel redundancy and increase of TLP using kernel reconstruction techniques including kernel fusion and thread injection. Disclosed experimental results show that our optimizations are very effective to boost the performance of CNNs by amounts up to 9.76 times for a single kernel and 2.05 times for a network.",Memory efficiency for convolutional neural networks operating on graphics processing units
Methods and systems for training a neural network include sampling multiple local sub-networks from a global neural network. The local sub-networks include a subset of neurons from each layer of the global neural network. The plurality of local sub-networks are trained at respective local processing devices to produce trained local parameters. The trained local parameters from each local sub-network are averaged to produce trained global parameters.,Memory efficient scalable deep learning with model parallelization
"An artificial neural network, which has a plurality of neurons each receiving a plurality of inputs whose effect is determined by adjust able weights at synapses individually connecting the inputs to the neuron to provide a sum signal to a sigmoidal function generator determining the output of the neuron, undergoes memory modification by a steepest-descent method in which individual variations in the outputs of the neurons are successively generated by small perturbations imposed on the sum signals. As each variation is generated on the output of a neuron, an overall error of all the neuron outputs in relation to their desired values is measured and compared to this error prior to the perturbation. The difference in these errors, with adjustments which may be changed as the neuron outputs converge toward their desired values, is used to modify each weight of the neuron presently subjected to the perturbation.",Memory modification of artificial neural networks
"Disclosed are various embodiments of memristive neural networks comprising neural nodes. Memristive nanofibers are used to form artificial synapses in the neural networks. Each memristive nanofiber may couple one or more neural nodes to one or more other neural nodes. In one case, a memristive neural network includes a first neural node, a second neural node, and a memristive fiber that couples the first neural node to the second neural node. The memristive fiber comprises a conductive core and a memristive shell, where the conductive core forms a communications path between the first neural node and the second neural node and the memristive shell forms a memristor synapse between the first neural node and the second neural node.",Memristive nanofiber neural networks
"A device with adjustable resistance includes two magnetic elements separated by an insulating or semi-conductor element. The resistance of the device depends on the position of a magnetic wall in one of the magnetic elements, the magnetic wall separating two areas of said magnetic element each having a separate homogeneous direction of magnetization. The device comprises means for moving the magnetic wall in the magnetic element by applying a spin-polarized electric current, such that the resistance of the device is adjustable in a continuous range of values. The invention is useful in neuromimetic circuits, neural networks and bio-inspired computers.",Memristor device with resistance adjustable by moving a magnetic wall by spin transfer and use of said memristor in a neural network
"A system for routing business-to-business (B2B) messages includes a cyclical neural network. The cyclical neural network contains neurons for determining a needed destination of a message based on content type of the message, for example. Neurons are monitored to establish a state of understanding of the network during processing, and tags may be applied to messages upon a determination of the needed destination.",Message routing using cyclical neural networks
A system and a method are for the estimation of the impact area of a smart load that can be launched from an aircraft as a function of data or signals indicative of the aircraft flight conditions upon release of the load and of predetermined impact conditions on the target. The estimation of a polygonal impact area defined by the coordinates of a central point and of a predetermined number of vertices is by corresponding neural networks.,Method and a system for estimating the impact area of a military load launched from an aircraft
"A method and apparatus for adaptive color scanning/printing data correction to effectively adjust to an arbitrary combination of color image scanning input and printing output devices for reproducing color image at optimized resemblance. An improved back propagation algorithm is employed to reduce the learning error and accelerate the process of learning procedure by increasing the rate of convergence. A method of characteristics extracting functionalization is utilized to urge the successful convergence of the learning procedure of the neural network, and reduce the color discrepancy and accelerate the process of learning convergence. An enhanced grey-scale balancing scheme is also utilized to extract the grey component of a learning sample under a predetermined condition and re fetch again to the neural network for accelerated convergence of the learning behavior. An apparatus for performing the color data correction includes an integrated neural network color processor that utilizes a small number of neural elements to reduce the complexity of the color data processing and computational complication.",Method and apparatus for adaptive color scanning/printing data correction employing neural networks
"A method enabling a neural network, having weights organized into a weight vector, to learn, comprising the steps of: (a) assigning a first memory location for storing a first learning rate, a second memory location for storing a momentum factor, a memory block for storing the weight vector, and a third memory location for storing a second learning rate; (b) initializing the learning rate, momentum factor, and weight vector; (c) storing the first learning rate, the momentum factor, and the weight vector into their respective memory locations; (d) saving the first learning rate in the second learning rate by storing it into the third memory location; (e) using a search technique to adjust the first learning rate to adjust the weight vector, and updating the first memory location and the memory block; (f) adapting the momentum factor using the first learning rate and the second learning rate; and repeating steps (c) through (f) until a predetermined convergence criterion has been met.",Method and apparatus for adaptive learning in neural networks
"Adaptive neural networks can be used to effectively enhance signal detection in the inherently noisy environment of an oil well. The neural network can be either non-recurrent or recurrent in nature. The system is implemented with a computer that accepts input from at least one sensor mounted to the wellhead or near the wellhead. The detected contaminated signal is a combination of the event signal and the noise from the environment. The event signal can be, for example, the detonation of a perforation gun. The noise can be either random or periodic. The use of adaptive filtering allows the noise to be more precisely predicted and then subtracted from the contaminated signal to produce a cleaner representation of the event signal. Once the predicted noise is subtracted, the remaining event signal can be analyzed using voice or sound recognition systems to produce an output describing what event occurred.",Method and apparatus for adaptively filtering noise to detect downhole events
"A method and apparatus is provided which analyzes an image of an object to detect and identify defects in the object utilizing multi-dimensional wavelet neural networks. &#8220;The present invention generates a signal representing part of the object, then extracts certain features of the signal. These features are then provided to a multidimensional neural network for classification, which indicates if the features correlate with a predetermined pattern. This process of analyzing the features to detect and identify predetermined patterns results in a robust fault detection and identification system which is computationally efficient and economical because of the learning element contained therein which lessens the need for human assistance.&#8221;",Method and apparatus for analyzing an image to detect and identify patterns
"A sales promotion program is dynamically selected from a plurality of programs for presentation in a program presentation unit by a neural network that makes its selection based on first detecting if a person is in the area immediately around the program presentation unit, then either selecting a general attract loop sales promotion program with the trained neural network using a set of predetermined system criteria if no person is detected in the immediate area or selecting a specific loop sales promotion program if at least one person is detected in the immediate area. The neural network is trained by selecting general attract loop programs that are run and then collecting data indicative of the number of persons responding to the general attract loop and also by selecting specific loop programs that are run if a person is in the immediate area and then collecting data indicative of the responses to the specific loop programs. The collected data thereby represents the success of the various sales programs in attracting and holding the attention of persons. The collected data is provided to the neural network in any one of a plurality of training schemes typical for neural networks, after which the trained neural network is provided with current, real-time selection data such that the trained network can select the most appropriate sales promotion program for running. The network can be retrained at regular intervals or in response to sales data or changes in the collected data.",Method and apparatus for automatic selection and presentation of sales promotion programs
"Relatively powerful hand-held computing devices, Digital Signal Processors, Audio signal processing technology, voice recognition technology, expert systems, Hidden Markov Models, and/or neural networks are employed in a device capable of real-time automated species identification by listening to bird vocalizations in the field, analyzing their waveforms, and comparing these waveforms against known reference samples. An apparatus for identifying animal species from their vocalizations, comprises a source of digital signal representative of at least one animal candidate vocalization; a feature extractor that receives the digital signal, recognizes notes therein and extracts phrases including plural notes and that produces a parametric representation of the extracted phrases; and a comparison engine that receives the parametric representation of at least one of the digital signal and the extracted phrases, and produces an output signal representing information about the animal candidate based on a likely match between the animal candidate vocalization and known animal vocalizations. A computer-implemented method of identifying animal species, comprises: obtaining a digital signal representing a vocalization by a candidate animal; transforming the digital signal into a parametric representation thereof; extracting from the parametric representation a sequence of notes defining a phrase; comparing the phrase to phrases known to be produced by a plurality of possible animal species; and identifying a most likely match for the vocalization by the candidate animal based upon the comparison. The comparison engine or comparison function may use Hidden Markov Models, expert systems and/or neural networks.",Method and apparatus for automatically identifying animal species from their vocalizations
"A method and apparatus for measuring the concentration of an analyte present in a biological fluid is disclosed. The method includes the steps of applying NIR radiation to calibration samples to produce calibration data, analyzing the calibration data to identify and remove outliers, constructing a calibration model, collecting and analyzing unknown samples to identify and remove outliers, and predicting analyte concentration of non-outliers from the calibration model. Analysis of the calibration data includes data pretreatment, data decomposition to remove redundant data, and identification and removal of outliers using generalized distances. The calibration model may utilize principal component regression, partial least squares, multiple linear regression, or artificial neural networks, and reduction using principal component analysis or partial least squares scores. Unknown sample data is analyzed using data pretreatment followed by projection into the calibration model space, and identification and removal of outliers, with prediction of analyte concentration using the calibration model. The apparatus includes a pump which circulates a sample through tubing to fill a flowcell. Light from a NIR source is synchronized with a detector, facilitating light and dark measurements, and passes through a monochrometer and the flowcell and strikes the detector, whereby radiation transmitted through the sample is measured. Measurement data is stored in a general purpose programmable computer also controlling the pump, the detector, synchronization, and the monochrometer. The computer includes a general purpose microprocessor configured with computer program code employing the steps of the method.",Method and apparatus for biological fluid analyte concentration measurement using generalized distance outlier detection
""" A method and apparatus for constructing, training and utilizing an artificial neural network (also termed herein a """"neural network"""", an ANN, or an NN) in order to transform a first color value in a first color coordinate system into a second color value in a second color coordinate system. """,Method and apparatus for color processing with neural networks
"A circuit element of a multi-dimensional dynamic adaptive neural network array (DANNA) may comprise a neuron/synapse select input functional to select the circuit element to function as one of a neuron and a synapse. In one embodiment of a DANNA array of such circuit elements, (wherein a circuit element or component thereof may be analog or digital), a destination neuron may be connected to a first neuron by a first synapse in one dimension, a second destination neuron may be connected to the first neuron by a second synapse in a second dimension and, optionally, a third destination neuron may be connected to the first neuron by a third synapse. The DANNA may thus form multiple levels of neuron and synapse circuit elements. In one embodiment, multiples of eight inputs may be selectively received by the circuit element selectively functioning as one of a neuron and a synapse. The dynamic adaptive neural network array (DANNA) may comprise a special purpose processor for performing one of a control, anomaly detection and classification application and may comprise a first structure connected to a neuroscience-inspired dynamic artificial neural network (NIDA), comprise substructures thereof or be combined with other neural networks.",Method and apparatus for constructing a dynamic adaptive neural network array (DANNA)
"A method and apparatus for constructing a neuroscience-inspired artificial neural network (NIDA) or a dynamic adaptive neural network array (DANNA) or combinations of substructures thereof comprises one of constructing a substructure of an artificial neural network for performing a subtask of the task of the artificial neural network or extracting a useful substructure based on one of activity, causality path, behavior and inputs and outputs. The method includes identifying useful substructures in artificial neural networks that may be either successful at performing a subtask or unsuccessful at performing a subtask. Successful substructures may be implanted in an artificial neural network and unsuccessful substructures may be extracted from the artificial neural network for performing the task. The method and apparatus supports constructing, using and reusing components and structures of a neuroscience-inspired artificial neural network dynamic architecture in software and a dynamic adaptive neural network array.","Method and apparatus for constructing, using and reusing components and structures of an artifical neural network"
"A machine tool having a tool member which is moveable along at least one axis relative to a workpiece to be machined, comprising thermosensors for sensing temperatures of a plurality of components of the machine tool. Responsive to the sensed temperatures, neural networks infer thermal deformations of the machine components. Based on the inferred values of thermal deformations, a correction signal is obtained which is combined with a drive signal for moving the tool member and/or workpiece to correct for any positioning error in the direction of the axis. Thermal deformations of machine components should be suitably inferred under the circumstances prevailing where the machine tool is installed. A corresponding method of correcting thermal deformations in a machine tool is also described.",Method and apparatus for correcting positioning errors on a machine tool
"A method for counting somatic cells or fat droplets in milk on-line during milking by an automated or semi-automated milking system comprising the steps of: flowing milk as milked by the milking system through a measuring chamber (59); illuminating milk that flows through the measuring chamber; and recording multiple two-dimensional digital images of illuminated milk that flows through the measuring chamber, wherein the images are recorded through a lens system (49) to preferably obtain a spatial resolution better than about 5 microns in the images. Finally, a somatic cell or fat droplet count score of the milk is determined from the images by means of digital image processing, preferably including the use of neural networks.",Method and apparatus for counting somatic cells or fat droplets in milk
"A system for using machine-learning to create a model for performing integrated circuit layout extraction is disclosed. The system of the present invention has two main phases: model creation and model application. The model creation phase comprises creating one or more extraction models using machine-learning techniques. First, a complex extraction problem is decomposed into smaller simpler extraction problems. Then, each smaller extraction problem is then analyzed to identify a set of physical parameters that fully define the smaller extraction problem. Next, models are created using machine learning techniques for all of the smaller simpler extraction problems. The machine learning is performed by first creating training data sets composed of the identified parameters from typical examples of the smaller extraction problem and the answers to those example extraction problems as solved using a highly accurate physics-based field solver. The training sets are then used to train the models. In one embodiment, neural networks are used to model the extraction problems. To train the neural network models. Bayesian inference is used in one embodiment. Bayesian inference may be implemented with normal Monte Carlo techniques or Hybrid Monte Carlo techniques. After the creation of a set of models for each of the smaller simpler extraction problems, the machine-learning based models may be used for extraction.",Method and apparatus for creating an extraction model
"A system for using machine-learning to create a model for performing integrated circuit layout extraction is disclosed. The system of the present invention has two main phases: model creation and model application. The model creation phase comprises creating one or more extraction models using machine-learning techniques. First, a complex extraction problem is decomposed into smaller simpler extraction problems. Then, each smaller extraction problem is then analyzed to identify a set of physical parameters that fully define the smaller extraction problem. Next, models are created using machine learning techniques for all of the smaller simpler extraction problems. The machine learning is performed by first creating training data sets composed of the identified parameters from typical examples of the smaller extraction problem and the answers to those example extraction problems as solved using a highly accurate physics-based field solver. The system them uses the created training sets to train neural networks that will be used to model the extraction problems. Bayesian inference is used to train the neural networks models. Bayesian inference may be implemented with normal Monte Carlo techniques or Hybrid Monte Carlo techniques. After the creation of a set of models for each of the smaller simpler extraction problems, the machine-learning based models may be used for extraction.",Method and apparatus for creating an extraction model using Bayesian inference
"A system for using machine learning based upon Bayesian inference using a hybrid Monte Carlo method to create a model for performing integrated circuit layout extraction is disclosed. The system of the present invention has two main phases: model creation and model application. The model creation phase comprises creating one or more extraction models using machine-learning techniques. First, a complex extraction problem is decomposed into smaller simpler extraction problems. Then, each smaller extraction problem is then analyzed to identify a set of physical parameters that fully define the smaller extraction problem. Then, for each of the smaller simpler extraction problems, complex mathematical models are created using machine learning techniques. The machine learning is performed by first creating training data sets composed of the identified parameters from typical examples of the smaller extraction problem and the answers to those example extraction problems as solved using a highly accurate physics-based field solver. Next, the system uses Bayesian inference implemented with a hybrid Monte Carlo method to train a set of neural networks for extraction problems. After the creation of a set of models for each of the smaller simpler extraction problems, the machine-learning based models may be used for extraction.",Method and apparatus for creating an extraction model using Bayesian inference implemented with the Hybrid Monte Carlo method
""" A data string is a sequence of atomic units of data that represent information. In the context of computer data, examples of data strings include executable programs, data files, and boot records consisting of sequences of bytes, or text files consisting of sequences of bytes or characters. The invention solves the problem of automatically constructing a classifier of data strings, i.e., constructing a classifier which, given a string, determines which of two or more class labels should be assigned to it. From a set of (string, class-label) pairs, this invention provides an automated technique for extracting features of data strings that are relevant to the classification decision, and an automated technique for developing a classifier which uses those features to classify correctly the data strings in the original examples and, with high accuracy, classify correctly novel data strings not contained in the example set. The classifier is developed using """"adaptive"""" or """"learning"""" techniques from the domain of statistical regression and classification, such as, e.g., multi-layer neural networks. As an example, the technique can be applied to the task of distinguishing files or boot records that are infected by computer viruses from files or boot records that are not infected. """,Method and apparatus for detecting a presence of a computer virus
"The present invention includes a method and apparatus for detecting exposure to environmental tobacco smoke by analyzing a sample of breath using electronic sensor technology, including surface acoustic-wave gas sensor technology. The method determines the presence and concentration of substance(s) (or a class of substances) indicative of environmental smoke exposure. Diagnostic software is used to identify substances where a stored library of signatures is compared to the signature obtained from the system. Signal processing and neural networks are preferably utilized in the analysis.",Method and apparatus for detecting environmental smoke exposure
"A method and system for estimating native hydrocarbons from oil-based drilling muds with the aid of NMR data. Adaptive echo stacking may be used to balance between precision and sensitivity to changes in the fluid composition. Apparent T2 decay time and effective diffusion constants derived from the NMR data may be transformed into an indication of native hydrocarbon type, using known diffusion constants, fuzzy logic, and neural networks.",Method and apparatus for detecting hydrocarbons with NMR logs in wells drilled with oil-based muds
"A method for determining routes of wiring nets by utilizing artificial neural networks includes the steps of dividing the wired area into smaller areas, representing each boundary through which one wiring net passes is capable of passing as an artificial neuron, changing an output value of the artificial neuron according to whether or not the wiring net actually passes through the boundary, composing an artificial neural network in which the interaction between the artificial neurons is taken into consideration according to one or more prescribed conditions restricting each route of the wiring nets while changing the output values of the artificial neurons, converging the output values of all artificial neurons, and determining the routes of all wiring nets by judging whether or not each wiring net passes through a boundary according to the converged output values of the artificial neurons.",Method and apparatus for determining wiring routes by utilizing artificial neural networks
"An automated speech recognition system converts a speech signal into a compact, coded representation that correlates to a speech phoneme set. A number of different neural network pattern matching schemes may be used to perform the necessary speech coding. An integrated user interface guides a user unfamiliar with the details of speech recognition or neural networks to quickly develop and test a neural network for phoneme recognition. To train the neural network, digitized voice data containing known phonemes that the user wants the neural network to ultimately recognize are processed by the integrated user interface. The digitized speech is segmented into phonemes with each segment being labelled with a corresponding phoneme code. Based on a user selected transformation method and transformation parameters, each segment is transformed into a series of multiple dimension vectors representative of the speech characteristics of that segment. These vectors are iteratively presented to a neural network to train/adapt that neural network to consistently distinguish and recognize these vectors and assign an appropriate phoneme code to each vector. Simultaneous display of the digitized speech, segments, vector sets, and a representation of the trained neural network assist the user in visually confirming the acceptability of the phoneme training set. A user may also selectively audibly confirm the acceptability of the digitization scheme, the segments, and the transform vectors so that satisfactory training data are presented to the neural network. If the user finds a particular step or parameter produces an unacceptable result, the user may modify one or more of the parameters and verify whether the modification effected an improvement in performance. The trained neural network is also automatically tested by presenting a test speech signal to the integrated user interface and observing both audibly and visually automatic segmentation of the speech, transformation into multidimensional vectors, and the resulting neural network assigned phoneme codes. A method of decoding such phoneme codes using the neural network is also disclosed.",Method and apparatus for developing a neural network for phoneme recognition
"A method structure for the compression of data utilizes an encoder which effects a transform with the aid of a coding neural network, and a decoder which includes a matched decoding neural network with effects almost the inverse transform of the encoder. The method puts in competition M coding neural networks (30.sub.1 to 30.sub.M) wherein M>1 positioned at the transmission end which effects a same type of transform and the encoded data of one of which are transmitted, after selection (32, 33) at a given instant, towards a matched decoding neural network which forms part of a set of several matched neural networks (60.sub.1 to 60.sub.Q) provided at the receiver end. Learning is effected on the basis of predetermined samples. The encoder may comprise, in addition to the coding neural network (30.sub.1 to 30.sub.M), a matched decoding neural network (35.sub.1 to 35.sub.M) so as to effect the selection (32, 33) of the best coding neural network in accordance with an error criterion.",Method and apparatus for encoding and decoding data utilizing data compression and neural networks
Interpolation techniques are described for use with data that may not be uniform and may be characterized as scattered. Such data may be obtained in instances where data acquisition may not be easily controlled such as in obtaining experimental data for use with models. Data interpolation techniques may be used in connection with the experimental data to produce a more complete and accurate data set representative of a variety of conditions using as input the non-uniform or scattered data. Such data sets may be used in a variety of applications including providing a realistic and complete set of data for training and verifying neural networks.,Method and apparatus for fast interpolation of multi-dimensional functions with non-rectangular data sets
"A method and apparatus for the prediction of time series data, specifically, the prediction of a foreign currency exchange rate. The method disclosed transforms the time series data into a difference of a series, compresses the transformed data using a log transformation, converts the compressed data into symbols, and subsequently trains one or more neural networks on the symbols such that a prediction is generated. Alternative embodiments demonstrate the conversion by a self-organizing map and training by a recurrent neural network.",Method and apparatus for foreign exchange rate time series prediction and classification
"A process model of an industrial process or system is generated. The model correlates a first number M of process parameters forming input values with a second number L of quality characteristics forming output values, which are processed to form feedback control signals for the process or system. A third number N of training data sets of the industrial process are first gathered and processed during a learning phase of the model with the help of a central processing unit, whereby a preliminary approximately model is used including a neural network with local approximation characteristics. The neural network is connected in parallel with a linear network. Both networks are connected to the same inputs. The neural network initially has a number N of neural cells corresponding to the number of training data sets. A weighted linear combination of the M process parameters is performed. The linear network and the neural network are connected with their outputs through weighting circuits to a common summing point. A stepwise regression is performed to reduce the number of neural cells from N to K and of linear paths from M to M-R. Closed loop feedback signals control the industrial process.",Method and apparatus for generating a model of an industrial production
"An input is classified into one of a plurality of possible outputs. A top-level classifier generates an approximate identification for the input as one of the possible outputs and selects two or more neural networks corresponding to the approximate identification. The selected neural networks generate two or more identifications for the input as one or more of the possible outputs. A postprocessor classifies the input as one of the possible outputs in accordance with the two or more identifications of the selected neural networks. According to an alternative embodiment, a top-level classifier selects a subset of neurons of a neural network and the subset of neurons identifies the input as one of the possible outputs.",Method and apparatus for hierarchical input classification using a neural network
"A method and apparatus for implementation of neural networks for face recognition is presented. A nonlinear filter or a nonlinear joint transform correlator (JTC) employs a supervised perceptron learning algorithm in a two-layer neural network for real-time face recognition. The nonlinear filter is generally implemented electronically, while the nonlinear joint transform correlator is generally implemented optically. The system implements perception learning to train with a sequence of facial images and then classifies a distorted input image in real-time. Computer simulations and optical experimental results show that the system can identify the input with the probability of error less than 3%. By using time multiplexing of the input image under investigation, that is, using more than one input image, the probability of error for classification can be reduced to zero.",Method and apparatus for implementation of neural networks for face recognition
"An automated speech recognition system converts a speech signal into a compact, coded representation that correlates to a speech phoneme set. A number of different neural network pattern matching schemes may be used to perform the necessary speech coding. An integrated user interface guides a user unfamiliar with the details of speech recognition or neural networks to quickly develop and test a neural network for phoneme recognition. To train the neural network, digitized voice data containing known phonemes that the user wants the neural network to ultimately recognize are processed by the integrated user interface. The digitized speech is segmented into phonemes with each segment being labelled with a corresponding phoneme code. Based on a user selected transformation method and transformation parameters, each segment is transformed into a series of multiple dimension vectors representative of the speech characteristics of that segment. These vectors are iteratively presented to a neural network to train/adapt that neural network to consistently distinguish and recognize these vectors and assign an appropriate phoneme code to each vector. Simultaneous display of the digitized speech, segments, vector sets, and a representation of the trained neural network assist the user in visually confirming the acceptability of the phoneme training set. A user may also selectively audibly confirm the acceptability of the digitization scheme, the segments, and the transform vectors so that satisfactory training data are presented to the neural network. If the user finds a particular step or parameter produces an unacceptable result, the user may modify one or more of the parameters and verify whether the modification effected an improvement in performance. The trained neural network is also automatically tested by presenting a test speech signal to the integrated user interface and observing both audibly and visually automatic segmentation of the speech, transformation into multidimensional vectors, and the resulting neural network assigned phoneme codes. A method of decoding such phoneme codes using the neural network is also disclosed.",Method and apparatus for interfacing and training a neural network for phoneme recognition
"A method and apparatus for model-free, real-time, system-wide signal timing for a complex road network is provided. It provides timings in response to instantaneous flow conditions while accounting for the inherent stochastic variations in traffic flow through the use of a simultaneous perturbation stochastic approximation (SPSA) algorithm. This is achieved by setting up several (M) parallel neural networks, each of which produces optimal controls (signal timings) for any time instant (within one of the M time periods) based on observed traffic conditions. The SPSA optimization technique is critical to the feasibility of the approach since it provides the values of weight parameters in each of the neural networks without the need for a model of the traffic flow dynamics.",Method and apparatus for model-free optimal signal timing for system-wide traffic control
"Certain aspects of the present disclosure support a method of designing the resource model in hardware (or software) for learning spiking neural networks. The present disclosure comprises accounting for resources in a different domain (e.g., negative log lack-of-resources instead of availability of resources), modulating weight changes for multiple spike events upon a single trigger, and strategically advancing or retarding the resource replenishment or decay (respectively) to overcome the limitation of single event-based triggering.",Method and apparatus for modeling neural resource based synaptic placticity
"Certain aspects of the present disclosure support a technique for neural learning of natural multi-spike trains in spiking neural networks. A synaptic weight can be adapted depending on a resource associated with the synapse, which can be depleted by weight change and can recover over time. In one aspect of the present disclosure, the weight adaptation may depend on a time since the last significant weight change.",Method and apparatus for neural learning of natural multi-spike trains in spiking neural networks
"A semantic attractor memory uses an evolving neural network architecture and learning rules derived from the study of human language acquisition and change to store, process and retrieve information. The architecture is based on multiple layer channels, with random connections from one layer to the next. One or more layers are devoted to processing input information. At least one processing layer is provided. One or more layers are devoted to processing outputs and feedback is provided from the outputs back to the processing layer or layers. Inputs from parallel channels are also provided to the one or more processing layers. With the exception of the feedback loop and central processing layers, the network is feedforward unless it is employed in a hybrid back-propagation configuration. The learning rules are based on non-stationary statistical processes, such as the Polya process or the processes leading to Bose-Einstein statistics, again derived from considerations of human language acquisition. The invention provides rapid, unsupervised processing of complex data sets, such as imagery or continuous human speech, and a means to capture successful processing or pattern classification constellations for implementation in other networks.",Method and apparatus for neural networking using semantic attractor architecture
"A semantic attractor memory uses an evolving neural network architecture and learning rules derived from the study of human language acquisition and change to store, process and retrieve information. The architecture is based on multiple layer channels, with random connections from one layer to the next. One or more layers are devoted to processing input information. At least one processing layer is provided. One or more layers are devoted to processing outputs and feedback is provided from the outputs back to the processing layer or layers. Inputs from parallel channels are also provided to the one or more processing layers. With the exception of the feedback loop and central processing layers, the network is feedforward unless it is employed in a hybrid back-propagation configuration. The learning rules are based on non-stationary statistical processes, such as the Polya process or the processes leading to Bose-Einstein statistics, again derived from considerations of human language acquisition. The invention provides rapid, unsupervised processing of complex data sets, such as imagery or continuous human speech, and a means to capture successful processing or pattern classification constellations for implementation in other networks.",Method and apparatus for neural networking using semantic attractor architecture
"Long and short term memory equations for neural networks are implemented by means of exchange of signals which carry information in the form of both binary and continuously modulated energy emissions. In one embodiment, array of parallel processors exhibits behavior of cooperative-competitive neural networks. Parallel bus interconnections and digital and analog processing of analog information contained in the exchanged energy emissions are employed with generally local synchronization of the processors.",Method and apparatus for parallel implementation of neural networks
Method and apparatus for performing close-loop programming of resistive memory devices in crossbar array based hardware circuits and systems. Invention provides iterative training of memristor crossbar arrays for neural networks by applying voltages corresponding to selected training patterns. Error is detected and measured as a function of the actual response to the training patterns versus the expected response to the training pattern.,Method and apparatus for performing close-loop programming of resistive memory devices in crossbar array based hardware circuits and systems
"A system for using machine learning based upon Bayesian inference using a hybrid monte carlo method to create a model for performing integrated circuit layout extraction is disclosed. The system of the present invention has two main phases: model creation and model application. The model creation phase comprises creating one or more extraction models using machine-learning techniques. First, a complex extraction problem is decomposed into smaller simpler extraction problems. Then, each smaller extraction problem is then analyzed to identify a set of physical parameters that fully define the smaller extraction problem. Next, complex mathematical models are created using machine learning techniques for all of the smaller simpler extraction problems. The machine learning is performed by first creating training data sets composed of the identified parameters from typical examples of the smaller extraction problem and the answers to those example extraction problems as solved using a highly accurate physics-based field solver. The system uses Bayesian inference implemented with a hybrid Monte Carlo method to train a set of neural networks for extraction problems. After the creation of a set of models for each of the smaller simpler extraction problems, the machine-learning based models may be used for extraction.",Method and apparatus for performing extraction using a model trained with Bayesian inference using a hybrid monte carlo method
"A system for using machine learning based upon Bayesian inference using a hybrid monte carlo method to create a model for performing integrated circuit layout extraction is disclosed. The system of the present invention has two main phases: model creation and model application. The model creation phase comprises creating one or more extraction models using machine-learning techniques. First, a complex extraction problem is decomposed into smaller simpler extraction problems. Then, each smaller extraction problem is then analyzed to identify a set of physical parameters that fully define the smaller extraction problem. Next, complex mathematical models are created using machine learning techniques for all of the smaller simpler extraction problems. The machine learning is performed by first creating training data sets composed of the identified parameters from typical examples of the smaller extraction problem and the answers to those example extraction problems as solved using a highly accurate physics-based field solver. Next, the system uses Bayesian inference implemented with a Monte Carlo method to train a set of neural networks for extraction problems. After the creation of a set of models for each of the smaller simpler extraction problems, the machine-learning based models may be used for extraction.",Method and apparatus for performing extraction using a model trained with Bayesian inference via a Monte Carlo method
"A system for using machine-learning to create a model for performing integrated circuit layout extraction is disclosed. The system of the present invention has two main phases: model creation and model application. The model creation phase comprises creating one or more extraction models using machine-learning techniques. First, a complex extraction problem is decomposed into smaller simpler extraction problems. Then, each smaller extraction problem is then analyzed to identify a set of physical parameters that fully define the smaller extraction problem. Next, models are created using machine learning techniques for all of the smaller simpler extraction problems. The machine learning is performed by first creating training data sets composed of the identified parameters from typical examples of the smaller extraction problem and the answers to those example extraction problems as solved using a highly accurate physics-based field solver. Next, the system trains a set of neural networks using the training sets. In one embodiment, Bayesian inference is used to train the neural networks that are used to model the extraction. After the creation the neural network based models for each of the smaller simpler extraction problems, the neural network based models may be used for extraction.",Method and apparatus for performing extraction using a neural network
"A system for using machine-learning to create a model for performing integrated circuit layout extraction is disclosed. The system of the present invention has two main phases: model creation and model application. The model creation phase comprises creating one or more extraction models using machine-learning techniques. First, a complex extraction problem is decomposed into smaller simpler extraction problems. Then, each smaller extraction problem is then analyzed to identify a set of physical parameters that fully define the smaller extraction problem. Next, models are created using machine learning techniques for all of the smaller simpler extraction problems. The machine learning is performed by first creating training data sets composed of the identified parameters from typical examples of the smaller extraction problem and the answers to those example extraction problems as solved using a highly accurate physics-based field solver. The training sets are then used to train the models. In one embodiment, neural networks are used to model the extraction problems. Bayesian inference is employed by one embodiment in order to train the neural network models. Bayesian inference may be implemented with normal Monte Carlo techniques or Hybrid Monte Carlo techniques. After the creation of a set of models for each of the smaller simpler extraction problems, the machine-learning based models may be used for extraction.",Method and apparatus for performing extraction using machine learning
The present invention provides a drilling system that utilizes a neural network for predictive control of drilling operations. A downhole processor controls the operation of the various devices in a bottom hole assembly to effect changes to drilling parameters and drilling direction to autonomously optimize the drilling effectiveness. The neural network iteratively updates a prediction model of the drilling operations and provides recommendations for drilling corrections to a drilling operator.,Method and apparatus for prediction control in drilling dynamics using neural networks
"A method for providing a virtual age estimation for predicting the remaining lifetime of a device of a given type, comprises the steps of monitoring a predetermined number of significant parameters of respective ones of a training set of devices of the given type, the parameters contributing respective wear increments, determining coefficients of a radial basis function neural network for modeling the wear increments determined from the training set operated to failure and whereof the respective virtual ages are normalized substantially to a desired norm value, deriving from the radial basis function neural network a formula for virtual age of a device of the given type, and applying the formula to the significant parameters from a further device of the given type for deriving wear increments for the further device.",Method and apparatus for providing a virtual age estimation for remaining lifetime prediction of a system using neural networks
"A method and apparatus are disclosed for recommending items of interest by fusing a plurality of recommendation scores from individual recommendation tools using one or more Radial Basis Function neural networks. The Radial Basis Function neural networks include N inputs and at least one output, interconnected by a plurality of hidden units in a hidden layer. A unique neural network can be used for each user, or a neural network can be shared by a plurality of users, such as a set of users having similar characteristics. A neural network training process initially trains each Radial Basis Function neural network using data from a training data set. A neural network cross-validation process selects the Radial Basis Function neural network that performs best on the cross-validation data set. A neural network program recommendation process uses the selected neural network(s) to recommend items of interest to a user.",Method and apparatus for recommending an item of interest using a radial basis function to fuse a plurality of recommendation scores
"Apparatus is shown for regenerating a signal stream of binary digits which has been distorted by intersymbol interference during passage through a channel (10 and 12) having insufficient channel bandwidth such that the channel output waveform comprises substantially an analog signal. (FIG. 2 at B and D.) After equalization (24) the channel output is converted to a digital sample signal stream at analog-to-digital converter (26). The converter (26) output is supplied to shift register (28) from which successive groups of digital sample signals produced over a plurality of bit intervals of channel output are shifted to decoder (22). Initialization bits that immediately precede the first group of binary digits to be regenerated also are supplied to decoder (22) through sector header reader (20) for use in decoding the first group of digital sample signals supplied to the decoder. During decoding of subsequent groups of digital sample signals, end bits (3,4 and 5) from the preceding group of regenerated binary digits are supplied to the decoder (22). The decoder includes a plurality of trained networks (40-1 through 40-5 and 50-1 through 50-m) of either the neural network or binary tree type.",Method and apparatus for regenerating a distorted binary signal stream
"In a speech recognition system, deep neural networks (DNNs) are employed in phoneme recognition. While DNNs typically provide better phoneme recognition performance than other techniques, such as Gaussian mixture models (GMM), adapting a DNN to a particular speaker is a real challenge. According to at least one example embodiment, speech data and corresponding speaker data are both applied as input to a DNN. In response, the DNN generates a prediction of a phoneme based on the input speech data and the corresponding speaker data. The speaker data may be generated from the corresponding speech data.",Method and apparatus for speech recognition using neural networks with speaker adaptation
"Certain aspects of the present disclosure support a technique for strategic synaptic failure and learning in spiking neural networks. A synaptic weight for a synaptic connection between a pre-synaptic neuron and a post-synaptic neuron can be first determined (e.g., according to a learning rule). Then, one or more failures of the synaptic connection can be determined based on a set of characteristics of the synaptic connection. The one or more failures can be omitted from computation of a neuronal behavior of the post-synaptic neuron.",Method and apparatus for strategic synaptic failure and learning in spiking neural networks
"Certain aspects of the present disclosure relate to a technique for adaptive structural delay plasticity applied in spiking neural networks. With the proposed method of structural delay plasticity, the requirement of modeling multiple synapses with different delays can be avoided. In this case, far fewer potential synapses should be modeled for learning.",Method and apparatus for structural delay plasticity in spiking neural networks
"Data samples describing a plurality of micro-segments that compose a symbol to be recognized are received from a device such as an electronic pad. A preprocessor maps the micro-segments into cells of an array that has several feature dimensions. The preprocessor assigns values to the cells based on the length of a micro-segment associated with the cell, and how well the features of the associated micro-segment correspond to the feature label of the cell. The cell values are used as inputs to a neural network that identifies the symbol. In one embodiment, recognizing symbols from large groups of symbols is facilitated by using a plurality of neural networks. Each neural network is trained to recognize symbols from a different subgroup of symbols, and each neural network can determine whether the symbol belongs to its subgroup.",Method and apparatus for symbol recognition using multidimensional preprocessing
"Data samples describing a plurality of micro-segments that compose a symbol to be recognized are received from a device such as an electronic pad. A preprocessor maps the micro-segments into cells of an array that has several feature dimensions. The preprocessor assigns values to the cells based on the length of a micro-segment associated with the cell, and how well the features of the associated micro-segment correspond to the feature label of the cell. The cell values are used as inputs to at least one of a plurality of neural networks, where each neural network is trained to identify symbols from a different group of symbols. A sorter examines the symbol to determine which neural network should be used to recognize the symbol. An output produced by the sorter controls a switching means that communicates the cell values to the proper neural network.",Method and apparatus for symbol recognition using multidimensional preprocessing and symbol sorting
"Pattern recognition of common modes by neural networks and other techniques are used to monitor and determine or predict the state of networks, computers, software systems, logical networks or other components of an information system, to report actual or predicted states, and to report other state characteristics.",Method and apparatus for system state monitoring using pattern recognition and neural networks
A method of training a neural network (2) having dynamically adjustable parameters controlled by a controller (10) which determine the response of the network (2). A set of input vectors (I.sub.l to I.sub.n) are input to network (2) at an input port (4). The corresponding set of output vectors (O'.sub.l to O'.sub.n) provided by the network (2) are compared to a target set of output vectors (O.sub.l to O.sub.n) by an error logger (12) which provides to the controller (10) a measure of similarity of the two sets. The controller (10) is arranged to alter the dynamic parameters independence on the average number of occasions the output vectors are different from the respective target output vectors. Measuring the similarity of the whole of the output set and target set and adjusting the parameters on this global measure rather than on the similarity of pairs of individual vectors provides enhanced training rates for neural networks having a data throughput rate that can be higher than the rate at which the parameters can be adjusted.,Method and apparatus for training a neural network depending on average mismatch
""" A signal processing apparatus and concomitant method for learning and integrating features from multiple resolutions for detecting and/or classifying objects. The signal processing apparatus comprises a hierarchical pyramid of neural networks (HPNN) having a """"fine-to-coarse"""" structure or a combination of the """"fine-to-coarse"""" and the """"coarse-to-fine"""" structures. """,Method and apparatus for training a neural network to detect objects in an image
"A signal processing apparatus and concomitant method for learning and integrating features from multiple resolutions for detecting and/or classifying objects are presented. Neural networks in a pattern tree structure with tree-structured descriptions of objects in terms of simple sub-patterns, are grown and trained to detect and integrate the sub-patterns. A plurality of objective functions and their approximations are presented to train the neural networks to detect sub-patterns of features of some class of objects. Objective functions for training neural networks to detect objects whose positions in the training data are uncertain and for addressing supervised learning where there are potential errors in the training data are also presented.",Method and apparatus for training a neural network to learn hierarchical representations of objects and to detect and classify objects with uncertain training data
"A method and apparatus for training neural networks using evolutionary programming. A network is adjusted to operate in a weighted configuration defined by a set of weight values and a plurality of training patterns are input to the network to generate evaluations of the training patterns as network outputs. Each evaluation is compared to a desired output to obtain a corresponding error. From all of the errors, an overall error value corresponding to the set of weight values is determined. The above steps are repeated with different weighted configurations to obtain a plurality of overall error values. Then, for each set of weight values, a score is determined by selecting error comparison values from a predetermined variable probability distribution and comparing them to the corresponding overall error value. A predetermined number of the sets of weight values determined to have the best scores are selected and copies are made. The copies are mutated by adding random numbers to their weights and the above steps are repeated with the best sets and the mutated copies defining the weighted configurations. This procedure is repeated until the overall error values diminish to below an acceptable threshold. The random numbers added to the weight values of copies are obtained from a continuous random distribution of numbers having zero mean and variance determined such that it would be expected to converge to zero as the different sets of weight values in successive iterations converge toward sets of weight values yielding the desired neural network performance.",Method and apparatus for training a neural network using evolutionary programming
"A neural network is trained to transform distant-talking cepstrum coefficients, derived from a microphone array receiving speech from a speaker distant therefrom, into a form substantially similar to close-talking cepstrum coefficients that would be derived from a microphone close to the speaker, for providing robust hands-free speech and speaker recognition in adverse practical environments with existing speech and speaker recognition systems which have been trained on close-talking speech.",Method and apparatus including microphone arrays and neural networks for speech/speaker recognition systems
""" A """"virtual string"""" is generated for synthesizing sound produced by plucked-string instruments using recurrent neural networks. The disclosed recurrent neural network, called a Scattering Recurrent Network (SRN), is based on the physics of waves traveling in the string. Vibration measured from a plucked string is used as the training data for the SRN. The trained SRN is a virtual model capable of generating tones similar to the tones generated by the physical string. As with a real string, the """"virtual string"""" corresponding to the SRN responds differently to different types of string """"plucking"""" motions. """,Method and apparatus of synthesizing plucked string instruments using recurrent neural networks
"A method and apparatus for predicting a signal value for a target element within a multi-element system is disclosed. The method includes modeling the multi-element system by defining fundamental physical relationships between the target element and other elements within the system. The resultant system model is in the form of a set of coupled non-linear differential equations. These differential equations are then approximated into linearized models about an operating point or series of operating points corresponding to the system behavior. The linearized differential equations are then subjected to a coupling analysis. The coupling analysis is employed to determine dynamic coupling between instruments. The coupling analysis assesses the degree of observability of the system and associated elements. The coupling analysis may be based upon observability tests, gramian analyses, or modal analyses. Based upon the coupling analysis, coupled elements are selected. The coupled elements correspond to system elements which are strongly coupled to the target element. A neural network is then trained using previous process values corresponding to the coupled elements. Thereafter, present operating system values corresponding to the coupled elements are fed to the trained neural network. The trained neural network processes the present operating system values to render a predicted value for the target element. This predicted value is then compared to the present system value to determine whether the target element is operating correctly.",Method and apparatus utilizing neural networks to predict a specified signal value within a multi-element system
"An artificial neural network (ANN) based system that is adapted to process an input pattern to generate an output pattern related thereto having a different number of components than the input pattern. The system (26) is comprised of an ANN (27) and a memory (28), such as a DRAM memory, that are serially connected. The input pattern (23) is applied to a processor (22), where it can be processed or not (the most general case), before it is applied to the ANN and stored therein as a prototype (if learned). A category is associated with each stored prototype. The processor computes the coefficients that allow the determination of the estimated values of the output pattern, these coefficients are the components of a so-called intermediate pattern (24). Assuming the ANN has already learned a number of input patterns, when a new input pattern is presented to the ANN in the recognition phase, the category of the closest prototype is output therefrom and is used as a pointer to the memory. In turn, the memory outputs the corresponding intermediate pattern. The input pattern and the intermediate pattern are applied to the processor to construct the output pattern (25) using the coefficients. Typically, the input pattern is a block of pixels in the field of scaling images.",Method and circuits for scaling images using neural networks
"An improved Artificial Neural Network (ANN) is disclosed that comprises a conventional ANN, a database block, and a compare and update circuit. The conventional ANN is formed by a plurality of neurons, each neuron having a prototype memory dedicated to store a prototype and a distance evaluator to evaluate the distance between the input pattern presented to the ANN and the prototype stored therein. The database block has: all the prototypes arranged in slices, each slice being capable to store up to a maximum number of prototypes; the input patterns or queries to be presented to the ANN; and the distances resulting of the evaluation performed during the recognition/classification phase. The compare and update circuit compares the distance with the distance previously found for the same input pattern updates or not the distance previously stored.",Method and circuits to virtually increase the number of prototypes in artificial neural networks
"An apparatus is provided for stimulating brain neural networks of a subject comprising: at least one transmitter configured to generate an electromagnetic field through the brain neural networks of a subject, at least one brain wave measuring device for detecting subject brain wave frequency, a CPU for processing data concerned with detection of brain wave frequency of a subject, having a database for storing and analyzing natural and affected brain scans, and at least one computer readable medium containing a predetermined protocol for transmission of the electromagnetic wave frequency profiles. The apparatus further provides a resonance effect thereby inducing newly generated brain cells to migrate toward a brain tissue area having the pathology or lesion of interest, and initiating new brain pathways at the brain region of interest.",Method and device for enhancing brain activity
A method for forming an associative computer memory comprises the step of forming an inhibitory memory matrix A=(ApA). According to the Wilshaw model constructed from a given set of address patterns and content patterns' and random matrix structure.,Method and device for realizing an associative memory based on inhibitory neural networks
"A method and apparatus for automated boundary delineation of a tubular structure in a 3D medical image of a patient using an infinitely recurrent neural network (IRNN) is disclosed. An unraveled cross-section image corresponding to a portion of a tubular structure is extracted from 3D medical image. The unraveled cross-section image is divided into a plurality of image chunks. A boundary of the portion of the tubular structure is detected based on the plurality of image chunks using a trained IRNN. The trained IRNN repeatedly inputs a sequential data stream, including the plurality of image chunks of the unraveled cross-section image, for a plurality of iterations while preserving a memory state between iterations, and detects, for each image chunk of the unraveled cross-section image input to the trained IRNN in the sequential data stream, a corresponding section of the boundary of the portion of the tubular structure.",Method and system for accurate boundary delineation of tubular structures in medical images using infinitely recurrent neural networks
"A method and system for adaptive vulnerability scanning (AVS) of an application is provided. The adaptive vulnerability scanning of an application assists in identifying new vulnerabilities dynamically. The endpoints of an application are scanned using a predefined set of rules. Subsequently, one or more possible vulnerabilities are presented. The vulnerabilities are analyzed and predefined rules are modified. The steps of scanning the application and modification of rules are iteratively repeated till the adaptive vulnerability scanning capability is achieved. A neural network is used for training the adaptive vulnerability scanner. This neural network is made to learn some rules based on predefined set of rules while undergoing the training phase. At least one weight in neural networks is altered while imparting the self learning capability.",Method and system for adaptive vulnerability scanning of an application
A recurrent neural network (RNN) method implemented on a computer system is used to produce summaries of unstructured text generated by multiple networks of individuals interacting over time by encoding the unstructured text into intermediate representations and decoding the intermediate representations into summaries of each network. Parameter data for the RNN is obtained by using multiple different versions of the same source texts to train the computer system. The method and computer system can be used to identify which of the networks match a query by determining which network generates the query with low or lowest cost.,Method and system for analyzing entities
"A method and system for anatomical object detection using marginal space deep neural networks is disclosed. The pose parameter space for an anatomical object is divided into a series of marginal search spaces with increasing dimensionality. A respective deep neural network is trained for each of the marginal search spaces, resulting in a series of trained deep neural networks. Each of the trained deep neural networks can evaluate hypotheses in a current parameter space using discriminative classification or a regression function. An anatomical object is detected in a medical image by sequentially applying the series of trained deep neural networks to the medical image.",Method and system for anatomical object detection using marginal space deep neural networks
"A method and system for anatomical object detection using marginal space deep neural networks is disclosed. The pose parameter space for an anatomical object is divided into a series of marginal search spaces with increasing dimensionality. A respective sparse deep neural network is trained for each of the marginal search spaces, resulting in a series of trained sparse deep neural networks. Each of the trained sparse deep neural networks is trained by injecting sparsity into a deep neural network by removing filter weights of the deep neural network.",Method and system for anatomical object detection using marginal space deep neural networks
A method and system for approximating a deep neural network for anatomical object detection is discloses. A deep neural network is trained to detect an anatomical object in medical images. An approximation of the trained deep neural network is calculated that reduces the computational complexity of the trained deep neural network. The anatomical object is detected in an input medical image of a patient using the approximation of the trained deep neural network.,Method and system for approximating deep neural networks for anatomical object detection
"The present invention relates to methods and systems for devising and implementing automated artificial neural networks to predict market performance and direction movements of the U.S. Treasury market, mortgage option-adjusted spreads (OAS), interest rate swap spreads, and U.S. Dollar/Mexican Peso exchange rate. The methods and systems of the present invention employ techniques used in actual neural networks naturally occurring in biological organisms to develop artificial neural network models for predicting movements in the financial market that are capable of extracting in a very consistent fashion non-linear relationships among input variables of the models that are readily apparent to the human traders.",Method and system for artificial neural networks to predict price movements in the financial markets
"Network management information stored by network devices in a switched network is obtained at a network management workstation. This is information that relates to the activity of the network devices on the network, such as the logical address of the network devices in communication with other devices. For TCP/IP networks utilizing the NMP protocol, this information is stored in the MIB or the RMON matrix group variables. This information feeds a neural network. The output of the neural network is a list of network devices grouped in virtual LANs (VLANs) such that network devices communicating, or having recently communicated, are grouped in the same VLAN. The network management information is periodically updated so the VLAN grouping can also be periodically refreshed to reflect current network device activity and thus optimize the network bandwidth.",Method and system for classifying network devices in virtual LANs
Disclosed is a an integrated circuit method and system for generating a compiler to map a code set to object code capable of being executed on an operating system platform. The integrated circuit is encoded with logic including at least one neural network. The at least one neural network in the integrated circuit is trained to convert the code set to object code. The at least one trained neural network is then used to convert the code set to object code.,Method and system for converting code to executable code using neural networks implemented in a very large scale integration (VLSI) integrated circuit
"Method for detecting malicious behavioral patterns which are related to malicious software such as a computer worm in computerized systems that include data exchange channels with other systems over a data network. Accordingly, hardware and/or software parameters are determined in the computerized system that is can characterize known behavioral patterns thereof. Known malicious code samples are learned by a machine learning process, such as decision trees and artificial neural networks, and the results of the machine learning process are analyzed in respect to the behavioral patterns of the computerized system. Then known and unknown malicious code samples are identified according to the results of the machine learning process.","Method and system for detecting malicious behavioral patterns in a computer, using machine learning"
"Method for detecting malicious behavioral patterns which are related to malicious software such as a computer worm in computerized systems that include data exchange channels with other systems over a data network. According to the proposed method, hardware and/or software parameters that can characterize known behavioral patterns in the computerized system are determined. Known malicious code samples are learned by a machine learning process, such as decision trees, Nave Bayes, Bayesian Networks, and artificial neural networks, and the results of the machine learning process are analyzed in respect to these behavioral patterns. Then, known and unknown malicious code samples are identified according to the results of the machine learning process.","Method and system for detecting malicious behavioral patterns in a computer, using machine learning"
"An artificial neural network system implemented on a computer for cell segmentation and classification of biological images. It includes a deep convolutional neural network as a feature extraction network, a first branch network connected to the feature extraction network to perform cell segmentation, and a second branch network connected to the feature extraction network to perform cell classification using the cell segmentation map generated by the first branch network. The feature extraction network is a modified VGG network where each convolutional layer uses multiple kernels of different sizes. The second branch network takes feature maps from two levels of the feature extraction network, and has multiple fully connected layers to independently process multiple cropped patches of the feature maps, the cropped patches being located at a centered and multiple shifted positions relative to the cell being classified; a voting method is used to determine the final cell classification.",Method and system for detection and classification of cells using convolutional neural networks
"Systems and methods for determining action items from knowledge base for execution of operation. The system receives instructions, present in a knowledge base, which are required to execute one or more operations. Thereafter, the system parses the instructions into one or more sentences and assigns a POS tag for each word in the one or more sentences. Further, the system assigns a predefined class for each of the POS tagged word. Based on the predefined class, the system determines the action items. The action item comprises one or more actions and one or more components on which the one or more actions are to be performed. The present disclosure enables automated systems to easily execute one or more operation based on the action items thereby reducing the delay in performance of the automated system due to complexity in interpreting the instructions.",Method and system for determining action items using neural networks from knowledge base for execution of operations
"A method and system for computer-aided differential diagnosis of diseases, and in particular, computer-aided differential diagnosis using neural networks. A first embodiment of the neural network distinguishes between a plurality of interstitial lung diseases on the basis of inputted clinical parameters and radiographic information. A second embodiment distinguishes between malignant and benign mammographic cases based upon similar inputted clinical and radiographic information. The neural networks were first trained using a hypothetical data base made up of hypothetical cases for each of the interstitial lung diseases and for malignant and benign cases. The performance of the neural network was evaluated using receiver operating characteristics (ROC) analysis. The decision performance of the neural network was compared to experienced radiologists and achieved a high performance comparable to that of the experienced radiologists. The neural network according to the invention can be made up of a single network or a plurality of successive or parallel networks. The neural network according to the invention can also be interfaced to a computer which provides computerized automated lung texture analysis to supply radiographic input data in an objective and automated manner.",Method and system for differential diagnosis based on clinical and radiological information using artificial neural networks
"A method and system for computer-aided differential diagnosis of diseases, and in particular, computer-aided differential diagnosis using neural networks. A first embodiment of the neural network distinguishes between a plurality of interstitial lung diseases on the basis of inputted clinical parameters and radiographic information. A second embodiment distinguishes between malignant and benign mammographic cases based upon similar inputted clinical and radiographic information. The neural networks were first trained using a hypothetical data base made up of hypothetical cases for each of the interstitial lung diseases and for malignant and benign cases. The performance of the neural network was evaluated using receiver operating characteristics (ROC) analysis. The decision performance of the neural network was compared to experienced radiologists and achieved a high performance comparable to that of the experienced radiologists. The neural network according to the invention can be made up of a single network or a plurality of successive or parallel networks. The neural network according to the invention can also be interfaced to a computer which provides computerized automated lung texture analysis to supply radiographic input data in an objective and automated manner.",Method and system for differential diagnosis based on clinical and radiological information using artificial neural networks
"A method and system for enhancing predictive accuracy of planet surface characteristics from orbit using an extended approach of Pan-Sharpening by using multiple high resolution bands to reconstruct high resolution hyperspectral image is disclosed. Sparsity based classification algorithm is applied to rock type classification. An Extended Yale B face database is used for performance evaluation; and utilizing deep Neural Networks for pixel classification. The present invention presents a system that can significantly enhance the predictive accuracy of surface characteristics from the orbit. The system utilizes complementary images collected from imagers onboard satellites. The present system and method generates high spatial high spectral resolution images; accurate detection of anomalous regions on Mars, Earth, or other planet surfaces; accurate rock/material classification using orbital data and the surface characterization performance will be comparable to in-situ results; and accurate chemical concentration estimation of rocks.",Method and system for enhancing predictive accuracy of planet surface characteristics from orbit
"A method for face image recognition is disclosed. The method comprises generating one or more face region pairs of face images to be compared and recognized; forming a plurality of feature modes by exchanging the two face regions of each face region pair and horizontally flipping each face region of each face region pair; receiving, by one or more convolutional neural networks, the plurality of feature modes, each of which forms a plurality of input maps in the convolutional neural network; extracting, by the one or more convolutional neural networks, relational features from the input maps, which reflect identity similarities of the face images; and recognizing whether the compared face images belong to the same identity based on the extracted relational features of the face images. In addition, a system for face image recognition is also disclosed.",Method and system for face image recognition
"Fully automated demand response may be implemented at end users, in accordance with terms agreed to by end users to reduce energy demand during demand response events. Demand reduction actions to implement the objectives of a demand response event at the end users may be determined, desirably using artificial intelligence and neural networks, based on energy demand curtailment objectives of the demand response event, hierarchy(ies) of demand reduction actions for respective demand response events ordered to minimize undesired impact at the end users, and monitoring data received from, or relating to implementing energy demand curtailment at, the end users. In addition, demand reduction actions may be automatically implemented at end users in the absence of a demand response event, to implement energy demand curtailment according to criteria of end users, where the demand reduction actions are determined based on monitoring data and a hierarchy(ies) of demand reduction actions and using artificial intelligence and neural networks.",Method and system for fully automated energy curtailment
"Systems and methods for training networks are provided. A method for training networks comprises receiving an input from each of a plurality of neural networks differing from each other in at least one of architecture, input modality, and feature type, connecting the plurality of neural networks through a common output layer, or through one or more common hidden layers and a common output layer to result in a joint network, and training the joint network.",Method and system for joint training of hybrid neural networks for acoustic modeling in automatic speech recognition
"Systems and methods for training networks are provided. A method for training networks comprises receiving an input from each of a plurality of neural networks differing from each other in at least one of architecture, input modality, and feature type, connecting the plurality of neural networks through a common output layer, or through one or more common hidden layers and a common output layer to result in a joint network, and training the joint network.",Method and system for joint training of hybrid neural networks for acoustic modeling in automatic speech recognition
"A method and system for anatomical landmark detection in medical images using deep neural networks is disclosed. For each of a plurality of image patches centered at a respective one of a plurality of voxels in the medical image, a subset of voxels within the image patch is input to a trained deep neural network based on a predetermined sampling pattern. A location of a target landmark in the medical image is detected using the trained deep neural network based on the subset of voxels input to the trained deep neural network from each of the plurality of image patches.",Method and system for landmark detection in medical images using deep neural networks
"Disclosed is a data analysis and cybersecurity method, which forms a time-based series of behavioral features, and analyzes the series of behavioral features for attack detection, new features derivation, and/or features evaluation. Analyzing the time based series of behavioral features may comprise using a Feed-Forward Neural Networks (FFNN) method, a Convolutional Neural Networks (CNN) method, a Recurrent Neural Networks (RNN) method, a Long Short-Term Memories (LSTMs) method, a principal Component Analysis (PCA) method, a Random Forest pipeline method, and/or an autoencoder method. In one embodiment, the behavioral features of the time-based series of behavioral features comprise human engineered features, and/or machined learned features, wherein the method may be used to learn new features from historic features.",Method and system for learning representations for log data in cybersecurity
"A method for modeling the performance of a gas turbine engine is provided. The method includes the steps of: 1) providing a processor; 2) inputting flight condition parameter data and engine output parameter data into a gas turbine engine model operating on the processor, which model includes a physics-based engine model that uses the flight condition parameter data to produce estimated engine output parameter data, and determines residuals from the engine output parameter data and the estimated engine output parameter data; 3) partitioning the flight condition parameter data and residuals into training data and testing data; 4) performing a correlation reduction on the training data, which analysis produces correlation adjusted training data; 5) performing an orientation reduction on the correlation adjusted training data, which reduction produces orientation adjusted training data; 6) reviewing the orientation adjusted training data relative to at least one predetermined criteria, and iteratively repeating the steps of performing a correlation reduction and an orientation reduction using the orientation adjusted training data if the criteria is not satisfied, and if the criteria is satisfied outputting the orientation adjusted training data; 7) producing estimated corrections to the orientation adjusted training data using one or more neural networks; 8) evaluating the neural adjusted data using the partitioned testing data; and 9) modeling the performance of the gas turbine using the estimated corrections to the orientation adjusted training data.",Method and system for modeling the performance of a gas turbine engine
"A method and system for computing the shortest path for traveling inside a network and visiting a predefined list of network addresses. The method can be used by a system management workstation communicating and a mobile program visiting the list of networks addresses; the system management workstation communicates with said mobile program to get the list of network addresses to be visited; the system management workstation communicates also with all the networks addresses of the list to get the parameter values for determining the shortest path. The system management platform computes the shortest path by running a Kohonen neural network reading in input the references to nodes and their,parameter values which form bi dimensional coordinates; the output is the ordered list of network addresses to be visited by the mobile program.",Method and system for optimizing the network path of mobile programs
"Examples of the present disclosure describe systems and methods relating to generating a relevance score on a given natural language answer to a natural language query for ranking the answer among other answers for the query, while generating a summary passage and a likely query to the given passage. For instance, multi-layered, recurrent neural networks may be used to encode the query and the passage, along with a multi-layered neural network for information retrieval features, to generate a relevant score for the passage. A multi-layered, recurrent neural network with soft attention and sequence-to-sequence learning task may be used as a decoder to generate a summary passage. A common encoding neural network may be employed to encode the passage for the ranking and the summarizing, in order to present concise and accurate natural language answers to the query.",Method and system for ranking and summarizing natural language passages
"A robust classification method for cancer detection from mass spectrometry data includes inputting the mass spectrometry data, preprocessing the spectrometry data, conducting robust feature selection, generating predictions for the test data sets using multiple data classifiers, the multiple data classifiers including artificial neural networks, support vector machines, weighted voting on data patterns, classification and regression trees, k-nearest neighbor classification, and logistic regression, and constructing and validating a meta-classifier by combining individual predictions of the multiple data classifiers to generate a robust prediction of a phenotype. The test data sets are used exclusively for validation of the meta-classifier.",Method and system for robust classification strategy for cancer detection from mass spectrometry data
"A robust classification method for cancer detection from mass spectrometry data includes inputting the mass spectrometry data, preprocessing the spectrometry data, conducting robust feature selection, generating predictions for the test data sets using multiple data classifiers, the multiple data classifiers including artificial neural networks, support vector machines, weighted voting on data patterns, classification and regression trees, k-nearest neighbor classification, and logistic regression, and constructing and validating a meta-classifier by combining individual predictions of the multiple data classifiers to generate a robust prediction of a phenotype. The test data sets are used exclusively for validation of the meta-classifier.",Method and system for robust classification strategy for cancer detection from mass spectrometry data
"A method and system processes utterances that are acquired either from an automatic speech recognition (ASR) system or text. The utterances have associated identities of each party, such as role A utterances and role B utterances. The information corresponding to utterances, such as word sequence and identity, are converted to features. Each feature is received in an input layer of a neural network (NN). A dimensionality of each feature is reduced, in a projection layer of the NN, to produce a reduced dimensional feature. The reduced dimensional feature is processed to provide probabilities of labels for the utterances.",Method and system for role dependent context sensitive spoken and textual language understanding with neural networks
"Methods and systems involving convolutional neural networks as applicable for semantic segmentation, including multi-task convolutional networks employing curriculum based transfer learning, are disclosed herein. In one example embodiment, a method of semantic segmentation involving a convolutional neural network includes training and applying the convolutional neural network. The training of the convolutional neural network includes each of training a semantic segmentation decoder network of the convolutional neural network, generating first feature maps by way of an encoder network of the convolutional neural network, based at least in part upon a dataset received at the encoder network, and training an instance segmentation decoder network of the convolutional neural network based at least in part upon the first feature maps. The applying includes receiving an image, and generating each of a semantic segmentation map and an instance segmentation map in response to the receiving of the image, in a single feedforward pass.",Method and system for semantic segmentation involving multi-task convolutional neural network
"A computerized method and system for the radiographic analysis of bone structure and risk of future fracture with or without the measurement of bone mass. Techniques including texture analysis for use in quantitating the bone structure and risk of future fracture. The texture analysis of the bone structure incorporates directionality information, for example in terms of the angular dependence of the RMS variation and first moment of the power spectrum of a ROI in the bony region of interest. The system also includes using dual energy imaging in order to obtain measures of both bone mass and bone structure with one exam. Specific applications are given for the analysis of regions within the vertebral bodies on conventional spine radiographs. Techniques include novel features that characterize the power spectrum of the bone structure and allow extraction of directionality features with which to characterize the spatial distribution and thickness of the bone trabeculae. These features are then merged using artificial neural networks in order to yield a likelihood of risk of future fracture. In addition, a method and system is presented in which dual-energy imaging techniques are used to yield measures of both bone mass and bone structure with one low-dose radiographic examination; thus, making the system desirable for screening (for osteoporosis and risk of future fracture).",Method and system for the computerized radiographic analysis of bone
"A computerized method and system for the radiographic analysis of bone structure and risk of future fracture with or without the measurement of bone mass. Techniques including texture analysis for use in quantitating the bone structure and risk of future fracture. The texture analysis of the bone structure incorporates directionality information, for example in terms of the angular dependence of the RMS variation and first moment of the power spectrum of a ROI in the bony region of interest. The system also includes using dual energy imaging in order to obtain measures of both bone mass and bone structure with one exam. Specific applications are given for the analysis of regions within the vertebral bodies on conventional spine radiographs. Techniques include novel features that characterize the power spectrum of the bone structure and allow extraction of directionality features with which to characterize the spatial distribution and thickness of the bone trabeculae. These features are then merged using artificial neural networks in order to yield a likelihood of risk of future fracture. In addition, a method and system is presented in which dual-energy imaging techniques are used to yield measures of both bone mass and bone structure with one low-dose radiographic examination; thus, making the system desirable for screening (for osteoporosis and risk of future fracture).",Method and system for the computerized radiographic analysis of bone
"Described herein is a method and system for training nonlinear adaptive filters (or neural networks) which have embedded memory. Such memory can arise in a multi-layer finite impulse response (FIR) architecture, or an infinite impulse response (IIR) architecture. We focus on filter architectures with separate linear dynamic components and static nonlinear components. Such filters can be structured so as to restrict their degrees of computational freedom based on a priori knowledge about the dynamic operation to be emulated. The method is detailed for an FIR architecture which consists of linear FIR filters together with nonlinear generalized single layer subnets. For the IIR case, we extend the methodology to a general nonlinear architecture which uses feedback. For these dynamic architectures, we describe how one can apply optimization techniques which make updates closer to the Newton direction than those of a steepest descent method, such as backpropagation. We detail a novel adaptive modified Gauss-Newton optimization technique, which uses an adaptive learning rate to determine both the magnitude and direction of update steps. For a wide range of adaptive filtering applications, the new training algorithm converges faster and to a smaller value of cost than both steepest-descent methods such as backpropagation-through-time, and standard quasi-Newton methods. We apply the algorithm to modeling the inverse of a nonlinear dynamic tracking system 5, as well as a nonlinear amplifier 6.",Method and system for training dynamic nonlinear adaptive filters which have embedded memory
"A method and system for utterance verification is disclosed. It first extracts a sequence of feature vectors from speech signal. At least one candidate string is obtained after speech recognition. Then, speech signal is segmented into speech segments according to the verification-unit-specified structure of candidate string for making each speech segment corresponding to a verification unit. After calculating the verification feature vectors of speech segments, these verification feature vectors are sequentially used to generate verification scores of speech segments in verification process. This invention uses neural networks for calculating verification scores, where each neural network is a Multi-Layer Perceptron (MLP) developed for each verification unit. Verification score is obtained through using feed-forward process of MLP. Finally, utterance verification score is obtained by combining all verification scores of speech segments and is used to compare with a pre-defined threshold for the decision of acceptance or rejection of the candidate string.",Method and system for utterance verification
"A method and apparatus for vascular disease detection and characterization using a recurrent neural network (RNN) is disclosed. A plurality of 2D cross-section image patches are extracted from a 3D computed tomography angiography (CTA) image, each extracted at a respective sampling point along a vessel centerline of a vessel of interest in the 3D CTA image. Vascular abnormalities in the vessel of interest are detected and characterized by classifying each of the sampling points along the vessel centerline based on the plurality of 2D cross-section image patches using a trained RNN.",Method and system for vascular disease detection using recurrent neural networks
"A method and apparatus for vascular disease detection and characterization using a recurrent neural network (RNN) is disclosed. A plurality of 2D cross-section image patches are extracted from a 3D computed tomography angiography (CTA) image, each extracted at a respective sampling point along a vessel centerline of a vessel of interest in the 3D CTA image. Vascular abnormalities in the vessel of interest are detected and characterized by classifying each of the sampling points along the vessel centerline based on the plurality of 2D cross-section image patches using a trained RNN.",Method and system for vascular disease detection using recurrent neural networks
"Processing gamma count rate decay curves using neural networks. At least some of the illustrative embodiments are methods comprising obtaining a gamma count rate decay curve one each for a plurality of gamma detectors of a nuclear logging tool (the gamma count rate decay curves recorded at a particular borehole depth), applying the gamma count rate decay curves to input nodes of a neural network, predicting by the neural network a geophysical parameter of the formation surrounding the borehole, repeating the obtaining, applying and predicting for a plurality of borehole depths, and producing a plot of the geophysical parameter of the formation as a function of borehole depth.",Method and system of processing gamma count rate curves using neural networks
"A neural network in a speech-recognition system has computing units organized in levels including at least one hidden level and one output level. The computing units of the hidden level are connected to the computing units of the output level via weighted connections, and the computing units of the output level correspond to acoustic-phonetic units of the general vocabulary. This network executes the following steps:determining a subset of acoustic-phonetic units necessary for recognizing all the words contained in the general vocabulary subset;eliminating from the neural network all the weighted connections afferent to computing units of the output level that correspond to acoustic-phonetic units not contained in the previously determined subset of acoustic-phonetic units, thus obtaining a compacted neural network optimized for recognition of the words contained in the general vocabulary subset; andexecuting, at each moment in time, only the compacted neural network.",Method for accelerating the execution of speech recognition neural networks and the related speech recognition device
"An engine misfire detection system (10) for detecting engine misfire. System (10) includes a conventional controller (12) having a memory unit (14) and a plurality of sensors (16). Controller (12) includes a plurality of neural networks, which are trained by system (10), and which determine whether a firing event is a misfire based upon events occurring before the firing event and events occurring after the firing event. The neural networks are adaptively trained to compensate for the effects of engine variability and aging.",Method for adaptive detection of engine misfire
"The invention is a method of allocating a computer to service a request for a data set in a system having a plurality of computers. The method is implemented on a neural having at an input layer having input nodes and an output layer having output nodes, where each output node is associated with a specific computer. Connecting the input nodes to the output nodes are weights w(j,k). Each output node is associated with a computer in the system, and the inputs to the input nodes are dependent upon the number of requests for specific pages.",Method for allocation of web pages using neural networks
"The invention provides a method for automated training of a plurality of artificial neural networks for phoneme recognition using training data, wherein the training data comprises speech signals subdivided into frames, each frame associated with a phoneme label, wherein the phoneme label indicates a phoneme associated with the frame. A sequence of frames from the training data are provided, wherein the number of frames in the sequence of frames is at least equal to the number of artificial neural networks. Each of the artificial neural networks is assigned a different subsequence of the provided sequence, wherein each subsequence comprises a predetermined number of frames. A common phoneme label for the sequence of frames is determined based on the phoneme labels of one or more frames of one or more subsequences of the provided sequence. Each artificial neural network using the common phoneme label.",Method for automated training of a plurality of artificial neural networks
"A method for a computer-aided control of a technical system is provided. The method involves use of a cooperative learning method and artificial neural networks. In this context, feed-forward networks are linked to one another such that the architecture as a whole meets an optimality criterion. The network approximates the rewards observed to the expected rewards as an appraiser. In this way, exclusively observations which have actually been made are used in optimum fashion to determine a quality function. In the network, the optimum action in respect of the quality function is modeled by a neural network, the neural network supplying the optimum action selection rule for the given control problem. The method is specifically used to control a gas turbine.",Method for computer-aided control and/or regulation using two neural networks wherein the second neural network models a quality function and can be used to control a gas turbine
"A defibrillator configurable for optimal behavior across a broad spectrum of patients, users, and circumstances is provided. A set of environmental characteristics that represent the patient population, the user population, and the possible circumstances are determined and then applied to a configure algorithm to determine an optimal behavior of the defibrillator as reflected through the set up parameters. The set of environmental characteristics can be entered manually or determined from dispatch data supplied by computerized dispatch systems. The optimal behavior can also be achieved using adaptation algorithms such as fuzzy logic and neural networks that allow the defibrillator to obtain measurements of the environmental characteristics and alter its behavior based on those measurements.",Method for configuring a defibrillator
"A method and system for design optimization that incorporates the advantages of both traditional response surface methodology (RSM) and neural networks is disclosed. The present invention employs a unique strategy called parameter-based partitioning of the given design space. In the design procedure, a sequence of composite response surfaces based on both neural networks and polynomial fits is used to traverse the design space to identify an optimal solution. The composite response surface has both the power of neural networks and the economy of low-order polynomials (in terms of the number of simulations needed and the network training requirements). The present invention handles design problems with many more parameters than would be possible using neural networks alone and permits a designer to rapidly perform a variety of trade-off studies before arriving at the final design.",Method for constructing composite response surfaces by combining neural networks with other interpolation or estimation techniques
"A method and system for data modeling that incorporates the advantages of both traditional response surface methodology (RSM) and neural networks is disclosed. The invention partitions the parameters into a first set of s simple parameters, where observable data are expressible as low order polynomials, and c complex parameters that reflect more complicated variation of the observed data. Variation of the data with the simple parameters is modeled using polynomials; and variation of the data with the complex parameters at each vertex is analyzed using a neural network. Variations with the simple parameters and with the complex parameters are expressed using a first sequence of shape functions and a second sequence of neural network functions. The first and second sequences are multiplicatively combined to form a composite response surface, dependent upon the parameter values, that can be used to identify an accurate model.",Method for constructing composite response surfaces by combining neural networks with polynominal interpolation or estimation techniques
"A technique for converting an existing expert system into one incorporating one or more neural networks includes the steps of separating the knowledge base and inference engine of the existing expert system, identifying the external and internal inputs and outputs, identifying subsystems from the inputs and outputs, using a neural network for each subsystem, training each neural network to learn the production rules of its associated subsystem, and computing exact or interpolated outputs from a given set of inputs. Each neural network utilizes a training algorithm which does not require repetitive training and which yields a global minimum to each given set of inputs.",Method for converting an existing expert system into one utilizing one or more neural networks
"To avoid the problem of category assignment in artificial neural networks (ANNs) based upon a mapping of the input space (like ROI and KNN algorithms), the present method uses &#8220;probabilities&#8221;. Now patterns memorized as prototypes do not represent categories any longer but the &#8220;probabilities&#8221; to belong to categories. Thus, after having memorized the most representative patterns in a first step of the learning phase, the second step consists of an evaluation of these probabilities. To that end, several counters are associated with each prototype and are used to evaluate the response frequency and accuracy for each neuron of the ANN. These counters are dynamically incremented during this second step using distances evaluation (between the input vectors and the prototypes) and error criteria (for example the differences between the desired responses and the response given by the ANN). At the end of the learning phase, a function of the contents of these counters allows an evaluation of these probabilities for each neuron to belong to predetermined categories. During the recognition phase, the probabilities associated with the neurons selected by the algorithm permit the characterization of new input vectors and more generally any kind of input (images, signals, sets of data) to detect and classify anomalies. The method allows a significant reduction in the number of neurons that are required in the ANN while improving its overall response accuracy.",Method for detecting and classifying anomalies using artificial neural networks
"An image point located in the region inside of an object image is determined from an image signal made up of a series of image signal components representing respective picture elements in a radiation image, which includes the object image and which has been recorded on a recording medium in accordance with a predetermined image recording menu. A plurality of different neural networks are prepared for a plurality of different image recording menus. Each of the neural networks receives an image signal and generates outputs which represent an image point. A neural network, which is optimum for the predetermined image recording menu, is selected from the plurality of the neural networks. Outputs, which represent the image point located in the region inside of the object image, are then obtained from the selected neural network.",Method for determining image points in object images using neural networks
"A method for determining spraying parameters that are suitable as input values for a paint spraying unit that can electrostatically charge a liquid paint. In this case, at least one artificial neural network is used to determine the spraying parameters, an output of such a neural network being available for each spraying parameter. A suitable number of real measured values are fed to the one neural network or a plurality of neural networks as input values, initially in a learning phase. The measured values further contain associated real spraying parameters in addition to a paint thickness distribution in the form of discrete values. Input values are fed to the one neural network or a plurality of neural networks in the application phase. The input values being the result of an analysis of the paint thickness distribution of a targeted, that is to say prescribed, spraying result.",Method for determining spraying parameters for a paint spraying unit
A sequence of measured quantities is determined for a chemical reactor and a data generator generates a curve in normal coordinates from a respective predetermined normal form that describes a type of critical state. Each normal form is imaged onto the sequence of measured quantities by neural networks whereby a respective neural network is allocated to a data generator. The imaging is optimized by applying parameter optimization methods. The neural network that converges best through use of parameter optimization method describes the critical state that lies closest to the actual state of the chemical reactor.,Method for determining state parameters of a chemical reactor with artificial neural networks
"A tool, and the method of making the tool, for process system identification that is based on the general purpose learning capabilities of neural networks. The tool and method can be used for a wide variety of system identification problems with little or no analytic effort. A neural network is trained using a process model to approximate a function which relates process input and output data to process parameter values. Once trained, the network can be used as a system identification tool. In principle, this approach can be used for linear or nonlinear processes, for open or closed loop identification, and for identifying any or all process parameters.",Method for developing a neural network tool for process identification
"A method for storing and searching documents also useful in disambiguating word senses and a method for generating a dictionary of context vectors. The dictionary of context vectors provides a context vector for each word stem in the dictionary. A context vector is a fixed length list of component values corresponding to a list of word-based features, the component values being an approximate measure of the conceptual relationship between the word stem and the word-based feature. Documents are stored by combining the context vectors of the words remaining in the document after uninteresting words are removed. The summary vector obtained by adding all of the context vectors of the remaining words is normalized. The normalized summary vector is stored for each document. The data base of normalized summary vectors is searched using a query vector and identifying the document whose vector is closest to that query vector. The normalized summary vectors of each document can be stored using cluster trees according to a centroid consistent algorithm to accelerate the searching process. Said searching process also gives an efficient way of finding nearest neighbor vectors in high-dimensional spaces.",Method for document retrieval and for word sense disambiguation using neural networks
"In a method for supplementing missing data in a time series used as an input to a neural network or for improving noise-infested data supplied to a neural network, error distribution densities for the missing values are calculated on the basis of the known measured values from the time series and their known or predetermined error distribution density, and samples are taken from this error distribution density according to the Monte Carlo method. These each lead to an estimated or predicted value whose average is introduced for the value to be predicted. The method can be employed for the operation as well as for the training of the neural network, and is suitable for use in all known fields of utilization of neural networks.",Method for editing an input quantity for a neural network
"A stress/strain curve is established by means of neural networks 1 to N and 4. To that end, parameters are input into the input 50, from which the neural networks 1 to N respectively establish the principal components of characteristic points. The curve type is selected on the basis of the output of the neural network 4. The principal components of the characteristic points of the corresponding curve type are then inverse-transformed. The stress/strain curve is then calculated by the generator 59 on the basis of the inverse transformation.",Method for establishing stress/strain curves by means of spline interpolation on the basis of characteristic points and with the use of neural networks
"A method for determining rock formation permeability from wireline well logs utilizes neural networks. The neural networks provide consistency, accuracy and overall quality without bias to the calculations.",Method for estimating formation permeability from wireline logs using neural networks
"A method for linearization of feedback in neural networks, and a neural network incorporating the feedback linearization method are presented. Control action is used to achieve tracking performance for a state-feedback linearizable, but unknown nonlinear control system. The control signal comprises a feedback linearization portion provided by neural networks, plus a robustifying portion that keep the control magnitude bounded. Proofs are provided to show that all of the signals in the closed-loop system are semi-globally uniformly ultimately bounded. This eliminates an off-line learning phase, and simplifies the initialization of neural network weights.",Method for feedback linearization of neural networks and neural network incorporating same
Provided is a method for filtering communications received from over a network for a person-to-person communication program. A communication is received for the person-to person communication program. The communication is processed to determine predefined language statements. Information on the determined language statements is inputted into a neural network to produce an output value. A determination is made as to whether the output value indicates that the communication is unacceptable. The communication is forwarded to the person-to-person communication program unchanged if the output value indicates that the communication is acceptable. An action is performed with respect to the communication upon determining that the communication is unacceptable that differs from the forwarding of the communication that occurs if the output value indicates that the communication is acceptable.,Method for filtering content using neural networks
"A method for forming a module (hydrodynamic or thermodynamic for example) intended for real-time simulation of the flow mode, at any point of a pipe, of a multiphase fluid stream comprising at least a liquid phase and at least a gas phase. The method comprises using a modelling system based on non-linear neural networks each having inputs for structure parameters and physical quantities, outputs where quantities necessary for estimation of the flow mode are available, and at least one intermediate layer. The neural networks are determined iteratively to adjust to the values of a learning base with predetermined tables connecting various values obtained for the output data to the corresponding values of the input data. A learning base suited to the imposed operating conditions is used and optimized neural networks best adjusted to the imposed operating conditions are generated.",Method for forming an optimized neural network module intended to simulate the flow mode of a multiphase fluid stream
"An apparatus includes an optical communications receiver receiving a turbulence-distorted, optical signal. The turbulence-distorted, optical signal includes a plurality of fundamental modes encoded via a combinatorial multiplexings dictionary. The received optical signal includes a plurality of two-dimensional images. Each two-dimensional image of the plurality of two-dimensional images respectively represents received fundamental modes of the plurality of fundamental modes. The receiver includes a neural network trained to assign to each two-dimensional image of the plurality of two-dimensional images at least one respective active fundamental mode of the plurality of fundamental modes and a corresponding accuracy probability based on the dictionary.",Method for free space optical communication utilizing patterned light and convolutional neural networks
A post-processing method for an optical character recognition (OCR) method for combining different OCR engines to identify and resolve characters and attributes of the characters that are erroneously recognized by multiple optical character recognition engines. The characters can originate from many different types of character environments. OCR engine outputs are synchronized in order to detect matches and mismatches between said OCR engine outputs by using synchronization heuristics. The mismatches are resolved using resolution heuristics and neural networks. The resolution heuristics and neural networks are based on observing many different conventional OCR engines in different character environments to find what specific OCR engine correctly identifies a certain character having particular attributes. The results are encoded into the resolution heuristics and neural networks to create an optimal OCR post-processing solution.,Method for identifying and resolving erroneous characters output by an optical character recognition system
"The present invention refers to a computer vision system for identifying the fungus Guignardia citricarpa, the causing agent of the citrus black spot. The invention refers to a method for identifying Guignardia citricarpa using a computer vision system comprising the steps of a) image acquisition from a collection disk using a digital camera connected to a microscope b) pre-processing to improve (or correct) the scanned images c) image segmentation to segregate each particle in the image d) analysis and extraction of relevant features of the segmented particles and e) identification using artificial intelligence techniques and artificial neural networks.",Method for identifying Guignardia citricarpa
"An artificial neural network is used to predict the current state of a process based upon sensor measurements of the process variables at previous times. The output of the neural network provides the process control system with the predicted process state, thereby reducing the time lag of the sensors and providing improved control of the process.",Method for improving process control by reducing lag time of sensors using artificial neural networks
"Particle patterns formed on an inclined bottom surface of a reaction vessel are photoelectrically detected to produce a two-dimensional image signal. The signal is processed to judge or classify the particle patterns into an agglutinated pattern, a non-agglutinated pattern or an uncertain pattern with the aid of a neural network. An image signal representing a particle pattern is first extracted, then the image signal is decomposed into a series of light intensity areas due to different contours of the inclined bottom surface. The integrated light intensities of each area are presented to a neural network. The neural network operates in a training mode and a classification mode. In the training mode the neural network is presented with numerous samples of decomposed images as well as their respective classification. In the classification mode the neural network will judge a decomposed image based on a generalization made during the training mode.",Method for judging particle agglutination patterns using neural networks
A method for training a probabilistic neural network to map seismic attributes or similar quantities.,Method for mapping seismic attributes using neural networks
"Method intended for real-time modelling, by neural networks, of hydrodynamic characteristics of multiphase flows in transient phase in pipes. In order to specifically take account of the possible flow regimes of fluids in pipes, various neural or expert models are formed for several flow regimes (or subregimes) in the whole of the variation range of the hydrodynamic characteristics of the flows (preferably for each one of them), as well as a neural model estimating the probability of belonging of the flows to each flow regime or subregime, knowing some of the characteristics thereof. The probabilities obtained are used for weighting the estimations delivered by each neural model, the result of the weighted sum being then the estimation eventually retained. Applications to various industries and notably for modelling of hydrocarbon flows in pipelines.",Method for modelling hydrodynamic characteristics of multiphase flows using neuronal networks
"Precise, three-dimensional localization of neuroanatomic substrates responsible for an established pattern of anti-social behavior such as violence, substance abuse, pedophilia and the like is used to guide temporally and spatially coordinated pulsed multi-origin ablative modalities, wherein the pulse duration is shorter than thermal relaxation time of the target tissue. By selectively destroying aberrant neural networks, the anti-social behavior is eliminated while minimizing unwanted neurologic side-effects.",Method for modification of anti-social behavior
"Described is a system for converting convolutional neural networks to spiking neural networks. A convolutional neural network (CNN) is adapted to fit a set of requirements of a spiking neural network (SNN), resulting in an adapted CNN. The adapted CNN is trained to obtain a set of learned weights, and the set of learned weights is then applied to a converted SNN having an architecture similar to the adapted CNN. The converted SNN is then implemented on neuromorphic hardware, resulting in reduced power consumption.",Method for neuromorphic implementation of convolutional neural networks
Magneto-electric nanoparticles in a subject interact with an external magnetic field to cause stimulation of neural networks in the subject. Electric signals in the neural network are coupled to magnetic dipoles induced in the nanoparticles to cause changes in electric pulse sequences of the subject's brain.,Method for non-invasive brain stimulation
Magneto-electric nanoparticles in a subject interact with an external magnetic field to cause stimulation of neural networks in the subject. Electric signals in the neural network are coupled to magnetic dipoles induced in the nanoparticles to cause changes in electric pulse sequences of the subject's brain.,Method for non-invasive brain stimulation
"Described is a system for object detection in images or videos using spiking neural networks. An intensity saliency map is generated from an intensity of an input image having color components using a spiking neural network. Additionally, a color saliency map is generated from a plurality of colors in the input image using a spiking neural network. An object detection model is generated by combining the intensity saliency map and multiple color saliency maps. The object detection model is used to detect multiple objects of interest in the input image.",Method for object detection in digital image and video using spiking neural networks
"A method and apparatus for designing a multilayer feed forward neural network that produces a design having a minimum number of connecting weights is based on a novel iterative procedure for inverting the full Hessian matrix of the neural network. The inversion of the full Hessian matrix results in a practical strategy for pruning weights of a trained neural network. The error caused by pruning is minimized by a correction that is applied to remaining (un-pruned) weights thus reducing the need for retraining. However, retraining may be applied to the network possibly leading to further the simplification of the network design.",Method for operating an optimal weight pruning apparatus for designing artificial neural networks
"A method for performing diagnostics of a structure subject to loads, in particular an aircraft structure, is implemented by an arrangement of sensors located at relevant points of the structure and corresponding neural networks. The method includes training the neural network in order to establish an associative relationship between the state of the structure in a subset of relevant points and the state of the structure in at least one residual relevant point. The state of the structure is detected in a plurality of relevant points under operating conditions. The state of the structure is estimated in at least one residual relevant point by the associated neural network on the basis of the pre-established associated relationship. The state of the estimated structure is compared with the detected state at the residual relevant point, such that an intact state of the structure is determined if the expected and detected values of the state parameter match, or a defective state of the structure is determined if these values differ.",Method for performing diagnostics of a structure subject to loads and system for implementing said method
"A method for predicting impact by using neural networks comprising steps of supplying a predetermined crash curve to a first neural network having an intermediate layer to train said first neural network by means of learning calculation and supplying a predetermined air bag deployment limit curve to a second neural network to train said second neural network, supplying data indicative of crash curve obtained by an acceleration sensing device on collision to said first and second neural networks, predicting in said first neural network a time instance at which a threshold displacement is going to reach based on the basis of the training result in said first neural network, comparing in said second neural network data indicative of crash curve on said collision and said air bag deployment limit curve to produce a decision signal of deploying the air bag according to the comparison result, calculating said decision signal and said time instance, to deploy the air bag depending on the impact, and supplying an operation command signal to an air bag deployment operation device.",Method for predicting impact and an impact prediction system for realizing the same by using neural networks
"A method for predicting the properties of crude oils by the application of neural networks articulated in phases and characterized by determining the T2 NMR relaxation curve of an unknown crude oil and converting it to a logarithmic relaxation curve; selecting the values of the logarithmic relaxation curve lying on a characterization grid; entering the selected values as input data for a multilayer neural network of the back propagation type, trained and optimized by means of genetic algorithms; predicting, by means of the trained and optimized neural network, the physico-chemical factors of the unknown crude oil.The method comprises a training and optimization process of the multilayer neural network of the back propagation type.The method thus defined allows the most representative physico-chemical factors of crude oils to be predicted rapidly and without onerous laboratory structures, or alternatively the distillation curve of crude oils with an acceptable approximation degree.",Method for predicting the properties of crude oils by the application of neural networks
"The method of making the tool, for process system identification that is based on the general purpose learning capabilities of neural networks. The method can be used for a wide variety of system identification problems with little or no analytic effort. A neural network is trained using a process model to approximate a function which relates process input and output data to process parameter values. Once trained, the network can be used as a system identification tool. In principle, this approach can be used for linear or nonlinear processes, for open or closed loop identification, and for identifying any or all process parameters.",Method for process system identification using neural network
"A binary tree and method of producing a binary tree are shown, together with artificial neural networks which include processing units of binary trees. The binary tree-producing method includes obtaining a set of binary training pattern vectors some of which are associated with a first pattern to be recognized, and the remainder of which are not associated with the first pattern. Those associated with the first pattern and the remainder are identified as category 1 and category 0 vectors, respectively. The set of vectors is used to generate a binary tree in computer memory, which tree includes a sequence of binary doublets each of which represents a tree node. One of four branch conditions is identified by each doublet including no branches, branch only left, branch only right or branch both left and right. The sequence of binary doublets is used to classify binary vectors. A hardware version of the tree may be implemented which includes a plurality of AND gates (1L, 1R, 2L, 2R, 3L and 5L) interconnected in an N-level binary tree (FIG. 3) to which N binary inputs (X.sub.1, X.sub.2 and X.sub.3) are connected to separate levels of the tree. Leaf nodes of the AND gate binary tree are connected to an OR gate (20), and a start signal (S) is supplied to the root node (1) of the tree.","Method for producing a binary tree, pattern recognition and binary vector classification method using binary trees, and system for classifying binary vectors"
"Recurrent neural networks are powerful tools for handling incomplete data problems in machine learning thanks to their significant generative capabilities. However, the computational demand for algorithms to work in real time applications requires specialized hardware and software solutions. We disclose a method for adding recurrent processing capabilities into a feedforward network without sacrificing much from computational efficiency. We assume a mixture model and generate samples of the last hidden layer according to the class decisions of the output layer, modify the hidden layer activity using the samples, and propagate to lower layers. For an incomplete data problem, the iterative procedure emulates feedforward-feedback loop, filling-in the missing hidden layer activity with meaningful representations.",Method for pseudo-recurrent processing of data using a feedforward neural network architecture
"An architecture for capture and generation, and a set of methods for characterization, prediction, and classification of traffic in packet networks are disclosed. The architecture consists of a device that stores packet timing information and processes the data so that characterization, prediction, and classification algorithms can perform operations in real-time. A methodology is disclosed for real-time traffic analysis, characterization, prediction, and classification in packet networks. The methodology is based on the simultaneous aggregation of packet arrival times at different times scales. The traffic is represented at the synchronous carrier level by the arrival or non-arrival of a packet. The invention does not require knowledge about the information source, nor needs to decode the information contents of the packets. Only the arrival timing information is required. The invention provides a characterization of the traffic on packet networks suitable for a real-time implementation. The methodology can be applied in real-time traffic classification by training a neural network from calculated second order statistics of the traffic of several known sources. Performance descriptors for the network can also be obtained by calculating the deviation of the traffic distribution from calculated models. Traffic prediction can also be done by training a neural network from a vector of the results of a given processing against a vector of results of the subsequent processing unit; noticing that the latter vector contains information at a larger time scale than the previous. The invention also provides a method of estimating an effective bandwidth measure in real time which can be used for connection admission control and dynamic routing in packet networks. The invention provides appropriate traffic descriptors that can be applied in more efficient traffic control on packet networks.",Method for real-time traffic analysis on packet networks
"According to the present invention, a method for recognition of normal and abnormal conditions can be performed with at least one neural network. First, trend data of an object system, before a recognition-step, are entered as input data to an input layer of each neural network and data of this system at the recognition-step are entered as objective output data to an output layer of the neural network. Thus, multiple sets of trend data showing at least one normal condition of this system are formed in the neural network in order to obtained learned weights and biases. Next, output data at every recognition-step are predicted by entering actual trend data as input data to the neural network, while the learned weights and biases are utilized. Then, the predicted output data are compared with actual output data at every recognition-step. Finally, the normal and abnormal conditions of this system can be recognized by real time interpretation of deviations between the predicted output data and the actual output data. The method of the present invention particularly can be applied to a control system requiring the recognition of abnormal conditions such as a control system for the operation of a plant, an automobile, a robot, an aircraft, a marine vessel, a medical apparatus, security apparatus and the like.",Method for recognition of abnormal conditions using neural networks
"A method for recognizing an object image comprises the steps of extracting a candidate for mineda predetermined object image from an overall image, and making a judgment as to whether the extracted candidate for the predetermined object image is or is not the predetermined object image. The candidate for the predetermined object image is extracted by causing the center point of a view window, which has a predetermined size, to travel to the position of the candidate for the predetermined object image, and determining an extraction area in accordance with the size and/or the shape of the candidate for the predetermined object image, the center point of the view window being taken as a reference during the determination of the extraction area. A learning method for a neural network comprises the steps of extracting a target object image, for which learning operations are to be carried out, from an image, feeding a signal, which represents the extracted target object image, into a neural network, and carrying out the learning operations of the neural network in accordance with the input target object image.",Method for recognizing object images and learning method for neural networks
"A method for recognizing an object image comprises the steps of extracting a candidate for a predetermined object image from an overall image, and making a judgment as to whether the extracted candidate for the predetermined object image is or is not the predetermined object image. The candidate for the predetermined object image is extracted by causing the center point of a view window, which has a predetermined size, to travel to the position of the candidate for the predetermined object image, and determining an extraction area in accordance with the size and/or the shape of the candidate for the predetermined object image, the center point of the view window being taken as a reference during the determination of the extraction area. A learning method for a neural network comprises the steps of extracting a target object image, for which learning operations are to be carried out, from an image, feeding a signal, which represents the extracted target object image, into a neural network, and carrying out the learning operations of the neural network in accordance with the input target object image.",Method for recognizing object images and learning method for neural networks
"A method for ruggedizing an ICE design, fabrication and application with neural networks as disclosed herein includes selecting a database for integrated computational element (ICE) optimization is provided. The method includes adjusting a plurality of ICE operational parameters according to an environmental factor recorded in the database and simulating environmentally compensated calibration inputs. The method includes modifying a plurality of ICE structure parameters to obtain an ICE candidate structure having improved performance according to a first algorithm applied to the database and validating the ICE candidate structure with an alternative algorithm applied to the database. Further, the method includes determining a plurality of manufacturing ICEs based on the validation with the first algorithm and the alternative algorithm, and fabricating one of the plurality of manufacturing ICEs. A method for determining a fluid characteristic using a calibrated ICE fabricated as above and supplemental elements is also provided.",Method for ruggedizing integrated computational elements for analyte detection in the oil and gas industry
"The present invention relates to methods for searching and constructing a 3D motif image database, wherein said 3D motif image database can be used to understand the connection relationship of a 3D network, e.g. a neural network comprising biological neural networks or artificial neural networks. The searching and constructing methods are applied on the 3D motif image database, a proper computer-aided graphic platform. The database not only facilitates the management of the huge amount of categorized data but also rationally excavates the hidden information cloaked within.",Method for searching and constructing 3D image database
"Seismic facies are identified in a volume of seismic data, wherein, first, a plurality of initial textural attributes representative of the volume of seismic data are calculated. Next, a probabilistic neural network is constructed from the calculated initial textural attributes. Then, final textural attributes are calculated throughout the volume of seismic data. Finally, the calculated final textural attributes are classified using the constructed probabilistic neural network.",Method for seismic facies interpretation using textural analysis and neural networks
"Methods are provided for developing medical diagnostic tests using decision-support systems, such as neural networks. Patient data or information, typically patient history or clinical data, are analyzed by the decision-support systems to identify important or relevant variables and decision-support systems are trained on the patient data. Patient data are augmented by biochemical test data, or results, where available, to refine performance. The resulting decision-support systems are employed to evaluate specific observation values and test results, to guide the development of biochemical or other diagnostic tests, too assess a course of treatment, to identify new diagnostic tests and disease markers, to identify useful therapies, and to provide the decision-support functionality for the test. Methods for identification of important input variables for a medical diagnostic tests for use in training the decision-support systems to guide the development of the tests, for improving the sensitivity and specificity of such tests, and for selecting diagnostic tests that improve overall diagnosis of, or potential for, a disease state and that permit the effectiveness of a selected therapeutic protocol to be assessed are provided. The methods for identification can be applied in any field in which statistics are used to determine outcomes. A method for evaluating the effectiveness of any given diagnostic test is also provided.",Method for selecting medical and biochemical diagnostic tests using neural network-related applications
"Neural networks learn expert system rules, for either business or real-time applications, to improve the robustness and speed of execution of the expert system. One or more neural networks are constructed which incorporate the production rules of one or more expert systems. Each neural network is constructed of neurons or neuron circuits each having only one significant processing element in the form of a multiplier. Each neural network utilizes a training algorithm which does not require repetitive training and which yields a global minimum to each given set of input vectors.",Method for structuring an expert system utilizing one or more neural networks
"A method for the computer-aided learning of a recurrent neural network for modeling a dynamic system which is characterized at respective times by an observable vector with one or more observables as entries is provided. The neural network includes both a causal network with a flow of information that is directed forwards in time and a retro-causal network with a flow of information which is directed backwards in time. The states of the dynamic system are characterized by first state vectors in the causal network and by second state vectors in the retro-causal network, wherein the state vectors each contain observables for the dynamic system and also hidden states of the dynamic system. Both networks are linked to one another by a combination of the observables from the relevant first and second state vectors and are learned on the basis of training date including known observables vectors.",Method for the computer-aided learning of a recurrent neural network for modeling a dynamic system
"A method for computer-assisted modeling of a technical system is disclosed. At multiple different operating points, the technical system is described by a first state vector with first state variable(s) and by a second state vector with second state variable(s). A neural network comprising a special form of a feed-forward network is used for the computer-assisted modeling of said system. The feed-forward network includes at least one bridging connector that connects a neural layer with an output layer, thereby bridging at least one hidden layer, which allows the training of networks with multiple hidden layers in a simple manner with known learning methods, e.g., the gradient descent method. The method may be used for modeling a gas turbine system, in which a neural network trained using the method may be used to estimate or predict nitrogen oxide or carbon monoxide emissions or parameters relating to combustion chamber vibrations.",Method for the computer-assisted modeling of a technical system
"The invention relates to a system and a method for training a number of neural networks, by determining a first training data record, wherein the training data have a particular accuracy, generating a number of second data training records by perturbing the first training data record with a random variable, and training each of the neural networks with one of the training data records. A prognosis and an estimation of the prognosis error can be carried out by means of such a system.",Method for training neural networks
"A Neural Gas network used for pattern recognition, sequence and image processing is extended to a supervised classifier with labeled prototypes by extending a cost function of the Neural Gas network with additive terms, each of which increases with a difference between elements of the class labels of a prototype and a training data point and decreases with their distance. The extended cost function is then iteratively minimized by adapting weight vectors of the prototypes. The trained network can then be used to classify mass spectrometric data, especially mass spectrometric data derived from biological samples.",Method for training of supervised prototype neural gas networks and their use in mass spectrometry
"An unsupervised back propagation method for training neural networks. For a set of inputs, target outputs are assigned 1's and 0's randomly or arbitrarily for a small number of outputs. The learning process is initiated and the convergence of outputs towards targets is monitored. At intervals, the learning is paused, and the values for those targets for the outputs which are converging at a less than average rate, are changed (e.g., 0.fwdarw.1, or 1.fwdarw.0), and the learning is then resumed with the new targets. The process is continuously iterated and the outputs converge on a stable classification, thereby providing unsupervised back propagation. In a further embodiment, samples classified with the trained network may serve as the training sets for additional subdivisions to grow additional layers of a hierarchical classification tree which converges to indivisible branch tips. After training is completed, such a tree may be used to classify new unlabelled samples with high efficiency. In yet another embodiment, the unsupervised back propagation method of the present invention may be adapted to classify fuzzy sets.",Method for unsupervised neural network classification with back propagation
"A method and a device for recognition of isolated words in large vocabularies are described, wherein recognition is performed through two sequential steps using neural networks and Markov models techniques, respectively, and the results of both techniques are adequately combined so as to improve recognition accuracy. The devices performing the combination also provide an evaluation of recognition reliability.",Method of and a device for speech recognition employing neural network and markov model recognition techniques
"To facilitate architecting of a multiple neural network, irrespective of the quantity of cases and the complexity of case dependence relationship, sets of input instances and the desirable outputs corresponding thereto are stored; the stored sets are read in sequence to discriminate whether all variables included in the input instances of the read set are included in the outputs of any given stored set, to mark variables not included in the outputs of any sets; the sets whose input instances include only the marked variables are selected from among the read sets; unit neural networks for learning the selected sets are formed and simultaneously variables included in the outputs of the formed unit neural networks are marked; a unit neural network for learning any given set is formed; and the formed unit neural networks are connected to each other to architect a multiple neural network.",Method of architecting multiple neural network and system therefor
A method of calibrating the selectable trip points of an overload relay wherein a neural network is used in the calibration process. The calibration method involves precisely positioning an indicia comprised of a number of graduation marks or symbols each representing a particular trip point and having a range and spacing unique to the characteristics of an overload detection circuit of a particular overload relay. The indicia is calibrated with respect to predetermined positions of a trip point indicator and fixed with respect to the predetermined positions of the trip point indicator. The range and spacing of the indicia graduations is derived from the neural networks learned trip point values and from trip point values obtained from the particular overload relay being calibrated.,Method of calibrating the trip point of an overload relay
"A method for computer-assisted determination of usage of electrical energy produced by a power generation plant such as a renewable power generation plant is provided. The method uses a plurality of neural networks having a different structure or being learned differently for calculating future energy amounts produced by a power generation plant. To do so, the energy outputs of the power generation plant forecasted by the plurality of the neural networks are used to build histograms. Based on the histograms, energy amounts for different confidence levels describing the likelihood of the availability of the energy amount are determined, and different uses are assigned to different energy amounts. Energy amounts having a higher likelihood of availability in the future are sold at higher prices than other energy amounts.","Method of computer-assisted determination of the usage of electrical energy produced by a power generation plant, particularly a renewable power generation plant"
"Computational models and calculations relating to trapped and scavenged air per cylinder (APC) improve scavenging and non-scavenging operational modes of internal combustion engines as well as the transition there-between. Data from sensors which include engine speed, manifold air pressure, barometric pressure, crankshaft position, and valve state are provided to a pair of artificial neural networks. A first neural network utilizes this data to calculate the nominal volume of gas, i.e., air trapped in the cylinder. A second neural network utilizes this data to calculate the trapping ratio. The output of the first network is utilized with the ideal gas law to calculate the actual mass of trapped APC. The actual mass of trapped APC is also divided by the trapping ratio calculated by the second network to determine the total APC and is further utilized to calculate the scavenged APC by subtracting the trapped APC from the total APC.",Method of continuously calculating trapped and scavenged air per cylinder
A method of decarburizing molten metal in the refining of steel using neural networks with a first neural network trained to analyze data representative of many process periods of one or more decarburization operations for providing an oxygen count for a preselected gas ratio of oxygen to diluent gas to cause the temperature of the molten metal bath to be decarburized to rise to a specified aim temperature and with a second neural network trained to analyze data representative of many process periods of one or more decarburization operations for providing an output schedule of oxygen counts to be injected into the bath to reduce the carbon level to a predetermined aim level in one or more successive stages corresponding to a preselected schedule of ratios of oxygen to diluent gas.,Method of decarburizing molten metal in the refining of steel using neural networks
"A process and apparatus for determining the levels in a vessel of two or more immiscible or partially-miscible components has been developed. The process begins with transmitting gamma rays, x-rays, microwaves, ultrasound waves, or sonar waves through the vessel by sequentially activating at least three stationary energy sources positioned adjacent to and in the vertical plane of the vessel. A set of intensities of the energy exiting the vessel corresponding to each energy source is measured using an array of stationary sensors where each set contains the intensity sensed by each sensor in the array of sensors. The sensors of the array are positioned in the vertical plane of the vessel and in alignment with the energy penetrating the vessel. The array of sensors contains a number of sensors that is at least one greater than the number of energy sources. The sets of intensities sensed by the array are recorded and an algorithm selected from the group consisting of partial least squares with latent variables, multiple linear regression, principal component regression, and neural networks is applied to the aggregate of the recorded sets to determine the levels of the components.",Method of determining fluid level and interface in a closed vessel
"Method for developing and adapting a system for determining the location of an object in a passenger compartment of a vehicle using a variety of transducers and pattern recognition technologies and techniques that applies to any combination of transducers that provide information about vehicle occupancy. These include weight sensors, capacitive sensors, inductive sensors, ultrasonic, optic, infrared, radar among others. The adaptation process begins with a selection of candidate transducers for a particular vehicle model based on, e.g., cost, vehicle interior passenger compartment geometry, desired accuracy and reliability, vehicle aesthetics, vehicle manufacturer preferences. Once a candidate set of transducers is selected, these transducers are mounted in the test vehicle and the vehicle is subjected to an extensive data collection process wherein various objects are placed in the vehicle at various locations and various databases are collected. A pattern recognition system is developed using the acquired data and an accuracy assessment is made. Further studies are made to determine which if any of the transducers can be eliminated from the design. The design process usually begins with a surplus of sensors plus an objective as to how many sensors are to be in the final vehicle installation. The adaptation process can determine the degree of importance of the transducers and the least important could be eliminated to reduce system cost and complexity. Various data collection techniques are utilized such as collecting data under the influence of thermal gradients and the use of neural networks to insure data quality. Other techniques used include the use of pre-processors, post-processors, modular networks, large databases and multiple databases.",Method of developing a system for identifying the presence and orientation of an object in a vehicle
"A computer simulator is provided for displaying the state of an artificial neural network in a simplified yet meaningful manner on a computer display terminal. The user may enter commands to select one or more areas of interest within the neural network for further information regarding its state of learning and operation. One display mode illustrates the output activity of each neuron as representatively sized and shaded boxes within the border of the neuron, while another display mode shows the connectivity as weighted synapses between a user-selected neuron and the remaining neurons of the network in a similar manner. A third display mode provides a tuning curve wherein the synapses associated with each of the neurons are represented within the borders of the same. Both grid block and line graph type characterization are supported. The methodology allows large neural networks on the order of thousands of neurons to be displayed in a meaningful manner.",Method of displaying the state of an artificial neural network
"A method of estimating the chromaticity of illumination of a colored image consisting of a plurality of color-encoded pixels. The image colors are first mapped into an intensity-independent chromaticity space which is then divided into a plurality of separate regions. For each region, a first binary value is assigned to the region if the region contains no chromaticity value; or, a second binary value is assigned to the region if it does contain a chromaticity value. The assigned values are then applied as inputs to a pre-trained neural network having two output ports and at least one intermediate layer containing a plurality rality of ports connectible between selected input ports and the output ports. The chromaticity space values which characterize the input image's chromaticity of illumination are then derived at the output ports. The network is pretrained trained by initially connecting an arbitrary number of the intermediate layer ports to selected input layer ports. A weight value is associated with each connection. The weight values, which have the effect of altering signals transmitted along each connection by a selected amount, are initialized with random values. Each one of a plurality of pre-stored data sets, each containing values characterizing presence or absence of color in selected regions of one of a corresponding plurality of known colored images, are sequentially presented as inputs to the network and the chromaticity space values derived at the output ports are compared with known chromaticity space values characterizing illumination of the known colored image to derive an error value representative of difference therebetween. The weight values are adjusted in response to the inputs in accordance with the well known back propagation algorithm. After the weights are adjusted the intermediate layer ports are adaptively reconnected to the input layer ports to eliminate connections to input layer ports which repeatedly receive zero value inputs. The training process continues until the error value is less than a selected threshold.",Method of estimating chromaticity of illumination using neural networks
"A fracture structure is grown from a plurality of starting points. A fractal structure, grown from respective starting points and interconnected by interactive growths, forms a neural network. A growth speed originated at a specific starting point is determined by the probability of a material reaching a grown portion from a remote location by means of a diffusion process and the probability of a growth promoting factor reaching a grown portion by means of a diffusion process from a portion grown from a starting point other than the specific one. Anisotropy is introduced into a space in which a fractal structure is to be grown, as required.",Method of fabricating a fractal structure for constructing complex neural networks
"A method of automating the calibration of lookup tables containing correction values to be used in an on-board vehicle system is disclosed. The method includes training a neural network to model engine behavior by outputting cylinder specific crankshaft acceleration correction values in response to any engine speed and load input conditions. The correction values generated are stored in a memory device. The training takes place off-board the vehicle, using a data set previously obtained from operating a representative engine under normal operating conditions.",Method of generation correction tables for misfire detection using neural networks
"A plurality of features determined from at least a portion of an image containing information about an object are processed with an inclusive neural network, and with a plurality of exclusive neural networks, so as to provide a plurality of inclusive probability values representing probabilities that the portion of the image corresponds to at least one of at least two different classes of objects, and for each exclusive neural network, so as to provide first and second exclusive probability values representing probabilities that the portion of the image respectively corresponds. or not. to at least one class of objects. The plurality of inclusive probability values, and the first and second exclusive probability values from each of the exclusive neural networks, provide for identifying whether the portion of the image corresponds, or not, to any of the at least two different classes of objects.",Method of identifying an object in a visual scene
"A method of image processing using neural networks. Images to be processed and displayed are received. Each image is divided into sections, each comprising pixels represented by color values. A neural network training procedure is executed for the sections to obtain color value tables and mapping tables. Each color value table comprises colors represented by the color values. The mapping tables record the relations between each pixel and the colors in the color value tables. The color value tables and the mapping tables are recorded in an electronic device for image display.",Method of image processing and electronic device utilizing the same
"A method for measuring tastes, which can better simulate the human gustation than known methods, as well as a taste sensor, computer program and an apparatus for measuring tastes, is disclosed. In this method, data processing is carried out by a two-phase radial basis function neural network. That is, by sensors, each of which sensors can quantify at least one component representing, individually or cooperatively, the taste of saltiness, sourness, sweetness, umami or bitterness, to obtain a response value from each sensor, and each of the obtained response values is input to a first phase radial basis function neural network to calculate the concentration of each component from each response value. Then, the concentration of each component is fed into a second phase radial basis function neural network, which correlates the concentration of each component with the intensities of saltiness, sourness, sweetness, umami and bitterness sensed by humans, to calculate the intensities of saltiness, sourness, sweetness, umami and bitterness sensed by humans.","Method of measuring taste using two phase radial basis function neural networks, a taste sensor, and a taste measuring apparatus"
"A quadrature mirror filter is applied to decompose an image into at least two sub-images each having a different resolution. These decomposed sub-images pass through self-organizing map neural networks for performing a non-supervisory classification learning. In a testing stage, the recognition process is performed from sub-images having a lower resolution. If the image can not be identified in this low resolution, the possible candidates are further recognized in a higher level of resolution.",Method of multi-level facial image recognition and system using the same
"A neural network (10) organizes the data items into a graphically oriented format by retrieving data items from a database (68) where each data item has a plurality of attributes. The neural network is organized (102) such that data items having similar attributes are assigned to neurons located closer together. The neurons of the neural network are matched (104) with the data items from the database and stored in a cross reference table. The cross reference table is displayed (106) on a computer screen (108) in a graphical format so that user visually relates the food items and sees the similarities and differences in their attribute data by the proximity of the data items to one another. The graphic format allows easy visual interpretation of the data items. For large databases, multiple neural networks (110, 112) can be organized hierarchically.",Method of organizing data into a graphically oriented format
"A method of analyzing data, particularly a speech signal, first pre-processes the signal by performing analog-to-digital conversion and cepstral analysis, producing a sequence of data frames. Then the sequence of data frames is partitioned into a plurality of data blocks. The data blocks may be subjected to further analysis, for example, by introducing them to a plurality of neural networks. The system may be implemented using either hardware or software or a combination thereof.",Method of partitioning a sequence of data frames
"A method of analyzing data, particularly a speech signal, first pre-processes the signal by performing analog-to-digital conversion and cepstral analysis, producing a sequence of data frames. Then the sequence of data frames is partitioned into a plurality of data blocks. The data blocks may be subjected to further analysis, for example, by introducing them to a plurality of neural networks. The system may be implemented using either hardware or software or a combination thereof.",Method of partitioning a sequence of data frames
"A method of processing information in an artificial neural network including a plurality of artificial neurons and weighted links coupling the neurons. In the method, those of the artificial neurons whose output values change by a value greater than a threshold value are selected. The output values of the selected neurons are calculated, and the influence which the changes in the output values of the selected neurons impose on the input values of the other artificial neurons is computed. The threshold value is changed such that an appropriate number of neurons are selected. The information processing in the artificial neural network is stopped when the threshold value decreased below a predetermined small value and the values output by all artificial neurons change by a value equal to or less than the threshold value.",Method of processing information in artificial neural networks
"A method of automatic labeling using an optimum-partitioned classified neural network includes searching for neural networks having minimum errors with respect to a number of L phoneme combinations from a number of K neural network combinations generated at an initial stage or updated, updating weights during learning of the K neural networks by K phoneme combination groups searched with the same neural networks, and composing an optimum-partitioned classified neural network combination using the K neural networks of which a total error sum has converged; and tuning a phoneme boundary of a first label file by using the phoneme combination group classification result and the optimum-partitioned classified neural network combination, and generating a final label file reflecting the tuning result.",Method of setting optimum-partitioned classified neural network and method and apparatus for automatic labeling using optimum-partitioned classified neural network
"A method of speeding up the execution of a wide class of neural networks for processing input signals evolving slowly through time, such as, for instance, voice, radar, sonar, video signals, and which requires no specialized, costly or hard-to-find hardware. The method requires storing, for the neurons in at least one level of the network, the activation value at a certain instant and comparing it with the one computed at the subsequent instant. If the activation is equal, the neuron carries out no activity, otherwise it propagates the difference in activation, multiplied by the interconnection weights, to the neurons it is connected to.",Method of speeding up the execution of neural networks for correlated signal processing
"A method, system, and computer program product of selecting a set of training images for a massive training artificial neural network (MTANN). The method comprises selecting the set of training images from a set of domain images; training the MTANN with the set of training images; applying a plurality of images from the set of domain images to the trained MTANN to obtain a corresponding plurality of scores; and determining the set of training images based on the plurality of images, the corresponding plurality of scores, and the set of training images. The method is useful for the reduction of false positives in computerized detection of abnormalities in medical images. In particular, the MTAAN can be used for the detection of lung nodules in low-dose CT (LDCT). The MTANN consists of a modified multilayer artificial neural network capable of operating on image data directly.",Method of training massive training artificial neural networks (MTANN) for the detection of abnormalities in medical images
"A method for training a hierarchy of trained neural networks for hand pose detection includes training a first neural network to generate a first plurality of activation features that classify an input depth map data corresponding to a hand based on a wrist angle of the hand, the training using a plurality of depth maps of a hand with predetermined wrist angles as inputs to the first neural network during the training, and storing the first neural network in a memory after the training for use in classifying an additional depth map corresponding to a hand based on an angle of a wrist of the hand in the additional depth map.",Method of training neural networks for hand pose detection
"A speech-recognition system for recognizing isolated words includes pre-processing circuitry for performing analog-to-digital conversion and cepstral analysis, and a plurality of neural networks which compute discriminant functions based on polynomial expansions. The system may be implemented using either hardware or software or a combination thereof. The speech wave-form of a spoken word is analyzed and converted into a sequence of data frames. The sequence of frames is partitioned into data blocks, and the data blocks are then broadcast to a plurality of neural networks. Using the data blocks, the neural networks compute polynomial expansions. The output of the neural networks is used to determine the identity of the spoken word. The neural networks utilize a matrix-inversion or alternatively a least-squares estimation training algorithm which does not require repetitive training and which yields a global minimum to each given set of training examples.",Method of training neural networks used for speech recognition
"A method is described to improve the data transfer rate between a personal computer or a host computer and a neural network implemented in hardware by merging a plurality of input patterns into a single input pattern configured to globally represent the set of input patterns. A base consolidated vector (U*n) representing the input pattern is defined to describe all the vectors (Un, . . . , Un+6) representing the input patterns derived thereof (Un, . . . , Un+6) by combining components having fixed and don't care values. The base consolidated vector is provided only once with all the components of the vectors. An artificial neural network (ANN) is then configured as a combination of sub-networks operating in parallel. In order to compute the distances with an adequate number of components, the prototypes are to include also components having a definite value and don't care conditions. During the learning phase, the consolidated vectors are stored as prototypes. During the recognition phase, when a new base consolidated vector is provided to ANN, each sub-network analyses a portion thereof After computing all the distances, they are sorted one sub-network at a time to obtain the distances associated to each vector.",Method to improve the data transfer rate between a computer and a neural network
"A method, a system and an apparatus for predicting and/or recognizing and/or classifying biological sequences, specially sequence families with binding site recognition motifs poorly conserved, comprising, advantageously, the use of neural networks rules; providing enhanced and more accurate results; and is preferably used when the biological sequence is a promoter.","Method, system and apparatus to predict and/or recognize and/or classify biological sequences"
"A method, system, and computer product is presented for mapping a set of patterns into an m-dimensional space so as to preserve relationships that may exist between these patterns. A subset of the input patterns is chosen and mapped into the m-dimensional space using an iterative nonlinear mapping process based on subset refinements. A set of n attributes are determined for each pattern, and one or more neural networks or other supervised machine learning techniques are then trained in accordance with the mapping produced by the iterative process. Additional input patterns not in the subset are mapped into the m-dimensional space by determining their n input attributes and using the neural networks in a feed-forward (prediction) mode.","Method, system, and computer program product for representing object relationships in a multidimensional space"
"A system, a method, and a computer program product for determining tactile cueing of a flight control input apparatus includes an interface for receiving observed parameters relating to the flight envelope of an aircraft. Upstream processing elements receive the observed states, convert dimensional aircraft state parameters into nondimensional aircraft state parameters, and provide the data to neural networks. The neural networks receive combinations of observed parameters and nondimensional aircraft state parameters and predict flight envelope limiting parameters. The neural networks are trained to predict the limiting parameters. A downstream processing element determines the most limiting flight envelope limiting parameter provided from the neural networks, therefore providing a tactile cueing position for a flight control input apparatus.","Method, system, and computer program product for tactile cueing flight control"
"Provided is a compiler to map application program code to object code capable of being executed on an operating system platform. A first neural network module is trained to generate characteristic output based on input information describing attributes of the application program. A second neural network module is trained to receive as input the application program code and the characteristic output and, in response, generate object code. The first and second neural network modules are used to convert the application program code to object code.","Method, system, and program for converting application program code to executable code using neural networks based on characteristics of the inputs"
"Disclosed is a system, method, and program for generating a compiler to map a code set to object code capable of being executed on an operating system platform. At least one neural network is trained to convert the code set to object code. The at least one trained neural network can then be used to convert the code set to the object code.","Method, system, and program for converting code to executable code using neural networks implemented in a software program"
"Disclosed is a method, system, and program for filtering a data object for content deemed unacceptable by a user. A data object requested by a viewer program is received. The data object is processed to determine predefined language statements. Information on the determined language statements is inputted into a neural network to produce an output value. A determination is then made as to whether the output value indicates that the data object is unacceptable. Viewer program access to the data object is inhibited upon determining that the data object is unacceptable.","Method, system, and program for filtering content using neural networks"
"A non-intrusive objective speech quality assessment is performed on a degraded speech signal. The methods are well suited for systems where random and bursty packet losses may occur and/or packet stream regeneration may also occur prior to speech signal quality assessment. In one embodiment received packetized speech is analyzed to determine to an overall final signal quality score. A limited set of trained neural networks, e.g., 5, corresponding to different signal features, each determine a signal feature quality score. A trained joint quality score determination module determines a joint quality score based on the signal feature quality scores. Packet loss is estimated based on received packet header information and/or detected gap durations. The determined joint quality score is adjusted, based on estimated packet loss information obtained from examining the speech signal, network level statistics and/or codec parameters to generate the final quality score.",Methods and apparatus for signal quality analysis
"Methods and apparatus for training a system for developing a process of data mining, false positive reduction, computer-aided detection, computer-aided diagnosis and artificial intelligence are provided. A method includes choosing a training set from a set of training cases using systematic data scaling and creating a classifier based on the training set using a classification method. The classifier yields fewer false positives. The method is suitable for use with a variety of data mining techniques including support vector machines, neural networks and decision trees.",Methods and apparatus to integrate systematic data scaling into genetic algorithm-based feature subset selection
A method for analyzing images to generate a plurality of output features includes receiving input features of the image and performing Fourier transforms on each input feature. Kernels having coefficients of a plurality of trained features are received and on-the-fly Fourier transforms (OTF-FTs) are performed on the coefficients in the kernels. The output of each Fourier transform and each OTF-FT are multiplied together to generate a plurality of products and each of the products are added to produce one sum for each output feature. Two-dimensional inverse Fourier transforms are performed on each sum.,Methods and systems for analyzing images in convolutional neural networks
A method for analyzing images to generate a plurality of output features includes receiving input features of the image and performing Fourier transforms on each input feature. Kernels having coefficients of a plurality of trained features are received and on-the-fly Fourier transforms (OTF-FTs) are performed on the coefficients in the kernels. The output of each Fourier transform and each OTF-FT are multiplied together to generate a plurality of products and each of the products are added to produce one sum for each output feature. Two-dimensional inverse Fourier transforms are performed on each sum.,Methods and systems for analyzing images in convolutional neural networks
"Methods, systems and apparatus that provide for perceptual, cognitive, and motor behaviors in an integrated system implemented using neural architectures. Components of the system communicate using artificial neurons that implement neural networks. The connections between these networks form representationsreferred to as semantic pointerswhich model the various firing patterns of biological neural network connections. Semantic pointers can be thought of as elements of a neural vector space, and can implement a form of abstraction level filtering or compression, in which high-dimensional structures can be abstracted one or more times thereby reducing the number of dimensions needed to represent a particular structure.",Methods and systems for artificial cognition
A system extracting features from a time-varying signal comprising a computer processor and a computer readable medium having computer executable instructions for providing: a bank of bandpass filters; a module approximating the output of those filters with nonlinear components; a module representing a decorrelated projection of the output of the filters with nonlinear components; and a module representing the temporal derivative of the decorrelated information with nonlinear components.,Methods and systems for extracting auditory features with neural networks
Internet routers are a key component in today's Internet. Each router forwards received packets toward their final destinations based upon a Longest Prefix Matching (LPM) algorithm select an entry from a routing table that determines the closest location to the final packet destination among several candidates. Prior art solutions to LPM lookup offer different tradeoffs and that it would be beneficial for a design methodology that provides for low power large scale IP lookup engines addressing the limitations within the prior art. According to embodiments of the invention a low-power large-scale IP lookup engine may be implemented exploiting clustered neural networks (CNNs). In addition to reduced power consumption embodiments of the invention provide reduced transistor count providing for reduced semiconductor die footprints and hence reduced die cost.,Methods and systems for network address lookup engines
"A method of forming semiconductor elements in an artificial neural network, the method including forming a substrate including an oxide layer, forming a Silicon layer on the oxide layer, depositing a thin film dopant layer on the Silicon layer, and controlling a concentration of the dopant in the thin film dopant layer.",Methods for fabricating artificial neural networks (ANN) based on doped semiconductor elements
"A system configured to reconstruct audio signals. The system may identify missing audio samples due to packet loss or detect distortion caused by audio clipping and may reconstruct the audio data. The system may employ a forward-looking neural network that recursively predicts audio samples based on previous audio samples and/or a backward-looking neural network that recursively predicts audio samples based on subsequent audio samples. The system may generate audio data using only the forward-looking neural network for low latency applications or may generate audio data using both neural networks for mid to high latency applications. To reduce distortion in output audio data, the system may generate the audio data by cross-fading between outputs of the neural networks and/or may cross-fade between the generated audio data and the input audio data.",Methods for reconstructing an audio signal
"Methods are provided for developing medical diagnostic tests using decision-support systems, such as neural networks. Patient data or information, typically patient history or clinical data, are analyzed by the decision-support systems to identify important or relevant variables and decision-support systems are trained on the patient data. Patient data are augmented by biochemical test data, or results, where available, to refine performance. The resulting decision-support systems are employed to evaluate specific observation values and test results, to guide the development of biochemical or other diagnostic tests, too assess a course of treatment, to identify new diagnostic tests and disease markers, to identify useful therapies, and to provide the decision-support functionality for the test. Methods for identification of important input variables for a medical diagnostic tests for use in training the decision-support systems to guide the development of the tests, for improving the sensitivity and specificity of such tests, and for selecting diagnostic tests that improve overall diagnosis of, or potential for, a disease state and that permit the effectiveness of a selected therapeutic protocol to be assessed are provided. The methods for identification can be applied in any field in which statistics are used to determine outcomes. A method for evaluating the effectiveness of any given diagnostic test is also provided.","Methods for selecting, developing and improving diagnostic tests for pregnancy-related conditions"
"Decision-support systems, such as neural networks, for assessing the risk of delivery within a predetermined time or the likelihood of preterm delivery are provided.","Methods for selecting, developing and improving diagnostic tests for pregnancy-related conditions"
"The present invention relates to implementing a system and method to improve speech recognition and speech enhancement of noisy speech. The present invention discloses a way to improve the noise robustness of a speech recognition system by providing additional input to a Neural Network speech classifier. The additional information characterizes the noise environment of the speech. The present invention further discloses a speech separation system that uses the output of the neural network. The speech separation system employs models for the speech and for the distractor or noise. The neural network is used to identify the most likely combinations of speech and noise. Furthermore, a system for efficiently finding the most likely clean speech log-spectrum value is disclosed.",Methods for speech enhancement and speech recognition using neural networks
"The present disclosure provides methods for applying artificial neural networks to flow cytometry data generated from biological samples to diagnose and characterize cancer in a subject. The disclosure also provides methods of training, testing, and validating artificial neural networks.",Methods for using artificial neural network analysis on flow cytometry data for cancer diagnosis
The present disclosure provides methods for applying artificial neural networks to flow cytometry data generated from biological samples to diagnose and characterize cancer in a subject.,Methods for using artificial neural network analysis on flow cytometry data for cancer diagnosis
"A method for testing a neural network, and apparatus for carrying out the method. A first embodiment of the method includes the steps of (a) providing a neural network having a set of connection values, (b) stimulating at least one input of the neural network with an input vector to obtain output signals at an output of the neural network, (c) obtaining a plurality of samples of the output signals, wherein at least one of the plurality of samples is delayed in time from another one of the samples, and wherein at least one of the plurality of samples may represent a difference between two samples, (d) generating an image from the plurality of samples, and (e) comparing the image to a reference image to determine an operational characteristic of the neural network. The step of generating generates an image that is comprised of a plurality of points, wherein each of the points is referenced to an x-y coordinate system, wherein a distance along the x-axis is a function of a value of the output of the neural network for a given input vector applied to a first input of the neural network, and wherein a distance along the y-axis is function of a value of the output of the neural network for the given input vector applied a second input of the neural network.",Metrics for specifying and/or testing neural networks
"Microprocessor assemblies are disclosed, which include a plurality of preprogrammed, cellular automaton microprocessors, a common radiant energy data waveguide into which said microprocessors can emit and from which said microprocessors can absorb modulated radiant energy signals, and a power supply radiant energy waveguide. Means are provided for each microprocessor to demodulate the absorbed signal and to modulate the emitted signal according to codes assigned to each said microprocessor. The common data waveguide provides for exchange of signals among the plurality of microprocessors. The relative degree of communication between two given microprocessors is determined by the degree to which the respective codes match. Said codes are subject to change. The change is determined by the demodulated inputs of the microprocessors. Means are provided for selective activation and deactivation of microprocessors through selective activation power supply. Changeability of the codes and the selective power supply provide for the means to induce a wide range of the desired patterns of connectivity and the desired degree of connectivity among the plurality of the microprocessors. There are also disclosed methods for making such microprocessor assemblies.",Microprocessor assemblies forming adaptive neural networks
"A hybrid router for dynamical control systems is described. The mobile hybrid software router (MHSR) combines distinctive computational and mathematical techniques, including evolutionary computation (EC), probabilistic simulations (PS), machine learning and artificial neural networks (A-NNs), in order to solve unique problems encountered in an unknown environment in real time. Embodied in intelligent mobile software agents (IMSAs), the MHSR operates within a multi-agent system (MAS) to continually optimize system operation. The MHSR is applied to several major complex system categories. In one embodiment of the system, the MHSR is implemented in hardware, including continuously programmable field programmable gate arrays (CP-FPGAs), for perpetually reconfigurable evolvable hardware operation. Whether in application-specific or multi-functional mode, the MHSR is useful to groups of agents in intelligent systems for adaptation to uncertain environments in order to perform self-organization capabilities.",Mobile hybrid software router
"Mobile phones and methods for mobile phone failure prediction include receiving respective log files from one or more mobile phone components, including at least one user application. The log files have heterogeneous formats. A likelihood of failure of one or more mobile phone components is determined based on the received log files by clustering the plurality of log files according to structural log patterns and determining feature representations of the log files based on the log clusters. A user is alerted to a potential failure if the likelihood of component failure exceeds a first threshold. An automatic system control action is performed if the likelihood of component failure exceeds a second threshold.",Mobile phone with system failure prediction using long short-term memory neural networks
"A system for determining the location of a mobile station based upon measurable mobile data values such as those provided by mobile-assisted handoff (MAHO) procedures. The mobile stations make signal strength measurements of nearby base stations and return that information to the serving base station. A timing advance necessary to synchronize the mobile may also be determined. The signal strength measurements and the timing advance data then provide information to map to an estimated vehicle location. Since the mobiles are assumed to measure signal strength discretely, there may be several consecutive positions along a road which return identical mobile data. The road is thus segmented into constant segements which are consecutively indexed, and an association is established between the associated mobile data vector and the index. The process for location of a mobile consists of first finding the road for the mobile unit, then finding the position along the road. The mobile vector is sequentially input into a look up table or neural networks (one for each road in the sector) until an output coordinate pair actually lies near the corresponding road. From that point on, the input vector provides an index to a constant region along the road, so the mobile is unambiguously located as to which road, and to which segment along the road it occupies.",Mobile telephone location process making use of handoff data
"A method and system for locating a mobile user of one or more mobile users while on a call in a wireless telecommunication network utilizes a decision network that determines if the call signal is propagating through a repeater station. When the call is propagating through a repeater station, the decision network alters the signal measurement parameters to correspond with the location of the mobile user relative to the repeater station co-ordinates. By revising signal measurement parameters to compensate for repeater stations, the present invention provides for improved position estimates of the location of the mobile user in the network. For multiple cell soft handoff conditions, the decision network utilizes trained neural networks.",Mobile user position locating system
"The model adaptation system of the present invention is a speaker verification system that embodies the capability to adapt models learned during the enrollment component to track aging of a user's voice. The system has the advantage of only requiring a single enrollment for the user. The model adaptation system and methods can be applied to several types of speaker recognition models including neural tree networks (NTN), Gaussian Mixture Models (GMMs), and dynamic time warping (DTW) or to multiple models (i.e., combinations of NTNs, GMMs and DTW). Moreover, the present invention can be applied to text-dependent or text-independent systems.",Model adaptation of neural tree networks and other fused models for speaker verification
"A method includes receiving an input data set, each entry including multiple features. The method includes receiving a user input identifying a target feature of the multiple features and a target value of the target feature. The method includes determining, one or more correlated features of the multiple features. The method includes providing the input data set to multiple neural networks (including multiple VAEs) to train the multiple neural networks. The method includes generating a simulated data set based on the input data set, each entry including at least the target feature and the one or more correlated features. Values of the one or more correlated features are randomized or pseudorandomized and the target feature is fixed at the target value. The method includes providing the simulated data set to the multiple neural networks to generate output data and displaying a GUI based on the output data.",Model building for simulation of one or more target features
"A novel 3-Input-3-Output (33) Model-Free Adaptive (MFA) controller with a set of artificial neural networks as part of the controller is introduced. A 33 MFA control system using the inventive 33 MFA controller is described to control key process variables including Power, Steam Throttle Pressure, and Steam Temperature of boiler-turbine-generator (BTG) units in conventional and advanced power plants. Those advanced power plants may comprise Once-Through Supercritical (OTSC) Boilers, Circulating Fluidized-Bed (CFB) Boilers, and Once-Through Supercritical Circulating Fluidized-Bed (OTSC CFB) Boilers.",Model-free adaptive control of advanced power plants
"Behavior of an electrical circuit can be modeled using a trained neural network. For example, using one or more neural networks, power consumption, including leakage power and switching energy, can be estimated. Also, a profile of current versus time can be generated for the electrical circuit. A hierarchy of neural networks may be used to model the circuit at different levels. In one embodiment, a circuit behavior is modeled using one or more neural networks, cluster values, and cluster probabilities.",Modeling behavior of an electrical circuit
"An Interestingness Modeler uses deep neural networks to learn deep semantic models (DSM) of interestingness. The DSM, consisting of two branches of deep neural networks or their convolutional versions, identifies and predicts target documents that would interest users reading source documents. The learned model observes, identifies, and detects naturally occurring signals of interestingness in click transitions between source and target documents derived from web browser logs. Interestingness is modeled with deep neural networks that map source-target document pairs to feature vectors in a latent space, trained on document transitions in view of a context and optional focus of source and target documents. Network parameters are learned to minimize distances between source documents and their corresponding interesting targets in that space. The resulting interestingness model has applicable uses, including, but not limited to, contextual entity searches, automatic text highlighting, prefetching documents of likely interest, automated content recommendation, automated advertisement placement, etc.",Modeling interestingness with deep neural networks
"In one embodiment of the present invention, a loudspeaker modeling subsystem configures a neural lumped parameter loudspeaker (NeLP) model to represent the behavior of a loudspeaker. The NeLP model is implemented as a cascaded combination of a lumped parameter model (LPM) and a neural network (NN) model. To configure the model, the loudspeaker modeling subsystem first estimates values for the parameters used in the LPM. The loudspeaker modeling subsystem then fixes these parameters and trains the NN model to act on a predicted output pressure that is generated via the LPM. More specifically, the loudspeaker modeling subsystem configures the NN to modify the predicted output pressure to minimize the error between the predicted output pressure and a measured loudspeaker output pressure. Notably, by strategically fusing the LPM and the NN model, the NeLP model leverages the strengths and mitigates the weaknesses typically associated with conventional loudspeaker modeling techniques.",Modeling loudspeakers based on cascading lumped parameter models with neural networks
"Computation-intensive applications such as sensor signal processing, sensor fusion, image processing, feature identification, pattern recognition, and early vision place stringent requirements on the computational capacity, size, weight, and power dissipation of modular computational systems intended for both embedded and high performance computer environments. Such ultra high speed, ultra high density computational modules will typically be configured with multiple processor, memory, dedicated sensor, and digital signal processing chips in close-packed multichip modules. The present invention relates to a novel architecture and associated apparatus for the development of highly multiplexed photonic interconnections between pairs of such electronic chips incorporated in vertical stacks within three-dimensional multichip module configurations. Vertical signal transmission through the chip substrates is accomplished by using a planar-waveguide-based optical power bus to provide a parallel array of beams to read out a modulator array that is flip-chip bonded to each silicon substrate. Local and quasi-local connectivity in the vertical dimension is accomplished by using diffractive optical structures that provide for both point-to-point interconnections and weighted fan-out within a local neighborhood. Global connectivity is incorporated by means of computer-generated volume holographic optical elements that are fabricated as a multilayer diffractive optical element. Several different architectural implementations of such computational modules are provided to address applications that include high-bandwidth two-dimensional displays, multilayer neural networks, image processors, multiple processors with access to shared memory, and rending engines for computer animation and graphics. In addition, subsystems of the computational-module architecture and apparatus are described that provide for compact optical readout of modulator-based flat panel displays.",Modulator-based photonic chip-to-chip interconnections for dense three-dimensional multichip module integration
"A machine learning paradigm called Graph Transformer Networks extends the applicability of gradient-based learning algorithms to systems composed of modules that take graphs as inputs and produce graphs as output. Training is performed by computing gradients of a global objective function with respect to all the parameters in the system using a kind of back-propagation procedure. A complete check reading system based on these concept is described. The system uses convolutional neural network character recognizers, combined with global training techniques to provides record accuracy on business and personal checks.",Module for constructing trainable modular network in which each module inputs and outputs data structured as a graph
"A method for configuring nanoscale neural network circuits using molecular-junction-nanowire crossbars, and nanoscale neural networks produced by this method. Summing of weighted inputs within a neural-network node is implemented using variable-resistance resistors selectively configured at molecular-junction-nanowire-crossbar junctions. Thresholding functions for neural network nodes are implemented using pFET and nFET components selectively configured at molecular-junction-nanowire-crossbar junctions to provide an inverter. The output of one level of neural network nodes is directed, through selectively configured connections, to the resistor elements of a second level of neural network nodes via circuits created in the molecular-junction-nanowire crossbar. An arbitrary number of inputs, outputs, neural network node levels, nodes, weighting functions, and thresholding functions for any desired neural network are readily obtained by the methods of the present invention.",Molecular-junction-nanowire-crossbar-based neural network
"A system (10) for monitoring and controlling a fabrication process includes at least a first subsystem (12), a crystallographic analysis subsystem (14), and a second subsystem (16), wherein the first subsystem and second subsystem perform respective fabrication steps on a workpiece. The crystallographic analysis subsystem may be coupled to both the first subsystem and second subsystem. The analysis subsystem acquires crystallographic information from the workpiece after the workpiece undergoes a fabrication step by the first subsystem and then provides information, based on the crystallographic information acquired, for modifying parameters associated with the respective fabrication steps. The system may also include neural networks (24, 28) to adaptively modify, based on historical process data (32), parameters provided to the respective fabrication steps. The analysis subsystem may include a electromagnetic source (61), a detector (66), a processor (67), a controller (68) and a scanning actuator (65).",Monitoring and control of a fabrication process
"A method of managing the processing of information using a first neural network, the information relating to the transmission of messages in a telecommunications network, uses the steps of: PA1 (i) monitoring the performance of the first neural network in processing the information; PA1 (ii) creating a second neural network of the same topology as the first when a predetermined performance threshold is reached, and PA1 (iii) retraining the second neural network while continuing to process the information using the first neural network. If the neural networks are implemented using objects, such retraining can be facilitated by using a persistance mechanism to enable the objects to be stored and moved. Applications in fraud detection.",Monitoring and retraining neural network
A method for generating an event includes monitoring a first neural network with a second neural network. The method also includes generating an event based on the monitoring. The event is generated at the second neural network. The event may be generated based on a spike received at the second network during the monitoring.,Monitoring neural networks with shadow networks
""" A monocrystalline monolith contains a 3-D array of interconnected lattice-matched devices (which may be of one kind exclusively, or that kind in combination with one or more other kinds) performing digital, analog, image-processing, or neural-network functions, singly or in combination. Localized inclusions of lattice-matched metal and (or) insulator can exist in the monolith, but monolith-wide layers of insulator are avoided. The devices may be self-isolated, junction-isolated, or insulator-isolated, and may include but not be limited to MOSFETs, BJTs, JFETs, MFETs, CCDs, resistors, and capacitors. The monolith is fabricated in a single apparatus using a process such as MBE or sputter epitaxy executed in a continuous or quasicontinuous manner under automatic control, and supplanting hundreds of discrete steps with handling and storage steps interpolated. """"Writing"""" on the growing crystal is done during crystal growth by methods that may include but not be limited to ion beams, laser beams, patterned light exposures, and physical masks. The interior volume of the fabrication apparatus is far cleaner and more highly controlled than that of a clean room. The apparatus is highly replicated and is amenable to mass production. The product has unprecedented volumetric function density, and high performance stems from short signal paths, low parasitic loading, and 3-D architecture. High reliability stems from contamination-free fabrication, small signal-arrival skew, and generous noise margins. Economy stems from mass-produced factory apparatus, automatic IC manufacture, and high IC yield. Among the IC products are fast and efficient memories with equally fast and efficient error-correction abilities, crosstalk-free operational amplifiers, and highly paralleled and copiously interconnected neural networks. """,Monocrystalline three-dimensional integrated circuit
""" A monocrystalline monolith contains a 3-D array of interconnected lattice-matched devices (which may be of one kind exclusively, or that kind in combination with one or more other kinds) performing digital, analog, image-processing, or neural-network functions, singly or in combination. Localized inclusions of lattice-matched metal and (or) insulator can exist in the monolith, but monolith-wide layers of insulator are avoided. The devices may be self-isolated, junction-isolated, or insulator-isolated, and may include but not be limited to MOSFETs, BJTs, JFETs, MFETs, CCDs, resistors, and capacitors. The monolith is fabricated in a single apparatus using a process such as MBE or sputter epitaxy executed in a continuous or quasicontinuous manner under automatic control, and supplanting hundreds of discrete steps with handling and storage steps interpolated. """"Writing"""" on the growing crystal is done during crystal growth by methods that may include but not be limited to ion beams, laser beams, patterned light exposures, and physical masks. The interior volume of the fabrication apparatus is far cleaner and more highly controlled than that of a clean room. The apparatus is highly, replicated and is amenable to mass production. The product has unprecedented volumetric function density, and high performance stems from short signal paths, low parasitic loading, and 3-D architecture. High reliability stems from contamination-free fabrication, small signal-arrival skew, and generous noise margins. Economy stems from mass-produced factory apparatus, automatic IC manufacture, and high IC yield. Among the IC products are fast and efficient memories with equally fast and efficient error-correction abilities, crosstalk-free operational amplifiers, and highly paralleled and copiously interconnected neural networks. """,Monocrystalline three-dimensional integrated circuit
"Methods of recognizing motions of an object in a video clip or an image sequence are disclosed. A plurality of frames are selected out of a video clip or an image sequence of interest. A text category is associated with each frame by applying an image classification technique with a trained deep-learning model for a set of categories containing various poses of an object within each frame. A super-character is formed by embedding respective text categories of the frames as corresponding ideograms in a 2-D symbol having multiple ideograms contained therein. Particular motion of the object is recognized by obtaining the meaning of the super-character with image classification of the 2-D symbol via a trained convolutional neural networks model for various motions of the object derived from specific sequential combinations of text categories. Ideograms may contain imagery data instead of text categories, e.g., detailed images or reduced-size images.",Motion recognition via a two-dimensional symbol having multiple ideograms contained therein
"Methods of recognizing motions of an object in a video clip or an image sequence are disclosed. A plurality of frames are selected out of a video clip or an image sequence of interest. A text category is associated with each frame by applying an image classification technique with a trained deep-learning model for a set of categories containing various poses of an object within each frame. A super-character is formed by embedding respective text categories of the frames as corresponding ideograms in a 2-D symbol having multiple ideograms contained therein. Particular motion of the object is recognized by obtaining the meaning of the super-character with image classification of the 2-D symbol via a trained convolutional neural networks model for various motions of the object derived from specific sequential combinations of text categories. Ideograms may contain imagery data instead of text categories, e.g., detailed images or reduced-size images.",Motion recognition via a two-dimensional symbol having multiple ideograms contained therein
"Methods of recognizing motions of an object in a video clip or an image sequence are disclosed. A plurality of frames are selected out of a video clip or an image sequence of interest. A text category is associated with each frame by applying an image classification technique with a trained deep-learning model for a set of categories containing various poses of an object within each frame. A super-character is formed by embedding respective text categories of the frames as corresponding ideograms in a 2-D symbol having multiple ideograms contained therein. Particular motion of the object is recognized by obtaining the meaning of the super-character with image classification of the 2-D symbol via a trained convolutional neural networks model for various motions of the object derived from specific sequential combinations of text categories. Ideograms may contain imagery data instead of text categories, e.g., detailed images or reduced-size images.",Motion recognition via a two-dimensional symbol having multiple ideograms contained therein
"The method disclosed receives a data stream from an MWD system and determines the response of a specific energy (SE) relationship and a rate of penetration (ROP) relationship respectively to variables controllable by the operator, in order to enable operation at a lowest SE, or a highest Rate-of-Penetration (ROP) to SE ratio. The method utilizes artificial neural networks trained by MWD data to deduce a depth-of-cut and torque based on relationships manifesting between the various data points collected, and an SE equation and a predicted ROP is evaluated over a series of probable operating points. The method continuously gathers and analyzes MWD data during the drilling operation and allows an operator to manage the controllable parameters such that operation at the lowest SE or highest ROP or ROP to SE ratio can be achieved during the drilling operation.",MSE based drilling optimization using neural network simulaton
"An air data sensing probe or MFP includes a barrel having multiple pressure sensing ports for sensing multiple pressures. Instrumentation coupled to the pressure sensing ports provides electrical signals related to the multiple pressures. A neural network, coupled to the instrumentation, receives as inputs the electrical signals related to the multiple pressures, and in response, the neural network provides, as an output, electrical signals indicative of at least one local air data parameter for the air data sensing probe.",Multi-function air data probes employing neural networks for determining local air data parameters
"A method for extracting features from cardiac acoustic signals includes the steps of obtaining a cardiac acoustic signal, and extracting physiologically significant features from the cardiac acoustic signal using a neural network. A method for evaluating cardiac acoustic signals includes the steps of obtaining a cardiac acoustic signal, analyzing the cardiac acoustic signal with a wavelet decomposition to extract time-frequency information, and identifying basic heart sounds using neural networks applied to the extracted time-frequency information. A method for determining cardiac event sequences from cardiac acoustic signals includes the steps of obtaining a cardiac acoustic signal, and processing a sequence of features extracted from the cardiac acoustic signal by a probabilistic finite-state automaton to determine a most probable sequence of cardiac events given the cardiac acoustic signal. A method for extracting findings from cardiac acoustic signals includes the steps of obtaining a cardiac acoustic signal, processing the cardiac acoustic signal to determine a most probable sequence of cardiac events given the cardiac acoustic signal, and extracting the clinical findings from the sequence of cardiac events. A method for determining a status of heart murmurs includes the steps of obtaining a cardiac acoustic signal, detecting a murmur, if any, from the cardiac acoustic signal, and determining whether the murmur is one of functional and pathological based upon expert rules.",Multi-modal cardiac diagnostic decision support system and method
"A method for extracting and evaluating features from cardiac acoustic signals includes the steps of obtaining a cardiac acoustic signal, extracting physiologically significant features from the cardiac acoustic signal using a neural network, analyzing the cardiac acoustic signal with a wavelist decomposition to extract time-frequency information, and identifying basic heart sounds using neutral networks applied to the extracted time-frequency information. A method for determining a status of heart murmurs includes the steps of obtaining a cardiac acoustic signal, detecting a murmur, if any, from the cardiac acoustic signal, and determining whether the murmur is one of functional and pathological based upon expert rules.",Multi-modal cardiac diagnostic decision support system and method
"Disclosed herein are devices, systems, and methods for detecting the presence and orientation of traffic lane markings. Deep convolutional neural networks are used with convolutional layers and max-pooling layers to generate fully connected nodes. After the convolutional and max-pooling layers, two sublayers are applied, one to determine presence and one to determine geometry. The presence of a lane marking segment as detected by the first sublayer can serve as a gate for the second sublayer by regulating the credit assignment for training the network. Only when the first sublayer predicts actual presence will the geometric layout of the lane marking segment contribute to the training of the overall network. This achieves advantages with respect to accuracy and efficiency and contributes to efficient robust model selection.",Multi-task deep convolutional neural networks for efficient and robust traffic lane detection
"A system configured to improve beamforming by using deep neural networks (DNNs). The system can use one trained DNN to focus on a first person speaking an utterance (e.g., target user) and one or more trained DNNs to focus on noise source(s) (e.g., wireless loudspeaker(s), a second person speaking, other localized sources of noise, or the like). The DNNs may generate time-frequency mask data that indicates individual frequency bands that correspond to the particular source detected by the DNN. Using this mask data, a beamformer can generate beamformed audio data that is specific to a source of noise. The system may perform noise cancellation to isolate first beamformed audio data associated with the target user by removing second beamformed audio data associated with noise source(s).",Multichannel noise cancellation using deep neural network masking
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using neural networks. One of the methods includes receiving, by a neural network in a speech recognition system, first data representing a first raw audio signal and second data representing a second raw audio signal, the first raw audio signal and the second raw audio signal for the same period of time, generating, by a spatial filtering convolutional layer in the neural network, a spatial filtered output the first data and the second data, generating, by a spectral filtering convolutional layer in the neural network, a spectral filtered output using the spatial filtered output, and processing, by one or more additional layers in the neural network, the spectral filtered output to predict sub-word units encoded in both the first raw audio signal and the second raw audio signal.",Multichannel raw-waveform neural networks
"A method for and system for training a connection network located between neuron layers within a multi-layer physical neural network. A multi-layer physical neural network can be formed having a plurality of inputs and a plurality outputs thereof, wherein the multi-layer physical neural network comprises a plurality of layers, wherein each layer comprises one or more connection networks and associated neurons. Thereafter, a training wave can be initiated across the connection networks associated with an initial layer of the multi-layer physical neural network which propagates thereafter through succeeding connection networks of succeeding layers of the neural network by successively closing and opening switches associated with each layer. One or more feedback signals thereof can be automatically provided to strengthen or weaken nanoconnections associated with each connection network.",Multilayer training in a physical neural network formed utilizing nanotechnology
"Methods and systems for processing multilingual DNN acoustic models are described. An example method may include receiving training data that includes a respective training data set for each of two or more or languages. A multilingual deep neural network (DNN) acoustic model may be processed based on the training data. The multilingual DNN acoustic model may include a feedforward neural network having multiple layers of one or more nodes. Each node of a given layer may connect with a respective weight to each node of a subsequent layer, and the multiple layers of one or more nodes may include one or more shared hidden layers of nodes and a language-specific output layer of nodes corresponding to each of the two or more languages. Additionally, weights associated with the multiple layers of one or more nodes of the processed multilingual DNN acoustic model may be stored in a database.","Multilingual, acoustic deep neural networks"
"A neuronal network analysis plate having alternating rows of recording wells and amplifying wells. The recording wells contain a neural cell network and a series of electrodes for recording the action potential signals of the neurons. The electrodes are connected to amplifiers in adjacent amplifying wells. The close proximity of these amplifiers ideal because it permits the parallel, non-multiplexed recording of action potential signals from multiple different active nerve cell networks. The amplifiers in the amplifying wells can then be connected to external amplification equipment. The neuronal network analysis plate may be contained within a single commercially available 24 or 96 well plate. The neuronal network analysis plate can be used to detect and quantify pharmacological and toxicological responses of the neural cells to one or more agents in vitro.",Multinetwork nerve cell assay platform with parallel recording capability
"A multiphase flow meter used in conjunction with an electrical submersible pump system in a well bore includes sensors to determine and transmit well bore pressure measurements, including tubing and down hole pressure measurements. The multiphase flow meter also includes at least one artificial neural network device to be used for outputting flow characteristics of the well bore. The artificial neural network device is trained to output tubing and downhole flow characteristics responsive to multiphase-flow pressure gradient calculations and pump and reservoir models, combined with standard down-hole pressure, tubing surface pressure readings, and the frequency applied to the electrical submersible pump motor.",Multiphase flow meter for electrical submersible pumps using artificial neural networks
"The present embodiments relate to detecting multiple landmarks in medical images. By way of introduction, the present embodiments described below include apparatuses and methods for detecting landmarks using hierarchical feature learning with end-to-end training. Multiple neural networks are provided with convolutional layers for extracting features from medical images and with a convolutional layer for learning spatial relationships between the extracted features. Each neural network is trained to detect different landmarks using a different resolution of the medical images, and the convolutional layers of each neural network are trained together with end-to-end training to learn appearance and spatial configuration simultaneously. The trained neural networks detect multiple landmarks in a test image iteratively by detecting landmarks at different resolutions, using landmarks detected a lesser resolutions to detect additional landmarks at higher resolutions.",Multiple landmark detection in medical images based on hierarchical feature learning and end-to-end training
An improved analog-to digital converter employs multiple sample and hold circuits to simultaneously supply multiple neural network A/D converters with samples of an analog input voltage so that the neural networks may simultaneously perform conversion of the different samples into a lower-order portion of the digital signals. A single fast A/D converter converts each sample into a higher-order portion of each digital signal.,Multiple neural network analog to digital converter for simultaneously processing multiple samples
A multistage neural network system can store neural networks as shader programs on GPU memory. Neural network weights can be stored as shader objects or textures on the GPU memory. The GPU can receive a number of neural network image processing tasks to perform on images captured by a client device. The GPU can execute the tasks per driver parameters and display results in real time or near real time on the client device.,Multistage neural network processing using a graphics processor
"A method and a system for generating a target character sequence from a semantic representation including a sequence of characters are provided. The method includes adapting a target background model, built from a vocabulary of words, to form an adapted background model. The adapted background model accepts subsequences of an input semantic representation as well as words from the vocabulary. The input semantic representation is represented as a sequence of character embeddings, which are input to an encoder. The encoder encodes each of the character embeddings to generate a respective character representation. A decoder then generates a target sequence of characters, based on the set of character representations. At a plurality of time steps, a next character in the target sequence is selected as a function of a previously generated character(s) of the target sequence and the adapted background model.",Natural language generation through character-based recurrent neural networks with finite-state prior knowledge
"A string of natural language texts is received and formed a multi-layer 2-D symbol in a computing system. The 2-D symbol comprises a matrix of NN pixels of K-bit data representing a super-character. The matrix is divided into MM sub-matrices with each sub-matrix containing (N/M)(N/M) pixels. K, N and M are positive integers, and N is preferably a multiple of M. Each sub-matrix represents one ideogram defined in an ideogram collection set. Super-character represents a meaning formed from a specific combination of a plurality of ideograms. The meaning of the super-character is learned by classifying the 2-D symbol via a trained convolutional neural networks model having bi-valued 33 filter kernels in a Cellular Neural Networks or Cellular Nonlinear Networks (CNN) based integrated circuit.",Natural language processing using a CNN based integrated circuit
"Natural language translation device contains a bus, an input interface connecting to the bus for receiving a source sentence in a first natural language to be translated to a target sentence in second natural language one word at a time in sequential order. A two-dimensional (2-D) symbol containing a super-character characterizing the i-th word of the target sentence based on the received source sentence is formed in accordance with a set of 2-D symbol creation rules. The i-th word of the target sentence is obtained by classifying the 2-D symbol via a deep learning model that contains multiple ordered convolution layers in a Cellular Neural Networks or Cellular Nonlinear Networks (CNN) based integrated circuit.",Natural language translation device
"A network architecture for the programmable emulation of large artificial neural networks ANN having digital operation employs a plurality L of neuron units of identical structure, each equipped with m neurons, the inputs (E) thereof being connected to network inputs (E.sub.N) multiplied or branching via individual input registers (REG.sub.E). The outputs (A) of the neuron units are connectable to network outputs (A.sub.N) at different points in time via individual multiplexers (MUX) and individual output registers (REG.sub.A) and the neuron units have individual auxiliary inputs via which signals can be supplied to them that represent weighting values (W) for weighting the appertaining neural connections and represent thresholds (0) for weighting input signals.",Network architecture for the programmable emulation of artificial neural networks having digital operation
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for determining neural network architectures. One of the methods includes generating, using a controller neural network having controller parameters and in accordance with current values of the controller parameters, a batch of output sequences. The method includes, for each output sequence in the batch: generating an instance of a child convolutional neural network (CNN) that includes multiple instances of a first convolutional cell having an architecture defined by the output sequence; training the instance of the child CNN to perform an image processing task; and evaluating a performance of the trained instance of the child CNN on the task to determine a performance metric for the trained instance of the child CNN; and using the performance metrics for the trained instances of the child CNN to adjust current values of the controller parameters of the controller neural network.",Neural architecture search for convolutional neural networks
"The neural semiconductor chip first includes: a global register and control logic circuit block, a R/W memory block and a plurality of neurons fed by buses transporting data such as the input vector data, set-up parameters, etc., and signals such as the feed back and control signals. The R/W memory block, typically a RAM, is common to all neurons to avoid circuit duplication, increasing thereby the number of neurons integrated in the chip. The R/W memory stores the prototype components. Each neuron comprises a computation block, a register block, an evaluation block and a daisy chain block to chain the neurons. All these blocks (except the computation block) have a symmetric structure and are designed so that each neuron may operate in a dual manner, i.e. either as a single neuron (single mode) or as two independent neurons (dual mode). Each neuron generates local signals. The neural chip further includes an OR circuit which performs an OR function for all corresponding local signals to generate global signals that are merged in an on-chip common communication bus shared by all neurons of the chip. The R/W memory block, the neurons and the OR circuit form an artificial neural network having high flexibility due to this dual mode feature which allows to mix single and dual neurons in the ANN.",Neural chip architecture and neural networks incorporated therein
"Two neural networks are used to control adaptively a vibration and noise-producing plant. The first neural network, the emulator, models the complex, nonlinear output of the plant with respect to certain controls and stimuli applied to the plant. The second neural network, the controller, calculates a control signal which affects the vibration and noise producing characteristics of the plant. By using the emulator model to calculate the nonlinear plant gradient, the controller matrix coefficients can be adapted by backpropagation of the plant gradient to produce a control signal which results in the minimum vibration and noise possible, given the current operating characteristics of the plant.",Neural net controller for noise and vibration reduction
"Two neural networks are used to control adaptively a vibration and noise-producing plant. The first neural network, the emulator, models the complex, nonlinear output of the plant with respect to certain controls and stimuli applied to the plant. The second neural network, the controller, calculates a control signal which affects the vibration and noise producing characteristics of the plant. By using the emulator model to calculate the nonlinear plant gradient, the controller matrix coefficients can be adapted by backpropagation of the plant gradient to produce a control signal which results in the minimum vibration and noise possible, given the current operating characteristics of the plant.",Neural net controller for noise and vibration reduction
"A method and apparatus are disclosed that modify [ies] and generalize [s] the use in artificial neural networks of the error backpropagation algorithm. Each neuron unit first divides a plurality of weighted inputs into more than one group, then sums up weighted inputs in each group to provide each group's intermediate outputs, and finally processes the intermediate outputs to produce an output of the neuron unit. Since the method uses, when modifying each weight, a partial differential coefficient generated by partially-differentiating the output of the neuron unit by each weighted input, the weight can be properly modified even if the output of a neuron unit as a function of intermediate outputs has a plurality of variables corresponding to the number of groups. Since the conventional method uses only one differential coefficient, that is, the differential coefficient of the output of a neuron unit differentiated by the sum of all weighted inputs in a neuron unit, for all weights in a neuron unit, it may be said that the method according to the present invention generalizes the conventional method. The present invention is especially useful for pulse density neural networks which express data as an ON-bit density of a bit string.",Neural network and method for training the neural network
Systems and methods are disclosed for applying neural networks in resource-constrained environments. A system may include a sensor located in a resource-constrained environment configured to generate sensor data of the resource-constrained environment. The system may also include a first computing device not located in the resource-constrained environment configured to produce a neural network structure based on the sensor data. The system may further include a second computing device located in the resource-constrained environment configured to provide the sensor data as input to the neural network structure. The second computing device may be further configured to determine a state of the resource-constrained environment based on the input of the sensor data to the neural network structure.,Neural network applications in resource constrained environments
Systems and methods are disclosed for applying neural networks in resource-constrained environments. A system may include a sensor located in a resource-constrained environment configured to generate first sensor data and second sensor data of the resource-constrained environment. The system may also include a first computing device not located in the resource-constrained environment configured to produce a neural network structure based on the first sensor data. The system may also include a second computing device configured to determine a state of the resource-constrained environment based on input of the second sensor data to the neural network structure. The system may also include a controller located in the resource-constrained environment configured to control a device in the resource-constrained environment based on the state of the resource-constrained environment determined by the second computing device. The second computing device may be further configured to calculate an activation area for the neural network structure.,Neural network applications in resource constrained environments
Systems and methods are disclosed for applying neural networks in resource-constrained environments. A system may include a sensor located in a resource-constrained environment configured to generate sensor data of the resource-constrained environment. The system may also include a first computing device not located in the resource-constrained environment configured to produce a neural network structure based on the sensor data. The system may further include a second computing device located in the resource-constrained environment configured to provide the sensor data as input to the neural network structure. The second computing device may be further configured to determine a state of the resource-constrained environment based on the input of the sensor data to the neural network structure.,Neural network applications in resource constrained environments
Systems and methods are disclosed for applying neural networks in resource-constrained environments. A system may include a sensor located in a resource-constrained environment configured to generate sensor data of the resource-constrained environment. The system may also include a first computing device not located in the resource-constrained environment configured to produce a neural network structure based on the sensor data. The system may further include a second computing device located in the resource-constrained environment configured to provide the sensor data as input to the neural network structure. The second computing device may be further configured to determine a state of the resource-constrained environment based on the input of the sensor data to the neural network structure.,Neural network applications in resource constrained environments
"An adaptive hierarchical neural network based system with online adaptation capabilities has been developed to automatically adjust the display window width and center for MR images. Our windowing system possesses the online training capabilities that make the adaptation of the optimal display parameters to personal preference as well as different viewing conditions possible. The online adaptation capabilities are primarily due to the use of the hierarchical neural networks and the development of a new width/center mapping system. The large training image set is hierarchically organized for efficient user interaction and effective re-mapping of the width/center settings in the training data set. The width/center values are modified in the training data through a width/center mapping function, which is estimated from the new width/center values of some representative images adjusted by the user. The width/center mapping process consists of a global spline mapping for the entire training images as well as a first-order polynomial sequence mapping for the image sequences selected in the user's new adjustment procedure.",Neural network based auto-windowing system for MR images
"Constructing and simulating artificial neural networks and components thereof within a spreadsheet environment results in user friendly neural networks which do not require algorithmic based software in order to train or operate. Such neural networks can be easily cascaded to form complex neural networks and neural network systems, including neural networks capable of self-organizing so as to self-train within a spreadsheet, neural networks which train simultaneously within a spreadsheet, and neural networks capable of autonomously moving, monitoring, analyzing, and altering data within a spreadsheet. Neural networks can also be cascaded together in self training neural network form to achieve a device prototyping system.",Neural network based database scanning system
"Fully automated methods and systems for processing complex data sets to identify abnormalities are described. In one embodiment, the system includes wavelet processing, recursive processing to determine prominent features, and then utilizing feed forward neural networks (FFNNs) to classify feature vectors generated in the wavelet and recursive processing. With respect to wavelet processing, multiresolution (five-level) and multidirection (two-dimensional) wavelet analysis with quadratic spline wavelets is performed to transform each image. The wavelets are a first-order derivative of a smoothing function and enhance the edges of image objects. Because two-dimensional wavelet transforms quantize an image in terms of space and spatial frequency and can be ordered linearly, the data is processed recursively to determine prominent features. A neural network approach derived from sequential recursive auto-associative memory is then used to parse the wavelet coefficients and hierarchy data. Since the wavelet coefficients are continuous, linear output instead of sigmoidal output is used. This variation is therefore referred to as linear output sequential recursive auto-associative memory, or LOSRAAM. The objective of training the LOSRAAM network is to have the output exactly match the input. Context units arising from serial evaluation of the wavelet coefficient triplets may be collected as vectors. These vectors are subjected to cluster analysis. This analysis yields a number of identifiable and discrete states. From these states, feature vectors are created. Each element in the feature vector represents the number of times the corresponding state from the above cluster analysis is found. Then, feed forward neural networks (FFNNs) are trained to classify feature vectors.",Neural network based methods and systems for analyzing complex data
"A new image reconstruction technique for imaging two- and three-phase flows using electrical capacitance tomography (ECT) has been developed based on multi-criteria optimization using an analog neural network, hereafter referred to as Neural Network Multi-criteria Optimization Image Reconstruction (NN-MOIRT)). The reconstruction technique is a combination between multi-criteria optimization image reconstruction technique for linear tomography, and the so-called linear back projection (LBP) technique commonly used for capacitance tomography. The multi-criteria optimization image reconstruction problem is solved using Hopfield model dynamic neural-network computing. For three-component imaging, the single-step sigmoid function in the Hopfield networks is replaced by a double-step sigmoid function, allowing the neural computation to converge to three-distinct stable regions in the output space corresponding to the three components, enabling the differentiation among the single phases.",Neural network based multi-criteria optimization image reconstruction technique for imaging two- and three-phase flow systems using electrical capacitance tomography
"Constructing and simulating artificial neural networks and components thereof within a spreadsheet environment results in user friendly neural networks which do not require algorithmic based software in order to train or operate. Such neural networks can be easily cascaded to form complex neural networks and neural network systems, including neural networks capable of self-organizing so as to self-train within a spreadsheet, neural networks which train simultaneously within a spreadsheet, and neural networks capable of autonomously moving, monitoring, analyzing, and altering data within a spreadsheet. Neural networks can also be cascaded together in self training neural network form to achieve a device prototyping system.",Neural network based prototyping system and method
"In a multi-layered neural network circuit provided with an input layer having input vectors, an intermediate layer having networks in tree-like structure whose outputs are necessarily determined by the values of the input vectors and whose number corresponds to the number of the input vectors of the input layer, and an output layer having plural output units for integrating all outputs of the intermediate layer, provided are learning-time memories for memorizing the numbers of times at learning in paths between the intermediate layer and the respective output units, threshold processing circuits for threshold-processing the outputs of the leaning-time memories, and connection control circuits to be controlled by the outputs of the threshold processing circuits for controlling connection of paths between the intermediate layer and the output units. The outputs of the intermediate layer connected by the connection control circuits are summed in each output unit. Thus, the neural network circuit for recognizing an image or the like can execute recognition and learning of data to be recognized at high speed with small circuit size, and the recognition accuracy for unlearned data is high.",Neural network circuit for adaptively controlling the coupling of neurons
"Neural networks are constructed (programmed), trained on historical data, and used to predict any of (1) optimal patient dosage of a single drug, (2) optimal patient dosage of one drug in respect of the patient's concurrent usage of another drug, (3a) optimal patient drug dosage in respect of diverse patient characteristics, (3b) sensitivity of recommended patient drug dosage to the patient characteristics, (4a) expected outcome versus patient drug dosage, (4b) sensitivity of the expected outcome to variant drug dosage(s), (5) expected outcome(s) from drug dosage(s) other than the projected optimal dosage. Both human and economic costs of both optimal and sub-optimal drug therapies may be extrapolated from the exercise of various optimized and trained neural networks. Heretofore little recognized sensitivities&#8212;such as, for example, patient race in the administration of psychotropic drugs&#8212;are made manifest. Individual prescribing physicians employing deviant patterns of drug therapy may be recognized. Although not intended to prescribe drugs, nor even to set prescription drug dosage, the neural networks are very sophisticated and authoritative &#8220;helps&#8221; to physicians, and to physician reviewers, in answering &#8220;what if&#8221; questions.",Neural network drug dosage estimation
"Neural networks provide efficient, robust and precise filtering techniques for compensating linear and non-linear distortion of an audio transducer such as a speaker, amplified broadcast antenna or perhaps a microphone. These techniques include both a method of characterizing the audio transducer to compute the inverse transfer functions and a method of implementing those inverse transfer functions for reproduction. The inverse transfer functions are preferably extracted using time domain calculations such as provided by linear and non-linear neural networks, which more accurately represent the properties of audio signals and the audio transducer than conventional frequency domain or modeling based approaches. Although the preferred approach is to compensate for both linear and non-linear distortion, the neural network filtering techniques may be applied independently.",Neural network filtering techniques for compensating linear and non-linear distortion of an audio transducer
"A neural-simulating system for an image processing system includes a plurality of networks arranged in a plurality of layers, the output signals of ones of the layers provide input signals to the others of the layers. Each of the plurality of layers include a plurality of neurons operating in parallel on the input signals to the layers. The plurality of neurons within a layer are arranged in groups. Each of the neurons within a group operates in parallel on the input signals. Each neuron within a group of neurons operates to extract a specific feature of an area of the image being processed. Each of the neurons derives output signals from the input signals representing the relative weight of the input signal applied thereto based upon a continuously differential transfer function for each function.",Neural network image processing system
"A method for determining depth to basement from aeromagnetic data utilizes neural networks to automate the laborious process of profile interpretation. The neural networks provide consistency, accuracy and overall quality without bias of interpretation.",Neural network interpretation of aeromagnetic data
"A neural network learning system is applied to extensive use in applications such as pattern and character recognizing operations, various controls, etc. The neural network learning system operates on, for example, a plurality of neural networks each having a different number of intermediate layer units to efficiently perform a learning process at a high speed with a reduced amount of hardware. A neural network system having a plurality of hierarchical neural networks each having an input layer, one or more intermediate layers and output layers is formed from a common input layer shared among two or more neural networks, or the common input layer and one or more intermediate layers and a learning controller for controlling a learning process performed by a plurality of neural networks.",Neural network learning system
"A neural network learning system is applied to extensive use in applications such as pattern and character recognizing operations, various controls, etc. The neural network learning system operates on, for example, a plurality of neural networks each having a different number of intermediate layer units to efficiently perform a learning process at a high speed with a reduced amount of hardware. A neural network system having a plurality of hierarchical neural networks each having an input layer, one or more intermediate layers and output layers is formed from a common input layer shared among two or more neural networks, or the common input layer and one or more intermediate layers and a learning controller for controlling a learning process performed by a plurality of neural networks.",Neural network learning system
"A method of generating mapping dictionaries for neural networks may be provided. A method may include receiving, at a current layer, encoded activation addresses from a previous layer and encoded weight addresses. The method may also include decoding the encoded activation addresses to generate decoded activation addresses, and decoding the encoded weight addresses to generate decoded weight addresses. Further, the method may include generating original activation addresses from the decoded activation addresses and the decoded weight addresses. Moreover, the method may include matching the original activation addresses to a mapping dictionary to generate encoded activation addresses for the current layer.",Neural network mapping dictionary generation
"A method and apparatus for disease, injury or condition screening or sensing wherein biopotentials are received from a plurality of measuring sensors located in the area of a suspected disease, injury or condition change site. These potentials are then processed and the processed values are provided to a particular type of neural network or a combination of neural networks uniquely adapted to receive and analyze data of an identifiable type to provide an indication of specific conditions.","Neural network method and apparatus for disease, injury and bodily condition screening or sensing"
"A new method to analyze and predict the binding energy for enzyme-transition state inhibitor interactions is presented. Computational neural networks are employed to discovery quantum mechanical features of transition states and putative inhibitors necessary for binding. The method is able to generate its own relationship between the quantum mechanical structure of the inhibitor and the strength of binding. Feed-forward neural networks with back propagation of error can be trained to recognize the quantum mechanical electrostatic potential at the entire van der Waals surface, rather than a collapsed representation, of a group of training inhibitors and to predict the strength of interactions between the enzyme and a group of novel inhibitors. The experimental results show that the neural networks can predict with quantitative accuracy the binding strength of new inhibitors. The method is in fact able to predict the large binding free energy of the transition state, when trained with less tightly bound inhibitors. The present method is also applicable to prediction of the binding free energy of a ligand to a receptor. The application of this approach to the study of transition state inhibitors and ligands would permit evaluation of chemical libraries of potential inhibitory, agonistic, or antagonistic agents. The method is amenable to incorporation in a computer-readable medium accessible by general-purpose computers.",Neural network methods to predict enzyme inhibitor or receptor ligand potency
"A new method to analyze and predict the binding energy for enzyme-transition state inhibitor interactions is presented. Computational neural networks are employed to discovery quantum mechanical features of transition states and putative inhibitors necessary for binding. The method is able to generate its own relationship between the quantum mechanical structure of the inhibitor and the strength of binding. Feed-forward neural networks with back propagation of error can be trained to recognize the quantum mechanical electrostatic potential at the entire van der Waals surface, rather than a collapsed representation, of a group of training inhibitors and to predict the strength of interactions between the enzyme and a group of novel inhibitors. The experimental results show that the neural networks can predict with quantitative accuracy the binding strength of new inhibitors. The method is in fact able to predict the large binding free energy of the transition state, when trained with less tightly bound inhibitors. The present method is also applicable to prediction of the binding free energy of a ligand to a receptor. The application of this approach to the study of transition state inhibitors and ligands would permit evaluation of chemical libraries of potential inhibitory, agonistic, or antagonistic agents. The method is amenable to incorporation in a computer-readable medium accessible by general-purpose computers.",Neural network methods to predict enzyme inhibitor or receptor ligand potency
"A new method to analyze and predict the binding energy for enzyme-transition state inhibitor interactions is presented. Computational neural networks are employed to discovery quantum mechanical features of transition states and putative inhibitors necessary for binding. The method is able to generate its own relationship between the quantum mechanical structure of the inhibitor and the strength of binding. Feed-forward neural networks with back propagation of error can be trained to recognize the quantum mechanical electrostatic potential at the entire van der Waals surface, rather than a collapsed representation, of a group of training inhibitors and to predict the strength of interactions between the enzyme and a group of novel inhibitors. The experimental results show that the neural networks can predict with quantitative accuracy the binding strength of new inhibitors. The method is in fact able to predict the large binding free energy of the transition state, when trained with less tightly bound inhibitors. The present method is also applicable to prediction of the binding free energy of a ligand to a receptor. The application of this approach to the study of transition state inhibitors and ligands would permit evaluation of chemical libraries of potential inhibitory, agonistic, or antagonistic agents. The method is amenable to incorporation in a computer-readable medium accessible by general-purpose computers.",Neural network methods to predict enzyme inhibitor or receptor ligand potency
"A system and method for a neural network is disclosed that is trained to recognize noise characteristics or other types of interference and to determine when an input waveform deviates from learned noise characteristics. A plurality of neural networks is preferably provided, which each receives a plurality of samples of intervals or windows of the input waveform. Each of the neural networks produces an output based on whether an anomaly is detected with respect to the noise, which the neural network is trained to detect. The plurality of outputs of the neural networks is preferably applied to a decision aid for deciding whether the input waveform contains a non-noise component. The decision aid may include a database, a computational section and a decision module. The system and method may provide a preliminary processing of the input waveform and is used to recognize the particular noise rather than a non-noise signal.",Neural network noise anomaly recognition system and method
"A computer neural network process measurement and control system and method uses real-time output data from a neural network to replace a sensor or laboratory input to a controller. The neural network can use readily available, inexpensive and reliable measurements from sensors as inputs, and produce predicted values of product properties as output data for input to the controller. The system and method overcome process deadtime, measurement deadtime, infrequent measurements, and measurement variability in laboratory data, thus providing improved control. An historical database can be used to provide a history of sensor and laboratory measurements to the neural network. The neural network can detect the appearance of new laboratory measurements in the history and automatically initiate retraining, on-line and in real-time. The system and method can use either a regulatory controller or a supervisory control architecture. A modular software implementation simplifies the building of multiple neural networks, and also optionally provides other control functions, such as supervisory controllers, expert systems, and statistical data filtering, thus allowing powerful extensions of the system and method. Template specification for the neural network, and data specification using data pointers allow the system and method to be more easily implemented.",Neural network process measurement and control
"Methods are developed on a digital computer for performing work order scheduling activity in a dynamic factory floor environment, in a manner which enables scheduling heuristic knowledge from a scheduler to be encoded through an adaptive learning process, thus eliminating the need to define these rules explicitly. A sequential assignment paradigm incrementally builds up a final schedule from a partial schedule, assigning each work order to appropriate resources in turns, taking advantage of the parallel processing capability of neural networks by selecting the most appropriate resource combination (i.e. schedule generation) for each work order under simultaneous interaction of multiple scheduling constraints.",Neural network system and method for factory floor scheduling
"A neural network system includes an input unit, an operation control unit, a parameter setting unit, a neural network group unit, and a display unit. The network group unit includes first and second neural networks. The first neural network operates according to the mean field approximation method to which the annealing is added, whereas the second neural network operates in accordance with the simulated annealing. Each of the first an second neural networks includes a plurality of neurons each connected via synapses to neurons so as to weighting outputs from the neurons based on synapse weights, thereby computing an output related to a total of weighted outputs from the neurons according to an output function. The parameter setting unit is responsive to a setting instruction to generate neuron parameters including synapse weights, threshold values, and output functions, which are set to the first neural network and which are selective set to the second neural network. The operation control unit responsive to an input of a problem analyzes the problem and then generates a setting instruction based on a result of the analysis to output the result to the parameter setting unit. After the neuron parameters are set thereto, in order for the first and second neural network to selectively or to iteratively operate, the operation control unit controls operations of computations in the network group unit in accordance with the analysis result and then presents results of the computations in the network group unit on the display unit.",Neural network system for determining optimal solution
"An algorithm method of predicting estimated sea energy, wave directions and other seastate data with respect to submerged sea-going vessels, based on inputs derived from signal processed measurements of keel depth, pitch, roll and forward speed applied to three neural networks for heading detection and to a fourth neural network for seastate estimations.",Neural network system for estimating conditions on submerged surfaces of seawater vessels
"A visual information processing device has a pair of neural networks which respectively comprise an upper layer and a lower layer of the device. Each of the pair of neural networks comprises a semiconductor integrated circuit having a plurality of neuron circuit regions which are disposed in a matrix form, each of the neuron circuit regions performing a neuron function; a molecule film having a photoelectric function and provided on the semiconductor integrated circuit, the molecule film having (i) a plurality of T.sub.ij signal input sections each performing a wiring function among the plurality of neuron circuit regions, in each of which a T.sub.ij signal representing the bonding strength among the plurality of neuron circuit regions is optically written, and (ii) a plurality of video input sections each performing a sensor function of sensing a visual image in which one pixel corresponds to one neuron circuit region; and a wiring for electrically connecting the semiconductor integrated circuit and the molecule film. Each of the plurality of neuron circuit regions is bonded with the neighboring neuron circuit regions in each of the pair of neural networks comprising the upper and lower layers, and each of the plurality of neuron circuit regions is bonded with the corresponding one between the pair of neural networks.",Neural network system for image processing
"The system includes an active medical device with means for delivering defibrillation shocks; means for continuous collection of the patient current cardiac activity parameters; and evaluator means with neuronal analysis comprising a neural network with at least two layers. This neural network comprises upstream three neural sub-networks receiving the respective parameters divided into separate sub-groups corresponding to classes of arrhythmogenic factors; and downstream an output neuron coupled to the three sub-networks and capable of outputting an index of risk of ventricular arrhythmia. The risk index is compared with a given threshold, to enable or disable at least one function of the device in case of crossing of the threshold.",Neural network system for the evaluation and the adaptation of antitachycardia therapy by an implantable defibrillator
"N neural networks having different set-values are provided, where N is an integer greater than 2. Each neural network has plurality of artificial neurons and processes information. An optimal output detecting circuit receives outputs of the N neural networks and determines the optimal one of the neural networks based on the outputs of the N neural networks. An output circuit receives and outputs the output of the neural network detected by the optimal output detecting circuit.",Neural network system having minimum energy function value
"A method for rapid and sensitive protein family identification is disclosed. The new designs include an n-gram term weighting algorithm for extracting local motif patterns, an enhanced n-gram method for extracting residues of long-range correlation, and integrated neural networks for combining global and motif sequence information.",Neural network system with N-gram term weighting method for molecular sequence classification and motif identification
A system that generates training images for neural networks includes one or more processors configured to receive input representing one or more selected areas in an image mask. The one or more processors are configured to form a labeled masked image by combining the image mask with an unlabeled image of equipment. The one or more processors also are configured to train an artificial neural network using the labeled masked image to one or more of automatically identify equipment damage appearing in one or more actual images of equipment and/or generate one or more training images for training another artificial neural network to automatically identify the equipment damage appearing in the one or more actual images of equipment.,Neural network training image generation system
"Long and short term memory equations for neural networks are implemented by means of exchange of signals which carry information in the form of both binary and continuously modulated energy emissions. In one embodiment, array of parallel processors exhibits behavior of cooperative-competitive neural networks. Parallel bus interconnections and digital and analog processing of analog information contained in the exchanged energy emissions are employed with generally local synchronization of the processors. Energy emission and detection is modulated as a function of a random code.",Neural network using random binary code
"Apparatus, and an accompanying method, for a neural network, particularly one suited for use in optical character recognition (OCR) systems, which through controlling back propagation and adjustment of neural weight and bias values through an output confidence measure, smoothly, rapidly and accurately adapts its response to actual changing input data (characters). Specifically, the results of appropriate actual unknown input characters, which have been recognized with an output confidence measure that lies within a pre-defined range, are used to adaptively re-train the network during pattern recognition. By limiting the maximum value of the output confidence measure at which this re-training will occur, the network re-trains itself only when the input characters have changed by a sufficient margin from initial training data such that this re-training is likely to produce a subsequent noticeable increase in the recognition accuracy provided by the network. Output confidence is measured as a ratio between the highest and next highest values produced by output neurons in the network. By broadening the entire base of training data to include actual dynamically changing input characters, the inventive neural network provides more robust performance than which heretofore occurs in neural networks known in the art.",Neural network with back propagation controlled through an output confidence measure
"A self healing ad hoc communications network and method of training for and healing the network. The network includes wireless devices or nodes that include a neural network element and the ad hoc network operates as a neural network. Some of the nodes are designated as healing nodes that are identified during network training and are strategically located in the network coverage area. Whenever one group of nodes loses connection with another a healing node may reposition itself to reconnect the two groups. Thus, the network can maintain connectivity without constraining node movement.",Neural network-based mobility management for healing mobile ad hoc radio networks
"A self healing ad hoc communications network and method of training for and healing the network. The network includes wireless devices or nodes that include a neural network element and the ad hoc network operates as a neural network. Some of the nodes are designated as healing nodes that are identified during network training and are strategically located in the network coverage area. Whenever one group of nodes loses connection with another a healing node may reposition itself to reconnect the two groups. Thus, the network can maintain connectivity without constraining node movement.",Neural network-based mobility management for healing mobile ad hoc radio networks
A self managed ad hoc communications network and method of managing the network. The network includes wireless devices or nodes that include a neural network element and the ad hoc network operates as a neural network. One of the nodes is designated as a Network Management System (NMS) that provides overall network management. Clusters of nodes are organized around cluster leaders. Each cluster leader manages a cluster of nodes and communications between node clusters. Each cluster may also have other nodes identified as lower order cluster leaders.,Neural network-based mobility management for mobile ad hoc radio networks
"A method of managing an ad hoc communications network of wireless devices or nodes. The network is connected if all nodes can communicate with each other and otherwise partitioned. Partitions are identified by recursively applying a connectivity function to a connectivity matrix representative of the network. The number of times the connectivity function is recursively applied is determined by the network diameter. If the result of the recursive application is a unity matrix, the network is connected; otherwise it is disconnected. Also, if the network diameter exceeds a selected maximum length, the network may be voluntarily partitioned into connected sub-networks by recursively applying the connectivity function a lesser number of times to the connectivity matrix. The lesser number of times is determined by the selected maximum length or maximum allowable number of hops.",Neural network-based mobility management for self-partition detection and identification of mobile ad hoc radio networks
"A self managed ad hoc communications network nodes and node mobility management. Nodes include an Artificial Neural Network (ANN) that determines connection to other network nodes. The ANN may use free space propagation link life estimation, inverse modeling for partition prediction, Stochastic Approximation, and/or coarse estimation. The node includes storage storing network tables and matrices indicating network connectivity and connection to other nodes. Also, a wireless communications unit provides for wireless communicating with other nodes.",Neural network-based node mobility and network connectivty predictions for mobile ad hoc radio networks
"A method is disclosed for computer-based control of the timing and level of gear shifts in a multi-speed automatic transmission operated in combination with an internal combustion engine and interposed fluid torque converter. The computer containing power control module signals gear shifts in response to its repeated cyclic processing of engine and transmission operation parameters including torque converter slippage. Here, such slippage is estimated using a neural network with suitable such parameters as input data. In preferred modes of operation, different neural networks are available for selection and use by the computer in different modes of engine-transmission operation.",Neural network-based virtual sensor for automatic transmission slip
The invention relates to an apparatus for detecting fraud using a neural network. The architecture of the system involves first employing a conceptual clustering technique to generate a collection of classes from historical data. Neural networks are provided for each class created by the clustering step and the networks are trained using the same historical data. This apparatus is particularly useful for detecting the incidence of fraudulent activity from very large amounts of data such as tax returns or insurance claims.,Neural network/conceptual clustering fraud detection architecture
"A neural network/expert system process control system and method combines the decision-making capabilities of expert systems with the predictive capabilities of neural networks for improved process control. Neural networks provide predictions of measurements which are difficult to make, or supervisory or regulatory control changes which are difficult to implement using classical control techniques. Expert systems make decisions automatically based on knowledge which is well-known and can be expressed in rules or other knowledge representation forms. Sensor and laboratory data is effictively used. In one approach, the output data from the neural network can be used by the controller in controlling the process, and the expert system can make a decision using sensor or lab data to control the controller(s). In another approach, the output data of the neural network can be used by the expert system in making its decision, and control of the process carried out using lab or sensor data. In another approach, the output data can be used both to control the process and to make decisions.",Neural network/expert system process control system and method
"Neural network type information processing devices have been proposed. In these devices, a matrix structure is utilized with impedance at the matrix intersection points. It has been found that excellent versatility in design is achieved by utilizing photoconductors at these intersection points and thus affording the possibility of controlling impedance by, in turn, controlling the level of incident light.",Neural networks
"The operation of neural networks begins with the initialization of the system with the information to be processed. Presently, this initialization is performed by pinning the system with rather large analog or digital signals representing this information. The problems associated with the high power required for such initialization are eliminated and accuracy is maintained by utilizing a specific set of input points and appropriately positioned switches. In particular, a switch corresponding to each amplifier is introduced, and the initializing data is introduced between the amplifier and this switch.",Neural networks
A neural network has inputs formed by square array of optical modulators M.sub.ij and outputs by optical detectors D.sub.ij coupled to threshold comparators. A holographic plate includes a spatial modulator whose elements are controlled by a controller to form an array of optical beams from a coherent optical source. Each optical beam optically interconnects a modulator M.sub.ij with a respective detector D.sub.ij. The weight values of the neural network are provided by the intensities of the optical beams. This obviates the need for an optical weighting mask between an array of light emitting diodes and a detector array allowing a higher density of lower power consumption components and reprogrammability of the network.,Neural networks
"The present invention relates to adaptive information processing systems, and in particular to associative memories utilizing confidence-mediated associations, and especially neural network systems comprising an auto-organizational apparatus and processes for dynamically mapping an input onto a semantically congruous and contemporaneously-valid, learned response. In particular the present invention relates to such an associative memory system in which provision is made for improving the congruence between an associative memory, by impressing a desired response on an associative memory mapping based on complex polar values.",Neural networks
"Methods (30) for training an artificial neural network (NN) are disclosed. An example method (30) includes: initializing the NN by selecting an output of the NN to be trained and connecting an output neuron of the NN to input neuron(s) in an input layer of the NN for the selected output; preparing a data set to be learnt by the NN; and, applying the prepared data set to the NN to be learnt by applying an input vector of the prepared data set to the first hidden layer of the NN, or the output layer of the NN if the NN has no hidden layer(s), and determining whether at least one neuron for the selected output in each layer of the NN can learn to produce the associated output for the input vector.",Neural networks and method for training neural networks
"Novel neural networks and novel methods for training those networks are disclosed. The novel networks are feedforward networks having at least three layers of neurons. The training methods are easy to implement, converge rapidly, and are guaranteed to converge to a solution. A novel network structure is used, in which each corner of the input vector hypercube may be considered separately. The problem of mapping may be reduced to a sum of corner classification sub-problems. Four efficient, alternative classification methods for use with the novel neural networks are also disclosed.",Neural networks and methods for training neural networks
"A television signal processing apparatus includes at least one neural network for processing a signal representing an image. The neural network includes a plurality of perceptrons each of which includes circuitry for weighting a plurality of delayed representations of said signal, circuitry for providing sums of weighted signals provided by said weighting circuitry, and circuitry for processing said sums with a sigmoidal transfer function. The neural network also includes circuitry for combining output signals provided by ones of said perceptrons for providing a processed signal.",Neural networks as for video signal processing
"A synthetic neural network having a plurality of neuronal elements arranged in an input layer, an output layer, and a hidden layer between the input layer and the output layer. The network has a first plurality of synaptic weighting elements interconnecting the neuronal elements of the input layer with the neuronal elements of the hidden layer, and a second plurality of synaptic weighting elements interconnecting the neuronal elements of the hidden layer with the neuronal elements of the output layer. The improvement involves the synaptic weighting elements in the synthetic neural network being in the form of a silicon dioxide film derived from a hydrogen silsesquioxane resin. Such a silicon dioxide film is characterized by a jV curve which includes both linear and non-linear regions.",Neural networks containing variable resistors as synapses
"A method of training a neural network to perform decoding of a time-varying signal comprising a sequence of input symbols, which is coded by a coder such that each coded output symbol depends on more than one input symbol, characterized by repetitively: providing a plurality of successive input symbols to the neural network and to the coder, comparing the network outputs with the input signals; and adapting the network parameters to reduce the differences therebetween.",Neural networks decoder
""" A machine for neural computation of acoustical patterns for use in real-time speech recognition, comprising a plurality of analog electronic neurons connected for the analysis and recognition of acoustical patterns, including speech. Input to the neural net is provided from a set of bandpass filters which separate the input acoustical patterns into frequency ranges. The neural net itself is organized into two parts, the first for performing the real-time decomposition of the input patterns into their primitives of energy, space (frequency) and time relations, and the second for decoding the resulting set of primitives into known phonemes and diphones. During operation, the outputs of the individual bandpass filters are rectified and fed to sets of neurons in an opponent center-surround organization of synaptic connections (""""on center"""" and """"off center""""). These units compute maxima and minima of energy at different frequencies. The next sets of neurons compute the temporal boundaries (""""on"""" and """"off""""), while the following sets of neurons compute the movement of the energy maxima (formants) up or down the frequency axis. Then, in order to recognize speech sounds at the phoneme or diphone level, the set of primitives belonging to the phoneme is decoded such that only one neuron or a non-overlapping group of neurons fire when a particular sound pattern is present at the input. The output from these neurons is then fed to an Erasable Programmable Read Only Memory (EPROM) decoder and computer for displaying in real-time a phonetic representation of the speech input. """,Neural networks for acoustical pattern recognition
"Embodiments described herein are directed to methods and systems for performing neural network computations on encrypted data. Encrypted data is received from a user. The encrypted data is encrypted with an encryption scheme that allows for computations on the ciphertext to generate encrypted results data. Neural network computations are performed on the encrypted data, using approximations of neural network functions to generate encrypted neural network results data from encrypted data. The approximations of neural network functions can approximate activation functions, where the activation functions are approximated using polynomial expressions. The encrypted neural network results data are communicated to the user associated with the encrypted data such that the user decrypts the encrypted data based on the encryption scheme. The functionality of the neural network system can be provided using a cloud computing platform that supports restricted access to particular neural networks.",Neural networks for encrypted data
"Systems, devices, media, and methods are presented for modeling facial representations using image segmentation with a client device. The systems and methods receive an image depicting a face, detect at least a portion of the face within the image, and identify a set of facial features within the portion of the face. The systems and methods generate a descriptor function representing the set of facial features, fit object functions of the descriptor function, identify an identification probability for each facial feature, and assign an identification to each facial feature.",Neural networks for facial modeling
"Systems, devices, media, and methods are presented for modeling facial representations using image segmentation with a client device. The systems and methods receive an image depicting a face, detect at least a portion of the face within the image, and identify a set of facial features within the portion of the face. The systems and methods generate a descriptor function representing the set of facial features, fit object functions of the descriptor function, identify an identification probability for each facial feature, and assign an identification to each facial feature.",Neural networks for facial modeling
"Methods and apparatus are disclosed for generating predictions of tendencies of a waveform segment to induce frisson. In one example, a method includes producing Mel-frequency cepstral coefficients corresponding to an audio waveform, dividing the waveform into a plurality of segments that have been tagged with a value indicating a likelihood that the segment will produce a frisson response in a listener, and training a neural network with the Mel-frequency cepstral coefficients and the segment tag values to generate predictions of a tendency of a waveform segment to induce frisson. In some examples, the method further includes displaying a visualization of the waveform, wherein the visualization indicates how likely portions of the visualized waveform are to induce frisson.",Neural networks for identifying the potential of digitized audio to induce frisson in listeners
"A method of identifying a source of ingress into a network includes storing frequency spectra of known sources of ingress, comparing the frequency spectrum of ingress to the frequency spectra of known sources of ingress, and determining from the comparison which of the frequency spectra of known sources of ingress is closest to the frequency spectrum of the ingress. Apparatus for identifying a source of ingress into a network includes memory for storing frequency spectra of known sources of ingress and a device for comparing the frequency spectrum of the ingress to frequency spectra of known sources of ingress and determining from the comparison which frequency spectrum of a known source of ingress is closest to the frequency spectrum of the ingress. A method of establishing ingress into a network includes developing a first frequency spectrum indicative of the condition of the network at a first time during the operation of the network, developing a second frequency spectrum indicative of the condition of the network at a second, later time, comparing the second frequency spectrum to the first frequency spectrum, and determining from the comparison a condition of the network at the second time. Apparatus for establishing ingress into a network includes a device for receiving frequency spectra. The device receives at least one first frequency spectrum indicative of the condition of the network at a first time during the operation of the network, and a second frequency spectrum indicative of the condition of the network at a second, later time. The device compares the second frequency spectrum to the first frequency spectrum and determines from the comparison the condition of the network at the second time.",Neural networks for ingress monitoring
"A method and system for implementing a neuro-controller. One example of a neuro-controller is a brain-like stochastic search. Another example is a neuro-controller for controlling a hypersonic aircraft. Using a variety of learning techniques, the method and system provide adaptable control of external devices (e.g., airplanes, plants, factories, and financial systems).",Neural networks for intelligent control
"Network interactions within a Boundary Contour (BC) System, a Feature Contour (FC) System, and an Object Recognition (OR) System are employed to provide a computer vision system capable of recognizing emerging segmentations. The BC System is defined by a hierarchy of orientationally tuned interactions, which can be divided into two successive subsystems called the OC filter and the CC loop. The OC filter contains oriented receptive fields or masks, which are sensitive to different properties of image contrasts. The OC filter generates inputs to the CC loop, which contains successive stages of spatially shore-range competitive interactions and spatially long-range cooperative interactions. Feedback between the competitive and cooperative stages synthesizes a global context-sensitive segmentation from among the many possible groupings of local featural elements.",Neural networks for machine vision
"A neural network system for identifying positions of objects in an input image can include an object detector neural network, a memory interface subsystem, and an external memory. The object detector neural network is configured to, at each time step of multiple successive time steps, (i) receive a first neural network input that represents the input image and a second neural network input that identifies a first set of positions of the input image that have each been classified as showing a respective object of the set of objects, and (ii) process the first and second inputs to generate a set of output scores that each represents a respective likelihood that an object that is not one of the objects shown at any of the positions in the first set of positions is shown at a respective position of the input image that corresponds to the output score.",Neural networks for object detection
"Neural networks for optimal estimation (including prediction) and/or control involve an execution step and a learning step, and are characterized by the learning step being performed by neural computations. The set of learning rules cause the circuit's connection strengths to learn to approximate the optimal estimation and/or control function that minimizes estimation error and/or a measure of control cost. The classical Kalman filter and the classical Kalman optimal controller are important examples of such an optimal estimation and/or control function. The circuit uses only a stream of noisy measurements to infer relevant properties of the external dynamical system, learn the optimal estimation and/or control function, and apply its learning of this optimal function to input data streams in an online manner. In this way, the circuit simultaneously learns and generates estimates and/or control output signals that are optimal, given the network's current state of learning.",Neural networks for prediction and control
"Systems, methods, devices, and other techniques for training and using a speaker verification neural network. A computing device may receive data that characterizes a first utterance. The computing device provides the data that characterizes the utterance to a speaker verification neural network. Subsequently, the computing device obtains, from the speaker verification neural network, a speaker representation that indicates speaking characteristics of a speaker of the first utterance. The computing device determines whether the first utterance is classified as an utterance of a registered user of the computing device. In response to determining that the first utterance is classified as an utterance of the registered user of the computing device, the device may perform an action for the registered user of the computing device.",Neural networks for speaker verification
"This document generally describes systems, methods, devices, and other techniques related to speaker verification, including (i) training a neural network for a speaker verification model, (ii) enrolling users at a client device, and (iii) verifying identities of users based on characteristics of the users' voices. Some implementations include a computer-implemented method. The method can include receiving, at a computing device, data that characterizes an utterance of a user of the computing device. A speaker representation can be generated, at the computing device, for the utterance using a neural network on the computing device. The neural network can be trained based on a plurality of training samples that each: (i) include data that characterizes a first utterance and data that characterizes one or more second utterances, and (ii) are labeled as a matching speakers sample or a non-matching speakers sample.",Neural networks for speaker verification
"A method for transforms input signals, by first defining a model for transforming the input signals, wherein the model is specified by constraints and a set of model parameters. An iterative inference procedure is derived from the model and the set of model parameters and unfolded into a set of layers, wherein there is one layer for each iteration of the procedure, and wherein a same set of network parameters is used by all layers. A neural network is formed by untying the set of network parameters such that there is one set of network parameters for each layer and each set of network parameters is separately maintainable and separately applicable to the corresponding layer. The neural network is trined to obtain a trained neural network, and then input signals are transformed using the trained neural network to obtain output signals.",Neural networks for transforming signals
"In some aspects, cultures of neurons derived from human induced pluripotent stem cells (iPS cells) that exhibit synchronous firing of neural networks are provided. In some embodiments, neuronal activity of the cultures may be detected or measured using a multi-electrode array.",Neural networks formed from cells derived from pluripotent stem cells
The present invention comprises systems and methods for handling large amounts of data prone to ambiguity and artifact in real-time in order to ensure patient safety while performing a procedure involving a sedation and analgesia system. The invention utilizes neural networks to weight data which may be more accurate or more indicative of true patient condition such that the patient condition reported to the controller and the user of a sedation and analgesia system will have increased accuracy and the incidence of false positive alarms will be reduced.,Neural networks in sedation and analgesia systems
"A method of accelerating the training of an artificial neural network uses a computer configured as an artificial neural network with a network input and a network output, and having a plurality of interconnected units arranged in layers including an input layer and an output layer. Each unit has a multiplicity of unit inputs and a set of variables for operating upon a unit inputs to provide a unit output in the range positive 1 and negative 1. A plurality of examples are serially provided to the network input and the network output is observed. The computer is programmed with a back propagation algorithm for calculating changes to the sets of variables in response to feedback representing differences between the network output for each example and the desired output. The absolute magnitude of the product of an input and the corresponding output of a unit is calculated. The feedback to that unit is adjusted in response to absolute magnitude so that said feedback is larger with a larger absolute magnitude than with a smaller absolute magnitude.",Neural networks learning method
A neural network comprising a plurality of neurons in which any one of the plurality of neurons is able to associate with itself or another neuron in the plurality of neurons via active connections to a further neuron in the plurality of neurons.,Neural networks with learning and expression capability
A neural network comprising a plurality of neurons in which any one of the plurality of neurons is able to associate with itself or another neuron in the plurality of neurons via active connections to a further neuron in the plurality of neurons.,Neural networks with learning and expression capability
"A neural network apparatus, and methods for training the neural network apparatus, for processing input information, supplied as a data array, for a prespecified application to indicate output categories characteristic of the processing for that application. In the invention, an input stage accepts the data array and converts it to a corresponding internal representation, and a data preprocessor analyzes the data array based on a plurality of feature attributes to generate a corresponding plurality of attribute measures. A neural network, comprising a plurality of interconnected neurons, processes the attribute measures to reach a neural state representative of corresponding category attributes; portions of the network are predefined to include a number of neurons and prespecified with a particular correspondence to the feature attributes to accept corresponding attribute measures for the data array, and portions of the network are prespecified with a particular correspondence to the category attributes. A data postprocessor indicates the category attributes by correlating the neural state with predefined category attribute measures, and an output stage combines the category measures in a prespecified manner to generate on output category for the input information.",Neural networks with subdivision
"A neural processing element for use in a modular neural network is provided. One embodiment provides a neural network comprising an array of autonomous modules (300). The modules (300) can be arranged in a variety of configurations to form neural networks with various topologies, for example, with a hierarchical modular structure. Each module (300) contains sufficient neurons (100) to enable it to do useful work as a stand alone system, with the advantage that many modules (300) can be connected together to create a wide variety of configurations and network sizes. This modular approach results in a scaleable system that meets increased workload with an increase in parallelism and thereby avoids the usually extensive increases in training times associated with unitary implementations.",Neural processing element for use in a neural network
"A neural prosthesis includes a centralized device that can provide power, data, and clock signals to one or more individual neural prosthesis subsystems. Each subsystem may include a number of individually addressable, programmable modules that can be dynamically allocated or shared among neural prosthetic networks to achieve complex, coordinated functions or to operate in autonomous groups.",Neural prosthesis
"A neural prosthesis includes a centralized device that can provide power, data, and clock signals to one or more individual neural prosthesis subsystems. Each subsystem may include a number of individually addressable, programmable modules that can be dynamically allocated or shared among neural prosthetic networks to achieve complex, coordinated functions or to operate in autonomous groups.",Neural prosthesis
"A neural prosthesis includes a centralized device that can provide power, data, and clock signals to one or more individual neural prosthesis subsystems. Each subsystem may include a number of individually addressable, programmable modules that can be dynamically allocated or shared among neural prosthetic networks to achieve complex, coordinated functions or to operate in autonomous groups.",Neural prosthesis
""" A base neural semiconductor chip (10) including a neural network or unit (11(#)). The neural network (11(#)) has a plurality of neuron circuits fed by different buses transporting data such as the input vector data, set-up parameters, and control signals. Each neuron circuit (11) includes logic for generating local result signals of the """"fire"""" type (F) and a local output signal (NOUT) of the distance or category type on respective buses (NR-BUS, NOUT-BUS). An OR circuit (12) performs an OR function for all corresponding local result and output signals to generate respective first global result (R*) and output (OUT*) signals on respective buses (R*-BUS, OUT*-BUS) that are merged in an on-chip common communication bus (COM*-BUS) shared by all neuron circuits of the chip. In a multi-chip network, an additional OR function is performed between all corresponding first global result and output signals (which are intermediate signals) to generate second global result (R**) and output (OUT**) signals, preferably by dotting onto an off-chip common communication bus (COM**-BUS) in the chip's driver block (19). This latter bus is shared by all the base neural network chips that are connected to it in order to incorporate a neural network of the desired size. In the chip, a multiplexer (21) may select either the intermediate output or the global output signal to be fed back to all neuron circuits of the neural network, depending on whether the chip is used in a single or multi-chip environment via a feed-back bus (OR-BUS). The feedback signal is the result of a collective processing of all the local output signals. """,Neural semiconductor chip and neural networks incorporated therein
"The disclosure concerns neural networks designed specially for the classification of objects represented by vectors X. If the vectors X include several parameters and if the objects have to be classified in a large number N of classes, the end result is a very large number of interconnections which become difficult to set up physically, are slow in their operation and require lengthy learning phases. The disclosed neural classification system has the particular feature of being constituted on the basis of P neural networks each individually carrying out the classification of objects in only two classes or, at any rate, in a small number of classes only. These networks give probabilities P.sub.i,j of membership in a class C.sub.i among two classes C.sub.i and C.sub.j. The outputs of these networks are connected to a signal processing module which, through simple functions (implementing linear combinations of the outputs and non-linear standardization functions) establishes, on N outputs, results P.sub.i (X) of classification among the N classes. The learning is done on classifications by pairs of classes, but the post-learning recognition gives classifications among N classes.",Neural system of classification and classification method using such a system
"Various neural-network based surrogate model construction methods are disclosed herein, along with various applications of such models. Designed for use when only a sparse amount of data is available (a sparse data condition), some embodiments of the disclosed systems and methods: create a pool of neural networks trained on a first portion of a sparse data set; generate for each of various multi-objective functions a set of neural network ensembles that minimize the multi-objective function; select a local ensemble from each set of ensembles based on data not included in said first portion of said sparse data set; and combine a subset of the local ensembles to form a global ensemble. This approach enables usage of larger candidate pools, multi-stage validation, and a comprehensive performance measure that provides more robust predictions in the voids of parameter space.",Neural-network based surrogate model construction methods and applications thereof
"A computer-aided training system uses electroencephalograms (EEGs) recorded from the trainee's scalp to alter the training protocol being presented by the computer, for example to present a new task to the trainee when he or she has mastered and automatized the current task. The index of the trainee's skill mastery and automatization is determined by analysis of the EEG using mathematical classification functions which distinguish different levels of skill acquisition. The functions are computed by computer neural networks and consist of a combination of EEG and other physiological variables which specifically characterize a trainee's level of focused attention and neurocognitive workload and his or her neurocognitive strategy. The functions are derived either for a group of trainees, or each trainee individually, performing a battery of one or more standard training tasks while wearing an EEG hat.",Neurocognitive adaptive computer-aided training method and system
"An adaptive process control system selectively controls vibrations in a given medium in real time. Unwanted vibrations present at a point being monitored in a given medium are sensed, and the system generates an appropriate offsetting vibration that is applied to the medium at a convenient location, which may be remote from the monitored point. The system includes a vibration sensor, such as one or more accelerometers, that sense both input and output vibrations present within the medium; at least one vibration generator, such as an electromagnetic shaker, that generates appropriate offsetting vibrations that are applied to the medium at one or more appropriate locations; and a neural network controller that controls the vibration generator(s) so as to force the sensed vibration at the monitored point(s) to a desired level. The adaptive vibration cancellation provided by the invention takes place in real time, and without the need to process time-consuming complex mathematical algorithms. A specific embodiment of the neural network controller includes a plurality of 4-layer neural networks configured in an adaptive filtered-x configuration.",Neurocontrolled adaptive process control system
"An adaptive process control system selectively controls vibrations in a given medium in real time. Unwanted vibrations present at a point being monitored in a given medium are sensed, and the system generates an appropriate offsetting vibration that is applied to the medium at a convenient location, which may be remote from the monitored point. The system includes a vibration sensor, such as one or more accelerometers, that sense both input and output vibrations present within the medium; at least one vibration generator, such as an electromagnetic shaker, that generates appropriate offsetting vibrations that are applied to the medium at one or more appropriate locations; and a neural network controller that controls the vibration generator(s) so as to force the sensed vibration at the monitored point(s) to a desired level. The adaptive vibration cancellation provided by the invention takes place in real time, and without the need to process time-consuming complex mathematical algorithms. A specific embodiment of the neural network controller includes a plurality of 4-layer neural networks configured in an adaptive filtered-x configuration.",Neurocontrolled adaptive process control system
"A hardware-implemented method for proofreading updates of connections in a hardware artificial neural network (hANN) includes computing a draft weight change independently at a connection between neuroids and at a corresponding dedicated special purpose nousoid, determining whether the draft weight changes agree, and executing a weight change at the connection equal to the draft weight change upon determining that the draft weight changes agree.",Neuromorphic device for proofreading connection adjustments in hardware artificial neural networks
"This invention solves the long-standing problem in Machine Learning of training a neural network on a spike-based neuromorphic computer. The preferred embodiment of the invention describes an algorithm for training a Restricted Boltzmann Machine (RBM) neural network, but the invention applies equally to training neural networks in the general class of Markov Random Fields. The standard CD algorithm for training an RBM on a general-purpose computer is unsuitable for implementation on a neuromorphic computer, as it requires the communication of real-valued parameter values between neurons, and/or shared memory access by neurons to stored parameter values. By employing the invention described, these requirements are eliminated, thus providing a training algorithm which can be implemented efficiently on a spike-based, distributed processor and memory, neuromorphic computer system.",Neuromorphic training algorithm for a Restricted Boltzmann Machine
"The improved neuron is connected to input buses which transport input data and control signals. It basically consists of a computation block, a register block, an evaluation block and a daisy chain block. All these blocks, except the computation block substantially have a symmetric construction. Registers are used to store data: the local norm and context, the distance, the AIF value and the category. The improved neuron further needs some R/W memory capacity which may be placed either in the neuron or outside. The evaluation circuit is connected to an output bus to generate global signals thereon. The daisy chain block allows to chain the improved neuron with others to form an artificial neural network (ANN). The improved neuron may work either as a single neuron (single mode) or as two independent neurons (dual mode). In the latter case, the computation block, which is common to the two dual neurons, must operate sequentially to service one neuron after the other. The selection between the two modes (single/dual) is made by the user which stores a specific logic value in a dedicated register of the control logic circuitry in each improved neuron.",Neuron architecture having a dual structure and neural networks incorporating the same
"Artificial neural networks (ANNs) are a distributed computing model in which computation is accomplished using many simple processing units (called neurons) and the data embodied by the connections between neurons (called synapses) and the strength of these connections (called synaptic weights). An attractive implementation of ANNs uses the conductance of non-volatile memory (NVM) elements to code the synaptic weight. In this application, the non-idealities in the response of the NVM (such as nonlinearity, saturation, stochasticity and asymmetry in response to programming pulses) lead to reduced network performance compared to an ideal network implementation. Disclosed is a method that improves performance by implementing a learning rate parameter that is local to each synaptic connection, a method for tuning this local learning rate, and an implementation that does not compromise the ability to train many synaptic weights in parallel during learning.","Neuron-centric local learning rate for artificial neural networks to increase performance, learning rate margin, and reduce power consumption"
"A neuronal phase-locked loop (NPLL) that can decode temporally-encoded information and convert it to a rate code is based on an algorithm similar to that of the electronic PLL, but is a stochastic device, implemented by neural networks (real or simulated). The simplest embodiment of the NPLL includes a phase detector (that is, a neuronal-plausible version of an ideal coincidence detector) and a controllable local oscillator that are connected in a negative feedback loop. The phase detector compares the firing times of the local oscillator and the input and provides an output whose firing rate is monotonically related to the time difference. The output rate is fed back to the local oscillator and forces it to phase-lock to the input. Every temporal interval at the input is associated with a specific pair of output rate and time difference values; the higher the output rate the further the local oscillator is driven from its intrinsic frequency. Sequences of input intervals, which, by definition, encode input information, are thus represented by sequences of firing rates at the NPLL's output. The NPLL is an adaptive device which can deal with signals whose exact characteristics are not known in advance and can adapt to changing conditions.",Neuronal phase-locked loops
"Constructing and simulating artificial neural networks and components thereof within a spreadsheet environment results in user friendly neural networks which do not require algorithmic based software in order to train or operate. Such neural networks can be easily cascaded to form complex neural networks and neural network systems, including neural networks capable of self-organizing so as to self-train within a spreadsheet, neural networks which train simultaneously within a spreadsheet, and neural networks capable of autonomously moving, monitoring, analyzing, and altering data within a spreadsheet. Neural networks can also be cascaded together in self training neural network form to achieve a device prototyping system.",Non-algorithmically implemented artificial neural networks and components thereof
"Constructing and simulating artificial neural networks and components thereof within a spreadsheet environment results in user friendly neural networks which do not require algorithmic based software in order to train or operate. Such neural networks can be easily cascaded to form complex neural networks and neural network systems, including neural networks capable of self-organizing so as to self-train within a spreadsheet, neural networks which train simultaneously within a spreadsheet, and neural networks capable of autonomously moving, monitoring, analyzing, and altering data within a spreadsheet. Neural networks can also be cascaded together in self training neural network form to achieve a device prototyping system.",Non-algorithmically implemented artificial neural networks and components thereof
"Sound processing techniques using recurrent neural networks are described. In one or more implementations, temporal dependencies are captured in sound data that are modeled through use of a recurrent neural network (RNN). The captured temporal dependencies are employed as part of feature extraction performed using nonnegative matrix factorization (NMF). One or more sound processing techniques are performed on the sound data based at least in part on the feature extraction.",Non-negative matrix factorization regularized by recurrent neural networks for audio processing
"A system and method of forecasting space weather (at Earth or another location) based on identifying complex patterns in solar, interplanetary, or geophysical data. These data may include current or historical measurements and/or modeled data (predicted or simulated). Data patterns (both non-event and event-related) are identified (even when another event is occurring). Such patterns may vary with recent/cyclic variations in solar (e.g. solar max/min), interplanetary, or geophysical activity. Embodiments are built around: (1) templates, (2) expert systems, (3) neural networks, (4) hybrid systems comprising combinations of (1), (2) and/or (3), and multimodal intelligent systems. Forecasts are customized and/or updated as new data arise and as systems are dynamically modified (e.g. via feedback between system parts). Numerical or other indexes are generated representing: forecasts, associated confidence levels, etc. The invention predicts events/non-events and/or other values or parameters associated with space weather (e.g. Dst, event onset time, duration, etc.).",Non-space weather prediction and notification system and method
"The present invention successfully combines neural-net discriminative feature processing with Gaussian-mixture distribution modeling (GMM). By training one or more neural networks to generate subword probability posteriors, then using transformations of these estimates as the base features for a conventionally-trained Gaussian-mixture based system, substantial error rate reductions may be achieved. The present invention effectively has two acoustic models in tandemfirst a neural net and then a GMM. By using a variety of combination schemes available for connectionist models, various systems based upon multiple features streams can be constructed with even greater error rate reductions.",Nonlinear mapping for feature extraction in automatic speech recognition
"Electronic communications can be normalized using neural networks. For example, an electronic representation of a noncanonical communication can be received. A normalized version of the noncanonical communication can be determined using a normalizer including a neural network. The neural network can receive a single vector at an input layer of the neural network and transform an output of a hidden layer of the neural network into multiple values that sum to a total value of one. Each value of the multiple values can be a number between zero and one and represent a probability of a particular character being in a particular position in the normalized version of the noncanonical communication. The neural network can determine the normalized version of the noncanonical communication based on the multiple values. Whether the normalized version should be output can be determined based on a result from a flagger including another neural network.",Normalizing electronic communications using a neural-network normalizer and a neural-network flagger
"A numeric encoding method and apparatus for neural networks, encodes numeric input data into a form applicable to an input of a neural network by partitioning a binary input into N-bit input segments, each of which is replaced with a code having M adjacent logic ones and 2.sup.N -1 logic zeros, the bit position of the least significant of the M logic ones corresponding to the binary value of the input segment it replaces. The codes are concatenated to form an encoded input. A decoding method decodes an output from the neural network into a binary form by partitioning the output into output segments having 2.sup.N +M-1 bits each, each of which is replaced with an N-bit binary segment being a bracketed weighted average of the significances of logic ones present in the output segment. The binary segments are concatenated to form a decoded output.",Numeric encoding method and apparatus for neural networks
"A deep learning object detection and recognition system contains a number of cellular neural networks (CNN) based integrated circuits (ICs) operatively coupling together via the network bus. The system is configured for detecting and then recognizing one or more objects out of a two-dimensional (2-D) imagery data. The 2-D imagery data is divided into N set of distinct sub-regions in accordance with respective N partition schemes. CNN based ICs are dynamically allocated for extracting features out of each sub-region for detecting and then recognizing an object potentially contained therein. Any two of the N sets of sub-regions overlap each other. N is a positive integer. Object detection is achieved with a two-category classification using a deep learning model based on approximated fully-connected layers, while object recognition is performed using a local database storing feature vectors of known objects.",Object detection and recognition apparatus based on CNN based integrated circuits
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating object detection predictions from a neural network. In some implementations, an input characterizing a first region of an environment is obtained. The input includes a projected laser image generated from a three-dimensional laser sensor reading of the first region, a camera image patch generated from a camera image of the first region, and a feature vector of features characterizing the first region. The input is processed using a high precision object detection neural network to generate a respective object score for each object category in a first set of one or more object categories. Each object score represents a respective likelihood that an object belonging to the object category is located in the first region of the environment.",Object detection neural networks
"Different candidate windows in an image are identified, such as by sliding a rectangular or other geometric shape of different sizes over an image to identify portions of the image (groups of pixels in the image). The candidate windows are analyzed by a set of convolutional neural networks, which are cascaded so that the input of one convolutional neural network layer is based on the input of another convolutional neural network layer. Each convolutional neural network layer drops or rejects one or more candidate windows that the convolutional neural network layer determines does not include an object (e.g., a face). The candidate windows that are identified as including an object (e.g., a face) are analyzed by another one of the convolutional neural network layers. The candidate windows identified by the last of the convolutional neural network layers are the indications of the objects (e.g., faces) in the image.",Object detection using cascaded convolutional neural networks
"Different candidate windows in an image are identified, such as by sliding a rectangular or other geometric shape of different sizes over an image to identify portions of the image (groups of pixels in the image). The candidate windows are analyzed by a set of convolutional neural networks, which are cascaded so that the input of one convolutional neural network layer is based on the input of another convolutional neural network layer. Each convolutional neural network layer drops or rejects one or more candidate windows that the convolutional neural network layer determines does not include an object (e.g., a face). The candidate windows that are identified as including an object (e.g., a face) are analyzed by another one of the convolutional neural network layers. The candidate windows identified by the last of the convolutional neural network layers are the indications of the objects (e.g., faces) in the image.",Object detection using cascaded convolutional neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for detecting objects in images. One of the methods includes receiving an input image. A full object mask is generated by providing the input image to a first deep neural network object detector that produces a full object mask for an object of a particular object type depicted in the input image. A partial object mask is generated by providing the input image to a second deep neural network object detector that produces a partial object mask for a portion of the object of the particular object type depicted in the input image. A bounding box is determined for the object in the image using the full object mask and the partial object mask.",Object detection using deep neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for identifying an object from a video. One of the methods includes obtaining multiple frames from a video, where each frame of the multiple frames depicts an object to be recognized, and processing, using an object recognition model, the multiple frames to generate data that represents a classification of the object to be recognized.",Object recognition from videos using recurrent neural networks
An odor discrimination method and device for an electronic nose system including olfactory pattern classification based on a binary spiking neural network with the capability to handle many sensor inputs in a noise environment while recognizing a large number of potential odors. The spiking neural networks process a large number of inputs arriving from a chemical sensor array and implemented with efficient use of chip surface area.,Odor discrimination using binary spiking neural network
"The present disclosure relates to artificial intelligence based systems and method for determination of traffic violations. The present disclosure provides systems and methods that use deep convolutional neural networks and machine vision based algorithms to perform a task of detection and recognition to provide complete solution to safe, legal and comfortable parking, driving and riding for commuters on the roadways. Roadway stewardship systems, Parking management systems when made on-demand and crowdsourced, can play a very strong role in regulating driving conditions in cities and highways. By allowing the on-demand, crowdsourced, roadway stewardship system to be automated, through the use of Artificial Intelligence (AI) sub-systems, users can be trained to recognize and be educated as well in the laws & regulations around the use of roadways; can help the process through an interactive console/game-play, which can also be used for monetization for individuals to earn money for their contribution. The AI assisted with Human Intelligence (HI) together called HAI in particular, can play a valuable role in reducing traffic density, traffic movement restrictions and fuel and time waste in large cities. Also proper driving on the roads can lead to faster and safer commute. In Addition, multiple other objects of interest can also be identified and trained to be recognized using the Stewardship System disclosed herein.",On-demand artificial intelligence and roadway stewardship system
"A circuit for implementing a neural network comprises a one dimensional systolic array of processing elements controlled by a microprocessor. The one dimensional systolic array can implement weighted sum and radial based type networks including neurons with a variety of different activation functions. Pipelined processing and partitioning is used to optimize data flows in the systolic array. Accordingly, the inventive circuit can implement a variety of neural networks in a very efficient manner.",One dimensional systolic array architecture for neural network
"An architecture and design of compact neural networks is presented for the maximum-likelihood sequence estimation (MLSE) of one-dimensional signals, such as sound, in digital communications. Optimization of a concave Lyapunov function associated with a compact neural network performs a combinatorial minimization of the detection cost, and truly paralleled operations in the analog domain are achievable via the collective computational behaviors. In addition, the MLSE performance can be improved by paralleled hardware annealing, a technique for obtaining optimal or near-optimal solutions in high-speed, real-time applications. For a sequence of length n, the network of complexity and throughput rate are O(L) and n/T.sub.c, respectively, where L is the number of symbols the inference spans and T.sub.c is the convergence time. The hardware architecture as well as network models, neuron models, and methods of feeding the input to the network are addressed in terms of the probability of error.",One-dimensional signal processor with optimized solution capability
"A method, computer readable medium, and system are disclosed for detecting and classifying hand gestures. The method includes the steps of receiving an unsegmented stream of data associated with a hand gesture, extracting spatio-temporal features from the unsegmented stream by a three-dimensional convolutional neural network (3DCNN), and producing a class label for the hand gesture based on the spatio-temporal features.",Online detection and classification of dynamic gestures with recurrent convolutional neural networks
"Methods and systems for online incremental adaptation of neural networks using Gaussian mixture models in speech recognition are described. In an example, a computing device may be configured to receive an audio signal and a subsequent audio signal, both signals having speech content. The computing device may be configured to apply a speaker-specific feature transform to the audio signal to obtain a transformed audio signal. The speaker-specific feature transform may be configured to include speaker-specific speech characteristics of a speaker-profile relating to the speech content. Further, the computing device may be configured to process the transformed audio signal using a neural network trained to estimate a respective speech content of the audio signal. Based on outputs of the neural network, the computing device may be configured to modify the speaker-specific feature transform, and apply the modified speaker-specific feature transform to a subsequent audio signal.",Online incremental adaptation of deep neural networks using auxiliary Gaussian mixture models in speech recognition
"A pyramidal pRAM neural network is used in an access control scheme for an ATM node, or other switch handling bursty traffic. Specifically, the neural network is a configured in a teacher forcing mode, and is trained either off-line or on-line. Cells arriving at the node, which are found to violate agreed quality of service parameters, may be dropped, depending on the expected state of the switch buffers, based on expected traffic arrival rates, but the control is adaptive, which means that violating cells may be allowed to gain access to the node, if the state of the switch allows it. Control is open-loop, which means that the response can be quicker.",Open loop adaptive access control of ATM networks using a neural network
"Aspects for supporting operation data of different bit widths in neural networks are described herein. The aspects may include a processing module that includes one or more processors. The processor may be capable of processing data of one or more respective bit-widths. Further, the aspects may include a determiner module configured to receive one or more instructions that include one or more operands and one or more width fields. The operands may correspond to one or more operand types and each of the width fields may indicate an operand bit-width of one operand type. The determiner module may be further configured to identify at least one operand bit-widths that is greater than each of the bit-widths. In addition, the aspects may include a processor combiner configured to designate a combination of two or more of the processors to process the operands.","Operation unit, method and device capable of supporting operation data of different bit widths"
"An automated speech recognition system converts a speech signal into a compact, coded representation that correlates to a speech phoneme set. A number of different neural network pattern matching schemes may be used to perform the necessary speech coding. An integrated user interface guides a user unfamiliar with the details of speech recognition or neural networks to quickly develop and test a neural network for phoneme recognition. To train the neural network, digitized voice data containing known phonemes that the user wants the neural network to ultimately recognize are processed by the integrated user interface. The digitized speech is segmented into phonemes with each segment being labelled with a corresponding phoneme code. Based on a user selected transformation method and transformation parameters, each segment is transformed into a series of multiple dimension vectors representative of the speech characteristics of that segment. These vectors are iteratively presented to a neural network to train/adapt that neural network to consistently distinguish and recognize these vectors and assign an appropriate phoneme code to each vector. Simultaneous display of the digitized speech, segments, vector sets, and a representation of the trained neural network assist the user in visually confirming the acceptability of the phoneme training set. A user may also selectively audibly confirm the acceptability of the digitization scheme, the segments, and the transform vectors so that satisfactory training data are presented to the neural network. If the user finds a particular step or parameter produces an unacceptable result, the user may modify one or more of the parameters and verify whether the modification effected an improvement in performance. The trained neural network is also automatically tested by presenting a test speech signal to the integrated user interface and observing both audibly and visually automatic segmentation of the speech, transformation into multidimensional vectors, and the resulting neural network assigned phoneme codes. A method of decoding such phoneme codes using the neural network is also disclosed.",Operator interactions for developing phoneme recognition by neural networks
"An analog signal having a value A is converted into an n-bit digital signal. An optical calculation part performs a part of a calculation shown below for an A/D conversion as below. EQU U.sub.i =[{{.SIGMA.(W.sub.ij .times.X.sub.j)+h.sub.i }.times.V}+A].times.Si . . . (1) The calculation of the equation (1) is performed for PA0 i=0, 1, . . . , n-1 respectively; PA0 the W.sub.ij is 0 if i.gtoreq.j.gtoreq.0, or -(2**j) if j>i.gtoreq.0; hi is -(2**i), or -{(2**i)-.epsilon.}(.vertline..epsilon..vertline..ltoreq.1); PA0 V and S.sub.i respectively have any desired positive values and the said .SIGMA. represents a summation of each expression following thereto for j=0, 1, . . . , n-1. The thresholding compares the result U.sub.i of the calculation of each equation (1) to a threshold value, and then 1 or 0 is selected. The result of the selection is then assigned to X.sub.i. The calculation of the equation (1) is then performed repeatedly until X.sub.i converge on solutions. The solution of each X.sub.i is then provided as digital values of the n-bit digital signal.",Optical A/D conversion using asymmetrical-neural-networks
"An optical neural network stores optical transmission weightings as angularly and spatially distributed gratings within a phase conjugate mirror (PCM), the PCM using a stimulated process to generate a phase conjugated return beam without separate external pump mechanisms. An error signal is generated in response to differences between the actual and a desired output optical pattern, and is used to adjust the PCM gratings toward the desired output. One or more intermediate image planes may be employed along with the input and output planes. The input and intermediate planes, as well as the error signal, are preferably displayed on the surface of a spatial light modulator. The output optical signal is transduced into an electrical format for training the neural network; with the error signal also generated electrically. A significant increase in neuron and interconnection capacity is realized, without cross-talk between neurons, compared to prior optical neural networks.",Optical neural network and method
Optical solutions for self regulating neural networks are carried out by ee processors. Two use the nonlinearity of devices such as a phosphor screen and nonlinear cladding of optical fibers whereby the nonlinear regulating process is carried out. The third is accomplished by a ring cavity having a damped inhibitory loop where the signals are combined 180.degree. out of phase.,Optical neuromorphic embodiments of self-regulating neural networks
"A system for performing optical pattern recognition includes a first detector neural network for detecting the presence of a particular optical pattern in an input image and a second locator neural network for locating and/or removing the particular optical pattern from the input image. The detector network and the locator network both comprise nodes which can take on the -1, +1, or undefined states. The nodes are arranged in layers and each node in a layer has a location corresponding to a pixel in the input image. A particular application of this neural network is in finding the amount field on a check and removing the line which borders the amount field.",Optical pattern recognition using detector and locator neural networks
"The present invention discloses low noise, optically coupled optoelectronic and all-optical artificial neuron devices that can be configured in an array to simulate the function of biological neural networks, and methods for making the artificial neurons. In a first optoelectronic embodiment, the device employs the regenerative pulsation property of astable multivibrators as optical pulse generators. A photosensitive detector, disposed in a circuit to control the state of an astable or bistable multivibrator, converts the intensity of the input light into a train of light pulses having a frequency that is a function of the intensity of the input signal. In an all-optical embodiment of an artificial neuron, an input signal is first integrated and the integrated signal transmitted to an optical pulse generator comprised of a nonlinear material disposed within the cavity of a Fabry-Perot etalon. The output of the etalon is a train of light pulses having a frequency that depends upon the intensity of the integrated input signal. When a weak light signal reaches the neuron's input port, there is no light pulse emitted from the output port. By contrast, a strong signal, or a group of weak signals, triggers a short-lived light pulse. The output pulse frequency is a function of the summed input signal power.",Optical pulse-coupled artificial neurons
"An optical vector multiplier can perform linear algebra calculations by using electro-optical modulators of sandwich-type construction or in liquid crystal fields such as occur, inter alia, in the case of neural networks. It can calculate linear algebra operations as rapidly as possible, although the matrix is represented by slow liquid crystal fields. In addition, it can also use the transposed matrix, can calculate the vector product of two vectors and store the resultant matrix of the vector product directly in the region of the matrix modulator cells. To this end, two rapid electro-optical modulators of sandwich-type construction, representing a vector, are disposed offset by 90.degree. and a matrix-shaped optical modulator that represents the matrix follows this arrangement. The vector modulator arrangement that is offset by 90.degree. can form the vector product of two vectors, the result being determined by a detector matrix whose detectors are located on the matrix modulator of each modulator cell. Thus the information can be stored locally there and processed.",Optical vector multiplier for neural networks
"A system, method, and process for configuring iterative, self-correcting algorithms, such as neural networks, so that the weights or characteristics to which the algorithm converge to do not require the use of test or validation sets, and the maximum error in failing to achieve optimal cessation of training can be calculated. In addition, a method for internally validating the correctness, i.e. determining the degree of accuracy of the predictions derived from the system, method, and process of the present invention is disclosed.",Optimal cessation of training and assessment of accuracy in a given class of neural networks
"A method and apparatus is provided for processing a measurement process to estimate a signal process, even if the signal and/or measurement processes have large and/or expanding ranges. The method synthesizes training data comprising realizations of the signal and measurement processes into a primary filter for estimating the signal process and, if required, an ancillary filter for providing the primary filter's estimation error statistics. The primary and ancillary filters each comprise an artificial recurrent neural network (RNN) and at least one range extender or reducer. Their implementation results in the filtering apparatus. Many types of range extender and reducer are disclosed, which have different degrees of effectiveness and computational cost. For a neural filter under design, range extenders and/or reducers are selected from those types jointly with the architecture of the RNN in consideration of the filtering accuracy, the RNN size and the computational cost of each selected range extender and reducer so as to maximize the cost effectiveness of the neural filter. The aforementioned synthesis is performed through training RNNs together with range extenders and/or reducers.",Optimal filtering by neural networks with range extenders and/or reducers
"A method and an apparatus are disclosed for processing a measurement process to estimate a signal process. The method synthesizes realizations of a signal process and a measurement process into a primary filter for estimating the signal process and, if required, an ancillary filter for providing the primary filter's estimation error statistics. Both the primary and the ancillary filters are made out of artificial recurrent neural networks (RNNs). Their implementation results in the filtering apparatus. The synthesis is performed through training RNNs. The weights/parameters and initial dynamic state of an RNN are determined by minimizing a training criterion by the variation of the same. The training criterion, which is constructed on the basis of a selected estimation error criterion, incorporates the aforementioned realizations. An alternative way to determine the initial dynamic state of an RNN is to simply set it equal to a canonical initial dynamic state. After adequate training, both the primary and the ancillary filters are recursive filters optimal for the given respective RNN architectures with the lagged feedbacks carrying the optimal conditional statistics. If appropriate RNN paradigms and estimation error criteria are selected, the primary and the ancillary filters of such paradigms are proven to approximate the respective optimal filters in performance (with respect to the selected estimation error criteria) to any desired degree of accuracy, provided that the RNNs that constitute the primary and ancillary filters are of sufficient sizes.",Optimal filtering by recurrent neural networks
An artificial neural network is disclosed that processes holography generated characteristic patterns of vibrating structures along with finite-element models. The present invention provides for a folding operation for conditioning training sets for optimally training forward-neural networks to process characteristic fringe patterns. The folding pattern increases the sensitivity of the feed-forward network for detecting changes in the characteristic pattern. The folding routine manipulates input pixels so as to be scaled according to the location in an intensity range rather than the position in the characteristic pattern.,Optimization of training sets for neural-net processing of characteristic patterns from vibrating solids
Neural network architectures are represented by symbol strings. An initial population of networks is trained and evaluated. The strings representing the fittest networks are modified according to a genetic algorithm and the process is repeated until an optimized network is produced.,Optimized artificial neural networks
"Certain embodiments involve generating or optimizing a neural network for risk assessment. The neural network can be generated using a relationship between various predictor variables and an outcome (e.g., a condition's presence or absence). The neural network can be used to determine a relationship between each of the predictor variables and a risk indicator. The neural network can be optimized by iteratively adjusting the neural network such that a monotonic relationship exists between each of the predictor variables and the risk indicator. The optimized neural network can be used both for accurately determining risk indicators using predictor variables and determining adverse action codes for the predictor variables, which indicate an effect or an amount of impact that a given predictor variable has on the risk indicator. The neural network can be used to generate adverse action codes upon which consumer behavior can be modified to improve the risk indicator score.",Optimizing neural networks for risk assessment
"A system and method for training a neural network that ceases training at or near the optimally trained point is presented. A neural network having an input layer, a hidden layer, and an output layer with each layer having one or more nodes is presented. Each node in the input layer is connected to each node in the hidden layer and each node in the hidden layer is connected to each node in the output layer. Each connection between nodes has an associated weight. All nodes in the input layer are connected to a different historical datum from the set of historical data. The neural network being operative by outputting a prediction or classification, the output of the output layer nodes, when presented with input data. The weights associated with the connections of the neural network are first adjusted by a training device. The training device then iteratively applies a training set to the neural network, the training set consisting of historical data. After each iteration the weights associated with the connections are adjusted according to the difference between the prediction or classification produced by the neural network given the training data and the known prediction or classification of the historical data. Additionally, after each iteration, a test set, consisting of different historical data from that in the training set, is presented to the neural network. The training device then determines the difference between the known result from the test set and the result from the presentation of the test set to the neural network. This difference, herein referred to as the variance, is then recorded along with the weights in the neural network. The variance is monitored at each iteration to determine if it is monotonically, within a given margin of error, decreasing. That is the prediction or classification resulting from the test set being presented to the neural network is getting successively closer to matching the known result from the test set. When the variance hits the inflection point where it begins to increase, training is ceased. At this point the neural network is no longer learning the pattern underlying the input data, but is instead over fitting the input data.",Optimum cessation of training in neural networks
"A neural network for processing sensory information. The network comprise one or more layers including interconnecting cells having individual states. Each cell is connected to one or more neighboring cells. Sensory signals and signals from interconnected neighboring cells control a current or a conductance within a cell to influence the cell's state. In some embodiments, the current or conductance of a cell can be controlled by a signal arising externally of the layer. Each cell can comprise an electrical circuit which receives an input signal and causes a current corresponding to the signal to pass through a variable conductance. The conductance is a function of the states of the one or more interconnecting neighboring cells. Proper interconnection of the cells on a layer can produce a neural network which is sensitive to predetermined patterns or the passage of such patterns across a sensor array whose signals are input into the network. The layers in the network can be made sensitive to distinct sensory parameters, so that networks which are sensitive to different wavelengths or polarizations of light energy can be produced.",Optoelectronic sensory neural network
"According to some aspects, a method of classifying speech recognition results is provided, using a neural network comprising a plurality of interconnected network units, each network unit having one or more weight values, the method comprising using at least one computer, performing acts of providing a first vector as input to a first network layer comprising one or more network units of the neural network, transforming, by a first network unit of the one or more network units, the input vector to produce a plurality of values, the transformation being based at least in part on a plurality of weight values of the first network unit, sorting the plurality of values to produce a sorted plurality of values, and providing the sorted plurality of values as input to a second network layer of the neural network.",Order statistic techniques for neural networks
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for organizing trained and untrained neural networks. In one aspect, a neural network device includes a collection of node assemblies interconnected by between-assembly links, each node assembly itself comprising a network of nodes interconnected by a plurality of within-assembly links, wherein each of the between-assembly links and the within-assembly links have an associated weight, each weight embodying a strength of connection between the nodes joined by the associated link, the nodes within each assembly being more likely to be connected to other nodes within that assembly than to be connected to nodes within others of the node assemblies.",Organizing neural networks
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for organizing trained and untrained neural networks. In one aspect, a neural network device includes a collection of node assemblies interconnected by between-assembly links, each node assembly itself comprising a network of nodes interconnected by a plurality of within-assembly links, wherein each of the between-assembly links and the within-assembly links have an associated weight, each weight embodying a strength of connection between the nodes joined by the associated link, the nodes within each assembly being more likely to be connected to other nodes within that assembly than to be connected to nodes within others of the node assemblies.",Organizing neural networks
"The neural computing paradigm is characterized as a dynamic and highly parallel computationally intensive system typically consisting of input weight multiplications, product summation, neural state calculations, and complete connectivity among the neurons. Herein is described neural network architecture called SNAP which uses a unique intercommunication scheme within an array structure that provides high performance for completely connected network models such as the Hopfield model. SNAP's packaging and expansion capabilities are addressed, demonstrating SNAP's scalability to larger networks. Each neuron generating a neuron value from a selected set of input function elements and communicating said neuron value back to said set of input function elements. The total connectivity of each neuron to all neurons is accomplished by an orthogonal row-column relationship of neurons where a given multiplier element operates during a first cycle as a row element within an input function to a column neuron, and during a second cycle as a column element within an input function to a row neuron.",Orthogonal row-column neural processor
"This application discloses a neural network that also functions as a connection oriented packet data network using an MPLS-type label switching technology. The neural network uses its intelligence to build and manage label switched paths (LSPs) to transport user packets and solve complex mathematical problems. However, the methods taught here can be applied to other data networks including ad-hoc, mobile, and traditional packet networks, cell or frame-switched networks, time-slot networks and the like.",Packet data neural network system and method
A recognition system comprises at least two field-programmable logic array devices connected to a common vector-input port of an array of a zero-instruction-set computers. Each field-programmable logic array device is configured to preprocess data from different respective media inputs and provide feature extraction vectors to the common vector-input port. Neural networks within the zero-instruction-set computer recognize the input patterns by comparing in parallel their vectors with those stored in each neural network cell. A variety of recognition jobs are made possible by changing the programming on-the-fly of the field-programmable logic array devices to suit each new job.,Parallel associative learning memory for a standalone hardwired recognition system
"In a parallel multi-value neural network having a main neural network 16 and a sub neural network 18 coupled with the main neural network 16 in parallel for an input signal, the main neural network 16 is trained with a training input signal by using a main multi-value teacher signal, and the sub neural network is successively trained with the training input signal by using multi-value errors between a multi-value output signal of the main neural network 16 derived through a multi-value threshold means 17 and the main multi-value teacher signal, so as to compensate the multi-value errors involved in the multi-value output signal of the main neural network 16 by the multi-value output signal of the sub neural network 18 derived through a multi-value threshold means 19. A desired multi-value output signal of the parallel multi-value neural network 15 is obtained by adding in modulo the multi-value output signals of both the neural networks through a multi-value modulo adder 20.",Parallel multi-value neural networks
A method for performing the addition of two N-bit binary numbers using palel neural networks. The value of a first register is converted and transferred into a second register in a mathematical fashion so as to add the numbers of the first register into the second register. When the first register contains all zeros then the desired sum is found in the second register.,Parallel neural network for a full binary adder
"A data processing system is provided that consists of a connection of a first neural network (N.sub.1) with at least one other neural network (N.sub.21, N.sub.22, . . . , N.sub.2n). The first neural network (N.sub.1) and the at least one other neural network (N.sub.21, N.sub.22, . . . , N.sub.2n) is an associative memory. First input data (E.sub.0) are supplied to both the first neural network (N.sub.1) and also to at least the one other neural network (N.sub.21, N.sub.22, . . . , N.sub.2n) Data (E.sub.11, E.sub.12, . . . , E.sub.1n) which are evaluated by at least the one other neural network (N.sub.21, N.sub.22, . . . , N.sub.2n), are supplied as further input data (E.sub.1) to the first neural network (N.sub.1).",Parallel neural networks having one neural network providing evaluated data to another neural network
A parallel convolutional neural network is provided. The CNN is implemented by a plurality of convolutional neural networks each on a respective processing node. Each CNN has a plurality of layers. A subset of the layers are interconnected between processing nodes such that activations are fed forward across nodes. The remaining subset is not so interconnected.,Parallelizing neural networks during training
"A heuristic approach to configuration and/or planning for wireless networks is disclosed herein. In one embodiment, statistics relating to mobile device cell usage are collected and monitored. The statistics may include UE measurements (RSRP/RSRQ), UE location, number of connection requests, duration of connectivity, average traffic load associated with the users, channel utilization, and other statistics. Based on statistical analysis of the data collected, neural network analysis, data fitting, or other analysis, adjustments to cell coverage parameters such as handover thresholds, inactivity timer values, contention window size, inter-frame duration, transmit power, DRX cycle duration, or other parameters may be identified.",Parameter optimization and event prediction based on cell heuristics
"A device, system, and method for approximating a neural network comprising N synapses or filters. The neural network may be partially-activated by iteratively executing a plurality of M partial pathways of the neural network to generate M partial outputs, wherein the M partial pathways respectively comprise M different continuous sequences of synapses or filters linking an input layer to an output layer. The M partial pathways may cumulatively span only a subset of the N synapses or filters such that a significant number of the remaining the N synapses or filters are not computed. The M partial outputs of the M partial pathways may be aggregated to generate an aggregated output approximating an output generated by fully-activating the neural network by executing a single instance of all N synapses or filters of the neural network. Training or prediction of the neural network may be performed based on the aggregated output.",Partial activation of multiple pathways in neural networks
"This invention comprises a method for generating functional neural networks using neural progenitor cells on microelectrode arrays (MEAs). The method involves dissociating neural progenitor cells from an embryo, propagating the neural progenitor cells, passaging the neural progenitor cells and seeding the neural progenitor cells on MEAs to produce a functional neural network. The neural progenitor cells may be continuously passaged to propagate an endless supply of neural progenitor cells. The resultant passaged progenitor cell derived neural network MEA may be used to detect and/or quantify various biological or chemical toxins.",Passaged neural stem cell-derived neuronal networks as sensing elements for detection of environmental threats
"A method and apparatus (system) is provided for the separation into and the identification of classes of events wherein each of the events is represented by a signal vector comprising the signals x1, x2, . . . , xj, . . . , xn. The system in principle is different from neural networks and statistical classifiers. The system comprises a plurality of assemblies. The training or adaptation module stores a set of training examples and has a set of procedures (linear programming, clustering and others) that operate on the training examples and determine a set of transfer function and threshold values. These transfer functions and threshold values are installed on a recognized module for use in the identification phase. The training module is extremely fast and can deal with very difficult pattern classification problems that arise in speech and image recognition, robotics, medical diagnosis, warfare systems and others. The systems also exploits parallelism in both the learning and recognition phases.",Pattern classification using linear programming
"A bill-recognition apparatus includes a neural network having a learning capability and performs high-efficiency pattern recognition of seven kinds of U.S. dollar bills. Pattern image data optically inputted through a sensor is compressed using plurality of column masks, and then a plurality of values representative of images (slab values) are determined. The image data is divided into a large number of strip-shaped segments, and some of theses segments are masked with column areas of masks. The values representative of images compressed through column masks are not influenced by a slight inclination of the pattern image during the reading operation. These values representative of images are inputted to a separation processing unit (neural network). From these values, the separation processing unit calculates separation values corresponding to respective decision patterns associated with pattern images, using weights which have been adjusted to optimum values for respective decision patterns. A correct pattern image is determined from the maximum value of the separation values. The above arrangement allows for a reduction in scale of the neural network and control system. Furthermore, bill recognition may also be achieved by separation processing using a plurality of small-scaled neural networks connected in cascade, or replacing weight functions in the same neural network and performing separation processing a plurality of times for the same slab values (cascade processing). In this way, it is possible to reduce the scale of the neural network and the control system.",Pattern recognition apparatus and method of optimizing mask for pattern recognition according to genetic algorithm
"A pattern recognition apparatus includes a pattern input unit inputting pattern data and learning data, and a neural network system including a plurality of neural networks, each of the plurality of neural networks being assigned a corresponding one of a plurality of identification classes and having only two output units of a first unit (Uo1) and a second unit (Uo2). Learning for each of the plurality of neural networks is performed by using the learning data. The image recognition apparatus also includes judgment unit judging which one of the identification classes the pattern data input from the image reading unit belongs to on the basis of output values A and B from the two output units (Uo1) and (Uo2) of all neural networks.",Pattern recognition apparatus using a neural network system
Apparatus and method for replacing the traditional amplifications by rime delays in a neural network that can be trained to analyze temporally-related patterns. Time delays comprise the synapses between feeder and stimulus cells in the network. The result is a multi-temporal trainable delay neural network.,Pattern recognition by simulated neural-like networks
"A pattern recognition device having modifiable feature detectors (28) which respond to a transduced input signal (26) and communicate a feature activity signal (30) to allow classification and an appropriate output action (70). A memory (40) stores a set of comparison patterns, and is used by an assigner (66) to find likely features, or parts, in the current input signal (26). Each part is assigned to a feature detector (28[m]) judged to be responsible for it. An updater (42) modifies each responsible feature detector (28[m]) so as to make its preferred feature more similar to its assigned part. The modification embodies a strong constraint on the feature learning process, in particular an assumption that the ideal features for describing the pattern domain occur independently. This constraint allows improved learning speed and potentially improved scaling properties. A first preferred embodiment uses a group of noisy-OR type neural networks (50) to implement the feature detectors (28) and memory (40), and to obtain the parts by a soft segmentation of the current input signal (26). A second preferred embodiment maintains a lossless memory (40) separate from the feature detectors (28), and the parts consist of differences between the current input signal (26) and comparison patterns stored in the memory (40).",Pattern recognizer with independent feature learning
"A pattern searching method using neural networks and correlation. This method combines the quickness and adaptiveness of neural networks with the accuracy of the mathematical correlation approach. Images are divided into small sub-images which are presented to the trained neural network. Sub-images that may contain the pattern or partial pattern are selected by the neural network. The neural network also provides the approximate location of the pattern, therefore the selected sub-images can be adjusted to contain the complete pattern. Desired patterns can be located by measuring the new sub-images' correlation values against the reference models in a small area. Experiments show that this superior method is able to find the desired patterns. Moreover, this method is much faster than traditional pattern searching methods which use only correlation.",Pattern searching method using neural networks and correlation
"A pattern searching method using neural networks and correlation. This method combines the quickness and adaptiveness of neural networks with the accuracy of the mathematical correlation approach. Images are divided into small sub-images which are presented to the trained neural network. Sub-images that may contain the pattern or partial pattern are selected by the neural network. The neural network also provides the approximate location of the pattern, therefore the selected sub-images can be adjusted to contain the complete pattern. Desired patterns can be located by measuring the new sub-images' correlation values against the reference models in a small area. Experiments show that this superior method is able to find the desired patterns. Moreover, this method is much faster than traditional pattern searching methods which use only correlation.",Pattern searching method using neural networks and correlation
"A processing element (PE) of a systolic array can perform neural networks computations in parallel on two or more sequential data elements of an input data set using the same weight. Thus, two or more output data elements corresponding to an output data set may be generated in parallel. Based on the size of the input data set and an input data type, the systolic array can process a single data element or multiple data elements in parallel.",Performing concurrent operations in a processing element
A likelihood of detecting a reflected signal characterized by phase discontinuities and background noise is enhanced by utilizing neural networks to identify coherency intervals. The received signal is processed into a predetermined format such as a digital time series. Neural networks perform different tests over arbitrary testing intervals to determine the likelihood of a phase discontinuity occurring in any such interval. An integration time generator subsequently uses this information to define a series of contiguous coherency intervals over the duration of the received signal. These coherency intervals are then used for piece-wise processing of the received signal by parallel quadrature receivers. The outputs are combined and processed for detecting the presence of the reflected signal.,Phase detection using neural networks
"Various implementations disclosed herein include an expert-assisted phoneme recognition neural network system configured to recognize phonemes within continuous large vocabulary speech sequences without using language specific models (left-context), look-ahead (right-context) information, or multi-pass sequence processing, and while operating within the resource constraints of low-power and real-time devices. To these ends, in various implementations, an expert-assisted phoneme recognition neural network system as described herein utilizes a-priori phonetic knowledge. Phonetics is concerned with the configuration of the human vocal tract while speaking and acoustic consequences on vocalizations. While similar sounding phonemes are difficult to detect and are frequently misidentified by previously known neural networks, phonetic knowledge gives insight into what aspects of sound acoustics contain the strongest contrast between similar sounding phonemes. Utilizing features that emphasize the respective second formants allows for more robust sound discrimination between these problematic phonemes.",Phoneme-expert assisted speech recognition and re-synthesis
"A method for generating three-dimensional facial models and photorealistic textures from inferences using deep neural networks relies upon generating a low frequency and a high frequency albedo map of the full and partial face, respectively. Then, the high frequency albedo map may be used for comparison with correlation matrices generated by a neural network trained by a large scale, high-resolution facial dataset with simulated partial visibility. The corresponding correlation matrices of the complete facial textures can then be retrieved. Finally, a full facial texture map may be synthesized, using convex combinations of the correlation matrices. A photorealistic facial texture for the three-dimensional face rendering can be obtained through optimization using the deep neural network and a loss function that incorporates the blended target correlation matrices.",Photorealistic facial texture inference using deep neural networks
A nonlinear signal mapper that can implement any continuous one-to-one nonlinear map of baseband or intermediate-frequency digital signals. The mapping method follows a &#8220;divide-and-conquer&#8221; approach in that a nonlinear map to be implemented is piecewise decomposed into a set of simpler nonlinear component maps. The component maps are implemented using code-enabled feed-forward neural networks (FF-NNs). Each code-enabled feed-forward neural network only operates on samples of a digital input signal that lie in a specified interval of the real-valued number line. Code-enabled FF-NNs are controlled by codewords produced by a scalar quantization encoder. The quantization encoder also controls a multiplexer that directs values produced by the FF-NNs to the nonlinear mapper's output.,Piecewise nonlinear mapper for digitals
"Described is a system for adapting neural networks. The system receives inputs to be learned by a multi-layered spiking neural network. A first mechanism is implemented to adapt weights on the connections via competition among neurons using Hebbian learning. Activity levels of the neurons are stabilized to allow the multi-layered spiking neural network to learn the inputs. A second mechanism is implemented to increase a learning rate of a neuron over time using Hebbian learning. A third mechanism is implemented, wherein newly created neurons, representing new inputs, copy at least one synaptic structure of older neurons in the multi-layered spiking neural network. The mechanisms are used for continuous, online learning of the inputs to the multi-layered spiking neural network. An autonomous system, such as an autonomous vehicle, can use the learned inputs to learn from its environment and perform tasks, such as classification and prediction.",Plastic neural networks
"A neural network structure includes input units for receiving input data, and a plurality of neural networks connected in parallel and connected to the input units. The plurality of neural networks learn in turn correspondence between the input data and teacher data so that the difference between the input data and the teacher becomes small. The neural network structure further includes output units connected to the plurality of neural networks, for outputting a result of learning on the basis of the results of learning in the plurality of neural networks.",Plural neural network system having a successive approximation learning method
"Technology is disclosed for inferring human attributes from images of people. The attributes can include, for example, gender, age, hair, and/or clothing. The technology uses part-based models, e.g., Poselets, to locate multiple normalized part patches from an image. The normalized part patches are provided into trained convolutional neural networks to generate feature data. Each convolution neural network applies multiple stages of convolution operations to one part patch to generate a set of fully connected feature data. The feature data for all part patches are concatenated and then provided into multiple trained classifiers (e.g., linear support vector machines) to predict attributes of the image.",Pose-aligned networks for deep attribute modeling
"Technology is disclosed for inferring human attributes from images of people. The attributes can include, for example, gender, age, hair, and/or clothing. The technology uses part-based models, e.g., Poselets, to locate multiple normalized part patches from an image. The normalized part patches are provided into trained convolutional neural networks to generate feature data. Each convolution neural network applies multiple stages of convolution operations to one part patch to generate a set of fully connected feature data. The feature data for all part patches are concatenated and then provided into multiple trained classifiers (e.g., linear support vector machines) to predict attributes of the image.",Pose-aligned networks for deep attribute modeling
"A face recognition system and process for identifying a person depicted in an input image and their face pose. This system and process entails locating and extracting face regions belonging to known people from a set of model images, and determining the face pose for each of the face regions extracted. All the extracted face regions are preprocessed by normalizing, cropping, categorizing and finally abstracting them. More specifically, the images are normalized and cropped to show only a person's face, categorized according to the face pose of the depicted person's face by assigning them to one of a series of face pose ranges, and abstracted preferably via an eigenface approach. The preprocessed face images are preferably used to train a neural network ensemble having a first stage made up of a bank of face recognition neural networks each of which is dedicated to a particular pose range, and a second stage constituting a single fusing neural network that is used to combine the outputs from each of the first stage neural networks. Once trained, the input of a face region which has been extracted from an input image and preprocessed (i.e., normalized, cropped and abstracted) will cause just one of the output units of the fusing portion of the neural network ensemble to become active. The active output unit indicates either the identify of the person whose face was extracted from the input image and the associated face pose, or that the identity of the person is unknown to the system.",Pose-invariant face recognition system and process
"A face recognition system and process for identifying a person depicted in an input image and their face pose. This system and process entails locating and extracting face regions belonging to known people from a set of model images, and determining the face pose for each of the face regions extracted. All the extracted face regions are preprocessed by normalizing, cropping, categorizing and finally abstracting them. More specifically, the images are normalized and cropped to show only a persons face, categorized according to the face pose of the depicted person's face by assigning them to one of a series of face pose ranges, and abstracted preferably via an eigenface approach. The preprocessed face images are preferably used to train a neural network ensemble having a first stage made up of a bank of face recognition neural networks each of which is dedicated to a particular pose range, and a second stage constituting a single fusing neural network that is used to combine the outputs from each of the first stage neural networks. Once trained, the input of a face region which has been extracted from an input image and preprocessed (i.e., normalized, cropped and abstracted) will cause just one of the output units of the fusing portion of the neural network ensemble to become active. The active output unit indicates either the identify of the person whose face was extracted from the input image and the associated face pose, or that the identity of the person is unknown to the system.",Pose-invariant face recognition system and process
"A face recognition system and process for identifying a person depicted in an input image and their face pose. This system and process entails locating and extracting face regions belonging to known people from a set of model images, and determining the face pose for each of the face regions extracted. All the extracted face regions are preprocessed by normalizing, cropping, categorizing and finally abstracting them. More specifically, the images are normalized and cropped to show only a persons face, categorized according to the face pose of the depicted person's face by assigning them to one of a series of face pose ranges, and abstracted preferably via an eigenface approach. The preprocessed face images are preferably used to train a neural network ensemble having a first stage made up of a bank of face recognition neural networks each of which is dedicated to a particular pose range, and a second stage constituting a single fusing neural network that is used to combine the outputs from each of the first stage neural networks. Once trained, the input of a face region which has been extracted from an input image and preprocessed (i.e., normalized, cropped and abstracted) will cause just one of the output units of the fusing portion of the neural network ensemble to become active. The active output unit indicates either the identify of the person whose face was extracted from the input image and the associated face pose, or that the identity of the person is unknown to the system.",Pose-invariant face recognition system and process
"A potential estimation apparatus estimates a potential of a photosensitive body of an image forming apparatus that carries out an electro-photography process using the photosensitive body. The potential estimation apparatus includes a sensor group for sensing and outputting data related to information which affects the electro-photography process, a storage unit for at least storing the data output from the sensor group and information related to charge of the photosensitive body, and an estimation circuit including a neural network for estimating a charged portion potential of the photosensitive body based on a charge retentivity of the photosensitive body learned by the neural network. The neural network in a learning mode receives at least one of the data output from the sensor group and time-sequentially sampled, and parameters which affect the charge retentivity of the photosensitive body as an input, and receives as a teaching value a charged portion potential which is obtained in advance with respect to at least an amount of charge and the charge retentivity of the photosensitive body.",Potential estimating apparatus using a plurality of neural networks for carrying out an electrographic process
"A potential estimation apparatus estimates a potential of a photosensitive body of an image forming apparatus that carries out an electro-photography process using the photosensitive body. The potential estimation apparatus includes a sensor group for sensing and outputting data related to information which affects the electro-photography process, a storage unit for at least storing the data output from the sensor group and information related to charge of the photosensitive body, and an estimation circuit including a neural network for estimating a charged portion potential of the photosensitive body based on a charge retentivity of the photosensitive body learned by the neural network. The neural network in a learning mode receives at least one of the data output from the sensor group and time-sequentially sampled, and parameters which affect the charge retentivity of the photosensitive body as an input, and receives as a teaching value a charged portion potential which is obtained in advance with respect to at least an amount of charge and the charge retentivity of the photosensitive body.",Potential estimating apparatus using a plurality of neural networks for carrying out an electrophotographic process
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for predicting likelihoods of conditions being satisfied using recurrent neural networks. One of the systems is configured to process a temporal sequence comprising a respective input at each of a plurality of time steps and comprises: one or more recurrent neural network layers; one or more logistic regression nodes, wherein each of the logistic regression nodes corresponds to a respective condition from a predetermined set of conditions, and wherein each of the logistic regression nodes is configured to, for each of the plurality of time steps: receive the network internal state for the time step; and process the network internal state for the time step in accordance with current values of a set of parameters of the logistic regression node to generate a future condition score for the corresponding condition for the time step.",Predicting likelihoods of conditions being satisfied using recurrent neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for predicting likelihoods of conditions being satisfied using recurrent neural networks. One of the systems is configured to process a temporal sequence comprising a respective input at each of a plurality of time steps and comprises: one or more recurrent neural network layers; one or more logistic regression nodes, wherein each of the logistic regression nodes corresponds to a respective condition from a predetermined set of conditions, and wherein each of the logistic regression nodes is configured to, for each of the plurality of time steps: receive the network internal state for the time step; and process the network internal state for the time step in accordance with current values of a set of parameters of the logistic regression node to generate a future condition score for the corresponding condition for the time step.",Predicting likelihoods of conditions being satisfied using recurrent neural networks
A method of predicting the outcome of a patient with neuroblastoma that includes obtaining experimental data on gene selections. The gene selection functions to predict the outcome of a patient with neuroblastoma when the expression of that gene selection is compared to the identical selection from a non-neuroblastoma cell or a different type of neuroblastoma cell. The invention also includes a method of targeting at least one product of a gene that includes administration of a therapeutic agent. The invention also includes the use of a gene selection for predicting the outcome of patient with neuroblastoma.,Prediction of clinical outcome using gene expression profiling and artificial neural networks for patients with neuroblastoma
"The invention relates to a diagnostic system which involves the use of a piece of observed information (5) coming from a process (1) monitored by a programmable automaton (10). The diagnostic system includes: an observation module (30) which collects, at input, the information observed (5) and delivers, at output, a piece of processed information (35) to a learning module (40); and a detection module (20) which collects, at input, the observed information (5) in order to apply a detection process (21) thereto including a diagnostic function (45), which comes from the learning module (40), in order to deliver a diagnostic result (25) at output. The observation module (30) and the detection module (20) are executed by the processing unit (11) of the programmable automaton (10) in the form of function units in accordance with standard IEC1131-3. The learning module (40) elaborates the diagnostic function (45) using an algorithm based on neural networks or on fuzzy logic.",Predictive diagnostic system in a programmable automaton
"Computer-implemented methods, articles of manufacture and computerized systems for identifying or alerting a user of certain data in electronic tax returns. A computerized tax return preparation system including a tax return preparation software application executed by a computing device receives first and second tax data and populates respective fields of the electronic tax return. The system executes a predictive model such as logistic regression, naive bayes, K-means clustering, clustering, k-nearest neighbor, and neural networks. First tax data is an input into the predictive model, which generates an output, which is compared with second tax data. An alert is generated when the second tax data does not satisfy pre-determined criteria relative to the first output generated by the predictive model. The same or other predictive model may be used as additional tax data is received for subsequent tax data analysis.",Predictive model based identification of potential errors in electronic tax return
"A data processing system and method for selecting securities and constructing an investment portfolio is based on a set of artificial neural networks which are designed to model and track the performance of each security in a given capital market and output a parameter which is related to the expected risk adjusted return for the security. Each artificial neural network is trained using a number of fundamental and price and volume history input parameters about the security and the underlying index. The system combines the expected return/appreciation potential data for each security via an optimization process to construct an investment portfolio which satisfies predetermined aggregate statistics. The data processing system receives input from the capital market and periodically evaluates the performance of the investment portfolio, rebalancing it whenever necessary to correct performance degradations.",Predictive neural network means and method for selecting a portfolio of securities wherein each network has been trained using data relating to a corresponding security
"Surfacing relevant and predictively trending digital entities to a user in a content feed is provided. Aspects of a predictive trending system use one or more predictive models, such as neural networks or regression models, to generate predictive trending scores of digital entities (e.g., documents, people, electronic communications, meetings, locations, digital images, digital videos, digital audio, etc.) based on historical scores and context. By taking into account trends and context, the predictive trending system calculates future trending scores of digital entities, and determines which digital entities are both relevant to a given user and likely to be trending around the user and the people in the user's network in the future. The predictive trending system curates the digital entities determined to be relevant and predicted to be trending around the user, and presents the digital entities in a content feed.",Predictive trending of digital entities
"In a disclosed method, a computing device receiver, from a wireless receiver (RX), first data indicative of channel properties of a first communication link between the wireless receiver (RX) in a first device and a wireless transmitter (TX) in a second device. The first device and the second device are located in a building. The computing device further executes a neural network to process the first data to distinguish humans from stationary objects within the building and detect presence of the human in the building. The computing device transmits result data indicative of the presence to at least one of the first device or the second device.",Presence detection with neural networks
"A system and method for tracking, monitoring and learning prisoner or parolee behavior involves obtaining prisoner or parolee data and monitoring data for at least one individual prisoner or parolee, storing the prisoner or parolee data and monitored data into a database, learning prisoner or parolee behavior from the prisoner or parolee data and the monitored data in the database, and updating the prisoner or parolee data and the monitored data in the database. Expert system (i.e. including but not limited to fuzzy logic, reinforcement learning, neural networks, artificial intelligence, etc.) algorithms are executed for determining and analyzing deviated behavior by the prisoner or parolee. A parole level is assigned to the prisoner or parolee and it is determined whether the prisoner or parolee is to be moved up or down a parole level depending on whether the prisoner or parolee behavior does not constitute or does constitute prisoner or parolee violations. Furthermore, the system tracks, monitors, and learns the behavior of the prisoner or parolee by controlling and regulating the permitted/prohibited locations or sectors, the permitted/prohibited location or sector dwell times, the permitted/prohibited travel routes, the permitted/prohibited travel times that the prisoner or parolee spends at or between various locations.",Prisoner tracking and warning system and corresponding methods
"The present invention discloses a general overall system 30 and a general overall method 10 for tracking, monitoring, and learning prisoner or parolee behavior. The system 30 and method 10 involve obtaining prisoner or parolee data and monitoring data for at least one individual prisoner or parolee 38, storing the prisoner or parolee data and monitoring data into a database, learning prisoner or parolee behavior from the prisoner or parolee data and the monitoring data in the database, and updating the prisoner or parolee data and the monitoring data in the database. The present invention involves learning both individual and aggregate prisoner or parolee behavior from the prisoner or parolee data and the monitoring data in the database. The present invention executes expert system (i.e. including but not limited to fuzzy logic, reinforcement learning, neural networks, artificial intelligence, etc.) algorithms for determining and analyzing deviated behavior by the prisoner or parolee 38. The present invention system 30 and method 10 is able to assign a parole level to the prisoner or parolee 38 and determine whether the prisoner or parolee 38 is to be moved up or down a parole level depending on whether the prisoner or parolee behavior does not constitute or does constitute prisoner or parolee violations. Furthermore, the present invention tracks, monitors, and learns the behavior of the prisoner or parolee 38 by controlling and regulating the permitted/prohibited locations or sectors, the permitted/prohibited location or sector dwell times, the permitted/prohibited travel routes, the permitted/prohibited travel times that the prisoner or parolee 38 spend at or between various locations.",Prisoner tracking and warning system and corresponding methods
"The present system performs linear transformations on input probabilities and produces outputs which indicate the likelihood of one or more events. The transformation performed is a product of linear transforms such as P.sub.o =[A.sub.j P.sub.j +B.sub.j ].multidot.[A.sub.k P.sub.k +B.sub.k ] where P.sub.j and P.sub.k are input probabilities, P.sub.o is an output event probability and A.sub.j, B.sub.j, A.sub.k and B.sub.k are transformation constants. The system includes a basic processing unit or computational unit which performs a probabilistic gate operation to convert two input probability signals into one output probability signal where the output probability is equal to the product of linear transformations of the input probabilities. By appropriate selection of transformation constants logical and probabilistic gates performing the functions of AND, NAND, OR, NOR, XOR, NOT, IMPLIES and NOT IMPLIES can be created. The basic unit can include three multipliers and two adders if a discrete component hardwired version is needed for speed or a single multiplier/adder, associated storage and multiplex circuits can be used to accomplish the functions of the hardwired version for economy. This basic unit can also be provided as a software implementation, can be implemented as a hardwired decision tree element implementation or implemented as a universal probabilistic processor and provided with a bus communication structure to create expert systems or neural networks suitable for specific tasks. The basic units can be combined to produce a virtual basic building block which has more virtual processors than physical processors to improve processor utilization. The building blocks can be combined into an array to produce either a high speed expert system or a high speed neural network.",Probabilistic inference gate
"The present disclosure proposes a method of moving object detection in variable bit-rate video steams based on probabilistic neural networks, and the method features a background generation module and a moving object detection module. The background generation module produces a model of background images which express properties of variable bit-rate video streams. The moving object detection module distinguishes a moving object in both low and high bit-rate video steams in an efficient manner. The detection result is generated by calculating the output value of the probabilistic neural networks.",Probabilistic neural network based moving object detection method and an apparatus using the same
"A statistical process, and system for implementing the process, is described for the analysis of stress waves generated in operating machinery or equipment. This technique is called Probabilistic Stress Wave Analysis. The process is applied to a population of individual feature values extracted from a digitized time waveform (such as a 2 second Stress Wave Pulse Train, or a 2 month history of Stress Wave Energy). Certain numeric descriptors of the statistical distributions of computed features are then employed as inputs to decision making routines (such as neural networks or simple threshold testing) to accurately classify the condition represented by the original time waveform data, and thereby determine a status of the operating machine/equipment.",Probabilistic stress wave analysis system and method
"More realistic neural networks are disclosed that are able to learn to solve complex problems though a decision making network, modeled as a virtual entity foraging in a digital environment. Specifically, the neural networks overcome many of the limitations in prior neural networks by using rewarded STDP bounded with rules to solve a complex problem.",Problem solving by plastic neuronal networks
"A neural network is provided for equalizing distorted data signals. The data signal to be equalized is coupled via time-delay elements to a group of networks for weighting. The output signals of the networks for weighting are coupled to the input terminals of a plurality of neurons whose outputs are coupled, via a respective amplifier, to input terminals of a further neuron having an output terminals where the equalized data signal can be tapped.",Procedure for equalizing distorted data signals
"A process is stated with which ADALINE-type neural networks whose inputs are Boolean variables can be realized using Boolean functions. In addition, a purely digital circuit arrangement for realizing ADALINE-type neural networks is stated. The digital circuit arrangement can be constructed with the aid of a digital base circuit. The digital base circuit generates the set of Boolean functions which replaces a neuron for any value of its input weighting factors. A process for training the circuit arrangement is stated. It is thus possible to realize and to train ADALINE-type neural networks entirely with the aid of purely digital circuit arrangements.",Process and arrangement for the Boolean realization of adaline-type neural networks
"Customizable neural network in which one or more resistors form each synapse. All the resistors in the synaptic array are identical, thus simplifying the processing issues. Highly doped, amorphous silicon is used as the resistor material, to create extremely high resistances occupying very small spaces. Connected in series with each resistor in the array is at least one severable conductor whose uppermost layer has a lower reflectivity of laser energy than typical metal conductors at a desired laser wavelength.",Process for forming synapses in neural networks and resistor therefor
"A method and a system applying data mining techniques and artificial intelligence algorithms, namely neural networks, operating via an Internet data exchange site, allowing portfolio management companies to access an on-line, standardized questionnaire (Request for Proposal) and present their capabilities. The method then analyses a large number of these questionnaires and classifies managers, categorizing them and ranking their capabilities. In addition, sponsors such as pension funds, endowments, and private clients can submit their offer for the management of their assets. The site provides a Request for Proposal that is modular and continuously adapted to new financial market conditions, legal considerations and Sponsors needs. Once completed by each manager, the questionnaire is maintained in a central database allowing each manager to have an up-to-date and on-line version of questionnaire. The site allows the manager to have access to offers for new mandates in an easier and more efficient way than the old approach that involves approaching each potential Sponsor individually in a time and money consuming manner. The site provides Sponsors the opportunity to request proposals for their mandate from a much higher number of management companies, thus increasing dramatically the efficiency and rationality of their final choice of managers.",Process of selecting portfolio managers based on automated artificial intelligence techniques
""" A process control system uses a performance model, in conjunction with an economic model, to meet either performance or economic objectives. The system operates either automatically, on-line, in """"real time"""" or manually off-line, in """"real time"""" to optimize the process to meet a selected objective. The performance model uses neural networks to determine the interrelationships of each of a set of independent variables (controllable inputs to the process) to each other and their relationship to a set of dependent variables (outputs of the process). The performance model is used to optimize the process to meet performance objectives. The economic model is used in conjunction with the performance model to meet economic objectives. """,Process optimization and control system that plots inter-relationships between variables to meet an objective
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating phoneme representations of acoustic sequences using projection sequences. One of the methods includes receiving an acoustic sequence, the acoustic sequence representing an utterance, and the acoustic sequence comprising a respective acoustic feature representation at each of a plurality of time steps; for each of the plurality of time steps, processing the acoustic feature representation through each of one or more long short-term memory (LSTM) layers; and for each of the plurality of time steps, processing the recurrent projected output generated by the highest LSTM layer for the time step using an output layer to generate a set of scores for the time step.",Processing acoustic sequences using long short-term memory (LSTM) neural networks that include recurrent projection layers
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating phoneme representations of acoustic sequences using projection sequences. One of the methods includes receiving an acoustic sequence, the acoustic sequence representing an utterance, and the acoustic sequence comprising a respective acoustic feature representation at each of a plurality of time steps; for each of the plurality of time steps, processing the acoustic feature representation through each of one or more long short-term memory (LSTM) layers; and for each of the plurality of time steps, processing the recurrent projected output generated by the highest LSTM layer for the time step using an output layer to generate a set of scores for the time step.",Processing acoustic sequences using long short-term memory (LSTM) neural networks that include recurrent projection layers
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing cell images using neural networks. One of the methods includes obtaining data comprising an input image of one or more biological cells illuminated with an optical microscopy technique; processing the data using a stained cell neural network; and processing the one or more stained cell images using a cell characteristic neural network, wherein the cell characteristic neural network has been configured through training to receive the one or more stained cell images and to process the one or more stained cell images to generate a cell characteristic output that characterizes features of the biological cells that are stained in the one or more stained cell images.",Processing cell images using neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for image processing using deep neural networks. One of the methods includes receiving data characterizing an input image; processing the data characterizing the input image using a deep neural network to generate an alternative representation of the input image, wherein the deep neural network comprises a plurality of subnetworks, wherein the subnetworks are arranged in a sequence from lowest to highest, and wherein processing the data characterizing the input image using the deep neural network comprises processing the data through each of the subnetworks in the sequence; and processing the alternative representation of the input image through an output layer to generate an output from the input image.",Processing images using deep neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for image processing using deep neural networks. One of the methods includes receiving data characterizing an input image; processing the data characterizing the input image using a deep neural network to generate an alternative representation of the input image, wherein the deep neural network comprises a plurality of subnetworks, wherein the subnetworks are arranged in a sequence from lowest to highest, and wherein processing the data characterizing the input image using the deep neural network comprises processing the data through each of the subnetworks in the sequence; and processing the alternative representation of the input image through an output layer to generate an output from the input image.",Processing images using deep neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for image processing using deep neural networks. One of the methods includes receiving data characterizing an input image; processing the data characterizing the input image using a deep neural network to generate an alternative representation of the input image, wherein the deep neural network comprises a plurality of subnetworks, wherein the subnetworks are arranged in a sequence from lowest to highest, and wherein processing the data characterizing the input image using the deep neural network comprises processing the data through each of the subnetworks in the sequence; and processing the alternative representation of the input image through an output layer to generate an output from the input image.",Processing images using deep neural networks
"A system and method for processing machine learning techniques (such as neural networks) and other non-graphics applications using a graphics processing unit (GPU) to accelerate and optimize the processing. The system and method transfers an architecture that can be used for a wide variety of machine learning techniques from the CPU to the GPU. The transfer of processing to the GPU is accomplished using several novel techniques that overcome the limitations and work well within the framework of the GPU architecture. With these limitations overcome, machine learning techniques are particularly well suited for processing on the GPU because the GPU is typically much more powerful than the typical CPU. Moreover, similar to graphics processing, processing of machine learning techniques involves problems with solving non-trivial solutions and large amounts of data.",Processing machine learning techniques using a graphics processing unit
"Structured documents are processed using convolutional neural networks. One of the methods includes receiving a rendered form of a structured document; mapping a grid of cells to the rendered form; assigning a respective numeric embedding to each cell in the grid, comprising, for each cell: identifying content in the structured document that corresponds to a portion of the rendered form that is mapped to the cell, mapping the identified content to a numeric embedding for the identified content, and assigning the numeric embedding for the identified content to the cell; generating a matrix representation of the structured document from the numeric embeddings assigned to the cells of the grids; and generating neural network features of the structured document by processing the matrix representation of the structured document through a subnetwork comprising one or more convolutional neural network layers.",Processing structured documents using convolutional neural networks
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for neural machine translation. In one aspect, a system is configured to receive an input sequence of source embeddings representing a source sequence of words in a source natural language and to generate an output sequence of target embeddings representing a target sequence of words that is a translation of the source sequence into a target natural language, the system comprising: a dilated convolutional neural network configured to process the input sequence of source embeddings to generate an encoded representation of the source sequence, and a masked dilated convolutional neural network configured to process the encoded representation of the source sequence to generate the output sequence of target embeddings.",Processing text sequences using neural networks
"A processor has an instruction fetch unit that fetches ISA instructions from memory and execution units that perform operations on instruction operands to generate results according to the processor's ISA. A hardware neural network unit (NNU) execution unit performs computations associated with artificial neural networks (ANN). The NNU has an array of ALUs, a first memory that holds data words associated with ANN neuron outputs, and a second memory that holds weight words associated with connections between ANN neurons. Each ALU multiplies a portion of the data words by a portion of the weight words to generate products and accumulates the products in an accumulator as an accumulated value. Activation function units normalize the accumulated values to generate outputs associated with ANN neurons. The ISA includes at least one instruction that instructs the processor to write data words and the weight words to the respective first and second memories.",Processor with architectural neural network execution unit
"An analog synapse circuit for an artificial neural network requiring less circuitry and interconnections than prior synapses, while affording better weight programming means uses two complementary floating-gate MOSFETs with tunneling injection in an inverter configuration, with each MOSFET storing a weight value. This weight value is set by storing a charge injected by Fowler-Nordheim tunneling, or other tunneling means, into the floating-gate, which shifts the threshold voltage of the device. A programming line applies a current pulse to the MOSFET floating gate to write or erase this stored charge, thereby adjusting the weight of the MOSFET. The two MOSFETs are connected with the gate electrodes connected together and the drain electrodes connected together to provide a common gate and common drain between the two MOSFETs. An input line is connected to the common gate, and an output line is connected to the common drain. The source electrodes of each MOSFET are connected to reference voltages. The synapse circuit may be used in either a feedforword or feedback network, and may be expanded from two to four quadrant operation. The synapse provides a single output current line which represents a function of the input voltage and the stored weights. A plurality of such synapses may be configured in a network, wherein the output lines of each synapse are connected at a current summing node at the input of a neuron. An active load in the input of the neuron allows for both excitatory and inhibitory output current from the synapse circuit.",Programmable analog synapse and neural networks incorporating same
The pulsating behavioral activity of a neural network such as that embodied n a brain tissue slice is monitored by measurement of intervals between spontaneous events to identify the presence of a chaotic regime and determine by real-time calculation a waiting time for electrical pulse intervention pursuant to a behavioral modifying program having a control or anti-control strategy.,Pulsating behavior monitoring and modification system for neural networks
"Relatedness between genes is quantified by constructing nonlinear models predicting gene expression. Effectiveness of the model is evaluated to provide a measurement of the relatedness of genes associated with the model. Various types of models, including full-logic or neural networks can be constructed. A graphical user interface presents results of the analysis to allow evaluation by a user. Each gene's contribution to the measurement of relatedness can be shown on a graph, and graphical representations of models used to predict gene expression can be displayed.",Quantifying gene relatedness via nonlinear prediction of gene
"An apparatus for controlling a quantization step size for use in an encoder which divides one image frame into first blocks and encodes the divided first blocks and transmits the encoded data at a constant transmission rate. The apparatus includes a forward analyzer for detecting image complexity with respect to each first block to be quantized, a luminance analyzer for outputting a luminance value representative of each first block, a picture quality estimator for restoring quantized data by using a quantization step size corresponding to the quantized data and generating a judgement reference value corresponding to a minimum blocking effect which cannot be visually recognized on the basis of the restored data of every second block composed of first blocks, a buffer for storing the quantized data and outputting buffer occupancy of the stored data, a neural network having stored weight values which are updated according to the judgement reference value of the picture quality estimator with respect to the quantized previous second block and the stored update rule, generating a quantization step size for the present second block on the basis of the motion vectors, and/or the image complexity and/or the luminance values with respect to the present second block, the buffer occupancy and the updated weight values, and supplying the quantization step size to the picture quality estimator, and a quantizer for quantizing data of the second blocks encoded by the encoder according to a corresponding quantization step size supplied from the neural network.",Quantization step size control apparatus using neural networks
"Aspects of the disclosure provide a method for configuring a Quantum Annealing (QA) device. Then QA device has a plurality of qubits and a plurality of couplers at overlapping intersections of the qubits. The method includes mapping a node of a neural network that have a plurality of nodes and connections between the nodes to a qubit in the QA device, and mapping a connection of the neural network to a coupler at an intersection in the QA device where two qubits corresponding to two nodes connected by the connection intersect. The method further includes mapping a node of the neural network to a chain of qubits. In an embodiment, a coupling between qubits in the chain is configured to be a ferromagnetic coupling in order to map the node of the neural network to the chain of qubits.",Quantum-assisted training of neural networks
"In a radiation image processing method utilizing a neural network, an image signal representing a radiation image is fed into a neural network, image processing is carried out on the image signal by the neural network, and an output representing the results of the image processing is obtained from the neural network. Image processing, with respect to the whole region of the radiation image, is carried out on the image signal by a first group of neurons of an intermediate layer of the neural network. Image processing, with respect to parts of the region of the radiation image, is carried out on the image signal by a second group of neurons of the intermediate layer of the neural network. Regardless of set values of initial conditions, the output of the neural network becomes converged to a global minimum corresponding to the stored information, and the results of operation obtained from the neural network are not trapped at a local minimum.",Radiation image processing method utilizing neural networks
"Technologies are generally provided for methods and circuitry to rank a large number of cells in a timeframe of about one sense cycle. In some examples, an architecture may be implemented to rank memory cells such as volatile memories, non-volatile memories, and other types of data storage devices, where there may not be an equivalent to threshold voltage. In other examples, an arbitrary group of circuits, such as in neural networks where there may not be an equivalent control gate to set the timing resolution, may be ranked. Relative sense timing may be used to rank the cells having different current carrying abilities. A ramped gate voltage may be used to control the timing resolution and to reduce contention between close separate cells. Digital logic may be used to latch and/or record the rank information.",Rank determination
"Technologies are generally provided for methods and circuitry to rank a large number of cells in a timeframe of about one sense cycle. In some examples, an architecture may be implemented to rank memory cells such as volatile memories, non-volatile memories, and other types of data storage devices, where there may not be an equivalent to threshold voltage. In other examples, an arbitrary group of circuits, such as in neural networks where there may not be an equivalent control gate to set the timing resolution, may be ranked. Relative sense timing may be used to rank the cells having different current carrying abilities. A ramped gate voltage may be used to control the timing resolution and to reduce contention between close separate cells. Digital logic may be used to latch and/or record the rank information.",Rank determination of circuits with distinct current carrying capabilities
"This specification describes, among other things, a computer-implemented method. The method can include training a baseline neural network using a first set of training data. For each node in a subset of interconnected nodes in the baseline neural network, a rank-k approximation of a filter for the node can be computed. A subset of nodes in a rank-constrained neural network can then be initialized with the rank-k approximations of the filters from the baseline neural network. The subset of nodes in the rank-constrained neural network can correspond to the subset of nodes in the baseline neural network. After initializing, the rank-constrained neural network can be trained using a second set of training data while maintaining a rank-k filter topology for the subset of nodes in the rank-constrained neural network.",Rank-constrained neural networks
"A data processing system and method for solving pattern classification problems and function-fitting problems includes a neural network in which N-dimensional input vectors are augmented with at least one element to form an N+j-dimensional projected input vector, whose magnitude is then preferably normalized to lie on the surface of a hypersphere. Weight vectors of at least a lowest intermediate layer of network nodes are preferably also constrained to lie on the N+j-dimensional surface. To train the network, the system compares network output values with known goal vectors, and an error function (which depends on all weights and threshold values of the intermediate and output nodes) is then minimized. In order to decrease the network's learning time even further, the weight vectors for the intermediate nodes are initially preferably set equal to known prototypes for the various classes of input vectors. Furthermore, the invention also allows separation of the network into sub-networks, which are then trained individually and later recombined. The network is able to use both hyperspheres and hyperplanes to form decision boundaries, and, indeed, can converge to the one even if it initially assumes the other.",Rapidly converging projective neural network
"Neural networks may be used to determine and predict formation dip angles and perform quality assurance assessments from data collected with a multi-component induction tool used for well logging. The neural networks make use of corrected, rotated and normalized data to provide the predictions and assessments. Synthetic data using various models is used to train the neural networks. The teachings herein provide for real-time determinations with a substantial degree of accuracy in the results.",Real time data quality control and determination of formation angles from multicomponent induction measurements using neural networks
"Methods and systems for audio source separation in real-time are described. In an embodiment, the present disclosure describes reading and decoding an audio source into PCM samples, fragmenting Pulse Code Modulation (PCM) samples into fragments, transforming fragments into spectrograms, performing audio source separation using a deep neural network (DNN) to generate an estimated magnitude spectrogram of the component(s) of the audio source, reconstructing the estimated time domain component signals, and streaming the component signals to a playback engine. In an embodiment, a semantic equalizer graphical user allows for real-time mixing of individual component signals.",Real-time audio source separation using deep neural networks
"A drilling control system provides, in one aspect, advisory actions for optimal drilling. Such a system or model utilizes downhole dynamics data and surface drilling parameters, to produce drilling models used to provide to a human operator with recommended drilling parameters for optimized performance. In another aspect, the output of the drilling control system is directly linked with rig instrumentation systems so as to provide a closed-loop automated drilling control system that optimizes drilling while taking into account the downhole dynamic behavior and surface parameters. The drilling models can be either static or dynamic. In one embodiment, the simulation of the drilling process uses neural networks to estimate some nonlinear function using the examples of input-output relations produced by the drilling process.",Real-time drilling optimization based on MWD dynamic measurements
A generated algorithm used by a neural network is captured during execution of an iteration of the neural network. A candidate algorithm is identified based on the generated algorithm. A determination is made that the candidate algorithm utilizes less memory than the generated algorithm. Based on the determination the neural network is updated by replacing the generated algorithm with the candidate algorithm.,Real-time resource usage reduction in artificial neural networks
"A real-time waveform analysis system utilizes neural networks to perform various stages of the analysis. The signal containing the waveform is first stored in a buffer and the buffer contents transmitted to a first and second neural network which have been previously trained to recognize the start point and the end point of the waveform respectively. A third neural network receives the signal occurring between the start and end points and classifies that waveform as comprising either an incomplete waveform, a normal waveform or one of a variety of predetermined characteristic classifications. Ambiguities in the output of the third neural network are arbitrated by a fourth neural network which may be given additional information which serves to resolve these ambiguities. In accordance with the preferred embodiment, the present invention is applied to a system analyzing respiratory waveforms of a patient undergoing anesthesia and the classifications of the waveform correspond to normal or various categories of abnormal features functioning in the respiratory signal. The system performs the analysis rapidly enough to be used in realtime systems and can be operated with relatively low cost hardware and with minimal software development required.",Real-time waveform analysis using artificial neural networks
"A real-time waveform analysis system utilizes neural networks to perform various stages of the analysis. The signal containing the waveform is first stored in a buffer and the buffer contents transmitted to a first and second neural network which have been previously trained to recognize the start point and the end point of the waveform respectively. A third neural network receives the signal occurring between the start and end points and classifies that waveform as comprising either an incomplete waveform, a normal waveform or one of a variety of predetermined characteristic classifications. Ambiguities in the output of the third neural network are arbitrated by a fourth neural network which may be given additional information which serves to resolve these ambiguities. In accordance with the preferred embodiment, the present invention is applied to a system analyzing respiratory waveforms of a patient undergoing anesthesia and the classifications of the waveform correspond to normal or various categories of abnormal features functioning in the respiratory signal. The system performs the analysis rapidly enough to be used in real-time systems and can be operated with relatively low cost hardware and with minimal software development required.",Real-time waveform analysis using artificial neural networks
"A recognizing apparatus is provided for recognizing a class to which an inputted characteristic pattern belongs from among a plurality of classes to be discriminated using a neural network. The classes are classified into a plurality of categories. The apparatus includes a network selecting portion for selecting a category to which the inputted characteristic pattern belongs and for selecting a neural network for use in discriminating the class to which the inputted characteristic pattern belongs in the selected category. The apparatus further includes a network memory portion, a network setting portion and a details discriminating portion. The network memory portion stores structures of a plurality of neural networks which have finished learning for respective categories, weights of the neural networks set by the learning and a plurality of discriminating algorithms to be used when the classes are discriminated by the neural networks. The network setting portion sets the structure and weights of a neural network selected by the network selecting portion and a discriminating alogrithm appropriate to the selected category. The details discriminating portion recognizes the class to which the inputted characteristic pattern belongs by performing the details discriminating operation using the neural network set by the neural network setting portion.",Recognizing apparatus
"The present invention extends to methods, systems, and computer program products for recognizing input gestures. A neural network is trained using example inputs and backpropagation to recognize specified input patterns. Input gesture data is representative of movements in contact on a multi-touch input display surface relative to one or more axes over time. Example inputs used for training the neural network to recognize a specified input pattern can be created from sampling input gesture data for example input gestures known to represent the specified input pattern. Trained neural networks can subsequently be used to recognize input gestures that are similar to known input gestures as the specified input pattern corresponding to the known input gestures.","Recognizing input gestures using a multi-touch input device, calculated graphs, and a neural network with link weights"
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for recognizing speech using neural networks. One of the methods includes receiving an audio input; processing the audio input using an acoustic model to generate a respective phoneme score for each of a plurality of phoneme labels; processing one or more of the phoneme scores using an inverse pronunciation model to generate a respective grapheme score for each of a plurality of grapheme labels; and processing one or more of the grapheme scores using a language model to generate a respective text label score for each of a plurality of text labels.",Recognizing speech using neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for content recommendation using neural networks. One of the methods includes receiving context information for an action recommendation; processing the context information using a neural network that comprises one or more Bayesian neural network layers to generate, for each of the actions, one or more parameters of a distribution over possible action scores for the action and selecting an action from plurality of possible actions using the parameters of the distributions over the possible action scores for the action.",Recommending content using neural networks
"A reconfigurable neural network circuit is provided. The reconfigurable neural network circuit comprises an electronic synapse array including multiple synapses interconnecting a plurality of digital electronic neurons. Each neuron comprises an integrator that integrates input spikes and generates a signal when the integrated inputs exceed a threshold. The circuit further comprises a control module for reconfiguring the synapse array. The control module comprises a global final state machine that controls timing for operation of the circuit, and a priority encoder that allows spiking neurons to sequentially access the synapse array.",Reconfigurable and customizable general-purpose circuits for neural networks
"A reconfigurable neural network circuit is provided. The reconfigurable neural network circuit comprises an electronic synapse array including multiple synapses interconnecting a plurality of digital electronic neurons. Each neuron comprises an integrator that integrates input spikes and generates a signal when the integrated inputs exceed a threshold. The circuit further comprises a control module for reconfiguring the synapse array. The control module comprises a global final state machine that controls timing for operation of the circuit, and a priority encoder that allows spiking neurons to sequentially access the synapse array.",Reconfigurable and customizable general-purpose circuits for neural networks
"A reconfigurable neural network circuit is provided. The reconfigurable neural network circuit comprises an electronic synapse array including multiple synapses interconnecting a plurality of digital electronic neurons. Each neuron comprises an integrator that integrates input spikes and generates a signal when the integrated inputs exceed a threshold. The circuit further comprises a control module for reconfiguring the synapse array. The control module comprises a global final state machine that controls timing for operation of the circuit, and a priority encoder that allows spiking neurons to sequentially access the synapse array.",Reconfigurable and customizable general-purpose circuits for neural networks
"The present invention describes the use of autonomous devices, which can be arranged in networks, such as neural networks, to better identify, track, and acquire sources of signals present in an environment. The environment may be a physical environment, such as a battlefield, or a more abstract environment, such as a communication network. The devices may be mobile, in the form of vehicles with sensors, or may be information agents, and may also interact with one another, thus allowing for a great deal of flexibility in carrying out a task. In some cases, the devices may be in the form of autonomous vehicles which can collaboratively sense, identify, or classify a number of sources or targets concurrently. The autonomous devices may function as mobile agents or attractors in a network, such as a neural network. The devices may also be aggregated to form a network of networks and provide scalability to a system in which the autonomous devices are operating.",Reconfigurable autonomous device networks
"Systems and methods are disclosed for forming reconfigurable neural networks with interconnected FPGAs each having a packet router. Neural network nodes are formed within the FPGAs and connections between nodes within an FPGA and connections to nodes external to the FPGA are made using packet routers that are configured within each FPGA. The FPGAs can be connected to each other using high-speed interconnects, such as high-speed serial digital interconnects. The FPGA arrays with packet routing allow for dynamic and reconfigurable neural networks to be formed thereby greatly improving the performance and intelligence of the neural network.",Reconfigurable neural network systems and methods utilizing FPGAs having packet routers
"Using a recurrent neural network (RNN) that has been trained to a satisfactory level of performance, highly discriminative features can be extracted by running a sample through the RNN, and then extracting a final hidden state hi, where i is the number of instructions of the sample. This resulting feature vector may then be concatenated with the other hand-engineered features, and a larger classifier may then be trained on hand-engineered as well as automatically determined features. Related apparatus, systems, techniques and articles are also described.",Recurrent neural networks for malware analysis
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating a target sequence from a source sequence. In one aspect, the system includes a recurrent neural network configured to, at each time step, receive am input for the time step and process the input to generate a progress score and a set of output scores; and a subsystem configured to, at each time step, generate the recurrent neural network input and provide the input to the recurrent neural network; determine, from the progress score, whether or not to emit a new output at the time step; and, in response to determining to emit a new output, select an output using the output scores and emit the selected output as the output at a next position in the output order.",Recurrent neural networks for online sequence generation
"A teaching method for a recurrent neural network having hidden, output and input neurons calculates weighting errors over a limited number of propagations of the network. This process permits the use of conventional teaching sets, such as are used with feedforward networks, to be used with recurrent networks. The teaching outputs are substituted for the computed activations of the output neurons in the forward propagation and error correction stages. Back propagated error from the last propagation is assumed to be zero for the hidden neurons. A method of reducing drift of the network with respect to a modeled process is also described and a forced cycling method to eliminate the time lag between network input and output.",Recurrent neural networks teaching system
"Systems and methods for reducing the size of deep neural networks are disclosed. In an embodiment, a server computer stores a plurality of training datasets, each of which comprise a plurality of training input matrices and a plurality of corresponding outputs. The server computer initiates training of a deep neural network using the plurality of training input matrices, a weight matrix, and the plurality of corresponding outputs. While the training of the deep neural network is being performed, the server computer identifies one or more weight values of the weight matrix for removal. The server computer removes the one or more weight values from the weight matrix to generate a reduced weight matrix. The server computer then stores the reduced weight matrix with the deep neural network.",Reducing the size of a neural network through reduction of the weight matrices
"The present disclosure is drawn to the reduction of parameters in fully connected layers of neural networks. For a layer whose output is defined by y=Wx, where y is the output vector, x is the input vector, and W is a matrix of connection parameters, vectors uij and vij are defined and submatrices Wi,j are computed as the outer product of uij and vij, so that Wi,j=vijuij, and W is obtained by appending submatrices Wi,j.",Reduction of parameters in fully connected layers of neural networks
"Sentiment analyzer systems may include feedback analytics servers configured to receive and analyze feedback data from various client devices. Feedback data may be received and analyzed to determine feedback context and sentiment scores. In some embodiments, natural language processing neural networks may be used to determine sentiment scores for the feedback data. Feedback data also may be grouped into feedback aggregations based on context, and sentiment scores may be calculated for each feedback aggregation. Sentiment analyzer outputs and corresponding output devices may be determined based on the sentiment scores and feedback contexts.",Relativistic sentiment analyzer
"A system may comprise one or more processors and memory storing instructions that, when executed by one or more processors, configure one or more processors to perform a number of operations or tasks, such as receiving a query or a document, and mapping the query or the document into a lower dimensional representation by performing at least one operational layer that shares at least two disparate tasks.",Representation learning using multi-task deep neural networks
"Arithmetic circuits and methods that perform efficient matrix multiplication for hardware acceleration of neural networks, machine learning, web search and other applications are disclosed herein. Various arrays of multiplier-accumulators may be coupled to form a matrix multiplier which processes data using high precision, fixed point residue number arithmetic.",Residue number matrix multiplier
"Described herein are systems and methods for multimodal recurrent network processing. In an embodiment, a system for evaluating multimodal data comprising a multimodal data input and a multimodal processing module is described. The multimodal data input may comprise the multimodal data, the multimodal data may comprise a first modality and a second modality. The multimodal processing module may be configured to receive the multimodal data comprising the first modality and the second modality; evaluate the first modality using a first recursive neural network comprising a first transformation matrix; evaluate the second modality using a second recursive neural network comprising the first transformation matrix; and determine an output based, at least in part, on evaluating the first modality and the second modality.",RGB-D scene labeling with multimodal recurrent neural networks
"A road surface condition-detecting system for a vehicle detects a road surface condition from road noise generated by a vehicle wheel. The road surface condition is determined based on parameter data of frequency components of the road noise, by a neural network. The road noise may be corrected by eliminating therefrom a disturbance, such as audio output and exhaust noise. A present state of the road surface condition may be determined based on at least two consecutive determinations made based on the road noise detected at regular time intervals. Exclusive neural networks may be used for respective road surface condition types. One of a plurality of neural networks provided for respective vehicle speed ranges may be selected according to an actual vehicle speed. Detected sound pressure levels of the road noise extracted by frequency analysis may be normalized within respective ranges defined by upper and lower limits set corresponding to predetermined frequency ranges before being supplied to the neural network.",Road surface condition-detecting system and anti-lock brake system employing same
"System and method for detecting objects in geospatial images, 3D point clouds and Digital Surface Models (DSMs). Deep Convolution Neural Networks (DCNNs) are trained using positive and negative training examples. Using a rotation pattern match of only positive examples reduces the number of negative examples required. In DCNNs softmax probability is variant of rotation angles. When rotation angle is coincident with object orientation, softmax probability has maximum value. During training, positive examples are rotated so that their orientation angles are zero. During detection, test images are rotated through different angles. At each angle, softmax probability is computed. A final object detection is based on maximum softmax probability as well as a pattern match between softmax probability patterns of all positive examples and the softmax probability pattern of a target object at different rotation angles. The object orientation is determined at the rotation angle when softmax probability has maximum value.",Rotation variant object detection in Deep Learning
"Apparatus and methods for high-level neuromorphic network description (HLND) framework that may be configured to enable users to define neuromorphic network architectures using a unified and unambiguous representation that is both human-readable and machine-interpretable. The framework may be used to define nodes types, node-to-node connection types, instantiate node instances for different node types, and to generate instances of connection types between these nodes. To facilitate framework usage, the HLND format may provide the flexibility required by computational neuroscientists and, at the same time, provides a user-friendly interface for users with limited experience in modeling neurons. The HLND kernel may comprise an interface to Elementary Network Description (END) that is optimized for efficient representation of neuronal systems in hardware-independent manner and enables seamless translation of HLND model description into hardware instructions for execution by various processing modules.",Round-trip engineering apparatus and methods for neural networks
"Disclosed is an electronic control circuit of the fail-safe emergency shut-down type which includes an input circuit, a first signal processing circuit, in which information is stored beforehand relating to extreme values input signals are permitted to reach, and an output circuit. The first signal processing circuit includes at least one neural network configured from very large numbers of neurons operating as integrators and in real-time which operate in parallel and which are mutually connected on a large scale. The networks are implemented in hardware and the extreme values are distributed over the neurons. When one of the extreme values is exceeded, the output circuit generates a shut-off signal and a component controlled thereby is placed in a safe state.",Safe system provided with neural circuit
A text mining network that improves the performance of search engines by using a network of computer entities with autonomous neural networks. Each neural network provides a weighted list of associated search terms for each search query. The lists of associated search terms from two or more computer entities are merged to a unique list of associated search terms by utilization of a virtual index algorithm. Document result sets from the autonomous entities are merged to a unique result set by a weighted combination of two or more result sets.,Scalable associative text mining network and method
"The neural computing paradigm is characterized as a dynamic and highly computationally intensive system typically consisting of input weight multiplications, product summation, neural state calculations, and complete connectivity among the neurons. Herein is described neural network architecture for a Scalable Neural Array Process (SNAP) which uses a unique intercommunication scheme within an array structure that provides high performance for completely connected network models such as the Hopfield model. SNAP's packaging and expansion capabilities are addressed, demonstrating SNAP's scalability to larger networks. Each neuron of the processor has an input function element, an activity function element, and a communicating adder. The neuron functions with two state modes, a compute state and a communications state. In response to a compute state, the input function element and said activity function generate a neuron value, and the communicating adder is placed in a compute mode and is responsive to the processor compute state. In a communications state a neuron is responsive to a communications state for operating the communicating adder for communicating a neuron value to an input function element.",Scalable neural array processor
"An Array Processor and Method for a Scalable Array Neural Processor (SNAP) permits computing as a dynamic and highly parallel computationally intensive system typically consisting of input weight multiplications, product summation, neural state calculations, and complete connectivity among the neurons. The Scalable Neural Array Processor (SNAP) uses a unique intercommunication scheme within an array structure that provides high performance for completely connected network models such as the Hopfield model. SNAP's packaging and expansion capabilities are addressed, demonstrating SNAP's scalability to larger networks. The array processor is scalable. It has an array of function elements and a plurality of orthogonal horizontal and vertical processing elements for communication, computation and reduction. This structure permits in a first computation state the generation of a set of output values and in the first communication state the processing elements produce, responsive to the output values, first reduction values. In a second computation state processing elements, responsive to the first reduction values, generate vertical output values, and in a second computation state the vertical output values are communicated back to the inputs of the function elements. Responsive to a third computation state responsive to the vertical output values, a second set of output values is generated by said function elements, and in a third communication state the horizontal processing elements produce second reduction values. In a fourth computation state the horizontal processing elements generate horizontal output values, and responsive to a fourth communication state the horizontal processing elements communicate the horizontal output values back to the inputs of the function elements.",Scalable neural array processor and method
"Embodiments of the invention relate to a scalable neural hardware for the noisy-OR model of Bayesian networks. One embodiment comprises a neural core circuit including a pseudo-random number generator for generating random numbers. The neural core circuit further comprises a plurality of incoming electronic axons, a plurality of neural modules, and a plurality of electronic synapses interconnecting the axons to the neural modules. Each synapse interconnects an axon with a neural module. Each neural module receives incoming spikes from interconnected axons. Each neural module represents a noisy-OR gate. Each neural module spikes probabilistically based on at least one random number generated by the pseudo-random number generator unit.",Scalable neural hardware for the noisy-OR model of Bayesian networks
"Embodiments of the invention relate to a scalable neural hardware for the noisy-OR model of Bayesian networks. One embodiment comprises a neural core circuit including a pseudo-random number generator for generating random numbers. The neural core circuit further comprises a plurality of incoming electronic axons, a plurality of neural modules, and a plurality of electronic synapses interconnecting the axons to the neural modules. Each synapse interconnects an axon with a neural module. Each neural module receives incoming spikes from interconnected axons. Each neural module represents a noisy-OR gate. Each neural module spikes probabilistically based on at least one random number generated by the pseudo-random number generator unit.",Scalable neural hardware for the noisy-OR model of Bayesian networks
"A parallel computer architecture supporting neural networks utilizing a novel method of separating a triangular array containing N processing elements on each edge into multiple smaller triangular arrays, each of dimension X and each representing a common building block processor group chip that can be interconnected for various size parallel processing implementations. The group chips are interconnected by a unique switching tree mechanism that maintains the complete connectivity capability and functionality possessed by the original triangular array of dimension N. For a given size K and X, K divisible by X, a triangular array containing K processor elements located on each edge of an equilateral triangular array is partitioned into K/X triangular arrays of dimension X and K(K-X)/2X.sup.2 square processor arrays of dimension X. An algorithm partitions a square array into two triangular arrays, each of dimension X. Assuming K=N and the chosen technology supports the placement of a triangular processor group chip of dimension X on a single chip, the final scalable parallel computing structure for N root tree processors utilizes N.sup.2 /X.sup.2 triangular processor group chips. The partitioning methodology creates a scalable organization of processor elements. An interconnection mechanism preserves the functionality of the original triangular array of dimension N in the implemented structure constructed of multiple triangular arrays of dimension X.",Scalable parallel group partitioned diagonal-fold switching tree computing apparatus
"A system and method for real-time location detection consists of three groups of components. Mobile subjects to be tracked are equipped with wireless transceivers capable of sending and optionally for receiving data over pre-determined radio frequency (RF) band(s). Router/base station access point devices are equipped with wireless transceivers capable of sending and receiving data over pre-determined radio frequency (RF) band(s) in order to communicate with mobile units. Routers are combined into specific overlapping router groups, with each group forming a spatial sub-network. System central processing and command station(s) perform data processing and implementation of computational models that determine the mobile unit location. System deployment consists of three phases: collection of training and testing data, network training and testing, and network adaptive maintenance.",Scalable real-time location detection based on overlapping neural networks
"Computer-readable media having computer-executable instructions distinguish the script type of at least one portion of a writing input. At least one sub-word of a writing line of a handwritten document is identified and is processed to determine the associated writing style that includes a cursive writing style and a hand-printed writing style. The writing line is consequently associated with a script type. The script type of a writing line is determined from the script types of the sub-words in the writing line. When the number of sub-words having a first script type is greater than the number of sub-words having a second script type, the script type of the writing line is categorized as the first script type. In addition, a script analyzer determines a writing style of at least one sub-word and selects one of a plurality of neural networks to categorize the script type of a writing line.",Script recognition for ink notes
"In the computer interpretation of seismic data, the critical first step is to identify the general class of an unknown event. For example, the classification might be: teleseismic, regional, local, vehicular, or noise. Self-organizing neural networks (SONNs) can be used for classifying such events. Both Kohonen and Adaptive Resonance Theory (ART) SONNs are useful for this purpose. Given the detection of a seismic event and the corresponding signal, computation is made of: the time-frequency distribution, its binary representation, and finally a shift-invariant representation, which is the magnitude of the two-dimensional Fourier transform (2-D FFT) of the binary time-frequency distribution. This pre-processed input is fed into the SONNs. These neural networks are able to group events that look similar. The ART SONN has an advantage in classifying the event because the types of cluster groups do not need to be pre-defined. The results from the SONNs together with an expert seismologist's classification are then used to derive event classification probabilities.",Seismic event classification system
"In general, the invention is directed to a technique for selection of parameter configurations for a neurostimulator using neural networks. The technique may be employed by a programming device to allow a clinician to select parameter configurations, and then program an implantable neurostimulator to deliver therapy using the selected parameter configurations. The parameter configurations may include one or more of a variety of parameters, such as electrode configurations defining electrode combinations and polarities for an electrode set implanted in a patient. The electrode set may be carried by one or more implanted leads that are electrically coupled to the neurostimulator. In operation, the programming device executes a parameter configuration search algorithm to guide the clinician in the selection of parameter configurations. The search algorithm relies on a neural network that identifies potential optimum parameter configurations.",Selection of neurostimulator parameter configurations using neural network
"In general, the invention is directed to a technique for selection of parameter configurations for a neurostimulator using neural networks. The technique may be employed by a programming device to allow a clinician to select parameter configurations, and then program an implantable neurostimulator to deliver therapy using the selected parameter configurations. The parameter configurations may include one or more of a variety of parameters, such as electrode configurations defining electrode combinations and polarities for an electrode set implanted in a patient. The electrode set may be carried by one or more implanted leads that are electrically coupled to the neurostimulator. In operation, the programming device executes a parameter configuration search algorithm to guide the clinician in the selection of parameter configurations. The search algorithm relies on a neural network that identifies potential optimum parameter configurations.",Selection of neurostimulator parameter configurations using neural networks
"In an approach for generating a selectivity estimation, one or more processors generate an artificial neural network and receive a DBMS query comprising one or more predicates. One or more processors replace one or more predicates in the one or more predicates that have strict operators with one or more predicates that have non-strict operators. One or more processors generate a selectivity function from the one or more predicates that has one or more arguments that are each comprised of an upper bound and a lower bound for a value in a predicate. One or more processors generate a training data set from a data distribution in the database and train the artificial neural network on the training data set to compute the selectivity function. One or more processors generate a selectivity estimation with the artificial neural network for one or more predicates in the DBMS query.",Selectivity estimation using artificial neural networks
"A method of updating a neural network may be provided. A method may include computing gradients for an operating matrix of a current layer of the neural network based on data of at least one of the current layer and at least one other layer of the neural network. The method may also include updating the operating matrix based on the computed gradients. Further, the method may include updating an indexing matrix of the current layer based on the updated operating matrix.",Self-adaptive neural networks
"A method and apparatus for using a neural network to process information includes multiple nodes arrayed in multiple layers for transforming input arrays from prior layers or the environment into output arrays for subsequent layers or output devices. Learning rules based on reinforcement are applied. Interconnections between nodes are provided in a manner whereby the number and structure of the interconnections are self-adjusted by the learning rules during learning. At least one of the layers is used as a processing layer, and multiple lateral inputs to each node of each processing layer are used to retrieve information. The invention provides rapid, unsupervised processing of complex data sets, such as imagery or continuous human speech, and captures successful processing or pattern classification constellations for implementation in other networks. The invention includes application-specific self-adjusting multi-layer architectures that employ reinforcement learning rules to create updated data arrays for computation.",Self-adjusting multi-layer neural network architectures and methods therefor
"A self-assembling learning system and apparatus determines self-assembling actions that are expected to reduce uncertainties that are embodied as probabilities and then updates the probabilities in accordance with information that results from the performing of the self-assembling actions. The updated probabilities inform the determination of subsequent self-assembling actions. Neural networks, simulations of multiple potential self-assembling actions, and expected values of information may be applied in determining the self-assembling actions that are to be performed. Sensors may be applied to receive information that inform the updating of probabilities, and the self-assembling apparatus may be a robotic device. Self-assembling actions may comprise modifications to relationships between elements of a computer-implemented system.",Self-assembling learning system and apparatus
"Systems and methods for automatically self-correcting or correcting in real-time one or more neural networks after detecting a triggering event, or breaching boundary conditions are provided. Such a triggering event may indicate incorrect output signal or data being generated by the one or more neural networks. In particular, machine controllers of the invention limit the operations of neural networks to be within boundary conditions. Autonomous machines of the invention can be self-corrected after a breach of a boundary condition is detected. Autonomous land vehicles of the invention are capable of determining the timing of automatic transition to the manual control from automated driving mode. The controller of the invention filters and saves input-output data sets that fall within boundary conditions for later training of neural networks. The controllers of the invention include security architectures to prevent damages from virus attacks or system malfunctions.",Self-correcting controller systems and methods of limiting the operation of neural networks to be within one or more conditions
"A digital data storage device such as a rotating magnetic disk drive contains an on-board condition monitoring system, comprising a neural network coupled to multiple inputs derived from measured parameters of disk drive operation. The neural network uses a configurable set of weights to compute one or more quantities representing disk drive condition as a function of the various inputs. The weights are stored in a configuration table, which can be overwritten by a host computer. The drive is sold and installed with one set of weights, based on the then existing knowledge of the disk drive designers, and may be updated in the field as the designers acquire experience data by simply writing the weights to the configuration table of the disk drive, without altering disk drive control code or other disk drive features. Preferably, the disk drive designers include as input to the neural network any parameter which might conceivably be useful, even if the designers initially believe that the parameter has no significance. In this case, the designers can assign the parameter a weight of zero during initial release. If subsequent experience then shows that the parameter has some unexpected significance, the neural network can be corrected simply by changing weighting factors, without altering the control programming code.",Self-monitoring storage device using neural networks
"A method for predicting a canonical form for an input text sequence includes predicting the canonical form with a neural network model. The model includes an encoder, which generates a first representation of the input text sequence based on a representation of n-grams in the text sequence and a second representation of the input text sequence generated by a first neural network. The model also includes a decoder which sequentially predicts terms of the canonical form based on the first and second representations and a predicted prefix of the canonical form. The canonical form can be used, for example, to query a knowledge base or to generate a next utterance in a discourse.",Semantic parsing using deep neural networks for predicting canonical forms
"Systems, methods, and computer-readable media for providing semantically-relevant discovery of solutions are described herein. In some examples, a computing device can receive an input, such as a query. The computing device can process each word of the input sequentially to determine a semantic representation of the input. Techniques and technologies described herein determine a response to the input, such as an answer, based on the semantic representation of the input matching a semantic representation of the response. An output including one or more relevant responses to the request can then be provided to the requestor. Example techniques described herein can apply machine learning to train a model with click-through data to provide semantically-relevant discovery of solutions. Example techniques described herein can apply recurrent neural networks (RNN) and/or long short term memory (LSTM) cells in the machine learning model.",Semantically-relevant discovery of solutions
"A cell employing floating gate storage device particularly suited for neural networks. The floating gate from the floating gate device extends to and becomes part of a second, field effect device. Current through the second device is affected by the charge on the floating gate. The weighting factor for the cell is determined by the amount of charge on the floating gate. By charging the floating gate to various levels, a continuum of weighting factors is obtained. Multiplication is obtained since the current through the second device is a function of the weighting factor.",Semiconductor cell for neural network and the like
"The invention is made of an apparatus which incorporates a sensor-based means for stabilizing random access networks. In the preferred embodiment, a grid of sensors is used to gather energy measurements for analysis. In a preferred embodiment a neural network has been trained to estimate the number of colliding users in a given slot. This information is used to set parameters in a backoff algorithm so as to stabilize the network and minimize the delay experienced by users. The invention has the ability to locate users geographically within the network coverage area. This information can be used in conjunction with a steerable beam or an array of antennas to develop geographically-determined Aloha subchannels, further increasing the capacity of the system.",Sensor-assisted aloha for wireless networks
"Methods, systems, apparatus, including computer programs encoded on computer storage medium, for generating a sentence summary. In one aspect, the method includes actions of tokenizing the sentence into a plurality of tokens, processing data representative of each token in a first order using an LSTM neural network to initialize an internal state of a second LSTM neural network, processing data representative of each token in a second order using the second LSTM neural network, comprising, for each token in the sentence: processing the data representative of the token using the second LSTM neural network in accordance with a current internal state of the second LSTM neural network to (i) generate an LSTM output for the token, and (ii) to update the current internal state of the second LSTM neural network, and generating the summarized version of the sentence using the outputs of the second LSTM neural network for the tokens.",Sentence compression using recurrent neural networks
"Apparatus for generating sequences of elements including at least one task unit, each of which has an upper and a lower neural network connected in a hierarchical relationship and is operable to output a sequence of elements. Each of the upper and lower neural networks is a class of temporal neural networks having an infinite number of internal states.",Sequence generator
"Systems and methods for sequence transcription with neural networks are provided. More particularly, a neural network can be implemented to map a plurality of training images received by the neural network into a probabilistic model of sequences comprising P(S|X) by maximizing log P(S|X) on the plurality of training images. X represents an input image and S represents an output sequence of characters for the input image. The trained neural network can process a received image containing characters associated with building numbers. The trained neural network can generate a predicted sequence of characters by processing the received image.",Sequence transcription with deep neural networks
"Systems and methods for sequence transcription with neural networks are provided. More particularly, a neural network can be implemented to map a plurality of training images received by the neural network into a probabilistic model of sequences comprising P(S|X) by maximizing log P(S|X) on the plurality of training images. X represents an input image and S represents an output sequence of characters for the input image. The trained neural network can process a received image containing characters associated with building numbers. The trained neural network can generate a predicted sequence of characters by processing the received image.",Sequence transcription with deep neural networks
"Shape recognition is performed based on determining whether one or more ink strokes is not part of a shape or a partial shape. Ink strokes are divided into segments and the segments analyzed employing a relative angular distance histogram. The histogram analysis yields stable, incremental, and discriminating featurization results. Neural networks may also be employed along with the histogram analysis to determine complete shapes from partial shape entries and autocomplete suggestions provided to users for conversion of the shape into a known object.",Shape recognition using partial shapes
"Shape recognition is performed based on determining whether one or more ink strokes is not part of a shape or a partial shape. Ink strokes are divided into segments and the segments analyzed employing a relative angular distance histogram. The histogram analysis yields stable, incremental, and discriminating featurization results. Neural networks may also be employed along with the histogram analysis to determine complete shapes from partial shape entries and autocomplete suggestions provided to users for conversion of the shape into a known object.",Shape recognition using partial shapes
"Shape recognition is performed based on determining whether one or more ink strokes is not part of a shape or a partial shape. Ink strokes are divided into segments and the segments analyzed employing a relative angular distance histogram. The histogram analysis yields stable, incremental, and discriminating featurization results. Neural networks may also be employed along with the histogram analysis to determine complete shapes from partial shape entries and autocomplete suggestions provided to users for conversion of the shape into a known object.",Shape recognition using partial shapes
"An automated speech recognition system converts a speech signal into a compact, coded representation that correlates to a speech phoneme set. A number of different neural network pattern matching schemes may be used to perform the necessary speech coding. An integrated user interface guides a user unfamiliar with the details of speech recognition or neural networks to quickly develop and test a neural network for phoneme recognition. To train the neural network, digitized voice data containing known phonemes that the user wants the neural network to ultimately recognize are processed by the integrated user interface. The digitized speech is segmented into phonemes with each segment being labelled with a corresponding phoneme code. Based on a user selected transformation method and transformation parameters, each segment is transformed into a series of multiple dimension vectors representative of the speech characteristics of that segment. These vectors are iteratively presented to a neural network to train/adapt that neural network to consistently distinguish and recognize these vectors and assign an appropriate phoneme code to each vector. Simultaneous display of the digitized speech, segments, vector sets, and a representation of the trained neural network assist the user in visually confirming the acceptability of the phoneme training set. A user may also selectively audibly confirm the acceptability of the digitization scheme, the segments, and the transform vectors so that satisfactory training data are presented to the neural network. If the user finds a particular step or parameter produces an unacceptable result, the user may modify one or more of the parameters and verify whether the modification effected an improvement in performance. The trained neural network is also automatically tested by presenting a test speech signal to the integrated user interface and observing both audibly and visually automatic segmentation of the speech, transformation into multidimensional vectors, and the resulting neural network assigned phoneme codes. A method of decoding such phoneme codes using the neural network is also disclosed.",Signal processing and training by a neural network for phoneme recognition
"A signal processing method and system combining smooth level wavelet pre-processing together with artificial neural networks all in the wavelet domain for signal denoising and extraction. Upon receiving a signal corrupted with noise, an n-level decomposition of the signal is performed using a discrete wavelet transform to produce a smooth component and a rough component for each decomposition level. The nth level smooth component is then inputted into a corresponding neural network pre-trained to filter out noise in that component by pattern recognition in the wavelet domain. Additional rough components, beginning at the highest level, may also be retained and inputted into corresponding neural networks pre-trained to filter out noise in those components also by pattern recognition in the wavelet domain. In any case, an inverse discrete wavelet transform is performed on the combined output from all the neural networks to recover a clean signal back in the time domain.",Signal processing method and system for noise removal and signal extraction
"In a signal processing arrangement for classifying objects on the basis of signals from a plurality of different sensors each of the signals from the sensors is applied to a pair of neural networks. One neural network of each pair processes predetermined characteristics of the object and the other neural network processes movement or special data of the object such that these networks provide detection, identification and movement information specific for the sensors. Feature vectors formed from this information specific for the sensors are applied to a neural network for determining the associations of the identification and movement information. The information obtained by this network is applied together with the feature vectors to a network for identifying and classifying the object. The information from the association and identification networks, respectively, are supplied together with the information specific for the sensors to an expert system which, by using further knowledge about data and facts of the potential objects, makes final decisions and conclusions for identification.",Signal processing unit for classifying objects on the basis of signals from sensors
"A method is provided which performs word recognition using the dynamic recurrent neural networks (DRNN) model and which is able to discriminate, with high precision, similar words for which misrecognition often occurs. When the vocal sounds of some words are input, the DRNN output corresponding to the input word vocal data is generated by the word detection signal output component using the DRNN word model and encoded into coded data by using a code book. When the DRNN output from the word detection signal output component has a correctness of a predetermined or greater level, a processor establishes a fixed period that includes the characteristic components of the input words in the DRNN output. The processor then examines the code data in the established fixed period. Discrimination of input words and words that are similar to the input words is accomplished on the basis of the examination results.",Similar word discrimination method and its apparatus
"The hardware of the present invention must be structured with the Brownian motion equation, Bayes' equation and its matrices as integral components. All data are input to a common bus bar. All data are then sent to all nodes simultaneously. Each node will have coded gates to admit the proper data to the appropriate matrix and Bayes' equation. Then, as the data are processed, they will be sent to a central data processing unit that integrates the data in the Brownian motion equation. The output is displayed in linguistic terms or in digital form by means of fuzzy logic.","Software engine for multiple, parallel processing with neural networks"
""" A circuit for emulating a nerve cell is used to generate one or more simple neural networks. In the preferred embodiment, the circuit comprises an LC ladder circuit including one or more modules, each of the modules comprising an """"L"""" two-port circuit comprising a first shunt branch having a variable capacitor, a second shunt branch having a series-connected conductance and a variable d.c. bias source, and a third branch connected in series with the first and second branches, the third branch comprising an active inductor. The inductor is formed by one or more operational amplifiers interconnected in a feedback configuration. Each of the variable capacitances and the inductances cooperate to emulate a portion of a neuron by receiving a stimulus and generating or propagating a unidirectional solitary wave output representing an action potential. """,Solitary wave circuit for neural network emulation
"A system for estimating the location of a stationary or moving sound source includes multiple microphones, which need not be physically aligned in a linear array or a regular geometric pattern in a given environment, an auralizer that generates auralized multi-channel signals based at least on array-related transfer functions and room impulse responses of the microphones as well as signal labels corresponding to the auralized multi-channel signals, a feature extractor that extracts features from the auralized multi-channel signals for efficient processing, and a neural network that can be trained to estimate the location of the sound source based at least on the features extracted from the auralized multi-channel signals and the corresponding signal labels.",Sound source estimation using neural networks
"A system and method of forecasting space weather (at Earth or another location) based on identifying complex patterns in solar, interplanetary, or geophysical data. These data may include current or historical measurements and/or modeled data (predicted or simulated). Data patterns, both non-event and event-related, are identified even when another event is occurring. Such patterns may vary with recent/cyclic variations in solar (e.g. solar max/min), interplanetary, or geophysical activity. Embodiments are built around: (1) templates, (2) expert systems, (3) neural networks, (4) hybrid systems comprising combinations of (1), (2) and/or (3), and multimodal intelligent systems. Forecasts are customized and/or updated as new data arise and as systems are dynamically modified, e.g. via feedback between system parts. Numerical or other indexes are generated representing forecasts, associated confidence levels, etc.",Space weather prediction system and method
"A system and method of forecasting space weather (at Earth or another location) based on identifying complex patterns in solar, interplanetary, or geophysical data. These data may include current or historical measurements and/or modeled data (predicted or simulated). Data patterns (both non-event and event-related) are identified (even when another event is occurring). Such patterns may vary with recent/cyclic variations in solar (e.g. solar max/min), interplanetary, or geophysical activity. Embodiments are built around: (1) templates, (2) expert systems, (3) neural networks, (4) hybrid systems comprising combinations of (1),(2) and/or (3), and multimodal intelligent systems. Forecasts are customized and/or updated as new data arise and as systems are dynamically modified (e.g. via feedback between system parts). Numerical or other indexes are generated representing: forecasts, associated confidence levels, etc. The invention predicts events/non-events and/or other values or parameters associated with space weather (e.g. Dst, event onset time, duration, etc.).",Space weather prediction system and method
"A system and method of forecasting space weather (at Earth or another location) based on identifying complex patterns in solar, interplanetary, or geophysical data. These data may include current or historical measurements and/or modeled data (predicted or simulated). Data patterns (both non-event and event-related) are identified (even when another event is occurring). Such patterns may vary with recent/cyclic variations in solar (e.g. solar max/min), interplanetary, or geophysical activity. Embodiments are built around: (1) templates, (2) expert systems, (3) neural networks, (4) hybrid systems comprising combinations of (1), (2) and/or (3), and multimodal intelligent systems. Forecasts are customized and/or updated as new data arise and as systems are dynamically modified (e.g. via feedback between system parts). Numerical or other indexes are generated representing: forecasts, associated confidence levels, etc. The invention predicts events/non-events and/or other values or parameters associated with space weather (e.g. Dst, event onset time, duration, etc.).",Space weather prediction system and method
"A system and method of forecasting space weather (at Earth or another location) based on identifying complex patterns in solar, interplanetary, or geophysical data. These data may include current or historical measurements and/or modeled data (predicted or simulated). Data patterns (both non-event and event-related) are identified (even when another event is occurring). Such patterns may vary with recent/cyclic variations in solar (e.g. solar max/min), interplanetary, or geophysical activity. Embodiments are built around: (1) templates, (2) expert systems, (3) neural networks, (4) hybrid systems comprising combinations of (1), (2) and/or (3), and multimodal intelligent systems. Forecasts are customized and/or updated as new data arise and as systems are dynamically modified (e.g. via feedback between system parts). Numerical or other indexes are generated representing: forecasts, associated confidence levels, etc. The invention predicts events/non-events and/or other values or parameters associated with space weather (e.g. Dst, event onset time, duration, etc.)",Space weather prediction system and method
"In some embodiments, a spam filtering method includes computing a pattern relevance for each of a set of message feature patterns, and using a neural network filter to classify incoming messages as spam or ham according to the pattern relevancies. Each message feature pattern is characterized by the simultaneous presence within a message of a specific set of message features (e.g., the presence of certain keywords within the message body, various message header heuristics, various message layout features, etc.). Each message feature may be spam- or ham-identifying, and may receive a tunable feature relevance weight from an external source (e.g. data file and/or human operator). The external feature relevance weights modulate the set of neuronal weights calculated through a training process of the neural network.",Spam filtering using feature relevance assignment in neural networks
"A speech recognition apparatus in which the speech signal is digitalized and subjected to special analysis, word end detection is effected by energy analysis of the speech signal and the recognition system utilizes a Markov model in combination with a neural network learning by specific training steps.",Speaker independent isolated word recognition system using neural networks
"A system and method for recognizing an utterance of a speech in which each reference pattern stored in a dictionary is constituted by a series of phonemes of a word to be recognized, each phoneme having a predetermined length of continued time and having a series of frames and a lattice point (i, j) of an i-th number phoneme at an j-th number frame having a discriminating score derived from Neural Networks for the corresponding phoneme. When the series of phonemes recognized by a phoneme recognition block is compared with each reference pattern, one i of the input series of phonemes recognized by the phoneme recognition block being calculated as a matching score as gk(i, j); ##EQU1## wherein ak(i, j) denotes an output score value of the Neural Networks of the j-th number phoneme at the j-th number frame of the reference pattern and p denoted a penalty constant to avoid an extreme shrinkage of the phonemes, a total matching score is calculated as gk (I, J), I denoting the number of frames of the input series of phonemes and J denoting the number of phonemes of the reference pattern k, and one of the reference patterns which gives a maximum matching score is output as the word recognition.",Speaker independent speech recognition system and method using neural network and/or DP matching technique
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for inputting speech data that corresponds to a particular utterance to a neural network; determining an evaluation vector based on output at a hidden layer of the neural network; comparing the evaluation vector with a reference vector that corresponds to a past utterance of a particular speaker; and based on comparing the evaluation vector and the reference vector, determining whether the particular utterance was likely spoken by the particular speaker.",Speaker verification using neural networks
"An apparatus and methods for spectroscopic detection of tissue abnormality, particularly precancerous cervical tissue, using neural networks to analyze in vivo measurements of fluorescence spectra. The invention excites fluorescence intensity spectra in both normal and abnormal tissue. This fluorescence spectroscopy data is used to train a group (ensemble) of neural networks, preferably radial basis function (RBF) neural networks. Once trained, fluorescence spectroscopy data from unknown tissue samples is classified by the trained neural networks. This process is used to differentiate pre-cancers from normal tissues, and can also be used to differentiate high grade pre-cancers from low grade pre-cancers. One embodiment of the invention is able to distinguish pre-cancerous tissue from both normal squamous tissue (NS) and normal columnar (NC) tissue in a single-stage of analysis. The invention demonstrates significantly smaller variability in classification accuracy, resulting in more reliable classification, with superior sensitivity. Moreover, the single-stage embodiment of the invention simplifies the decision-making process as compared to a two-stage embodiment.",Spectroscopic detection of cervical pre-cancer using radial basis function networks
"An Animation Synthesizer uses trainable probabilistic models, such as Hidden Markov Models (HMM), Artificial Neural Networks (ANN), etc., to provide speech and text driven body animation synthesis. Probabilistic models are trained using synchronized motion and speech inputs (e.g., live or recorded audio/video feeds) at various speech levels, such as sentences, phrases, words, phonemes, sub-phonemes, etc., depending upon the available data, and the motion type or body part being modeled. The Animation Synthesizer then uses the trainable probabilistic model for selecting animation trajectories for one or more different body parts (e.g., face, head, hands, arms, etc.) based on an arbitrary text and/or speech input. These animation trajectories are then used to synthesize a sequence of animations for digital avatars, cartoon characters, computer generated anthropomorphic persons or creatures, actual motions for physical robots, etc., that are synchronized with a speech output corresponding to the text and/or speech input.",Speech and text driven HMM-based body animation synthesis
"A speech recognition method according to the present invention uses distances calculated through a variance weighting process using covariance matrixes as the local distances (prediction residuals) between the feature vectors of input syllables/sound elements and predicted vectors formed by different statuses of reference neural prediction models (NPM's) using finite status transition networks. The category to minimize the accumulated value of these local distances along the status transitions of all the prediction models is figured out by dynamic programming, and used as the recognition output. Learning of the reference prediction models used in this recognition method is accomplished by repeating said distance calculating process and the process to correct the parameters of the different statuses and the covariance matrixes of said prediction models in the direction of reducing the distance between the learning patterns whose category is known and the prediction models of the same category as this known category, and what have satisfied prescribed conditions of convergence through these calculating and correcting processes are determined as reference pattern models.",Speech recognition by neural network adapted to reference pattern learning
A speech recognition system can recognize a plurality of voice data having different patterns. The speech recognition system has a voice recognizing and processing device including a plurality of speech recognition neural networks that have previously learned different voice patterns to recognize given voice data. Each of the speech recognition neutral networks is adapted to judge whether or not input voice data coincides with one of the voice data to be recognized. Each neural network then outputs adaptation judgment data representing the adaptation in speech recognition. A selector responsive to the adaptation judgment data from each of the speech recognition neural networks selects one of the neural networks that has the highest adaptation in speech recognition. An output control device outputs the result of speech recognition from the speech recognition neural network selected by the selector.,Speech recognition system using neural networks
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for speech recognition using neural networks. A feature vector that models audio characteristics of a portion of an utterance is received. Data indicative of latent variables of multivariate factor analysis is received. The feature vector and the data indicative of the latent variables is provided as input to a neural network. A candidate transcription for the utterance is determined based on at least an output of the neural network.",Speech recognition using neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media for speech recognition. One method includes obtaining an input acoustic sequence, the input acoustic sequence representing an utterance, and the input acoustic sequence comprising a respective acoustic feature representation at each of a first number of time steps; processing the input acoustic sequence using a first neural network to convert the input acoustic sequence into an alternative representation for the input acoustic sequence; processing the alternative representation for the input acoustic sequence using an attention-based Recurrent Neural Network (RNN) to generate, for each position in an output sequence order, a set of substring scores that includes a respective substring score for each substring in a set of substrings; and generating a sequence of substrings that represent a transcription of the utterance.",Speech recognition with attention-based recurrent neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media for speech recognition. One method includes obtaining an input acoustic sequence, the input acoustic sequence representing an utterance, and the input acoustic sequence comprising a respective acoustic feature representation at each of a first number of time steps; processing the input acoustic sequence using a first neural network to convert the input acoustic sequence into an alternative representation for the input acoustic sequence; processing the alternative representation for the input acoustic sequence using an attention-based Recurrent Neural Network (RNN) to generate, for each position in an output sequence order, a set of substring scores that includes a respective substring score for each substring in a set of substrings; and generating a sequence of substrings that represent a transcription of the utterance.",Speech recognition with attention-based recurrent neural networks
"A method and system for is disclosed for speech synthesis using deep neural networks. A neural network may be trained to map input phonetic transcriptions of training-time text strings into sequences of acoustic feature vectors, which yield predefined speech waveforms when processed by a signal generation module. The training-time text strings may correspond to written transcriptions of speech carried in the predefined speech waveforms. Subsequent to training, a run-time text string may be translated to a run-time phonetic transcription, which may include a run-time sequence of phonetic-context descriptors, each of which contains a phonetic speech unit, data indicating phonetic context, and data indicating time duration of the respective phonetic speech unit. The trained neural network may then map the run-time sequence of the phonetic-context descriptors to run-time predicted feature vectors, which may in turn be translated into synthesized speech by the signal generation module.",Speech synthesis using deep neural networks
"A speech-recognition system for recognizing isolated words includes pre-processing circuitry for performing analog-to-digital conversion and cepstral analysis, and a plurality of neural networks which compute discriminant functions based on polynomial expansions. The system may be implemented using hardware, software, or any combination of hardware and software components. The speech wave-form of a spoken word is analyzed and converted into a sequence of data frames. The sequence of frames is partitioned into data blocks, and the data blocks are then broadcast to a plurality of neural networks. Using the data blocks, the neural networks compute polynomial expansions. The output of the neural networks is used to determine the identity of the spoken word. The neural networks utilize a training algorithm which does not require repetitive training and which yields a global minimum to each given set of training examples.",Speech-recognition system utilizing neural networks and method of using same
"A method of allocating subscriber lines in a telecommunications network into speed bins. With the method, more intelligent business actions can then be taken in the provision of high-speed data services over the subscriber lines. For example, only qualified lines might be used for high-speed data services, with the other lines being allocated to POTS service. The lines are divided into speed bins using a pair of neural networks, with one predicting upstream speed and one predicting downstream speed. The combined predictions are then mapped to a speed bin, which is the basis for further business actions. The disclosure describes that the neural networks are created using conditional fuzzy logic to precondition the neural networks by line speed.",Speed binning by neural network
"A method of accelerating the training of an artificial neural network uses a computer configured as an artificial neural network with a network input and a network output, and having a plurality of interconnected units arranged in layers including an input layer and an output layer. Each unit has a multiplicity of unit inputs and a set of variables for operating upon a unit inputs to provide a unit output. A plurality of examples are serially provided to the network input and the network output is observed. The computer is programmed with a back propagation algorithm for adjusting each set of variables in response to feedback representing differences between the network output for each example and the desired output. The examples are iterated until the signs of the outputs of the units of the output layer converge. Then each set of variables is multiplied by a multiplier. The examples are reiterated until the magnitude of the outputs of the units of the output layer converge.",Speeding learning in neural networks
"Pulse trains are utilized for the transmission of information in a neural network. A squash function is achieved by logically OR'ing together pulsed outputs, giving f(x) approximately 1-e.sup.-x. For Back Propagation, as derived by Rumelhart, the derivative of the squash function is available by examining the time when no OR'ed together pulses are present, being 1-f(x), or e.sup.-x. Logically AND'ing of the two signals. Mulitplication of input frequencies by weights is accomplished by modulating the width of the output pulses, while keeping the frequency the same.",Spike transmission for neural networks
"Described is system for simulating spiking neural networks for image and video processing. The system processes an image with a spiking neural network simulator having a plurality of inter-connected modules. Each module comprises a plurality of neuron elements. Processing the image further comprises performing a neuron state update for each module, that includes aggregating input spikes and updating neuron membrane potentials, and performing spike propagation for each module, which includes transferring spikes generated in a current time step. Finally, an analysis result is output.",Spiking neural network simulator for image and video processing
"A neural network architecture consisting of input weight multiplications, product summation, neural state calculations, and complete connectivity among the neuron processing elements. Neural networks are modelled using a sequential pipelined neurocomputer producing high performance with minimum hardware by sequentially processing each neuron in the completely connected network model. An N neuron network is implemented using multipliers, a pipelined adder tree structure, and activation functions. The activation functions are provided by using one activation function module and sequentially passing the N input product summations sequentially through it. One bus provides N.times.N communications by sequentially providing N neuron values to the multiplier registers. The neuron values are ensured of reaching corresponding multipliers through a tag compare function. The neuron information includes a source tag and a valid signal. Higher performance is provided by connecting a number of the neurocomputers in a parallel.",SPIN: a sequential pipeline neurocomputer
"Techniques are provided for calculating reset parameters for recurrent neural networks (RNN). A methodology implementing the techniques according to an embodiment includes generating a sequence of statistics. The calculation of each statistic is based on outputs of an RNN that is periodically re-initialized at a selected RNN reset time such that each of the calculated statistics is associated with a unique RNN reset time selected from a pre-determined range of reset times. The method further includes analyzing the sequence to identify a maximum interval during which the sequence remains relatively constant. The method further includes selecting a reset time parameter and reset context duration parameter, for re-initialization of the RNN during operation. The reset time parameter is based on the duration of the identified maximum interval and the reset context duration parameter is based on a time associated with the starting point of the identified maximum interval.",Statistical-analysis-based reset of recurrent neural networks for automatic speech recognition
"Aspects described herein may allow for the application of stochastic gradient boosting techniques to the training of deep neural networks by disallowing gradient back propagation from examples that are correctly classified by the neural network model while still keeping correctly classified examples in the gradient averaging. Removing the gradient contribution from correctly classified examples may regularize the deep neural network and prevent the model from overfitting. Further aspects described herein may provide for scheduled boosting during the training of the deep neural network model conditioned on a mini-batch accuracy and/or a number of training iterations. The model training process may start un-boosted, using maximum likelihood objectives or another first loss function. Once a threshold mini-batch accuracy and/or number of iterations are reached, the model training process may begin using boosting by disallowing gradient back propagation from correctly classified examples while continue to average over all mini-batch examples.",Stochastic gradient boosting for deep neural networks
"Aspects described herein may allow for the application of stochastic gradient boosting techniques to the training of deep neural networks by disallowing gradient back propagation from examples that are correctly classified by the neural network model while still keeping correctly classified examples in the gradient averaging. Removing the gradient contribution from correctly classified examples may regularize the deep neural network and prevent the model from overfitting. Further aspects described herein may provide for scheduled boosting during the training of the deep neural network model conditioned on a mini-batch accuracy and/or a number of training iterations. The model training process may start un-boosted, using maximum likelihood objectives or another first loss function. Once a threshold mini-batch accuracy and/or number of iterations are reached, the model training process may begin using boosting by disallowing gradient back propagation from correctly classified examples while continue to average over all mini-batch examples.",Stochastic gradient boosting for deep neural networks
"The present invention integrates an on-board navigation system to provide energy management for an electric vehicle (EV) and a hybrid electric vehicle (HEV). The HEV control strategy of the present invention accommodates the goals of fuel economy while always meeting driver demand for power and maintaining the functionality of the traction motor battery system using battery parameter controllers. In the preferred embodiment of the present strategy, a vehicle system controller tightly integrates the navigation system information with energy management while en route to a known destination. Present vehicle location is continuously monitored, expectations of driver demand are determined, and vehicle accommodations are made. The system can be configured to includes as part of its present vehicle location data on road patterns, geography with date and time, altitude changes, speed limits, driving patterns of a vehicle driver, and weather. The vehicle accommodations can be configured to use discrete control laws, fuzzy logic, or neural networks.",Strategy to use an on-board navigation system for electric and hybrid electric vehicle energy management
"A system for monitoring the structural integrity of a mechanical structure. The system utilizes a trainable adaptive interpreter such as a neural network to analyze data from the structure to characterize the structure's health. An actuator is attached to the mechanical structure for generating vibrations in response to an input signal. A sensor, also attached to the mechanical structure, senses the vibrations and generates an output signal in response thereto. The sensor output signal is then coupled to a pre-trained adaptive interpreter for generating an output which characterizes the structural integrity of the mechanical structure. The system can provide continual health monitoring of a structural system to detect structural damage and pinpoint probable location of the damage. The system can operate while the structural system is in service there by significantly reducing structural inspection costs.",Structural health monitoring using active members and neural networks
"A neural system comprises multiple neurons interconnected via synapse devices. Each neuron integrates input signals arriving on its dendrite, generates a spike in response to the integrated input signals exceeding a threshold, and sends the spike to the interconnected neurons via its axon. The system further includes multiple noruens, each noruen is interconnected via the interconnect network with those neurons that the noruen's corresponding neuron sends its axon to. Each noruen integrates input spikes from connected spiking neurons and generates a spike in response to the integrated input spikes exceeding a threshold. There can be one noruen for every corresponding neuron. For a first neuron connected via its axon via a synapse to dendrite of a second neuron, a noruen corresponding to the second neuron is connected via its axon through the same synapse to dendrite of the noruen corresponding to the first neuron.",Structural plasticity in spiking neural networks with symmetric dual of an electronic neuron
"A neural system comprises multiple neurons interconnected via synapse devices. Each neuron integrates input signals arriving on its dendrite, generates a spike in response to the integrated input signals exceeding a threshold, and sends the spike to the interconnected neurons via its axon. The system further includes multiple noruens, each noruen is interconnected via the interconnect network with those neurons that the noruen's corresponding neuron sends its axon to. Each noruen integrates input spikes from connected spiking neurons and generates a spike in response to the integrated input spikes exceeding a threshold. There can be one noruen for every corresponding neuron. For a first neuron connected via its axon via a synapse to dendrite of a second neuron, a noruen corresponding to the second neuron is connected via its axon through the same synapse to dendrite of the noruen corresponding to the first neuron.",Structural plasticity in spiking neural networks with symmetric dual of an electronic neuron
"A neural system comprises multiple neurons interconnected via synapse devices. Each neuron integrates input signals arriving on its dendrite, generates a spike in response to the integrated input signals exceeding a threshold, and sends the spike to the interconnected neurons via its axon. The system further includes multiple noruens, each noruen is interconnected via the interconnect network with those neurons that the noruen's corresponding neuron sends its axon to. Each noruen integrates input spikes from connected spiking neurons and generates a spike in response to the integrated input spikes exceeding a threshold. There can be one noruen for every corresponding neuron. For a first neuron connected via its axon via a synapse to dendrite of a second neuron, a noruen corresponding to the second neuron is connected via its axon through the same synapse to dendrite of the noruen corresponding to the first neuron.",Structural plasticity in spiking neural networks with symmetric dual of an electronic neuron
"A neural system comprises multiple neurons interconnected via synapse devices. Each neuron integrates input signals arriving on its dendrite, generates a spike in response to the integrated input signals exceeding a threshold, and sends the spike to the interconnected neurons via its axon. The system further includes multiple noruens, each noruen is interconnected via the interconnect network with those neurons that the noruen's corresponding neuron sends its axon to. Each noruen integrates input spikes from connected spiking neurons and generates a spike in response to the integrated input spikes exceeding a threshold. There can be one noruen for every corresponding neuron. For a first neuron connected via its axon via a synapse to dendrite of a second neuron, a noruen corresponding to the second neuron is connected via its axon through the same synapse to dendrite of the noruen corresponding to the first neuron.",Structural plasticity in spiking neural networks with symmetric dual of an electronic neuron
"A neural system comprises multiple neurons interconnected via synapse devices. Each neuron integrates input signals arriving on its dendrite, generates a spike in response to the integrated input signals exceeding a threshold, and sends the spike to the interconnected neurons via its axon. The system further includes multiple noruens, each noruen is interconnected via the interconnect network with those neurons that the noruen's corresponding neuron sends its axon to. Each noruen integrates input spikes from connected spiking neurons and generates a spike in response to the integrated input spikes exceeding a threshold. There can be one noruen for every corresponding neuron. For a first neuron connected via its axon via a synapse to dendrite of a second neuron, a noruen corresponding to the second neuron is connected via its axon through the same synapse to dendrite of the noruen corresponding to the first neuron.",Structural plasticity in spiking neural networks with symmetric dual of an electronic neuron
"The present disclosure provides an improved approach to implement structure learning of neural networks by exploiting correlations in the data/problem the networks aim to solve. A greedy approach is described that finds bottlenecks of information gain from the bottom convolutional layers all the way to the fully connected layers. Rather than simply making the architecture deeper, additional computation and capacitance is only added where it is required.",Structure learning in convolutional neural networks
"A student neural network that is capable of receiving a series of tutoring inputs from one or more teacher networks to generate a student network output that is similar to the output of the one or more teacher networks. The tutoring inputs are repeatedly processed by the student until, using a suitable method such as back propagation of errors, the outputs of the student approximate the outputs of the teachers within a predefined range. Once the desired outputs are obtained, the weights of the student network are set. Using this weight set the student is now capable of solving all of the problems of the teacher networks without the need for adjustment of its internal weights. If the user desires to use the student to solve a different series of problems, the user only needs to retrain the student by supplying a different series of tutoring inputs.",Student neural network
"A computer-implemented method for detecting objects by using subcategory-aware convolutional neural networks (CNNs) is presented. The method includes generating object region proposals from an image by a region proposal network (RPN) which utilizes subcategory information, and classifying and refining the object region proposals by an object detection network (ODN) that simultaneously performs object category classification, subcategory classification, and bounding box regression. The image is an image pyramid used as input to the RPN and the ODN. The RPN and the ODN each include a feature extrapolating layer to detect object categories with scale variations among the objects.",Subcategory-aware convolutional neural networks for object detection
"This application is directed to a low cost IC solution that provides Super CMOS microelectronics macros. Hereinafter, SCMOS refers to Super CMOS and Schottky CMOS. SCMOS device solutions includes a niche circuit element, such as complementary low threshold Schottky barrier diode pairs (SBD) made by selected metal barrier contacts (Co, Ti, Ni or other metal atoms or compounds) to P- and N- Si beds of the CMOS transistors. A DTL like new circuit topology and designed wide contents of broad product libraries, which used the integrated SBD and transistors (BJT, CMOS, and Flash versions) as basic components. The macros are composed of diodes that are selectively attached to the diffusion bed of the transistors, configuring them to form (i) generic logic gates, (ii) functional blocks of microprocessors and microcontrollers such as but not limited to data paths, multipliers, muliplier-accumaltors, (ii) memory cells and control circuits of various types (SRAM's with single or multiple read/write port(s), binary and ternary CAM's), (iii) multiplexers, crossbar switches, switch matrices in network processors, graphics processors and other processors to implement a variety of communication protocols and algorithms of data processing engines for (iv) Analytics, (v) block-chain and encryption-based security engines (vi) Artificial Neural Networks with specific circuits to emulate or to implement a self-learning data processor similar to or derived from the neurons and synapses of human or animal brains, (vii) analog circuits and functional blocks from simple to the complicated including but not limited to power conversion, control and management either based on charge pumps or inductors, sensor signal amplifiers and conditioners, interface drivers, wireline data transceivers, oscillators and clock synthesizers with phase and/or delay locked loops, temperature monitors and controllers; all the above are built from discrete components to all grades of VLSI chips. Solar photovoltaic electricity conversion, bio-lab-on-a-chip, hyperspectral imaging (capture/sensing and processing), wireless communication with various transceiver and/or transponder circuits for ranges of frequency that extend beyond a few 100 MHz, up to multi-THz, ambient energy harvesting either mechanical vibrations or antenna-based electromagnetic are newly extended or nacent fields of the SCMOS IC applications.",Super CMOS devices on a microelectronics system
"Data analysis systems are provided, especially target imaging and identification systems, which utilize a CAM that associatively stores a plurality of known data sets such as target data sets in a synaptic interconnectivity matrix modeled upon the model of learning of neural networks. In accordance with preferred embodiments the systems are able to identify unknown objects when only a partial data set from the object is available. The system is robust and fast, utilizing parallel processing due to the massive interconnectivity of neural elements so that the image produced exhibits the properties of super-resolution. Since the system is modeled after a neural network, it is fault tolerant and highly reliable.",Super resolution
"Methods, systems, and apparatus for efficiently performing a computation of a convolutional neural network layer. One of the methods includes transforming a X by Y by Z input tensor into a X by Y by Z input tensor, wherein X is smaller than or equal to X, Y is smaller than or equal to Y, and Z is larger than or equal to Z; obtaining one or more modified weight matrices, wherein the modified weight matrices operate on the X by Y by Z input tensor to generate a U by V by W output tensor, and the U by V by W output tensor comprises a transformed U by V by W output tensor, wherein U is smaller than or equal to U, V is smaller than or equal to V, and W is larger than or equal to W; and processing the X by Y by Z input tensor using the modified weight matrices to generate the U by V by W output tensor, wherein the U by V by W output tensor comprises the U by V by W output tensor.",Superpixel methods for convolutional neural networks
"A set of virtual images can be generated based on one or more real images and target rendering specifications, such that the set of virtual images correspond to (for example) different rendering specifications (or combinations thereof) than do the real images. A machine-learning model can be trained using the set of virtual images. Another real image can then be processed using the trained machine-learning model. The processing can include segmenting the other real image to detect whether and/or which objects are represented (and/or a state of the object). The object data can then be used to identify (for example) a state of a procedure.",Surgical simulation for training detection and classification neural networks
"A surveillance system and method are provided. The surveillance system includes an image capture device configured to capture an actual image of a target area depicting an object. The surveillance system further includes a processor. The processor is configured to render, based on a set of 3D Computer Aided Design (CAD) models, synthetic images with intermediate shape corresponding concept labels. The processor is further configured to form a multi-layer Convolutional Neural Network (CNN) which jointly models multiple intermediate shape concepts, based on the rendered synthetic images. The processor is also configured to perform an intra-class appearance variation-aware and occlusion-aware 3D object parsing on the actual image by applying the CNN to the actual image to generate an image pair including a 2D and 3D geometric structure of the object depicted in the actual image. The surveillance system further includes a display device configured to display the image pair.",Surveillance system with landmark localization on objects in images using convolutional neural networks
Techniques are described for making electronic neural networks with variable synapse strengths using the variability of transistor conductance or transconductance with gate bias and utilizing capacitors for the temporary storage of the gate bias used for control.,Switched networks
"Discrete-time neural networks are implemented using switched capacitors, switches and inverters and advantage is taken of the inherent saturation of the inverters to implement the neuron non-linearity without additional elements.",Switched neural networks
"Neuronal networks of electronic neurons interconnected via electronic synapses with synaptic weight normalization. The synaptic weights are based on learning rules for the neuronal network, such that a synaptic weight for a synapse determines the effect of a spiking source neuron on a target neuron connected via the synapse. Each synaptic weight is maintained within a predetermined range by performing synaptic weight normalization for neural network stability.",Synaptic weight normalized spiking neuronal networks
"Neural networks of suitable topology are trained with pairs of images, where one image of each pair depicts a garment, and the other image of each pair depicts the garment being worn by a model. Once trained, the neural network can synthesize an image based on a new image of a garment, where the synthesized image could plausibly have appeared in the training set, paired with the new image of the garment. Quantitative parameters controlling the image synthesis permit adjustment of features of the synthetic image, including the skin tone, body shape and pose of the model, accessories depicted in the synthetic image, and characteristics of the garment as depicted, such as length, sleeve style, collar style or tightness.",Synthesizing images of clothing on models
Provided are a system and article of manufacture for filtering communications received from over a network for a person-to-person communication program. A communication is received for the person-to person communication program. The communication is processed to determine predefined language statements. Information on the determined language statements is inputted into a neural network to produce an output value. A determination is made as to whether the output value indicates that the communication is unacceptable. The communication is forwarded to the person-to-person communication program unchanged if the output value indicates that the communication is acceptable. An action is performed with respect to the communication upon determining that the communication is unacceptable that differs from the forwarding of the communication that occurs if the output value indicates that the communication is acceptable.,System and article of manufacturing for filtering content using neural networks
"A system and method for processing machine learning techniques (such as neural networks) and other non-graphics applications using a graphics processing unit (GPU) to accelerate and optimize the processing. The system and method transfers an architecture that can be used for a wide variety of machine learning techniques from the CPU to the GPU. The transfer of processing to the GPU is accomplished using several novel techniques that overcome the limitations and work well within the framework of the GPU architecture. With these limitations overcome, machine learning techniques are particularly well suited for processing on the GPU because the GPU is typically much more powerful than the typical CPU. Moreover, similar to graphics processing, processing of machine learning techniques involves problems with solving non-trivial solutions and large amounts of data.",System and method for accelerating and optimizing the processing of machine learning techniques using a graphics processing unit
"A process and neural network architecture for on-line adjustment of the weights of the neural network in a manner that corrects errors made by a nonlinear controller designed based on a model for the dynamics of a process under control. A computer system is provided for controlling the dynamic output response signal of a nonlinear physical process, where the physical process is represented by a fixed model of the process. The computer system includes a controlled device for responding to the output response signal of the system. The computer system also includes a linear controller for providing a pseudo control signal that is based on the fixed model for the process and provides a second controller, connected to the linear controller, for receiving the pseudo control signal and for providing a modified pseudo control signal to correct for the errors made in modeling the nonlinearities in the process. A response network is also included as part of the computer system. The response network receives the modified pseudo control signal and provides the output response signal to the controlled device. The second controller preferably is a neural network. The computer system may include a plurality of neural networks with each neural network designated to control a selected variable or degree of freedom within the system.",System and method for adaptive control of uncertain nonlinear processes
"A process and neural network architecture for on-line adjustment of the weights of the neural network in a manner that corrects errors made by a nonlinear controller designed based on a model for the dynamics of a process under control. A computer system is provided for controlling the dynamic output response signal of a nonlinear physical process, where the physical process is represented by a fixed model of the process. The computer system includes a controlled device for responding to the output response signal of the system. The computer system also includes a linear controller for providing a pseudo control signal that is based on the fixed model for the process and provides a second controller, connected to the linear controller, for receiving the pseudo control signal and for providing a modified pseudo control signal to correct for the errors made in modeling the nonlinearities in the process. A response network is also included as part of the computer system. The response network receives the modified pseudo control signal and provides the output response signal to the controlled device. The second controller preferably is a neural network. The computer system may include a plurality of neural networks with each neural network designated to control a selected variable or degree of freedom within the system.",System and method for adaptive control of uncertain nonlinear processes
A method for advanced condition monitoring of an asset system includes using a plurality of auto-associative neural networks to determine estimates of actual values sensed by at least one sensor in at least one of the plurality of operating regimes; determining a residual between the estimated sensed values and the actual values sensed by the at least one sensor from each of the plurality of auto-associative neural networks; and combining the residuals by using a fuzzy supervisory model blender; performing a fault diagnostic on the combined residuals; and determining a change of the operation of the asset system by analysis of the combined residuals. An alert is provided if necessary. A smart sensor system includes an on-board processing unit for performing the method of the invention.,System and method for advanced condition monitoring of an asset system
"An application provisioning system and method. A server provides an application provisioning service. A user of a client provides a schema defining an application. The application interacts with peripherals coupled to the client and receives input from sensors coupled to the peripherals. The sensor data is provided to the server for processing, including by neural networks. The application includes a workflow defining a finite state machine that traverses states at least partially based on the response to sensor data. The server may provide dynamic reallocation of compute resources to resolve demand for classifier training job requests; use of jurisdictional certificates to define data usage and sharing; and data fusion. Applications include manufacturing verification, medical diagnosis and treatment, genomics and viral detection.",System and method for applying a deep learning neural network to data obtained from one or more sensors
"A method and system for forming an interpretation of an input expression, where the input expression is expressed in a medium, the interpretation is a sequence of symbols, and each symbol is a symbol in a known symbol set. In general, the system processes an acquired input data set representative of the input expression, to form a set of segments, which are then used to specify a set of consegmentations. Each consegmentation and each possible interpretation for the input expression is represented in a data structure. The data structure is graphically representable by a graph comprising a two-dimensional array of nodes arranged in rows and columns and selectively connected by directed arcs. Each path, extending through the nodes and along the directed arcs, represents one consegmentation and one possible interpretation for the input expression. All of the consegmentations and all of the possible interpretations for the input expression are represented by the set of paths extending through the graph. For each row of nodes in the graph, a set of scores is produced for the known symbol set, using a complex of optimally trained neural information processing networks. Thereafter the system computes an a posteriori probability for one or more symbol sequence interpretations. By deriving each a posteriori probability solely through analysis of the acquired input data set, highly reliable probabilities are produced for competing interpretations for the input expression.",System and method for automated interpretation of input expressions using novel a posteriori probability measures and optimally trained information processing networks
"A system and method for detecting pulmonary embolisms in a subject's vasculature are provided. In some aspects, the method includes acquiring a set of images representing a vasculature of the subject, and analyzing the set of images to identify pulmonary embolism candidates associated with the vasculature. The method also includes generating, for identified pulmonary embolism candidates, image patches based on a vessel-aligned image representation, and applying a set of convolutional neural networks to the generated image patches to identify pulmonary embolisms. The method further includes generating a report indicating identified pulmonary embolisms.",System and method for automatic pulmonary embolism detection
"Systems and methods are provided through which a graphic image is classified in terms of being natural versus computer generated, or being a scientific slide presentation versus a comic image. The image is classified by extracting appropriate feature(s) from the image, and using the feature(s) to determine, within a predetermined degree of accuracy, the graphic classification of the image.The classification determination uses a trained model. The trained model is created by using machine learning algorithms such as Neural Networks, Support Vector Machines, and Learning Vector Quantizations.Subsequently, the trained model is used to classify a group of images of unknown classification automatically.",System and method for classification of images and videos
"A method and system for electronically classifying a pre-processed heart sound signal of a patient as functional (normal) or pathological is provided. The pre-processed patient heart sound signal is segmentised and features are extracted therefrom (104) to build up a feature vector which is representative of the heart sound signal. The feature vector is then fed to a diagnostic decision support network (105) comprising a plurality of artificial neural networks, each relating to a known heart pathology, which is in turn used to conduct the classification.",System and method for classifying a heart sound
"A method and system for electronically classifying a pre-processed heart sound signal of a patient as functional (normal) or pathological is provided. The pre-processed patient heart sound signal is segmentised and features are extracted therefrom (104) to build up a feature vector which is representative of the heart sound signal. The feature vector is then fed to a diagnostic decision support network (105) comprising a plurality of artificial neural networks, each relating to a known heart pathology, which is in turn used to conduct the classification.",System and method for classifying a heart sound
"Designs for cognitive memory systems storing input data, images, or patterns, and retrieving it without knowledge of where stored when cognitive memory is prompted by query pattern that is related to sought stored pattern. Retrieval system of cognitive memory uses autoassociative neural networks and techniques for pre-processing query pattern to establish relationship between query pattern and sought stored pattern, to locate sought pattern, and to retrieve it and ancillary data. Cognitive memory, when connected to computer or information appliance introduces computational architecture that applies to systems and methods for navigation, location and recognition of objects in images, character recognition, facial recognition, medical analysis and diagnosis, video image analysis, and to photographic search engines that when prompted with a query photograph containing faces and objects will retrieve related photographs stored in computer or other information appliance, and will identify URL's of related photographs and documents stored on the World Wide Web.",System and method for cognitive memory and auto-associative neural network based pattern recognition
"System and method for improving the performance of learning agents such as neural networks, genetic algorithms and decision trees that derive prediction methods from a training set of data. In part of the method, a population of learning agents of different classes is trained on the data set, each agent producing in response a prediction method based on the agent's input representation. Feature combinations are extracted from the prediction methods produced by the learning agents. The input representations of the learning agents are then modified by including therein a feature combination extracted from another learning agent. In another part of a method, the parameter values of the learning agents are changed to improve the accuracy of the prediction method. A fitness measure is determined for each learning agent based on the prediction method the agent produces. Parameter values of a learning agent are then selected based on the agent's fitness measure. Variation is introduced into the selected parameter values, and another learning agent of the same class is defined using the varied parameter values. The learning agents are then again trained on the data set to cause a learning agent to produce a prediction method based on the derived feature combinations and varied parameter values.",System and method for combining multiple learning agents to produce a prediction method
"Systems and methods are provided for combining multiple segmentations into a single unique segmentation that contains attributes of the original segmentations. This new segmentation forms an ensemble or combination segmentation that has a unique set of attributes from the original segmentations without enumerating every possible set of combinations. In one example, two or more segments are combined into a single segmentation using a technique such as k-means clustering or Self-Organizing Map Neural Networks. After the first combination phase is performed, a Bayesian technique is then applied in a second phase to adjust or further alter the ensemble combination of segments.",System and method for combining segmentation data
"A device, system, and method is provided for storing a sparse neural network. A plurality of weights of the sparse neural network may be obtained. Each weight may represent a unique connection between a pair of a plurality of artificial neurons in different layers of a plurality of neuron layers. A minority of pairs of neurons in adjacent neuron layers are connected in the sparse neural network. Each of the plurality of weights of the sparse neural network may be stored with an association to a unique index. The unique index may uniquely identify a pair of artificial neurons that have a connection represented by the weight. Only non-zero weights may be stored that represent connections between pairs of neurons (and zero weights may not be stored that represent no connections between pairs of neurons).",System and method for compact and efficient sparse neural networks
"A system and method is provided that predicts operational parameters for all unit operations in water treatment plants or the like. Initial training with historical operations data, for example, allows the system and method to develop equations that can in turn predict the present and future performance of the plant in real time. In addition, the system and method can control operations of the plant in real time. The system improves the performance of the plant to meet predetermined subpoints of various parameters. For example, the predetermined subpoints can be used to enable the plant to meet regulatory needs while controlling for other parameters such as cost, chemical fees, flow rates and power consumption. The system and method include a non-linear predictive model for turbidity. The system considers the influent water quality and analyzes treatment options available to predict the dose of various chemicals required to get desired treatment. It will then predict plant performance resulting from intended operator changes in real time. The system preferably includes general regression neural networks with modeling modifications to learn if the works including learning patterns to make predictions and cost for operations control of unit operations and/or the system. The system includes virtual sensors for parameters that cannot be detected on-line. The system and method determine sufficient data to monitor and control all water quality parameters in the water treatment plant. The water treatment plant operations can be predicted and controlled as a plurality of coupled unit operations. In one embodiment, a unit operation block consist of a power mixer, a rapid mix basin, flocculation basin, and settling tank controlled as a coagulation control loop.",System and method for controlling effluents in treatment systems
"A system and method for generating modeling software for processing control, used in power plant control, cement plants or other industrial control applications, using models such as expert systems, fuzzy logic, genetic optimization algorithms, and neural networks to convert sensor data into actionable data, information and/or diagnostics. The present invention includes a graphical programming environment, graphical programming tools, graphical user interface (GUI), visual feedback, real-time refresh, run-time object swap, logic standby (safety recovery), modeling and optimization to allows a user to create a control system for an industrial process, and that allows the user to change the process without any manual compile, assemble or load steps other than a save and refresh pushbutton.",System and method for creating a graphical control programming environment
"A system and method for designing a fixed weight analog neural network to perform analog signal processing allows the neural network to be designed with off-line training and implemented with low precision components. A global system error is iteratively computed in accordance with initialized neural functions and weights corresponding to a desired analog neural network configuration for analog signal processing. The neural weights are selectively modified during training and then expected values of weight implementation errors are added thereto. The error adjusted neural weights are used to recompute the global system error and the result thereof is compared to a desired global system error. These steps are repeated as long as the recomputed global system error is greater than the desired global system error. Following that, MOSFET parameters representing MOSFET channel widths and lengths are computed which correspond to the neural functions and weights. Such MOSFET device parameters are then used to implement the desired analog neural network configuration.",System and method for designing fixed weight analog neural networks
"The present invention provides cavitation detection systems and methods employing a classifier for detecting, diagnosing and/or classifying cavitation in a pumping system. The classifier can be integral to tie cavitation detection system and/or operatively coupled to the cavitation system via a controller, diagnostic device and/or computer. Parameters such as flow, pressure and motor speed arc measured and/or estimated, and then provided to a classifier system Such systems include Bayesian, Fuzzy Set, nonlinear regression, neural networks and other training systems, for example The classifier system provides a signal indicative of the existence and extent of cavitation. An exemplary classification system is presented that delineates cavitation extent into one or more of the following categories: 0 (no cavitation), 1 (incipient cavitation), 2 (medium cavitation), 3 (fill cavitation) and 4 (surging cavitation). The cavitation signal can be utilized for monitoring and/or controlling a pumping system to mitigate pump wear, failure and other conditions associated with cavitation.",System and method for detecting and diagnosing pump cavitation
"A system and method for detecting behavior of a computing platform that includes obtaining platform data; for each data motif identifiers in a set data motif identifiers, performing data motif detection on data in an associated timescale, wherein a first data motif identifier operates on data in a first timescale, wherein a second data motif identifier operates on data in a second timescale, wherein the first timescale and second timescale are different; in a neural network model, synthesizing platform data anomaly detection with at least a set of features inputs from data motif detection of the set of motif identifiers; and signaling if a platform data anomaly is detected through the neural network model.",System and method for detecting platform anomalies through neural networks
"A system for unwrapping an artificial neural network (ANN) to determine the tilization and functionality of the nodes uses a network generator for generating an initial ANN architecture. Training and pruning processors operate to generate minimal ANN architectures having increasingly lower levels of classification accuracy. A network analyzer uses an analysis controller to receive minimal ANN architectures from the pruning processor. A connection analyzer operates on the minimal ANN architectures to identify the inputs to the minimal ANN architecture and determine the information represented by and contained in the network inputs. A node analyzer, coupled to the connection analyzer, then defines the utilization and functionality of each node in the minimal ANN architecture in terms of known functions.",System and method for determining node functionality in artificial neural networks
"A system and a method for diagnosis of engine conditions are proposed. In particular, the system and the method are directed to an extraction of features from different information sources and to their processing. These features, together with a series connection of two neural networks, form the crux of the system and method, so that a dependable diagnosis of engine conditions, particularly an error recognition is possible. As a result thereof, maintenance corresponding to the current engine condition is enabled.",System and method for diagnosing jet engine conditions
"In the design and implementation of neural networks, training is determined by a series of architectural and parametric decisions. A method is disclosed that, using genetic algorithms, improves the training characteristics of a neural network. The method begins with a population and iteratively modifies one or more parameters in each generation based on the network with the best training response in the previous generation.",System and method for dynamic learning control in genetically enhanced back-propagation neural networks
"Systems and methods for selecting an appropriate caching algorithm to be used when temporarily storing data accessed by an executing application using a neural network may dynamically and/or iteratively replace an initial caching algorithm being used for the application. An input layer of the neural network may gather values of performance related parameters, such as cache hit rates, data throughput rates, or memory access request response times. The neural network may detect a pattern or change in a pattern of accesses, or a change in a workload, a hardware component, or an operating system parameter. Dependent on these and/or other inputs, the neural network may select and apply a caching algorithm likely to improve performance of the application. Other inputs to the neural network may include values of hardware configuration parameters and/or operating system parameters. The neural network may perform a training exercise or may be self-training, e.g., using reinforcement learning.",System and method for effective caching using neural networks
"An efficient technique of machine learning is provided for training a plurality of convolutional neural networks (CNNs) with increased speed and accuracy using a genetic evolutionary model. A plurality of artificial chromosomes may be stored representing weights of artificial neuron connections of the plurality of respective CNNs. A plurality of pairs of the chromosomes may be recombined to generate, for each pair, a new chromosome (with a different set of weights than in either chromosome of the pair) by selecting entire filters as inseparable groups of a plurality of weights from each of the pair of chromosomes (e.g., filter-by-filter recombination). A plurality of weights of each of the new or original plurality of chromosomes may be mutated by propagating recursive error corrections incrementally throughout the CNN. A small random sampling of weights may optionally be further mutated to zero, random values, or a sum of current and random values.",System and method for efficient evolution of deep convolutional neural networks using filter-wise recombination and propagated mutations
"A system and integration infrastructure to provide a distributed matrix or neural network of connected real-time decision support modules designed to perform business intelligence evaluations in real time. The system and integration infrastructure provide a network of intelligence superimposed upon any company's existing IT data centers, and cloud computing connections. The system is highly customizable to the unique business model deployed by the client company within the best practices of the client company's industry. Whether or not the client company has integrated their diverse enterprise systems, the elements of the matrix are annealed to the various data sources, transaction logs and client software installations currently deployed. These matrix elements or neurons are designed to house critical operational data, determined by the operational model of the client company to be of critical importance. When combined with monitor neurons, they automatically assess the gap between the desired state of a critical element and the current condition in real time. Trigger conditions are pre-established, but modified by an executive controller in real-time, and the system is pre programmed to automatically respond in a prescribed manner to critical conditions having been met even when these conditions come from otherwise stove-piped enterprise applications.",System and method for employing the use of neural networks for the purpose of real-time business intelligence and automation control
"Systems and methods of evolving music tracks are disclosed. One example method providing a plurality of Artificial Neural Networks (ANNs). Each of the ANNs uses a time signature input. The method also includes producing a rhythm from each of the plurality of ANNs. The method also includes evolving a next generation of ANNs based upon a user selection of one of the plurality of rhythms and upon the previous generation of ANNs. An example system includes a plurality of Compositional Pattern Producing Networks (CPPNs). Each of the CPPNs uses a time signature input to produce a rhythm. The system also includes logic configured to receive a selection of one or more of the CPPN, and logic configured to generate at least one evolved CPPN based upon the selection.",System and method for evolving music tracks
"According to exemplary methods of training a convolutional neural network, input images are received into a computerized device having an image processor. The image processor evaluates the input images using first convolutional layers. The number of first convolutional layers is based on a first size for the input images. Each layer of the first convolutional layers receives layer input signals comprising features of the input images and generates layer output signals that include signals from the input images and ones of the layer output signals from previous layers within the first convolutional layers. Responsive to an input image being a second size larger than the first size, additional convolutional layers are added to the convolutional neural network. The number of additional convolutional layers is based on the second size in relation to the first size. The additional convolutional layers are initialized using weights from the first convolutional layers. Feature maps comprising the layer output signals are created.",System and method for expanding and training convolutional neural networks for large size input images
"A regularization system and method for image restoration in homogeneous or inhomogeneous environments. The system and method includes features similar to a neural network with intermediate levels of structure including a pixel having processing capabilities; clusters consisting of a plurality of interconnected pixels and also having processing capabilities; and an image space comprised of a plurality of interconnected pixels and clusters and also having processing capabilities. The system and method also include means for assigning a regularization parameter to each pixel depending on the local variance of intensity of pixels; decomposing the image space into clusters of pixels, each cluster having the same regularization parameter; imposing a blurring function on each pixel; rapidly forming a regularized image by simultaneous local and global encoding of a regularization matrix onto each pixel directed through a process of gradient energy decent; and a means of assessing the output image.",System and method for image regularization in inhomogeneous environments using clustering in neural networks
"In general, certain embodiments of the present disclosure provide methods and systems for object detection by a neural network comprising a convolution-nonlinearity step and a recurrent step. In a training mode, a dataset is passed into the neural network, and the neural network is trained to accurately output a box size and a center location of an object of interest. The box size corresponds to the smallest possible bounding box around the object of interest and the center location corresponds to the location of the center of the bounding box. In an inference mode, an image that is not part of the dataset is passed into the neural network. The neural network automatically identifies an object of interest and draws a box around the identified object of interest. The box drawn around the identified object of interest corresponds to the smallest possible bounding box around the object of interest.",System and method for improved general object detection using neural networks
"A system and method for knowledge verification utilizing biopotentials and physiologic metrics, which includes a computer-based device having stored thereon Probe, Relevant and Gallery image data, and a biopotential amplifier removably connected to a human subject via disposable Ag/AgCl electrodes. Furthermore, the system comprises an analog-to-digital (A/D) converter to digitize said biopotential data for subsequent storage on said computer-based device, analysis software for discriminating said subject's event-related response to the exogenous stimuli, a visual display system comprising an LCD video monitor, and control software for presenting the Probe, Relevant and Gallery visual stimuli in a weighted, pseudo-random sequence which can be modulated by the outcome of said analysis software. Probe image data are not generally known to said human subjects but relevant to the knowledge to be verified; Relevant image data are generally known to said human subjects but not relevant to the knowledge to be verified; and Gallery image data are not generally known to said human subjects and not relevant to the knowledge to be verified. Said knowledge verification system can utilize parametric or non-parametric, e.g., artificial neural networks, analysis to provide an output of verification, or non-verification of knowledge of interest. Exemplary headband and electrode configurations optimized to produce the desired signals are disclosed.",System and method for knowledge verification utilizing biopotentials and physiologic metrics
"System and method for layer-wise training of deep neural networks (DNNs) are disclosed. In an embodiment, multiple labelled images are received at a layer of multiple layers of a DNN. Further, the labelled images are pre-processed. The pre-processed images are then transformed based on a predetermined weight matrix to obtain feature representation of the pre-processed images at the layer, the feature representation comprise feature vectors and associated labels. Furthermore, kernel similarity between the feature vectors is determined based on a predefined kernel function. Moreover, a Gaussian kernel matrix is determined based on the kernel similarity. In addition, an error function is computed based on the predetermined weight matrix and the Gaussian kernel matrix. Also, a weight matrix associated with the layer is computed based on the error function and predetermined weight matrix, thereby training the layer of the multiple layers.",System and method for layer-wise training of deep neural networks
"Described is a system for location recognition for mobile platforms, such as autonomous robotic exploration. In operation, an image in front of the platform is converted into a high-dimensional feature vector. The image reflects a scene proximate the mobile platform. A candidate location identification of the scene is then determined. The candidate location identification is then stored in a history buffer. Upon receiving a cue, the system then determines if the candidate location identification is a known location or a new location.",System and method for location recognition and learning utilizing convolutional neural networks for robotic exploration
"A system and method for lossy image and video compression and transmission that utilizes a neural network as a function to map a known noise image to a desired or target image, allowing the transfer only of hyperparameters of the function instead of a compressed version of the image itself. This allows the recreation of a high-quality approximation of the desired image by any system receiving the hyperparameters, provided that the receiving system possesses the same noise image and a similar neural network. The amount of data required to transfer an image of a given quality is dramatically reduced versus existing image compression technology. Being that video is simply a series of images, the application of this image compression system and method allows the transfer of video content at rates greater than existing technologies in relation to the same image quality.",System and method for lossy image and video compression and transmission utilizing neural networks
"An intelligent controller for on-line monitoring of circulation system in order to minimize a problem of streaming electrification and to avoid degradation of the electrical insulation of the system. The controller is designed to combine advantages of fuzzy logic and neural networks, and includes a fuzzy logic (employing a pseudo-neural network) for acquiring analog input data from a plurality of sensors and for interpreting this input data into fuzzyfier outputs. A main processor consisting of a fully connected feed-forward neural network serves for processing the fuzzifier outputs in order to obtain controlling instructions for the system.",System and method for mitigation of streaming electrification in power transformers by intelligent cooling system control
"A system and method for noninvasively detecting coronary artery disease. The system and method utilize a vasodilator drug to increase the signal-to-noise ratio of an acoustic signal that represents diastolic heart sounds of a patient. A wavelet transform is performed on the acoustic signal to provide parameters for a feature vector. Scaled clinical examination parameters such as a patient's sex, age, body weight, smoking condition, blood pressure, and family history are also included in the feature vector. The feature vector is used as an input pattern to neural networks. The output of the neural networks represent a diagnosis of coronary stenosis in a patient.",System and method for noninvasive detection of arterial stenosis
"This disclosure relates to system and method for optical character recognition. In one embodiment, the method comprises providing an image data to a plurality of customized machine learning algorithms or various customized neural networks, configured to recognize a set of pre-defined characters. The method comprises presenting one or more suggestions for the character to the user in response to negative character recognition, and training a customized machine learning algorithm corresponding to the character if one of the suggestions is identified by the user. If the suggestions are rejected by the user, the method comprises prompting the user to identify the character and determining presence of the character in the set of pre-defined characters. The method further comprises training a customized machine learning algorithm corresponding to the character if the character is present, or dynamically creating a customized machine learning algorithm corresponding to the character if the character is not present.",System and method for optical character recognition
A parallel convolutional neural network is provided. The CNN is implemented by a plurality of convolutional neural networks each on a respective processing node. Each CNN has a plurality of layers. A subset of the layers are interconnected between processing nodes such that activations are fed forward across nodes. The remaining subset is not so interconnected.,System and method for parallelizing convolutional neural networks
"Described is a system for real-time object recognition. During operation, the system extracts convolutional neural network (CNN) feature vectors from an input image. The input image reflects a scene proximate the system, with the feature vector representing an object in the input image. The CNN feature vector is matched against feature vectors stored in a feature dictionary to identify k nearest neighbors for each object class stored in the feature dictionary. The matching results in a probability distribution over object classes stored in the feature dictionary. The probability distribution provides a confidence score that each of the object classes in the feature dictionary are representative of the object in the input image. Based on the confidence scores, the object in the input image is then recognized as being a particular object class when the confidence score for the particular object class exceeds a threshold.",System and method for performing real-time video object recognition utilizing convolutional neural networks
"A system and method are disclosed for determining the pose angle of an object in an input image. In a preferred embodiment, the present system comprises a pose estimator having a prototype projector, a regression estimator, and an angle calculator. The prototype projector is preferably adapted to reduce the input image dimensionality for faster further processing by projecting the input pixels of the image onto a Self-Organizing Map (SOM) neural network. The regression estimator is preferably implemented as a neural network and adapted to map the projections to a pattern unique to each pose. The angle calculator preferably includes a curve fitter and an error analyzer. The curve fitter is preferably adapted to estimate the pose angle from the mapping pattern. The error analyzer is preferably adapted to produce a confidence signal representing the likelihood of the input image being a face at the calculated pose. The system also preferably includes two network trainers responsible for synthesizing the neural networks.",System and method for pose-angle estimation
"A method for predicting parameters of hydrocarbons includes the steps of generating an NMR spectrum of a sample of a hydrocarbon having different hydrogen or carbon types related to structures or sample composition; dividing the NMR spectrum into regions corresponding to the different hydrogen or carbon types related to structures or sample composition; evaluating different spectral regions by either (i) determining average molecular parameters, and (ii) quantifying a signal intensity of said at least one region of said different regions, based upon a desired parameter to be predicted so as to provide spectrum extracted quantities; and applying the spectrum extracted quantities to a trained neural network trained to correlate spectrum extracted quantities with hydrocarbon parameters so as to predict the desired parameters from the spectrum extracted quantity. A system is also provided.",System and method for predicting parameter of hydrocarbon with spectroscopy and neural networks
A system and method for printing target colors includes a print-engine interface and a neural network component. The print-engine interface is in operative communication with a print engine of a printing system. The neural network component is calibrated to the print engine for printing a target color on a substrate. The neural network is in operative communication with the print-engine interface and communicates a parameter associated with printing the target color on the substrate utilizing the print engine.,System and method for printing target colors with process colors utilizing parallel feedforward neural networks
"A system and method for processing patient polysomnograph data are provided. An abstractor obtains raw patient polysomnograph data and generates a subset of the data to include selected factors, including data clusters. The subset of the patient polysomnograph data is transferred to two or more neural networks that process the data and generate sleep classification data. An integrator obtains the sleep classification data from the two or more neural networks by integrating the sleep classification data from each neural network. A cumulative sleep stage score is generated including confidence values and accuracy estimations for review.",System and method for processing patient polysomnograph data utilizing multiple neural network processing
"A method for ranking candidate speech recognition results includes generating, with a controller, a plurality of feature vectors for the candidate speech recognition results, each feature vector including one or more of trigger pair features, a confidence score feature, and word-level features. The method further includes providing the plurality of feature vectors as inputs to a neural network, generating a plurality of ranking scores corresponding to the plurality of feature vectors for the plurality of candidate speech recognition results based on an output layer of the neural network, and operating the automated system using the candidate speech recognition result in the plurality of candidate speech recognition results corresponding to a highest ranking score in the plurality of ranking scores as input.",System and method for ranking of hybrid speech recognition results with neural networks
"A system and method for script and orientation detection of images using artificial neural networks (ANNs) are disclosed. In one example, textual content in the image is extracted. Further, a vertical component run (VCR) and horizontal component run (HCR) are obtained by vectorizing each connected component in the extracted textual content. Furthermore, a zonal density run (ZDR) is obtained for each connected component in the extracted textual content. In addition, a concatenated vertical document vector (VDV), horizontal document vector (HDV), and zonal density vector (ZDV) is computed by normalizing the obtained VCR, HCR, and ZDR, respectively, for each connected component. Moreover, the script in the image is determined using a script detection ANN module and the concatenated VDV, HDV, and ZDV of the image. Also, the orientation of the image is determined using an orientation detection ANN module and the concatenated VDV, HDV, and ZDV of the image.",System and method for script and orientation detection of images using artificial neural networks
Deep recurrent neural networks applied to speech recognition. The deep recurrent neural networks (RNNs) are preferably implemented by stacked long short-term memory bidirectional RNNs. The RNNs are trained using end-to-end training with suitable regularisation.,System and method for speech recognition using deep recurrent neural networks
Deep recurrent neural networks applied to speech recognition. The deep recurrent neural networks (RNNs) are preferably implemented by stacked long short-term memory bidirectional RNNs. The RNNs are trained using end-to-end training with suitable regularisation.,System and method for speech recognition using deep recurrent neural networks
Deep recurrent neural networks applied to speech recognition. The deep recurrent neural networks (RNNs) are preferably implemented by stacked long short-term memory bidirectional RNNs. The RNNs are trained using end-to-end training with suitable regularization.,System and method for speech recognition using deep recurrent neural networks
A system for teaching compositionality to convolutional neural networks includes an unmasked convolutional neural network comprising a first set of convolutional neural network layers; a first masked convolutional neural network comprising a second set of convolutional neural network layers; the unmasked convolutional neural network and the first masked convolutional network sharing convolutional neural network weights; the system training the unmasked and first masked convolutional neural networks simultaneously based on an objective function that seeks to reduce both discriminative loss and compositional loss.,System and method for teaching compositionality to convolutional neural networks
"A technique and system for counting the number of repetitions of approximately the same action in an input video sequence using 3D convolutional neural networks is disclosed. The proposed system runs online and not on the complete video. It analyzes sequentially blocks of 20 non-consecutive frames. The cycle length within each block is evaluated using a deep network architecture and the information is then integrated over time. A unique property of the disclosed method is that it is shown to successfully train on entirely synthetic data, created by synthesizing moving random patches. It therefore effectively exploits the high generalization capability of deep neural networks. Coupled with a region of interest detection mechanism and a suitable mechanism to identify the time scale of the video, the system is robust enough to handle real world videos collected from YouTube and elsewhere, as well as non-video signals such as sensor data revealing repetitious physical movement.",System and method for the detection and counting of repetitions of repetitive activity via a trained network
"Systems and methods for training a neural network or an ensemble of neural networks are described. A hyper-parameter that controls the variance of the ensemble predictors is used to address overfitting. For larger values of the hyper-parameter, the predictions from the ensemble have more variance, so there is less overfitting. This technique can be applied to ensemble learning with various cost functions, structures and parameter sharing. A cost function is provided and a set of techniques for learning are described.",System and method for training neural networks
"A method of global optimization of complex, highly nonlinear, multivariant systems is described. An artificial neural network (ANN) is trained to create an approximate inverse model. The desired behavior for a particular system is then input to the inverse model to derive approximate model parameters for the particular system. Optimization of the approximate model parameters yields optimal model parameters. The method is applied to the synthesis of mechanical linkages where examples of a type of linkage mechanism are used to train an ANN and derive the approximate inverse model. Inverse models for a number of linkage mechanism types are derived and stored. For a linkage mechanism with unknown linkage parameters, a power spectrum representation of the coupler curve is developed and the inverse model for the type of linkage mechanism retrieved. The representation of the desired coupler curve is input and the approximate linkage parameters derived. Optimization further refines the linkage parameters.",System and method of global optimization using artificial neural networks
"Predicting gas saturation of a formation using neural networks. At least some of the illustrative embodiments include obtaining a gamma count rate decay curve one each for a plurality of gamma detectors of a nuclear logging tool (the gamma count rate decay curves recorded at a particular borehole depth), applying at least a portion of each gamma count rate decay curve to input nodes of a neural network, predicting a value indicative of gas saturation of a formation (the predicting by the neural network in the absence of a formation porosity value supplied to the neural network), and producing a plot of the value indicative of gas saturation of the formation as a function of borehole depth.",System and method of predicting gas saturation of a formation using neural networks
"A system and method for predicting oil reservoir properties throughout the reservoir using well data and seismic data. While the reservoir properties in the vicinity of a well borehole are usually known (i.e. by well logging), the reservoir properties between wells are unknown and difficult to estimate. Because the relationships between reservoir properties and seismic data is seldom obvious, the method uses Artificial Neural Networks (ANN's) to estimate these relationships. First, the method calculates the intersections between the seismic data and wellbore date, i.e. seismic reflectors are correlated to geological markers in the wellbores. Second, the method estimates the significance between seismic attributes and borehole properties. Next, the method models or calibrates the relationship between reservoir properties and seismic attributes by training an ANN using seismic attributes and wellbore data close to the intersections. Finally, the trained ANN uses the seismic attributes to predict the reservoir properties between wells. Advantageously, statistic methods are used to estimate the confidence of the predictions.",System and method of predicting reservoir properties
"A method and system for re-establishing a pathway in a damaged or severed neural network includes an imaging device, an alignment device and a treatment device. An accurate image of the damaged neural network is created. An alignment device imparts wave energy into a damaged region of the neural network to direct re-growth axons into a remaining endoneurial tube to direct axon growth back to the correct targets to re-establish the severed neural network.",System and method of repairing of neural networks
"An ultrasonic flowmeter using ultrasonic pulses transmitted within a pipe containing flowing fluid determines values, including flow rate or fluid velocity of the flowing fluid. The ultrasonic flowmeter transmits trains of ultrasonic pulses having velocity components either in the upstream or downstream direction. The ultrasonic flowmeter includes the transducer placed downstream external to the pipe and a transducer placed upstream external to the pipe. Time measurements are made to determine a time, TU, required for a pulse train to travel from the downstream transducer to the upstream transducer and the time, TD, required for a pulse train to travel from the upstream transducer to the downstream transducer. The ultrasonic flowmeter is configured to have consistent triggering of the pulses of the pulse train to reduce error. Also, the electronics are simplified to allow for lower timing resolution requirements. Once TU and TD are determined, a series of validation filters, parameter filters, coarse flow rate filters, and refined flow rate filters are used to determine flow measurement. Alternatively, fluid velocity filters are used. Also, diameter filters are used to determine the current interior diameter of the pipe. All measurements are made noninvasively. The system and method includes determining coefficients for the various filters to account for variability in dimensions, parameters and conditions involved.",System and method using digital filters and neural networks to determine fluid flow
"A system and methods for detecting polyps using optical images acquired during a colonoscopy. In some aspects, a method includes receiving the set of optical images from the input and generating polyp candidates by analyzing the received set of optical images. The method also includes generating a plurality of image patches around locations associated with each polyp candidate, applying a set of convolutional neural networks to the corresponding image patches, and computing probabilities indicative of a maximum response for each convolutional neural network. The method further includes identifying polyps using the computed probabilities for each polyp candidate, and generating a report indicating identified polyps.",System and methods for automatic polyp detection using convulutional neural networks
"The present invention is embodied in a system and process for automatically learning a reliable tracking system. The tracking system is learned by using information produced by an initial object model in combination with an initial tracking function, and a data acquisition function for gathering observations about each image. The initial tracking function probabilistically determines the configuration of one or more target objects in a temporal sequence of images. The observations gathered by the data acquisition function include information that is relevant to parameters desired for a final object model. These relevant observations may include information such as the color, shape, or size of a tracked object, and depend on the parameters necessary to support the final tracking function. A learning function based on a learning method such as, for example, neural networks, Bayesian belief networks (BBN), discrimination functions, decision trees, expectation-maximization on mixtures of Guassians, probability distribution functions (PDF), estimation through moment computation, PDF estimation through histograms, etc., then uses the observations and probabilistic target location information to probabilistically learn an object model automatically tailored to specific target objects. The learned object model is then used in combination with the final tracking function to probabilistically locate and track specific target objects in one or more sequential images.",System and process for bootstrap initialization of vision-based tracking systems
Methods for system failure prediction include clustering log files according to structural log patterns. Feature representations of the log files are determined based on the log clusters. A likelihood of a system failure is determined based on the feature representations using a neural network. An automatic system control action is performed if the likelihood of system failure exceeds a threshold.,System failure prediction using long short-term memory neural networks
"A system for bearinqs-only contact state estimation in response to target bearing and ownship speed and course information provided for a plurality of observation legs at successive points in time, includes a plurality of neural networks and a data fusion circuit. Each of the neural networks generates range-normalized parameter estimate information for one of the observation legs in response to target bearing and ownship speed and course information for an associated one of the observation legs, provided thereto at each point in time and information generated for the previous point in time. The data fusion system receives the range-normalized parameter estimate information from the neural networks and generates the contact state estimate in response thereto.",System for bearing-only contact state estimation using recurrent neural networks
"A function for compensating an error between a teacher signal and an output signal with a weight value is defined. A multilayered neural network is changed so that the function becomes minimum. Thus, the multilayered neural network can be adaptively controlled.",System for controlling an object and medium using neural networks
"A system for detecting information leakage in e-mails using neural network and support vector machines is provided. This system does not use the content of the e-mail or the content of the attachments in the e-mail. Instead, a set of non-sensitive variables or attributes is picked from the e-mails originating from a given establishment and also from the profiles of the users sending those mails. The said attributes are extracted for all outbound mails. This extraction process does not involve reading the main text of the mail and thus the sensitivity of the mail information is protected. These attributes are chosen using filters built into the detection hardware. Neural networks and support vector machine built into the detection hardware are then used on these attributes to detect pattern violation and possible information leakage.",System for detecting information leakage in outbound e-mails without using the content of the mail
"A method, computer program product, and system (100) for computerized analysis of the likelihood of malignancy in a pulmonary nodule using artificial neural networks (ANNs) (S4). The method, on which the computer program product and the system is based on, includes obtaining a digital outline of a nodule; generating objective measures corresponding to physical features of the outline of the nodule; applying the generated objective measures to an ANN; and determining a likelihood of malignancy of the nodule based on an output of the ANN. Techniques include novel developments and implementations of artificial neural networks and feature extraction for digital images. Output from the inventive method yields an estimate of the likelihood of malignancy (S7) for a pulmonary nodule.",System for detection of malignancy in pulmonary nodules
"Method for controlling an occupant protection device in a vehicle in which data is acquired from at least one sensor relating to an occupant in a seat to be protected by the occupant protection device, the type of occupant is classified based on the acquired data and when the occupant is classified as an empty seat or a rear-facing child seat, deployment of the occupant protection device is disabled or adjusted. Otherwise, the size of the occupant is classified based on the acquired data, the position of the occupant is determined by one of a plurality of algorithms selected based on the classified size of the occupant using the acquired data, each algorithm being applicable for a specific size of occupant. Deployment of the occupant protection device is disabled or adjusted when the determined position of the occupant is more likely to result in injury to the occupant if the occupant protection device were to deploy. The algorithms may be pattern recognition algorithms such as neural networks.",System for determining the occupancy state of a seat in a vehicle and controlling a component based thereon
The present invention discloses a system for extracting targets from radar signatures. Disclosed is a unique combination of Wavelet technology and neural networks using fractal geometry techniques that estimates the Fractal Dimension of a target even in the presence of high background noise.,System for extracting targets from radar signatures
The present invention discloses a system for extracting targets from radar signatures. Disclosed is a unique combination of Wavelet technology and neural networks using fractal geometry techniques that estimates the Fractal Dimension of a target even in the presence of high background noise.,System for extracting targets from radar signatures
"System for monitoring the discharging/charging cycles of a rechargeable battery which includes adaptive calculation means for providing a predictive indication of when the battery will reach a critical discharge voltage. The adaptive calculation means includes parameters which can be modified by other adaptive calculation means so as to optimize the monitor's performance depending on the battery's actual use. The adaptive calculation means may be neural networks formed by a microprocessor and memory, and the monitor system may be coupled to a host system.","System for monitoring charging/discharging cycles of a rechargeable battery, and host device including a smart battery"
"A system for processing Aeromagnetic survey data to determine depth to basement rock is disclosed. The system uses Neural Networks having an input layer of elements, a hidden layer of elements and an output layer of elements which are interconnected by a weighted system of interconnections. A training session using known input and output data is used to train the Neural Network by adjusting the weighting functions repetitively to minimize any error in the output of the Neural Network.",System for neural network interpretation of aeromagnetic data
"A prediction method that estimates the real-time position of a mobile device based on previously observed data is provided. The present invention can be used in real-time navigation, including providing real-time alerts of an upcoming destination and notifications of emergency events in close geographic proximity. The prediction method utilizes neural networks and/or functions generated using genetic algorithms in estimating the mobile device's real-time position. The prediction method provides reliable Location-Based Services (LBS) in events where traditional positioning technologies become unreliable. It is also seamless, as the user remains unaware of any interruption in accessing the positioning technology.",System for pattern recognition in real-time location-based services applications
"A system (22) for synthesis of textured images, comprising a texture analyser (24) and a texture synthesizer (28). The texture analyser (24) comprises an analyzing neural network (30) which learns to characterize a texture by calculating synaptic coefficients (C.sub.ab), utilizing at least one proximity function which characterizes a neighbourhood around pixels of said texture. The texture synthesizer (28) comprises a synthesizing neural network (40) which receives the synaptic coefficients (C.sub.ab) thus calculated and which, utilizing a relaxation mechanism, synthesizes a replica of the texture learned. The neural networks (30), (40) may have a tree-type structure.","System for processing textured images, texture analyser and texture synthesizer"
"A system for retrieving multimedia information is provided using a computer coupled to a computer-based network, such as the Internet, and particularly the World Wide Web (WWW). The system includes a web browser, a graphic user interface enabled through the web browser to allow a user to input a query representing the information the user wishes to retrieve, and an agent server for producing, training, and evolving first agents and second agents. Each of the first agents retrieves documents (Web page) from the network at a different first network address and at other addresses linked from the document at the first network address. Each of the second agents executes a search on different search engines on the network in accordance with the query to retrieve documents at network addresses provided by the search engine. The system includes a natural language processor which determines the subject categories and important terms of the query, and of the text of each agent retrieved document. The agent server generates and trains an artificial neural network in accordance with the natural language processed query, and embeds the trained artificial neural network in each of the first and second agents. During the search, the first and second agents process through their artificial neural network the subject categories and important terms of each document they retrieve to determine a retrieval value for the document. The graphic user interface displays to the user the addresses of the retrieved documents which are above a threshold retrieval value. The user manually, or the agent server automatically, selects which of the retrieved documents are relevant. Periodically, the artificial neural network of the first and second agents is expanded and retrained by the agent server in accordance with the selected relevant documents to improve their ability to retrieve documents which may be relevant to the query. Further, the agent server can evolve an artificial neural network based on the current artificial neural network, the retrieved documents, and their selected relevancy, by iteratively producing, training, and testing several generations of neural networks to produce an evolved agent. The artificial neural network of the evolved agent then replaces the current artificial neural network used by the agents to search the Internet. One or more concurrent search of the Internet may be provided.",System for retrieving multimedia information from the internet using multiple evolving intelligent agents
"An artificial neural network (ANN) based system that is adapted to process an input pattern to generate an output pattern related thereto having a different number of components than the input pattern. The system (26) is comprised of an ANN (27) and a memory (28), such as a DRAM memory, that are serially connected. The input pattern (23) is applied to a processor (22), where it can be processed or not (the most general case), before it is applied to the ANN and stored therein as a prototype (if learned). A category is associated with each stored prototype. The processor computes the coefficients that allow the determination of the estimated values of the output pattern, these coefficients are the components of a so-called intermediate pattern (24). Assuming the ANN has already learned a number of input patterns, when a new input pattern is presented to the ANN in the recognition phase, the category of the closest prototype is output therefrom and is used as a pointer to the memory. In turn, the memory outputs the corresponding intermediate pattern. The input pattern and the intermediate pattern are applied to the processor to construct the output pattern (25) using the coefficients. Typically, the input pattern is a block of pixels in the field of scaling images.",System for scaling images using neural networks
"A system for monitoring the discharging/charging cycles of a rechargeable battery which includes adaptive calculation means for providing a predictive indication of when the battery will reach a critical discharge voltage. The adaptive calculation means includes parameters which can be modified by other adaptive calculation means so as to optimize the monitor's performance depending on the battery's actual use. The adaptive calculation means may be neural networks formed by a microprocessor and memory, and the monitor system may be coupled to a host system.","System monitoring the discharging period of the charging/discharging cycles of a rechargeable battery, and host device including a smart battery"
"System on chips (SoCs) of a microprocessor electrically connected with electronic memory devices and/or optically connected with a optical memory device are disclosed along with various embodiments of building block of the microprocessor and the electronic memory devices, wherein the microprocessor can comprise digital unit and/or neural networks based unit.",System on chip (SoC) based on phase transition and/or phase change material
"A system of self-organizing mobile robotic agents (MRAs) in a multi-robotic system (MRS) is disclosed. MRAs cooperate, learn and interact with the environment. The system uses various AI technologies including genetic algorithms, genetic programming and evolving artificial neural networks to develop emergent dynamic behaviors. The collective behaviors of autonomous intelligent robotic agents are applied to numerous applications. The system uses hybrid control architectures. The system also develops dynamic coalitions of groups of autonomous MRAs for formation and reformation in order to perform complex tasks.","System, method and apparatus for organizing groups of self-configurable mobile robotic agents in a multi-robotic system"
"A system of self-organizing mobile robotic agents (MRAs) in a multi-robotic system (MRS) is disclosed. MRAs cooperate, learn and interact with the environment. The system uses various AI technologies including genetic algorithms, genetic programming and evolving artificial neural networks to develop emergent dynamic behaviors. The collective behaviors of autonomous intelligent robotic agents are applied to numerous applications. The system uses hybrid control architectures. The system also develops dynamic coalitions of groups of autonomous MRAs for formation and reformation in order to perform complex tasks.","System, method and apparatus for organizing groups of self-configurable mobile robotic agents in a multi-robotic system"
"The invention provides a technique for pattern recognition that employs a state machine that incorporates a sequence of table-look-up operations. A sequence of input parameters, derived according to an application-specific algorithm, generates a corresponding sequence of memory addresses for these operations. The memory tables are organized in a hierarchical structure that corresponds to the input sequence. Table data is designed to recognize a specific library of input patterns. An input sequence traces an input-specific path through the memory tables until one of the patterns in the library is recognized or until it is determined that the input sequence is inconsistent with f the library patterns. For each library pattern, the table data is designed to accommodate the variations in the input values that are specific to the application (e.g., variations due to noise and/or tolerances). Table data can be derived by analysis, simulation, learning or a combination of these methods. The invention can replace neural networks or DSP correlation techniques in real-time applications. It achieves very high performance by comparing the input sequence to all of the patterns in the library simultaneously. The invention can be employed to improve the image quality of a caligraphic display system that uses flat-panel display technology. A method for improving the performance of display systems that employ image memories.","System, method and apparatus for pattern recognition with application to symbol recognition and regeneration for a calligraphic display"
"The invention provides a technique for pattern recognition that employs a state machine that incorporates a sequence of table-look-up operations. A sequence of input parameters, derived according to an application-specific algorithm, generates a corresponding sequence of memory addresses for these operations. The memory tables are organized in a hierarchical structure that corresponds to the input sequence. Table data is designed to recognize a specific library of input patterns. An input sequence traces an input-specific path through the memory tables until one of the patterns in the library is recognized or until it is determined that the input sequence is inconsistent with f the library patterns. For each library pattern, the table data is designed to accommodate the variations in the input values that are specific to the application (e.g., variations due to noise and/or tolerances). Table data can be derived by analysis, simulation, learning or a combination of these methods. The invention can replace neural networks or DSP correlation techniques in real-time applications. It achieves very high performance by comparing the input sequence to all of the patterns in the library simultaneously. The invention can be employed to improve the image quality of a caligraphic display system that uses flat-panel display technology. A method for improving the performance of display systems that employ image memories is also provided.","System, method and apparatus for pattern recognition with application to symbol recognition and regeneration for a calligraphic display"
"The invention provides a technique for pattern recognition that employs a state machine that incorporates a sequence of table-look-up operations. A sequence of input parameters, derived according to an application-specific algorithm, generates a corresponding sequence of memory addresses for these operations. The memory tables are organized in a hierarchical structure that corresponds to the input sequence. Table data is designed to recognize a specific library of input patterns. An input sequence traces an input-specific path through the memory tables until one of the patterns in the library is recognized or until it is determined that the input sequence is inconsistent with any of the library patterns. For each library pattern, the table data is designed to accommodate the variations in the input values that are specific to the application (e.g., variations due to noise and/or tolerances). Table data can be derived by analysis, simulation, learning or a combination of these methods. The invention can replace neural networks or DSP correlation techniques in real-time applications. It achieves very high performance by comparing the input sequence to all of the patterns in the library simultaneously. The invention can be employed to improve the image quality of a caligraphic display system that uses flat-panel display technology. A method for improving the performance of display systems that employ image memories to refresh a computer generated image is also disclosed.","System, method and apparatus for pattern recognition with application to symbol recognition and regeneration for a display"
"A system, method and product for determining a vehicle key fob location. The system may include a control unit for mounting in a vehicle and configured to receive multiple signals, each representing a strength of a wireless signal transmitted between the fob and one of multiple antennas located on a vehicle, and multiple neural networks having a cascade topology. The neural networks may include a first neural network for determining one of a vehicle internal position and a vehicle external position of the fob based on the wireless signal strengths, a second neural network in communication with the first neural network for determining one of multiple vehicle interior positions of the fob based on the wireless signal strengths, and a third neural network in communication with the first neural network for determining one of multiple vehicle exterior positions of the fob based on the wireless signal strengths.","System, method and product for locating vehicle key using neural networks"
"A method and computer product is presented for mapping n-dimensional input patterns into an m-dimensional space so as to preserve relationships that may exist in the n-dimensional space. A subset of the input patterns is chosen and mapped into the m-dimensional space using an iterative nonlinear mapping process. A set of locally defined neural networks is created, then trained in accordance with the mapping produced by the iterative process. Additional input patterns not in the subset are mapped into the m-dimensional space by using one of the local neural networks. In an alternative embodiment, the local neural networks are only used after training and use of a global neural network. The global neural network is trained in accordance with the mapping produced by the iterative process. Input patterns are initially projected into the m-dimensional space using the global neural network. Local neural networks are then used to refine the results of the global network.","System, method, and computer program product for representing object relationships in a multidimensional space"
"A recognition system includes an image capturing device and a server. The image capturing device generates a Mth-layer calculation result based on image data and a convolutional neural network (CNN), and transmits feature information associated with the Mth-layer calculation result. M is a positive integer, M is equal to or greater than 1, M is less than or equal to N, and N is a predetermined positive integer. The server receives the feature information. The server generates a Kth-layer calculation result based on the feature information and the CNN by an iterative method when M is less than N. K is a positive integer which is greater than M and less than or equal to N. The server generates a first recognition result associated with the image data based on the Kth-layer calculation result and a first recognition model when K is equal to N.","System, method, and non-transitory computer readable storage medium for image recognition based on convolutional neural networks"
"Dimensionality reduction systems and methods facilitate visualization, understanding, and interpretation of high-dimensionality data sets, so long as the essential information of the data set is preserved during the dimensionality reduction process. In some of the disclosed embodiments, dimensionality reduction is accomplished using clustering, evolutionary computation of low-dimensionality coordinates for cluster kernels, particle swarm optimization of kernel positions, and training of neural networks based on the kernel mapping. The fitness function chosen for the evolutionary computation and particle swarm optimization is designed to preserve kernel distances and any other information deemed useful to the current application of the disclosed techniques, such as linear correlation with a variable that is to be predicted from future measurements. Various error measures are suitable and can be used.",Systems and methods employing cooperative optimization-based dimensionality reduction
"Dimensionality reduction systems and methods facilitate visualization, understanding, and interpretation of high-dimensionality data sets, so long as the essential information of the data set is preserved during the dimensionality reduction process. In some of the disclosed embodiments, dimensionality reduction is accomplished using clustering, evolutionary computation of low-dimensionality coordinates for cluster kernels, particle swarm optimization of kernel positions, and training of neural networks based on the kernel mapping. The fitness function chosen for the evolutionary computation and particle swarm optimization is designed to preserve kernel distances and any other information deemed useful to the current application of the disclosed techniques, such as linear correlation with a variable that is to be predicted from future measurements. Various error measures are suitable and can be used.",Systems and methods employing cooperative optimization-based dimensionality reduction
"A method for training a deep neural network, comprises receiving and formatting speech data for the training, preconditioning a system of equations to be used for analyzing the speech data in connection with the training by using a non-fixed point quasi-Newton preconditioning scheme, and employing flexible Krylov subspace solvers in response to variations in the preconditioning scheme for different iterations of the training.",Systems and methods for accelerating hessian-free optimization for deep neural networks by implicit preconditioning and sampling
"A method for training a deep neural network, comprises receiving and formatting speech data for the training, preconditioning a system of equations to be used for analyzing the speech data in connection with the training by using a non-fixed point quasi-Newton preconditioning scheme, and employing flexible Krylov subspace solvers in response to variations in the preconditioning scheme for different iterations of the training.",Systems and methods for accelerating hessian-free optimization for deep neural networks by implicit preconditioning and sampling
"Described herein are systems and methods for generating and using attention-based deep learning architectures for visual question answering task (VQA) to automatically generate answers for image-related (still or video images) questions. To generate the correct answers, it is important for a model's attention to focus on the relevant regions of an image according to the question because different questions may ask about the attributes of different image regions. In embodiments, such question-guided attention is learned with a configurable convolutional neural network (ABC-CNN). Embodiments of the ABC-CNN models determine the attention maps by convolving image feature map with the configurable convolutional kernels determined by the questions semantics. In embodiments, the question-guided attention maps focus on the question-related regions and filters out noise in the unrelated regions.",Systems and methods for attention-based configurable convolutional neural networks (ABC-CNN) for visual question answering
"Logic circuits provide networks to simulate the functions of neural networks of the brain, and can discriminate degrees of state, and combinations of degrees of state, corresponding to a number of neurons. Logic circuits comprise Recursive AND NOT Conjunctions (RANCs), or AND NOT gates. A RANC is a general logic circuit that performs conjunctions for 2n possible combinations of truth values of n propositions. The RANCs function dynamically, with capabilities of excitation and inhibition. Networks of RANCs are capable of subserving a variety of brain functions, including creative and analytical thought processes. A complete n-RANC produces all conjunctions corresponding to the 2n possible combinations of truth values of n propositions.",Systems and methods for brain-like information processing
"Systems, methods, and articles are provided for classifying account data using artificial neural networks. An example embodiment may include receiving account holder data for a plurality of account holders, identifying through computer automated operations relationships between the plurality of account holders and the account holder data, and analyzing the account holder data of the plurality of account holders to create one or more classifications based on the relationships between the plurality of account holders and the account holder data. Another example embodiment may include classifying financial account holder data for a plurality of financial account holders using a Kohonen network, and displaying a graphical representation of the classified financial account holder data to visualize one or more relationships between plurality of financial account holders and the financial account holder data. Other embodiments may be described and claimed.",Systems and methods for classifying account data using artificial neural networks
"A method for training a deep neural network (DNN), comprises receiving and formatting speech data for the training, performing Hessian-free sequence training (HFST) on a first subset of a plurality of subsets of the speech data, and iteratively performing the HFST on successive subsets of the plurality of subsets of the speech data, wherein iteratively performing the HFST comprises reusing information from at least one previous iteration.",Systems and methods for combining stochastic average gradient and hessian-free optimization for sequence training of deep neural networks
"A method for training a deep neural network (DNN), comprises receiving and formatting speech data for the training, performing Hessian-free sequence training (HFST) on a first subset of a plurality of subsets of the speech data, and iteratively performing the HFST on successive subsets of the plurality of subsets of the speech data, wherein iteratively performing the HFST comprises reusing information from at least one previous iteration.",Systems and methods for combining stochastic average gradient and hessian-free optimization for sequence training of deep neural networks
"A compact convolutional neural network may include a preliminary layer group, one or more intermediate layer groups, a final layer group, and/or other layers/layer groups. The preliminary layer group may include an input layer, a first preliminary normalization layer, a preliminary padding layer, a preliminary convolution layer, a preliminary activation layer, a second preliminary normalization layer, and a preliminary downsampling layer. One or more intermediate layer groups may include an intermediate squeeze layer, a first intermediate normalization layer, an intermediate padding layer, a first intermediate expand layer, a second intermediate expand layer, an intermediate concatenation layer, a second intermediate normalization layer, an intermediate activation layer, and an intermediate combination layer. The final layer group may include a final dropout layer, a final convolution layer, a final activation layer, a first final normalization layer, a final downsampling layer, a final flatten layer, and a second final normalization layer.",Systems and methods for compact convolutional neural networks
"The present disclosure relates to systems and methods for detecting and identifying anomalies within a discrete wavelet database. In one implementation, the system may include one or more memories storing instructions and one or more processors configured to execute the instructions. The instructions may include instructions to receive a new wavelet, convert the net transaction to a wavelet, convert the wavelet to a tensor using an exponential smoothing average, calculate a difference field between the tensor and a field having one or more previous transactions represented as tensors, perform a weighted summation of the difference field to produce a difference vector, apply one or more models to the difference vector to determine a likelihood of the new wavelet representing an anomaly, and add the new wavelet to the field when the likelihood is below a threshold.",Systems and methods for converting discrete wavelets to tensor fields and using neural networks to process tensor fields
"Systems and methods are described to address shortcomings in a conventional conversation system via a novel technique utilizing artificial neural networks to train the conversation system whether or not to continue context. In some aspects, an interactive media guidance application determines a type of conversation continuity in a natural language conversation comprising first and second queries. The interactive media guidance application determines a first token in the first query and a second token in the second query. The interactive media guidance application identifies entity data for the first and second tokens. The interactive media guidance application retrieves, from a knowledge graph, graph connections between the entity data for the first and second tokens. The interactive media guidance application applies this data as inputs to an artificial neural network. The interactive media guidance application determines an output that indicates the type of conversation continuity between the first and second queries.",Systems and methods for determining context switching in conversation
"Systems and methods are disclosed for determining personal characteristics from images by generating a baseline gender model and an age estimation model using one or more convolutional neural networks (CNNs); capturing correspondences of faces by face tracking, and applying incremental learning to the CNNs and enforcing correspondence constraint such that CNN outputs are consistent and stable for one person.",Systems and methods for determining personal characteristics
"Systems, methods, and non-transitory computer-readable media can acquire video content for which video feature descriptors are to be determined. The video content can be processed based at least in part on a convolutional neural network including a set of two-dimensional convolutional layers and a set of three-dimensional convolutional layers. One or more outputs can be generated from the convolutional neural network. A plurality of video feature descriptors for the video content can be determined based at least in part on the one or more outputs from the convolutional neural network.",Systems and methods for determining video feature descriptors based on convolutional neural networks
"Systems, methods, and non-transitory computer-readable media can acquire video content for which video feature descriptors are to be determined. The video content can be processed based at least in part on a convolutional neural network including a set of two-dimensional convolutional layers and a set of three-dimensional convolutional layers. One or more outputs can be generated from the convolutional neural network. A plurality of video feature descriptors for the video content can be determined based at least in part on the one or more outputs from the convolutional neural network.",Systems and methods for determining video feature descriptors based on convolutional neural networks
"The present invention provides systems and methods for dynamic detection and prevention of electronic fraud and network intrusion using an integrated set of intelligent technologies. The intelligent technologies include neural networks, multi-agents, data mining, case-based reasoning, rule-based reasoning, fuzzy logic, constraint programming, and genetic algorithms. The systems and methods of the present invention involve a fraud detection and prevention model that successfully detects and prevents electronic fraud and network intrusion in real-time. The model is not sensitive to known or unknown different types of fraud or network intrusion attacks, and can be used to detect and prevent fraud and network intrusion across multiple networks and industries.",Systems and methods for dynamic detection and prevention of electronic fraud
"The present invention provides systems and methods for dynamic detection and prevention of electronic fraud and network intrusion using an integrated set of intelligent technologies. The intelligent technologies include neural networks, multi-agents, data mining, case-based reasoning, rule-based reasoning, fuzzy logic, constraint programming, and genetic algorithms. The systems and methods of the present invention involve a fraud detection and prevention model that successfully detects and prevents electronic fraud and network intrusion in real-time. The model is not sensitive to known or unknown different types of fraud or network intrusion attacks, and can be used to detect and prevent fraud and network intrusion across multiple networks and industries.",Systems and methods for dynamic detection and prevention of electronic fraud
Provided is a method for training a neural network to detect features in a retinal image. The method may include the steps of: combining and randomizing feature images into a Training data set; combining and randomizing the feature images into a testing dataset; training a plurality of neural networks having different architectures using a subset of the training dataset while testing on a subset of the testing dataset; identifying the best neural network based on each of the plurality of neural networks performance on the testing data set; inputting images to the best neural network and identifying a limited number of false positives and false negative and adding the false positives and false negatives to the training dataset and testing dataset; and repeating the foregoing steps until an objective performance threshold is reached.,Systems and methods for feature detection in retinal images
"A method for generating data explanations in a recursive cortical network includes receiving a set of evidence data at child feature nodes of a first layer of the recursive cortical network, setting a transformation configuration that directs messaging of evidence data and transformed data between layers of the network, performing a series of transformations on the evidence data according to the transformation configuration, the series including at least one forward transformation and at least one reverse transformation, and outputting the transformed evidence data.",Systems and methods for generating data explanations for neural networks and related systems
"Systems, methods, and non-transitory computer-readable media can receive a first image including a representation of a first user. A second image including a representation of a second user can be received. A first set of poselets associated with the first user can be detected in the first image. A second set of poselets associated with the second user can be detected in the second image. The first image including the first set of poselets can be inputted into a first instance of a neural network to generate a first multi-dimensional vector. The second image including the second set of poselets can be inputted into a second instance of the neural network to generate a second multi-dimensional vector. A first distance metric between the first multi-dimensional vector and the second multi-dimensional vector can be determined.",Systems and methods for identifying users in media content based on poselets and neural networks
"Systems, methods, and non-transitory computer-readable media can receive a first image including a representation of a first user. A second image including a representation of a second user can be received. A first set of poselets associated with the first user can be detected in the first image. A second set of poselets associated with the second user can be detected in the second image. The first image including the first set of poselets can be inputted into a first instance of a neural network to generate a first multi-dimensional vector. The second image including the second set of poselets can be inputted into a second instance of the neural network to generate a second multi-dimensional vector. A first distance metric between the first multi-dimensional vector and the second multi-dimensional vector can be determined.",Systems and methods for identifying users in media content based on poselets and neural networks
"The present disclosure relates to systems and methods for parsing unstructured data with neural networks. In one implementation, a system for parsing unstructured data may include at least one processor and at least one non-transitory memory storing instructions that, when executed by the at least one processor, cause the system to: receive unstructured data; apply a classifier to the unstructured data to identify a type of the unstructured data; based on the identification, select a corresponding neural network; apply the selected neural network to the unstructured data to obtain structured data; and output the structured data.",Systems and methods for parsing log files using classification and plurality of neural networks
"Systems, methods, and non-transitory computer-readable media can obtain a set of video frames at a first resolution. Process the set of video frames using a convolutional neural network to output one or more signals, the convolutional neural network including (i) a set of two-dimensional convolutional layers and (ii) a set of three-dimensional convolutional layers, wherein the processing causes the set of video frames to be reduced to a second resolution. Process the one or more signals using a set of three-dimensional de-convolutional layers of the convolutional neural network. Obtain one or more outputs corresponding to the set of video frames from the convolutional neural network.",Systems and methods for processing content using convolutional neural networks
"Systems and methods for providing convolutional neural network based image synthesis using localized loss functions is disclosed. A first image including desired content and a second image including a desired style are received. The images are analyzed to determine a local loss function. The first and second images are merged using the local loss function to generate an image that includes the desired content presented in the desired style. Similar processes can also be utilized to generate image hybrids and to perform on-model texture synthesis. In a number of embodiments, Condensed Feature Extraction Networks are also generated using a convolutional neural network previously trained to perform image classification, where the Condensed Feature Extraction Networks approximates intermediate neural activations of the convolutional neural network utilized during training.","Systems and methods for providing convolutional neural network based image synthesis using stable and controllable parametric models, a multiscale synthesis framework and novel network architectures"
"Systems and methods for providing convolutional neural network based image synthesis using localized loss functions is disclosed. A first image including desired content and a second image including a desired style are received. The images are analyzed to determine a local loss function. The first and second images are merged using the local loss function to generate an image that includes the desired content presented in the desired style. Similar processes can also be utilized to generate image hybrids and to perform on-model texture synthesis. In a number of embodiments, Condensed Feature Extraction Networks are also generated using a convolutional neural network previously trained to perform image classification, where the Condensed Feature Extraction Networks approximates intermediate neural activations of the convolutional neural network utilized during training.","Systems and methods for providing convolutional neural network based image synthesis using stable and controllable parametric models, a multiscale synthesis framework and novel network architectures"
"Various embodiments of the invention are neural network adaptive control systems and methods configured to concurrently consider both recorded and current data, so that persistent excitation is not required. A neural network adaptive control system of the present invention can specifically select and record data that has as many linearly independent elements as the dimension of the basis of the uncertainty. Using this recorded data along with current data, the neural network adaptive control system can guarantee global exponential parameter convergence in adaptive parameter estimation problems. Other embodiments of the neural network adaptive control system are also disclosed.",Systems and methods for training neural networks based on concurrent use of current and recorded data
"The present invention involves methods and systems for treatment of brain disorders using neuromodulation of brain networks. Treatment of one or more brain networks associated with a brain disorder is realized with a consideration of network dynamics and coupling effects such as indirect stimulation of non-target regions. A brain modulation system (BMS) increases, decreases, or otherwise modulates network regional activity in a differential manner. Therapy may aim to maintain electrical or chemical (relative) characteristics within a specified range. Therapy is initiated/adjusted using network functional imaging data including the use of brain network modeling. Linking rules may guide in the setting and subsequent adjusting of the therapy related to regions of brain network. Novel techniques are described for deterring the emergence of neural adaptation and of unintentional/indirect modulation arising from connectivity between network structures.",Systems and methods for treating disorders of the central nervous system by modulation of brain networks
"Described herein are systems and methods that exploit hierarchical Recurrent Neural Networks (RNNs) to tackle the video captioning problem; that is, generating one or multiple sentences to describe a realistic video. Embodiments of the hierarchical framework comprise a sentence generator and a paragraph generator. In embodiments, the sentence generator produces one simple short sentence that describes a specific short video interval. In embodiments, it exploits both temporal- and spatial-attention mechanisms to selectively focus on visual elements during generation. In embodiments, the paragraph generator captures the inter-sentence dependency by taking as input the sentential embedding produced by the sentence generator, combining it with the paragraph history, and outputting the new initial state for the sentence generator.",Systems and methods for video paragraph captioning using hierarchical recurrent neural networks
"Systems, methods, and computer program products are provided to provide noise reduction for an input signal using a neural network. A feed-forward set of neuron groups is provided to enhance neuron activity within a particular frequency band based on prior reception of activity within that frequency band, and also to attenuate surrounding frequency bands. A surround-inhibition set of neuron groups further attenuates activity surrounding the stimulated frequency band.",Systems and methods using neural networks to reduce noise in audio signals
"Stimulus-response patterns are analyzed using deduction protocols applied through AI systems such as expert systems and neural networks. Generating an output signal matrix database involves: (i) constructing a stimulated physical matrix; (ii) detecting a physical signal at each unit of the physical matrix; (iii) transducing each physical signal to generate an electrical output signal; (iv) storing each output signal in an output signal matrix data structure; and (v) repeating steps (i)-(iv) to iteratively store output signal matrix data structures for a plurality of stimuli to form an output signal matrix database. Individual output signal matrices are compared to such output signal matrix databases according for qualitative analysis. The stimulated physical matrices comprise an ordered array of units, each confining (1) either a different responder of a living thing or a probe corresponding to such a different responder and, (2) an identifier for the responder or probe. The living thing is provided a stimulus capable of repressing the responders of a plurality of the units and the identifier provides a physical signal corresponding to the repression of such different responder.",Systems for generating and analyzing stimulus-response output signal matrices
"Stimulus-response patterns are analyzed using deduction protocols applied through AI systems such as expert systems and neural networks. Generating an output signal matrix database involves: (i) constructing a stimulated physical matrix; (ii) detecting a physical signal at each unit of the physical matrix; (iii) transducing each physical signal to generate an electrical output signal; (iv) storing each output signal in an output signal matrix data structure; and (v) repeating steps (i)-(iv) to iteratively store output signal matrix data structures for a plurality of stimuli to form an output signal matrix database. Individual output signal matrices are compared to such output signal matrix databases according for qualitative analysis. The stimulated physical matrices comprise an ordered array of units, each confining (1) either a different responder of a living thing or a probe corresponding to such a different responder and, (2) an identifier for the responder or probe. The living thing is provided a stimulus capable of repressing the responders of a plurality of the units and the identifier provides a physical signal corresponding to the repression of such different responder.",Systems for generating and analyzing stimulus-response output signal matrices
"Stimulus-response patterns are analyzed using deduction protocols applied through AI systems such as expert systems and neural networks. Generating an output signal matrix database involves: (i) constructing a stimulated physical matrix; (ii) detecting a physical signal at each unit of the physical matrix; (iii) transducing each physical signal to generate an electrical output signal; (iv) storing each output signal in an output signal matrix data structure; and (v) repeating steps (i)-(iv) to iteratively store output signal matrix data structures for a plurality of stimuli to form an output signal matrix database. Individual output signal matrices are compared to such output signal matrix databases according for qualitative analysis. The stimulated physical matrices comprise an ordered array of units, each confining (1) either a different responder of a living thing or a probe corresponding to such a different responder and, (2) an identifier for the responder or probe. The living thing is provided a stimulus capable of repressing the responders of a plurality of the units and the identifier provides a physical signal corresponding to the repression of such different responder.",Systems for generating and analyzing stimulus-response output signal matrices
"Disclosed are systems, methods, circuits and associated computer executable code for deep learning based natural language understanding, wherein training of one or more neural networks, includes: producing character strings inputs noise on a per-character basis, and introducing the produced noise into machine training character strings inputs fed to a word tokenization and spelling correction language-model, to generate spell corrected word sets outputs; feeding machine training word sets inputs, including one or more right examples of correctly semantically-tagged word sets, to a word semantics derivation model, to generate semantically tagged sentences outputs. Upon models reaching a training steady state, the word tokenization and spelling correction language-model is fed with input character strings representing real linguistic user inputs, generating word sets outputs that are fed as inputs to the word semantics derivation model for generating semantically tagged sentences outputs.",Systems methods circuits and associated computer executable code for deep learning based natural language understanding
"Described herein is a neural network-based vector control method for the induction motor. The disclosure includes an approach to implement optimal vector control for an induction motor by using an NN; a NN controller to substitute two decoupled proportional-integral (PI) controllers in current loop; and, a mechanism to train the NN controller by using a Levenberg-Marquardt (LM)+forward accumulation through time (FATT) algorithm.","Systems, methods and devices for vector control of induction machines using artificial neural networks"
"An example method for controlling an AC electrical machine can include providing a PWM converter operably connected between an electrical power source and the AC electrical machine and providing a neural network vector control system operably connected to the PWM converter. The control system can include a current-loop neural network configured to receive a plurality of inputs. The current-loop neural network can be configured to optimize the compensating dq-control voltage. The inputs can be d- and q-axis currents, d- and q-axis error signals, predicted d- and q-axis current signals, and a feedback compensating dq-control voltage. The d- and q-axis error signals can be a difference between the d- and q-axis currents and reference d- and q-axis currents, respectively. The method can further include outputting a compensating dq-control voltage from the current-loop neural network and controlling the PWM converter using the compensating dq-control voltage.","Systems, methods and devices for vector control of permanent magnet synchronous machines using artificial neural networks"
"Apparatus and methods for high-level neuromorphic network description (HLND) using tags. The framework may be used to define nodes types, define node-to-node connection types, instantiate node instances for different node types, and/or generate instances of connection types between these nodes. The HLND format may be used to define nodes types, define node-to-node connection types, instantiate node instances for different node types, dynamically identify and/or select network subsets using tags, and/or generate instances of one or more connections between these nodes using such subsets. To facilitate the HLND operation and disambiguation, individual elements of the network (e.g., nodes, extensions, connections, I/O ports) may be assigned at least one unique tag. The tags may be used to identify and/or refer to respective network elements. The HLND kernel may comprises an interface to Elementary Network Description.",Tag-based apparatus and methods for neural networks
"A simulation application receives simulation parameters associated with a simulation to be generated. The simulation parameters include geometry associated with the simulation and corresponding boundary conditions. The simulation engine processes the simulation parameters and then, using a neural network, generates a solution estimate. Based on the estimated solution, the simulation engine then executes a finite element analysis solver using the solution estimate as a starting point. The FEA solver iterates until a converged solution is reached. The converged solution is then provided to the end-user.",Techniques for warm starting finite element analyses with deep neural networks
"A system for analyzing images of objects such as vehicles. According to certain aspects, the system includes a user interface device configured to capture a set of images depicting a target vehicle, and transfer the set of images to a server that stores a set of base image models. The server analyzes the set of images using a base image model corresponding to the target vehicle, a set of correlational filters, and a set of convolutional neural networks (CNNs) to determine a set of changes to the target vehicle as depicted in the set of images. The server further transmits, to the user interface device, information indicative of the set of changes for a user to view or otherwise access.","Technology for capturing, transmitting, and analyzing images of objects"
"A sequence generator employing a neural network having its output coupled to at least one plurality of delay elements. The delayed outputs are fed back to an input interconnection network, wherein they contribute to the next state transition through an appropriate combination of interconnections.",Temporal sequences with neural networks
"An apparatus, article and method containing an artificial neural network that, after training, produces new trainable nodes such that input data representative of a first event and input data representative of a second event both activate a subset of the new trainable nodes. The artificial neural network can generate an output that is influenced by the input data of both events. In various embodiments, the new trainable nodes are sequentially produced and show decreasing trainability over time such that, at a particular point in time, newer produced nodes are more trainable than earlier produced nodes. The artificial neural network can be included in various embodiments of methods, apparatus and articles for use in predicting or profiling events.",Temporally dynamic artificial neural networks
"In certain aspects, the disclosure provides soluble heteromeric polypeptide complexes comprising an extracellular domain of a type I serine/threonine kinase receptor of the TGF-beta family and an extracellular domain of a type II serine/threonine kinase receptor of the TGF-beta family. In some embodiments, the disclosure provides soluble polypeptide complexes comprising an extracellular domain of a type II receptor selected from: ActRIIA, ActRIIB, TGFBRII, BMPRII, and MISRII. In some embodiments, the disclosure provides soluble polypeptide complexes comprising an extracellular domain of a type I receptor selected from: ALK1, ALK2, ALK3, ALK4, ALK5, ALK6, and ALK7. Optionally the soluble complex is a heterodimer. In certain aspects, such soluble polypeptide complexes may be used to regulate (promote or inhibit) growth of tissues or cells including, for example, muscle, bone, cartilage, fat, neural tissue, tumors, cancerous cells, and/or cells of hematopoietic lineages, including red blood cells. In certain aspects, such soluble polypeptide complexes are can be used to improve muscle formation, bone formation, hematopoiesis, metabolic parameters, and disorders associated with these tissues, cellular networks, and endocrine systems.",TGF-beta superfamily type I and type II receptor heteromultimers and uses thereof
"A three-dimensional convolutional neural network may include a preliminary layer group, one or more intermediate layer groups, a final layer group, and/or other layers/layer groups. The preliminary layer group may include an input layer, a preliminary three-dimensional padding layer, a preliminary three-dimensional convolution layer, a preliminary activation layer, a preliminary normalization layer, and a preliminary downsampling layer. One or more intermediate layer groups may include an intermediate three-dimensional squeeze layer, a first intermediate normalization layer, an intermediate three-dimensional padding layer, a first intermediate three-dimensional expand layer, a second intermediate three-dimensional expand layer, an intermediate concatenation layer, a second intermediate normalization layer, an intermediate activation layer, and an intermediate combination layer. The final layer group may include a final dropout layer, a final three-dimensional convolution layer, a final activation layer, a final normalization layer, a final three-dimensional downsampling layer, and a final flatten layer.",Three-dimensional convolutional neural networks for video highlight detection
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing word sequences using neural networks. One of the methods includes receiving a first sequence of words arranged according to a first order; and for each word in the first sequence, beginning with a first word in the first order: determining a topic vector that is associated with the word; generating a combined input from the word and the topic vector, and processing the combined input through one or more sequence modeling layers to generate a sequence modeling output for the word; and processing one or more of the sequence modeling outputs through an output layer to generate a neural network output for the first sequence of words.",Topic-based sequence modeling neural networks
"A trainable, state-sampled, network controller (TSSNC) or state-sampled controller (SSC) requires little information regarding a plant (as with neural networks), but can use what information is available (as in classical controllers), and provides a linear network (as for CMAC) improving calculation speeds. A form of a governing differential equation characterizing a plant may include parameters and their derivatives of various orders as variables combined in linear and nonlinear terms. Classical control theory, and a method such as a Fourier transform of governing equations, may provide 8a form of a control law, linear in certain weights or coefficients. Knowledge of coefficients is not required for either the form of the governing equations or the form of the control law. An optimization method may be used to train the SSC, defining a table of weights (contributions to coefficients) to be used in the matrix equation representing the control law the solution yielding a control output to the plant. Sampling plant outputs, during training, may be done at a selected spatial frequency in state space (each dimension a variable from the control law). Sampling is used to provide ideal interpolation of the weights over the entire range of interest. Minimum memory is used with maximum accuracy of interpolation, and any control/output value may be calculated as needed in real time by a minimal processor.","Trainable, state-sampled, network controller"
"A speech signal is subjected imperfect to vocal tract analysis model and the output therefrom is analyzed by a neural network. The output from the neural network is compared with the parameters stored in the network definition function, to derive measurement of the quality of the speech signal supplied to the source. The network definition function is determined by applying to the trainable processing apparatus a distortion perception measure indicative of the extent to which a distortion would be perceptible to a human listener.",Trained artificial neural networks using an imperfect vocal tract model for assessment of speech signal quality
A neural network is trained using a training neural network having the same topology as the original network but having a differential network output and accepting also differential network inputs. This new training method enables deeper neural networks to be successfully trained by avoiding a problem occuring in conventional training methods in which errors vanish as they are propagated in the reverse direction through deep networks. An acceleration in convergence rate is achieved by adjusting the error used in training to compensate for the linkage between multiple training data points.,Training a neural network using differential input
"Systems, methods, and devices for classifying or detecting mold samples or training computer models (such as neural networks), are disclosed. A method includes obtaining a microscopy image of a mold sample. The method includes determining a classification of the mold sample based on non-image data corresponding to the mold sample. The method further includes training a computer model based on the microscopy image and a label indicating the classification.",Training and machine learning classification of mold in digital microscopy images
"A processing unit can acquire datasets from respective data sources, each having a respective unique data domain. The processing unit can determine values of a plurality of features based on the plurality of datasets. The processing unit can modify input-specific parameters or history parameters of a computational model based on the values of the features. In some examples, the processing unit can determine an estimated value of a target feature based at least in part on the modified computational model and values of one or more reference features. In some examples, the computational model can include neural networks for several input sets. An output layer of at least one of the neural networks can be connected to the respective hidden layer(s) of one or more other(s) of the neural networks. In some examples, the neural networks can be operated to provide transformed feature value(s) for respective times.",Training and operation of computational models
"A convolutional neural network is implemented on a graphics processing unit. The network is then trained through a series of forward and backward passes, with convolutional kernels and bias matrices modified on each backward pass according to a gradient of an error function. The implementation takes advantage of parallel processing capabilities of pixel shader units on a GPU, and utilizes a set of start-to-finish formulas to program the computations on the pixel shaders. Input and output to the program is done through textures, and a multi-pass summation process is used when sums are needed across pixel shader unit registers.",Training convolutional neural networks on graphics processing units
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a deep neural network. One of the methods includes generating a plurality of feature vectors that each model a different portion of an audio waveform, generating a first posterior probability vector for a first feature vector using a first neural network, determining whether one of the scores in the first posterior probability vector satisfies a first threshold value, generating a second posterior probability vector for each subsequent feature vector using a second neural network, wherein the second neural network is trained to identify the same key words and key phrases and includes more inner layer nodes than the first neural network, and determining whether one of the scores in the second posterior probability vector satisfies a second threshold value.",Training multiple neural networks with different accuracy
"A method of training an artificial neural network uses a computer configured as a plurality of interconnected neural units arranged in a layered network including an input layer having a network input, and an output layer having a network output. A neural unit has a first subunit and a second subunit. The first subunit having one or more first inputs, and a corresponding first set of variables for operating upon the first inputs to provide a first output. The first set of variables can change in response to feedback representing differences between desired network outputs for selected network inputs and actual network outputs. The second subunit has a plurality of second inputs, and a corresponding second set of variables for operating upon said second inputs to provide a second output. The second set of variables can change in response to differences between desired network outputs for selected network inputs and actual network outputs. The computer provides an activating variable representing the difference between current second output and previous second outputs. A series of examples of data is provided as network input to said network. The activating variable is added to the feedback to accelerate the change of said first set of variables. The actual resulting network outputs are compared to desired outputs corresponding to the examples. The examples are iterated until the network outputs converge to a solution.",Training neural networks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network. One of the methods includes obtaining partitioned training data for the neural network, wherein the partitioned training data comprises a plurality of training items each of which is assigned to a respective one of a plurality of partitions, wherein each partition is associated with a respective difficulty level; and training the neural network on each of the partitions in a sequence from a partition associated with an easiest difficulty level to a partition associated with a hardest difficulty level, wherein, for each of the partitions, training the neural network comprises: training the neural network on a sequence of training items that includes training items selected from the training items in the partition interspersed with training items selected from the training items in all of the partitions.",Training neural networks on partitioned training data
"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a neural network used to select actions performed by a reinforcement learning agent interacting with an environment. In one aspect, a method includes maintaining a replay memory, where the replay memory stores pieces of experience data generated as a result of the reinforcement learning agent interacting with the environment. Each piece of experience data is associated with a respective expected learning progress measure that is a measure of an expected amount of progress made in the training of the neural network if the neural network is trained on the piece of experience data. The method further includes selecting a piece of experience data from the replay memory by prioritizing for selection pieces of experience data having relatively higher expected learning progress measures and training the neural network on the selected piece of experience data.",Training neural networks using a prioritized experience memory
"This document generally describes a neural network training system, including one or more computers, that trains a recurrent neural network (RNN) to receive an input, e.g., an input sequence, and to generate a sequence of outputs from the input sequence. In some implementations, training can include, for each position after an initial position in a training target sequence, selecting a preceding output of the RNN to provide as input to the RNN at the position, including determining whether to select as the preceding output (i) a true output in a preceding position in the output order or (ii) a value derived from an output of the RNN for the preceding position in an output order generated in accordance with current values of the parameters of the recurrent neural network.",Training recurrent neural networks to generate sequences
""" In order for neural network technology to make useful determinations of the identity of letters and numbers that are processed in real time at a postal service sorting center, it is necessary for the neural network to """"learn"""" to recognize accurately the many shapes and sizes in which each letter or number are formed on the address surface of the envelope by postal service users. It has been realized that accuracy in the recognition of many letters and numbers is not appreciably sacrificed if the neural network is instructed to identify those characteristics of each letter or number which are in the category """"invariant."""" Then, rather than requiring the neural network to recognize all gradations of shape, location, size, etc. of the identified invariant characteristic, a generalized and bounded description of the invariant segments is used which requires far less inputting of sample data and less processing of information relating to an unknown letter or number. """,Training system for neural networks
A means and method for training an electronic network of analog cells. A generic universal programmer interface (GUPI) is provided to enable connection of an adaptor to a host computer via a personal computer personal programmer (PCPP) for training an ETANN chip. An opening in the top of the GUPI provides for installation of the adaptor. The adaptor of the present invention plugs into the GUPI module to provide for connecting either an ETANN chip or a Confidence Test Module (CTM) for access by the user via the host computer. A target socket located on the top surface of the adaptor allows the user to physically connect the ETANN chip or the CTM to adapter of the present invention. The adaptor provides the resources needed for training an ETANN in several modes including: digital to analog conversion for driving the ETANN's analog input pins; a single analog to digital converter with an 80 channel analog multiplexer for measuring the ETANN's analog outputs; neuron perturbation circuitry; synapse current measurement circuitry; neuron sum measurement circuitry; V.sub.PP management circuitry; a binary searching synapse weight measurement circuit; isolation switches and the logic necessary to connect all these resources to the ETANN and the GUPI base. The present invention also includes host computer software necessary to control the operation of the adapter.,Training system for neural networks and the like
"Systems and methods are provided for training neural networks and other systems with heterogeneous data. Heterogeneous data are partitioned into a number of data categories. A user or system may then assign an importance indication to each category as well as an order value which would affect training times and their distribution (higher order favoring larger categories and longer training times). Using those as input parameters, the ordered training generates a distribution of training iterations (across data categories) and a single training data stream so that the distribution of data samples in the stream is identical to the distribution of training iterations. Finally, the data steam is used to train a recognition system (e.g., an electronic ink recognition system).",Training with heterogeneous data
"Methods and systems for transforming image data and training or testing neural networks. Images from textbooks can contain valuable related text. Transforming the related text into discrete determinate labels can be performed using natural language processing. Once transformed, the images and the labels can be advantageously used together to train neural networks.",Transformation of textbook information
"A rule-based expert system is generated from a neural network. The neural network is trained in such a way as to avoid redundancy and to select input weights to the various processing elements in such a way as to nullify the input weights which have smaller absolute values. The neural network is translated into a set of rules by a heuristic search technique. Additionally, the translation distinguishes between positive and negative attributes for efficiency and can adequately explore rule size exponential with a given parameter. Both explicit and implicit knowledge of adapted neural networks are decoded and represented as if--then rules.",Translation of a neural network into a rule-based expert system
"A rule-based expert system is generated from a neural network. The neural network is trained in such a way as to avoid redundancy and to select input weights to the various processing elements in such a way as to nullify the input weights which have smaller absolute values. The neural network is translated into a set of rules by a heuristic search technique. Additionally, the translation distinguishes between positive and negative attributes for efficiency and can adequately explore rule size exponential with a given parameter. Both explicit and implicit knowledge of adapted neural networks are decoded and represented as if--then rules.",Translation of a neural network into a rule-based expert system
"Systems and processes for performing unit-selection text-to-speech synthesis are provided. In one example process, a sequence of target units can represent a spoken pronunciation of text. A set of predicted acoustic model parameters of a second target unit can be determined using a set of acoustic features of a first candidate speech segment of a first target unit and a set of linguistic features of the second target unit. A likelihood score of the second candidate speech segment with respect to the first candidate speech segment can be determined using the set of predicted acoustic model parameters of the second target unit and a set of acoustic features of the second candidate speech segment of the second target unit. The second candidate speech segment can be selected for speech synthesis based on the determined likelihood score. Speech corresponding to the received text can be generated using the selected second candidate speech segment.",Unit-selection text-to-speech synthesis using concatenation-sensitive neural networks
"Method of programming Ovonic memory multistate-digital multibit memory elements, and use thereof for neural networks and data storage. The device is programmed by applying an energy pulse which is insufficient to switch the memory element from said high resistance state to said low resistance state, but sufficient to modify said memory material such that accumulation of additional energy pulses causes the memory element to switch from said high resistance state to said low resistance state.",Universal memory element and method of programming same
"A universal memory element having multi-level, non-detectable states and methods and apparatus for programming the same, and methods and applications embodying the same in neural networks, artificial intelligence and data storage systems. The universal memory element is programmed by applying one or more sub-interval energy pulses insufficient to switch the memory element from said high resistance state to said low resistance state, but sufficient to modify the memory material such that accumulation of additional energy pulses causes the memory element to switch from said high resistance state to said low resistance state.","Universal memory element with systems employing same and apparatus and method for reading, writing and programming same"
"Adaptive control for a wide variety of complex processes is provided by an ANN controller with input and hidden layers having a plurality of neurons, and an output layer with a single neuron. The inputs to the ANN are a time sequence of error values, and the neuron paths are weighted as a function of these error values and the present-time process output. The present-time error value may be added to the output layer of the ANN to provide faster response to sudden input changes. The controller of this invention can efficiently handle processes with nonlinear, time-varying, coupled and variable-structure behaviors as well as process parameter and/or structure uncertainties. Large steady-state gains in the process can be compensated by attenuating the ANN block output.",Universal process control using artificial neural networks
"During training mode, first input data is provided to a first neural network to generate first output data indicating that the first input data is classified in a first cluster. The first input data includes at least one of a continuous feature or a categorical feature. Second input data is generated and provided to at least one second neural network to generate second output data. The at least one second neural network corresponds to a variational autoencoder. An aggregate loss corresponding to the second output data is determined, including at least one of evaluating a first loss function for the continuous feature or evaluating a second loss function for the categorical feature. Based on the aggregate loss, at least one parameter of at least one neural network is adjusted. During use mode, the neural networks are used to determine cluster identifications and anomaly likelihoods for received data samples.",Unsupervised model building for clustering and anomaly detection
"An unsupervised back propagation method for training neural networks. For a set of inputs, target outputs are assigned l's and O's randomly or arbitrarily for a small number of outputs. The learning process is initiated and the convergence of outputs towards targets is monitored. At intervals, the learning is paused, and the values for those targets for the outputs which are converging at a less than average rate, are changed (e.g., 0.fwdarw.1, or 1.fwdarw.0), and the learning is then resumed with the new targets. The process is continuously iterated and the outputs converge on a stable classification, thereby providing unsupervised back propagation. In a further embodiment, samples classified with the trained network may serve as the training sets for additional subdivisions to grow additional layers of a hierarchical classification tree which converges to indivisible branch tips. After training is completed, such a tree may be used to classify new unlabelled samples with high efficiency. In yet another embodiment, the unsupervised back propagation method of the present invention may be adapted to classify fuzzy sets.",Unsupervised neural network classification with back propagation
"Bottleneck link speed, or the transmission speed of the slowest link within a path between two nodes, is determining by transmitting a sequence of ICMP ECHO data packets from the source node to the target node at a selected interval and measuring the return data packet intervals. Rather than using statistical analysis methods, the return data packet interval measurements are input into an adaptive resonance theory neural network trained with the expected interval for every known, existing network transmission speed. The neural network will then classify the return data packet interval measurements, indicating the bottleneck link speed. Since most of the computation&#8212;that required to train the neural network&#8212;may be performed before the data packet interval measurements are made rather than after, the bottleneck link speed may be determined from the return data packet interval measurements significantly faster and using less computational resources than with statistical analysis techniques. Moreover, fewer measurements are required to determine bottleneck link speed to the same degree of accuracy.",Use of adaptive resonance theory (ART) neural networks to compute bottleneck link speed in heterogeneous networking environments
"A system for generating annotations of a document, including a plurality of neurons connected as a neural network, the neurons being associated with words, sentences and documents. An activity regulator regulates a minimum and/or maximum number of neurons of the neural network that are excited at any given time. The neurons are displayed to a user and identify the neurons that correspond to sentences containing a predetermined percentage of document meaning. The annotations can be also based on a context of the user's search query. The query can include keywords, documents considered relevant by the user, or both. Positions of the neurons relative to each other can be changed on a display device, based on input from the user, with the change in position of one neuron changing the resulting annotations. The input from the user can also include changing a relevance of neurons relative to each other, or indicating relevance or irrelevance of a document or sentence.",Use of neural networks for annotating search results
"A system for identifying keywords in search results includes a plurality of neurons connected as a neural network, the neurons being associated with words and documents. An activity regulator regulates a minimum and/or maximum number of neurons of the neural network that are excited at any given time. Means for displaying the neurons to a user and identifying the neurons that correspond to keywords can be provided. Means for changing positions of the neurons relative to each other based on input from the user can be provided. The change in position of one neuron changes the keywords. The input from the user can be dragging a neuron on a display device, or changing a relevance of two neurons relative to each other. The neural network can be excited by a query that comprises words selected by a user. The neural network can be a bidirectional network. The user can inhibit neurons of the neural network by indicating irrelevance of a document. The neural network can be excited by a query that identifies a document considered relevant by a user. The neural network can also include neurons that represent groups of words. The neural network can be excited by a query that identifies a plurality of documents considered relevant by a user, and can output keywords associated with the plurality of documents.",Use of neural networks for keyword generation
"A system for identifying keywords in search results includes a plurality of neurons connected as a neural network, the neurons being associated with words and documents. An activity regulator regulates a minimum and/or maximum number of neurons of the neural network that are excited at any given time. Means for displaying the neurons to a user and identifying the neurons that correspond to keywords can be provided. Means for changing positions of the neurons relative to each other based on input from the user can be provided. The change in position of one neuron changes the keywords. The input from the user can be dragging a neuron on a display device, or changing a relevance of two neurons relative to each other. The neural network can be excited by a query that comprises words selected by a user. The neural network can be a bidirectional network. The user can inhibit neurons of the neural network by indicating irrelevance of a document. The neural network can be excited by a query that identifies a document considered relevant by a user. The neural network can also include neurons that represent groups of words. The neural network can be excited by a query that identifies a plurality of documents considered relevant by a user, and can output keywords associated with the plurality of documents.",Use of neural networks for keyword generation
"A method, computer program, computer and system for training a neural network that receives a plurality of input digital images and, for each specific input digital image, outputs data for determining a relevance level of groups of pixels in the specific input digital image.",Using image analysis algorithms for providing training data to neural networks
"In cancer-cell screening, a patient's cells are classified by a convolutional neural network (CNN) to identify abnormal cells. In one approach, a mask having a center more transparent than the mask's periphery is used to mask an input image containing a cell of interest to yield a masked image. Since the cell is usually located around an image center, and since the image often contains irrelevant objects, such as normal cells and micro-organisms, around an image periphery, interference due to the irrelevant objects in training the CNN and in classification is diminished by using the masked image rather than the original one. In another approach, masking is applied to feature maps before classification. In the CNN, this masking is accomplished by convolving each feature map with a convolutional kernel to produce an intermediate feature map followed by chopping off a peripheral region thereof to yield a downsized feature map.",Using masks to improve classification performance of convolutional neural networks with applications to cancer-cell screening
"A data mining system and method are provided. The system includes at least one client and a service broker configured to include an interface to receive a consultation request from the client. The service broker forwards the consultation request to a Neugent to invoke a consultation of the Neugent, and forwards to the client a result object returned by the Neugent.",Using neural networks for data mining
"A prediction method that estimates the real-time position of a mobile device based on previously observed data is provided. The present invention can be used in real-time navigation, including providing real-time alerts of an upcoming destination and notifications of emergency events in close geographic proximity. The prediction method utilizes neural networks and/or functions generated using genetic algorithms in estimating the mobile device's real-time position. The prediction method provides reliable Location-Based Services (LBS) in events where traditional positioning technologies become unreliable. It is also seamless, as the user remains unaware of any interruption in accessing the positioning technology.",Using pattern recognition in real-time LBS applications
"A system for mitigating network attacks is provided. The system includes a protected network including a plurality of devices. The system further includes one or more attack mitigation devices communicatively coupled to the protected network. The attack mitigation devices are configured and operable to employ a recurrent neural network (RNN) to obtain probability information related to a request stream. The request stream may include a plurality of at least one of: HTTP, RTSP and/or DNS messages. The attack mitigation devices are further configured to analyze the obtained probability information to detect one or more atypical requests in the request stream. The attack mitigation services are also configured and operable to perform, in response to detecting one or more atypical requests, mitigation actions on the one or more atypical requests in order to block an attack.",Using recurrent neural networks to defeat DNS denial of service attacks
"Methods, systems, and apparatus, including computer programs encoded on computer storage media for classification using neural networks. One method includes receiving audio data corresponding to an utterance. Obtaining a transcription of the utterance. Generating a representation of the audio data. Generating a representation of the transcription of the utterance. Providing (i) the representation of the audio data and (ii) the representation of the transcription of the utterance to a classifier that, based on a given representation of the audio data and a given representation of the transcription of the utterance, is trained to output an indication of whether the utterance associated with the given representation is likely directed to an automated assistance or is likely not directed to an automated assistant. Receiving, from the classifier, an indication of whether the utterance corresponding to the received audio data is likely directed to the automated assistant or is likely not directed to the automated assistant. Selectively instructing the automated assistant based at least on the indication of whether the utterance corresponding to the received audio data is likely directed to the automated assistant or is likely not directed to the automated assistant.",Utterance classifier
"A neural-simulating system for an image processing system includes a plurality of networks arranged in a plurality of layers, the output signals of ones of the layers provide input signals to the others of the layers. Each of the plurality of layers include a plurality of neurons operating in parallel on the input signals to the layers. The plurality of neurons within a layer are arrange in groups. Each of the neurons within a group operate in parallel on the input signals. Each neuron within a group of neuron operates to extract a specific feature of an area of the image being processed. Each of the neutrons derives output signals from the input signals representing the relative weight of the input signal and a gain weight associated with each of the neurons applied thereto based upon a continuously differential transfer function for each function.",Variable gain neural network image processing system
"Systems and methods for performing vector control of grid-connected power electronic converters using a neural network are described herein. Optionally, the grid-connected power electronic converters can be used in renewable and electric power system applications. In order to improve performance and stability under disturbance conditions, integrals of error signals can be introduced as inputs to the neural network. Alternatively or additionally, grid disturbance voltage can be introduced to an output of a trained neural network.",Vector control of grid-connected power electronic converter using artificial neural networks
"A vector neural network (VNN) of interconnected neurons is provided in transition mappings of potential targets wherein the threshold (energy) of a single frame does not provide adequate information (energy) to declare a target position. The VNN enhances the signal-to-noise ratio (SNR) by integrating target energy over multiple frames including the steps of postulating massive numbers of target tracks (the hypotheses), propagating these target tracks over multiple frames, and accommodating different velocity targets by pixel quantization. The VNN then defers thresholding to subsequent target stages when higher SNR's are prevalent so that the loss of target information is minimized, and the VNN can declare both target location and velocity. The VNN can further include target maneuver detection by a process of energy balancing hypotheses.",Vector neural networks
"A system for predicting and evading crash of a vehicle includes an image pick-up device mounted on the vehicle for picking up images of actual ever-changing views when the vehicle is on running to produce actual image data, a crash predicting device associated with said image pick-up device, said crash predicting device being successively supplied with the actual image data for predicting occurrence of crash between the vehicle and potentially dangerous objects on the roadway to produce an operational signal when there is possibility of crash and a safety drive ensuring device connected to said crash predicting device for actuating, in response to the operational signal, an occupant protecting mechanism which is operatively connected thereto and equipped in the vehicle. The crash predicting device includes a neural network which is previously trained with training data to predict the possibility of crash, the training data representing ever-changing views previously picked-up from said image picking-up device during driving of the vehicle for causing actual crash.",Vehicle crash predictive and evasive operation system by neural networks
"This invention is a system to identify and monitor contents and/or parts of the passenger compartment of a motor vehicle, such as an automobile or truck, by processing the signal received from the contents or parts using one or more techniques, including neural networks or other pattern recognition systems, and technologies including ultrasonic and electromagnetic radiation. The received signal may be a reflection of a transmitted signal, the reflection of some natural signal within the vehicle, or may be some signal emitted naturally by the object. Information obtained by the identification and monitoring system is then used to affect the operation of some other system in the vehicle such as the airbag, entertainment system, heating and air conditioning system, or the system to darken portions of the mirrors or windshield, among others.",Vehicle interior identification and monitoring system
"A method for determining a position of a vehicle in a lane includes receiving perception information from a first camera positioned on a first side of a vehicle and a second camera positioned on a second side of the vehicle. The method includes determining, using one or more neural networks, a position of the vehicle with respect to lane markings on the first side and the second side of the vehicle. The method further includes notifying a driver or control system of the position of the vehicle.",Vehicle lane boundary position
"A collision warning and avoidance system which comprising an integrated on-board Train Navigation Unit (3) and a GPS Interface Subsystem to locate a train. The system includes a GPS (2) location signal, at least one fixed transponder station (31) and a calibrated, rectified transponder identification subsystem for scanning the track based transponders for override of train controls in the event of a collision risk and further comprising a database of all transponders, their location and the track ID on which they are located. Data and information are computer processed and analysed in neural networks in one train to identify, rank, and evaluate collision hazards.","Vehicle navigation, collision avoidance and control system"
This disclosure relates to improved vehicle re-identification techniques. The techniques described herein utilize artificial intelligence (AI) and machine learning functions to re-identify vehicles across multiple cameras. Vehicle re-identification can be performed using an image of the vehicle that is captured from any single viewpoint. Attention maps may be generated that identify regions of the vehicle that include visual patterns that overlap between the viewpoint of the captured image and one or more additional viewpoints. The attention maps are used to generate a multi-view representation of the vehicle that provides a global view of the vehicle across multiple viewpoints. The multi-view representation of the vehicle can then be compared to previously captured image data to perform vehicle re-identification.,"Vehicle re-identification techniques using neural networks for image analysis, viewpoint-aware pattern recognition, and generation of multi- view vehicle representations"
"A vehicle includes a powertrain having an electric machine and an engine. The vehicle also includes a controller programmed to operate the powertrain according to a predicted vehicle speed profile for a predetermined route segmented according to a group of driving zone types, wherein each driving zone type is associated with a different characteristic speed profile shape and vehicle location. The controller is further programmed to update the predicted segment speed profile in response to deviation between the predicted speed profile and a measured speed profile.",Vehicle speed profile prediction using neural networks
"A speech recognition neural network system includes an encoder neural network and a decoder neural network. The encoder neural network generates an encoded sequence from an input acoustic sequence that represents an utterance. The input acoustic sequence includes a respective acoustic feature representation at each of a plurality of input time steps, the encoded sequence includes a respective encoded representation at each of a plurality of time reduced time steps, and the number of time reduced time steps is less than the number of input time steps. The encoder neural network includes a time reduction subnetwork, a convolutional LSTM subnetwork, and a network in network subnetwork. The decoder neural network receives the encoded sequence and processes the encoded sequence to generate, for each position in an output sequence order, a set of substring scores that includes a respective substring score for each substring in a set of substrings.",Very deep convolutional neural networks for end-to-end speech recognition
"Certain exemplary embodiments provide a method comprising: providing system electrical load information for an electric power system to one or more neural networks; and via the one or more neural networks, predicting a system electrical load for a predetermined immediate future period.",Very short term load prediction
"A system and method for detecting and analyzing anomalies in a machine during operation. The system and method includes at least one sensor configured to detect characteristics of the machine indicative of machine vibration, at least one other sensor configured to detect characteristics of the machine indicative of other than machine vibration, a plurality of neural networks to receive input data, at least one neural network receiving vibration data from the at least one sensor, and at least one other neural network receiving non-vibration data from the at least one other sensor, and an expert system to receive output data from the neural networks and responsively analyze machine operation for anomalies.",Vibration analysis system and method for a machine
A method of processing data within a convolutional attention recurrent neural network (RNN) includes generating a current multi-dimensional attention map. The current multi-dimensional attention map indicates areas of interest in a first frame from a sequence of spatio-temporal data. The method further includes receiving a multi-dimensional feature map. The method also includes convolving the current multi-dimensional attention map and the multi-dimensional feature map to obtain a multi-dimensional hidden state and a next multi-dimensional attention map. The method identifies a class of interest in the first frame based on the multi-dimensional hidden state and training data.,Video analysis with convolutional attention recurrent neural networks
"Methods and systems are provided for deblurring images. A neural network is trained where the training includes selecting a central training image from a sequence of blurred images. An earlier training image and a later training image are selected based on the earlier training image preceding the central training image in the sequence and the later training image following the central training image in the sequence and based on proximity of the images to the central training image in the sequence. A training output image is generated by the neural network from the central training image, the earlier training image, and the later training image. Similarity is evaluated between the training output image and a reference image. The neural network is modified based on the evaluated similarity. The trained neural network is used to generate a deblurred output image from a blurry input image.",Video deblurring using neural networks
"The architectures for a scalable neural processor (SNAP) and a Triangular Scalable Neural Array Processor (T-SNAP) are expanded to handle network simulations where the number of neurons to be modeled exceeds the number of physical neurons implemented. This virtual neural processing is described for three general virtual architectural approaches for handling the virtual neurons, one for SNAP and one for TSNAP, and a third approach applied to both SNAP and TSNAP.",Virtual neurocomputer architectures for neural networks
"A virtual vehicle sensor includes a neural network which produces a sensor output based on a linear combination of non-linear physical signals generated by conventional physical sensors. Instead of determining an output directly, the neural network determines the polynomial coefficients as functions of the physical signals indicative of other engine operating parameters. The sensor is manufactured using relatively limited data collection to calibrate a simulation model. The output of the simulation model is used for model-based mapping to generate more comprehensive maps used for training the neural network. The trained neural network is embedded in a controller and acts as the virtual sensor to monitor engine parameters which are difficult to measure or for which conventional physical sensors do not currently exist. The virtual sensor may be used to sense parameters such as in-cylinder residual mass fraction, emission levels, in-cylinder pressure rise during combustion, and exhaust gas temperature.",Virtual vehicle sensors based on neural networks trained using data generated by simulation models
"A neural classifier that allows visualization of the query, the training data and the decision regions in a single two-dimensional display, providing benefits for both the designer and the user. The visual neural classifier is formed from a set of experts and a visualization network. Visualization is accomplished by a funnel-shaped multilayer dimensionality reduction network configured to learn one or more classification tasks. If a single dimensionality reduction network does not provide sufficiently accurate classification results, a group of these dimensionality reduction networks may be arranged in a modular architecture. Among these dimensionality reduction networks, the experts receive the input data and the visualization network combines the decisions of the experts to form the final classification decision.",Visual neural classifier
Technical solutions are described for training an object-recognition neural network that identifies an object in a computer-readable image. An example method includes assigning a first neural network for determining a visual alignment model of the images for determining a normalized alignment of the object. The method further includes assigning a second neural network for determining a visual representation model of the images for recognizing the object. The method further includes determining the visual alignment model by training the first neural network and determining the visual representation model by training the second neural network independent of the first. The method further includes determining a combined object recognition model by training a combination of the first neural network and the second neural network. The method further includes recognizing the object in the image based on the combined object recognition model by passing the image through each of the neural networks.,Visual object recognition
"Convolutional neural networks can be visualized. For example, a graphical user interface (GUI) can include a matrix of symbols indicating feature-map values that represent a likelihood of a particular feature being present or absent in an input to a convolutional neural network. The GUI can also include a node-link diagram representing a feed forward neural network that forms part of the convolutional neural network. The node-link diagram can include a first row of symbols representing an input layer to the feed forward neural network, a second row of symbols representing a hidden layer of the feed forward neural network, and a third row of symbols representing an output layer of the feed forward neural network. Lines between the rows of symbols can represent connections between nodes in the input layer, the hidden layer, and the output layer of the feed forward neural network.",Visualizing convolutional neural networks
"Deep neural networks can be visualized. For example, first values for a first layer of nodes in a neural network, second values for a second layer of nodes in the neural network, and/or third values for connections between the first layer of nodes and the second layer of nodes can be received. A quilt graph can be output that includes (i) a first set of symbols having visual characteristics representative of the first values and representing the first layer of nodes along a first axis; (ii) a second set of symbols having visual characteristics representative of the second values and representing the second layer of nodes along a second axis; and/or (iii) a matrix of blocks between the first axis and the second axis having visual characteristics representative of the third values and representing the connections between the first layer of nodes and the second layer of nodes.",Visualizing deep neural networks
"A voltage-mode pulse width modulation (PWM) VLSI implementation of neural networks, comprising: a voltage-pulse converter for converting an input voltage into a neuron-state pulse; a synapse multiplier, including a multiplier cell for multiplying the neuron-state pulse by an input weight voltage and an integral and summation cell for integrating and summing up the multiplied output and producing a first output voltage; and a sigmoid circuit for converting the first output voltage into a second output voltage with the non-linear activation function of neuron.",Voltage-mode pulse width modulation VLSI implementation of neural networks
"A computing system accesses complementary image data of a biological tissue structure (BTS), which can include a human cardiovascular structure. The complementary image data is comprised of two-dimensional images which represent different views of the BTS respectively aligned with a plurality of distinct image planes. A plurality of separate convolutional neural networks (CNNs) are used to respectively process each of the plurality of two-dimensional images. Each CNN determines a probability map which is then adaptively fused into a single segmented output. A contouring operation is automatically performed to calculate at least one clinical measurement and/or create at least one 3D volume.",Volumetric quantification of cardiovascular structures from medical imaging
"The present invention relates to a system and a method for signal classification. The system comprises a sensor array for receiving a series of input signals such as acoustic signals, pixel-based image signal (such as from infrared images detectors), light signals, temperature signals, etc., a wavelet transform module for transforming the input signals so that characteristics of the signals are represented in the form of wavelet transform coefficients and an array of hybrid neural networks for classifying the signals into multiple distinct categories and generating a classification output signal. The hybrid neural networks each comprise a location neural network for processing data embedded in the frequency versus time location segment of the output of the transform module, a magnitude neural network for processing magnitude information embedded in the magnitude segment of the output of the transform module, and a classification neural network for processing the outputs from the location and magnitude neural networks. A method for processing the signal using the system of the present invention is also described.",Wavelet-based hybrid neurosystem for classifying a signal or an image represented by the signal in a data system
"A method of training a neural net includes receiving a plurality of sets of data, each set representative of a plurality of inputs to the neural net and a resulting at least one output from the neural net and calculating a plurality of network weights for the neural network based on the received plurality of sets of data. Calculating the plurality of network weights including attributing greater weight in the calculation to at least one set of the plurality of sets of data than at least one other set of the plurality of sets of data.",Weighted pattern learning for neural networks
"The input signals to the weighted summation circuitry are weighted by respective weighting factors on a digit-sliced basis. Each of the weighting factors is expressed as a respective plurality of portions of different weighting significance, the portions being R in number. The portions of the weighting factors expressed as digits that have the same weighting significance constitute a rank of values. These ranks of values are normalized by dividing each of them by its respective weighting significance. R ranks of capacitors are connected in R respective networks that sum the input signals, as weighted respectively by each of the ranks of normalized values, to get normalized respective partial summation results. To generate a final weighted summation result, means are provided to sum the respective partial summation results provided from the R respective networks, after the respective partial summation results have been weighted by their corresponding weighting significances to remove normalization. Where the weighted summation circuitry is used in a neural net layer, this final weighted summation result is supplied to a non-linear amplifier with sigmoidal transfer characteristic to obtain an axonal response to the synaptic input signals after their weighted summation.",Weighted summation circuits having different-weight ranks of capacitive structures
"Methods and systems for optimizing wellbore completion and, in particular, methods and systems for optimizing hydraulic fracturing parameters are disclosed. In some embodiments, a method of optimizing wellbore completion includes gathering wellbore data, screening and processing the gathered wellbore data, utilizing the screened and processed wellbore data to define an optimized model, and utilizing the optimized model to evaluate combinations of available wellbore completion parameters. In some instances, the optimized model is defined using artificial neural networks, genetic algorithms, and/or boosted regression trees. Further, in some embodiments the combinations of available wellbore completion parameters include hydraulic fracturing parameters, such as number of fractures, fracturing fluid type, proppant type, fracturing volume, and/or other parameters.",Wellbore completion and hydraulic fracturing optimization methods and associated systems
"Coverage-based quality-of-service (QoS) in wireless networks. A premium QoS service is provided by the network to users who qualify to receive QoS signals by moving handsets into a bounded premium service geographical coverage area. A mobile handset periodically transmits handset lat-long data to the wireless network via a control channel. The network includes data that defines the bounded geographical coverage area. The wireless network receives the handset lat-long data and maps the data to coverage area data. If the handset lat-long data maps into the coverage area data, the user handset is authorized to receive and use the premium QoS signals over a 3G network; otherwise, the user falls back to default service on a 2G network. Alternatively, the network utilizes a trained neural network to process the lat-long data to qualify the handset for premium services.",Wireless network coverage based on quality of service
"A simulation method and system partitions network traffic into background traffic and explicit traffic, wherein explicit traffic is processed in detail, and background traffic is processed at a more abstract level. The packets of explicit traffic are modeled in complete detail, so that precise timing and behavior characteristics can be determined, whereas large volumes of traffic are modeled more abstractly as background flows, and only certain aspects, such as routing through the network, are simulated. Tracer packets are used to model the background traffic and carry a number of characteristics of interest for generating simulation results. In this manner, the effect of the background traffic on the explicit traffic can be modeled at each network element. The abstract processing of background traffic is facilitated by techniques that include multi-variate table look-up, neural networks, and the like.",Wireless network hybrid simulation
"An XML-based symbolic computer language, interpreter, and corresponding execution environments are disclosed. The XML-based symbolic computer language, called OLIN (One Language Intelligent Network) enables a computer program to be written as an XML-compliant document. OLIN programs are interpreted by an interpreter by parsing the XML content to extract symbolic expressions embedded therein, and evaluating those symbolic expressions. The XML-based symbolic computer language is object-oriented and is based on inherent principles of the LISP programming language. Accordingly, code and data are treated the same. The language provides built-in structures and functions for implementing neural networks and genetic programming. OLIN programs may be executed by a single computer, or via a multiprocessing environment, including distributing processing environments and multiprocessor computers.",XML-based symbolic language and interpreter
"This disclosure relates to improved sketch-based image retrieval (SBIR) techniques. The SBIR techniques utilize an architecture comprising three interconnected neural networks to enable zero-shot image recognition and retrieval based on free-hand sketches. Zero-shot learning may be implemented to retrieve one or more images corresponding to the sketches without prior training on all categories of the sketches. The neural network architecture may do so, at least in part, by training encoder hashing functions to mitigate heterogeneity of sketches and images, and by applying semantic knowledge that is learned during a limited training phase to unknown categories.",Zero-shot sketch-based image retrieval techniques using neural networks for sketch-image recognition and retrieval
